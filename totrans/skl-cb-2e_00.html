<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Preface</h1>
                </header>
            
            <article>
                
<p class="mce-root">Starting with installing and setting up scikit-learn, this book contains highly practical recipes on common supervised and unsupervised machine learning concepts. Acquire your data for analysis; select the necessary features for your model; and implement popular techniques such as linear models, classification, regression, clustering, and more in no time at all! The book also contains recipes on evaluating and fine-tuning the performance of your model. The recipes contain both the underlying motivations and theory for trying a technique, plus all the code in detail.</p>
<div class="packt_quote">"Premature optimization is the root of all evil"</div>
<p>                                                                                                               - Donald Knuth</p>
<p class="mce-root">scikit-learn and Python allow fast prototyping, which is in a sense the opposite of Donald Knuth's premature optimization. Personally, scikit-learn has allowed me to prototype what I once thought was impossible, including large-scale facial recognition systems and stock market trading simulations. You can gain instant insights and build prototypes with scikit-learn. Data science is, by definition, scientific and has many failed hypotheses. Thankfully, with scikit-learn you can see what works (and what does not) within the next few minutes.</p>
<p class="mce-root">Additionally, Jupyter (IPython) notebooks feature a nice interface that is very welcoming to beginners and experts alike and encourages a new scientific software engineering mindset. This welcoming nature is refreshing because, in innovation, we are all beginners.</p>
<p class="mce-root">In the last chapter of this book, you can make your own estimator and Python transitions from a scripting language to more of an object-oriented language. The Python data science ecosystem has the basic components for you to make your own unique style and contribute heavily to the data science team and artificial intelligence.</p>
<p class="mce-root">In analogous fashion, algorithms work as a team in the stacker. Diverse algorithms of different styles vote to make better predictions. Some make better choices than others, but as long as the algorithms are different, the choice in the end will be the best. Stackers and blenders came to prominence in the Netflix $1 million prize competition won by the team Pragmatic Chaos.</p>
<p>Welcome to the world of scikit-learn: a very powerful, simple, and expressive machine learning library. I am truly excited to see what you come up with.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What this book covers</h1>
                </header>
            
            <article>
                
<p><a href="9a5af114-e518-47ef-ac63-edf9ae69384c.xhtml" target="_blank"><span>Chapter </span>1</a>, <em>High-Performance Machine Learning – NumPy</em>, features your first machine learning algorithm with support vector machines. We distinguish between classification (what type?) and regression (how much?). We predict an outcome on data we have not seen.</p>
<p class="mce-root"><a href="fc0168e6-2811-415a-89b6-f6290b505078.xhtml" target="_blank"><span>Chapter </span>2</a>, <em>Pre-Model Workflow and Pre-Processing</em>, exposes a realistic industrial setting with plenty of data munging and pre-processing. To do machine learning, you need good data, and this chapter tells you how to get it and get it into good form for machine learning.</p>
<p class="mce-root"><a href="1bdae9eb-0206-4caa-bec6-9064d19fbb58.xhtml" target="_blank"><span>Chapter </span>3</a>, <em>Dimensionality Reduction</em>, discusses reducing the number of features to simplify machine learning and allow better use of computational resources.</p>
<p class="mce-root"><a href="0d984ce3-5928-4f25-9260-ac10fc0e6c99.xhtml" target="_blank"><span>Chapter </span>4</a>, <em>Linear Models with scikit-learn</em>, tells the story of linear regression, the oldest predictive model, from the machine learning and artificial intelligence lenses. You deal with correlated features with ridge regression, eliminate related features with LASSO and cross-validation, or eliminate outliers with robust median-based regression.</p>
<p class="mce-root"><a href="d2473ebe-f050-4e72-bbf9-fabe5d62d441.xhtml" target="_blank"><span>Chapter </span>5</a>, <em>Linear Models – Logistic Regression</em>, examines the important healthcare datasets for cancer and diabetes with logistic regression. This model highlights both similarities and differences between regression and classification, the two types of supervised learning.</p>
<p class="mce-root"><a href="caba13f2-27d4-4fef-918d-9e30e1fd3d1c.xhtml" target="_blank"><span>Chapter </span>6</a>, <em>Building Models with Distance Metrics</em>, places points in your familiar Euclidean space of school geometry, as distance is synonymous with similarity. How close (similar) or far away are two points? Can we group them together? With Euclid's help, we can approach unsupervised learning with k-means clustering and place points in categories we do not know in advance.<br/>
<a href="14f897e6-fb0d-4c17-a253-298002d70f08.xhtml" target="_blank"/></p>
<p class="mce-root"><a href="14f897e6-fb0d-4c17-a253-298002d70f08.xhtml" target="_blank"><span>Chapter </span>7</a>, <em>Cross-Validation and Post-Model Workflow</em>, features how to select a model that works well with cross-validation: iterated training and testing of predictions. We also save computational work with the pickle module.</p>
<p class="mce-root"><a href="02d9949f-5f09-481d-b48b-e52cd4718360.xhtml" target="_blank"><span>Chapter </span>8</a>, <em>Support Vector Machines</em>, examines in detail the support vector machine, a powerful and easy-to-understand algorithm.</p>
<p class="mce-root"><a href="9fdf265d-8934-4bbb-8b3a-dd5cd2c33cc7.xhtml" target="_blank"><span>Chapter </span>9</a>, <em>Tree Algorithms and Ensembles</em>, features the algorithms of decision making: decision trees. This chapter introduces meta-learning algorithms, diverse algorithms that vote in some fashion to increase overall predictive accuracy.</p>
<p class="mce-root"><a href="8bbca390-082d-4b9f-85c0-84ea90146609.xhtml" target="_blank"><span>Chapter </span>10</a>, <em>Text and Multiclass Classification with scikit-learn</em>, reviews the basics of natural language processing with the simple bag-of-words model. In general, we view classification with three or more categories.<br/>
<a href="c330ea80-2d7f-4ea7-b67a-1b19f572da5e.xhtml" target="_blank"/></p>
<p class="mce-root"><a href="c330ea80-2d7f-4ea7-b67a-1b19f572da5e.xhtml" target="_blank"><span>Chapter </span>11</a>, <em>Neural Networks</em>, introduces a neural network and perceptrons, the components of a neural network. Each layer figures out a step in a process, leading to a desired outcome. As we do not program any steps specifically, we venture into artificial intelligence. Save the neural network so that you can keep training it later, or load it and utilize it as part of a stacking ensemble.</p>
<p class="mce-root"/>
<p class="mce-root"><a href="42d18b3f-e2bc-4bc7-88e4-2c3689a0d484.xhtml" target="_blank"><span>Chapter </span>12</a>, <em>Create a Simple Estimator</em>, helps you make your own scikit-learn estimator, which you can contribute to the scikit-learn community and take part in the evolution of data science with scikit-learn.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Who this book is for</h1>
                </header>
            
            <article>
                
<p><span>This book is for data analysts who are familiar with Python but not so much with scikit-learn, and Python programmers who would like to dive into the world of machine learning in a direct, straightforward fashion.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What you need for this book</h1>
                </header>
            
            <article>
                
<p>You will need to install following libraries:</p>
<ul>
<li>anaconda 4.1.1</li>
<li>numba 0.26.0</li>
<li>numpy 1.12.1</li>
<li>pandas 0.20.3</li>
<li>pandas-datareader 0.4.0</li>
<li>patsy 0.4.1</li>
<li>scikit-learn 0.19.0</li>
<li>scipy 0.19.1</li>
<li>statsmodels 0.8.0</li>
<li>sympy 1.0</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Conventions</h1>
                </header>
            
            <article>
                
<p>In this book, you will find a number of text styles that distinguish between different kinds of information. Here are some examples of these styles and an explanation of their meaning.</p>
<p>Code words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles are shown as follows: "<span>The <kbd>scikit-learn</kbd> library requires input tables of two-dimensional NumPy arrays</span><span>.</span>"</p>
<p>Any command-line input or output is written as follows:</p>
<pre><span><strong>import numpy as np #Load the numpy library for fast array</strong><br/><strong>computations</strong><br/><strong>import pandas as pd #Load the pandas data-analysis library</strong><br/><strong>import matplotlib.pyplot as plt #Load the pyplot visualization</strong><br/><strong>library</strong><br/></span></pre>
<p><strong>New terms</strong> and <strong>important words</strong> are shown in bold.</p>
<p class="mce-root"/>
<div class="packt_infobox">Warnings or important notes appear in a box like this.</div>
<div class="packt_tip">Tips and tricks appear like this.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Reader feedback</h1>
                </header>
            
            <article>
                
<p>Feedback from our readers is always welcome. Let us know what you think about this book-what you liked or disliked. Reader feedback is important for us as it helps us develop titles that you will really get the most out of.</p>
<p>To send us general feedback, simply e-mail <kbd><span>feedback@packtpub.com</span></kbd>, and mention the book's title in the subject of your message.</p>
<p>If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, see our author guide at <span><a href="http://www.packtpub.com/authors" target="_blank">www.packtpub.com/authors</a></span>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Customer support</h1>
                </header>
            
            <article>
                
<p>Now that you are the proud owner of a Packt book, we have a number of things to help you to get the most from your purchase.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Downloading the example code</h1>
                </header>
            
            <article>
                
<p>You can download the example code files for this book from your account at <a href="http://www.packtpub.com" target="_blank">http://www.packtpub.com</a>. If you purchased this book elsewhere, you can visit <a href="http://www.packtpub.com/support" target="_blank">http://www.packtpub.com/support</a> and register to have the files e-mailed directly to you.</p>
<p>You can download the code files by following these steps:</p>
<ol>
<li>Log in or register to our website using your e-mail address and password.</li>
<li>Hover the mouse pointer on the <span class="packt_screen">SUPPORT</span> tab at the top.</li>
<li>Click on <span class="packt_screen">Code Downloads &amp; Errata</span>.</li>
<li>Enter the name of the book in the <span class="packt_screen">Search</span> box.</li>
<li>Select the book for which you're looking to download the code files.</li>
<li>Choose from the drop-down menu where you purchased this book from.</li>
<li>Click on <span class="packt_screen">Code Download</span>.</li>
</ol>
<p>Once the file is downloaded, please make sure that you unzip or extract the folder using the latest version of:</p>
<ul>
<li>WinRAR / 7-Zip for Windows</li>
<li>Zipeg / iZip / UnRarX for Mac</li>
<li>7-Zip / PeaZip for Linux</li>
</ul>
<p><span>The code bundle for the book is also hosted on GitHub at <a href="https://github.com/PacktPublishing/scikit-learn-Cookbook-Second-Edition" target="_blank">https://github.com/PacktPublishing/scikit-learn-Cookbook-Second-Edition</a>. We also have other code bundles from our rich catalog of books and videos available at <a href="https://github.com/PacktPublishing/">https://github.com/PacktPublishing/</a>. Check them out!</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Errata</h1>
                </header>
            
            <article>
                
<p>Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you find a mistake in one of our books-maybe a mistake in the text or the code-we would be grateful if you could report this to us. By doing so, you can save other readers from frustration and help us improve subsequent versions of this book. If you find any errata, please report them by visiting <span><a href="http://www.packtpub.com/submit-errata" target="_blank">http://www.packtpub.com/submit-errata</a></span>, selecting your book, clicking on the <span class="packt_screen">Errata Submission Form</span> link, and entering the details of your errata. Once your errata are verified, your submission will be accepted and the errata will be uploaded to our website or added to any list of existing errata under the Errata section of that title.</p>
<p>To view the previously submitted errata, go to <span><a href="https://www.packtpub.com/books/content/support" target="_blank">https://www.packtpub.com/books/content/support</a></span> and enter the name of the book in the search field. The required information will appear under the <span class="packt_screen">Errata</span> section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Piracy</h1>
                </header>
            
            <article>
                
<p>Piracy of copyrighted material on the Internet is an ongoing problem across all media. At Packt, we take the protection of our copyright and licenses very seriously. If you come across any illegal copies of our works in any form on the Internet, please provide us with the location address or website name immediately so that we can pursue a remedy.</p>
<p>Please contact us at <kbd><span>copyright@packtpub.com</span></kbd> with a link to the suspected pirated material.</p>
<p>We appreciate your help in protecting our authors and our ability to bring you valuable content.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<p>If you have a problem with any aspect of this book, you can contact us at <kbd><span>questions@packtpub.com</span></kbd>, and we will do our best to address the problem.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    </body></html>