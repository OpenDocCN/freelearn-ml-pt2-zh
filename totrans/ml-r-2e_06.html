<html><head></head><body><div class="chapter" title="Chapter&#xA0;6.&#xA0;Forecasting Numeric Data &#x2013; Regression Methods"><div class="titlepage"><div><div><h1 class="title"><a id="ch06"/>Chapter 6. Forecasting Numeric Data – Regression Methods</h1></div></div></div><p>Mathematical relationships help us to understand many aspects of everyday life. For example, body weight is a function of one's calorie intake, income is often related to education and job experience, and poll numbers help us estimate a presidential candidate's odds of being re-elected.</p><p>When such relationships are expressed with exact numbers, we gain additional clarity. For example, an additional 250 kilocalories consumed daily may result in nearly a kilogram of weight gain per month; each year of job experience may be worth an additional $1,000 in yearly salary; and a president is more likely to be re-elected when the economy is strong. Obviously, these equations do not perfectly fit every situation, but we expect that they are reasonably correct, on average.</p><p>This chapter extends our machine learning toolkit by going beyond the classification methods covered previously and introducing techniques for estimating relationships among numeric data. While examining several real-world numeric prediction tasks, you will learn:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The basic statistical principles used in regression, a technique that models the size and the strength of numeric relationships</li><li class="listitem" style="list-style-type: disc">How to prepare data for regression analysis, and estimate and interpret a regression model</li><li class="listitem" style="list-style-type: disc">A pair of hybrid techniques known as regression trees and model trees, which adapt decision tree classifiers for numeric prediction tasks</li></ul></div><p>Based on a large body of work in the field of statistics, the methods used in this chapter are a bit heavier on math than those covered previously, but don't worry! Even if your algebra skills are a bit rusty, R takes care of the heavy lifting.</p><div class="section" title="Understanding regression"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec29"/>Understanding regression</h1></div></div></div><p>Regression is <a id="id455" class="indexterm"/>concerned with specifying the relationship between a single numeric <a id="id456" class="indexterm"/>
<span class="strong"><strong>dependent variable</strong></span> (the value to be predicted) and one or more numeric <span class="strong"><strong>independent variables</strong></span> (the predictors). As the name implies, the <a id="id457" class="indexterm"/>dependent variable depends upon the value of the independent variable or variables. The simplest forms of regression assume that the relationship between the independent and dependent variables follows a straight line.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note16"/>Note</h3><p>The origin of the term "regression" to describe the process of fitting lines to data is rooted in a study of genetics by Sir Francis Galton in the late 19th century. He discovered that fathers who were extremely short or extremely tall tended to have sons whose heights were closer to the average height. He called this phenomenon "regression to the mean".</p></div></div><p>You might recall from basic <a id="id458" class="indexterm"/>algebra that lines can be defined in a <span class="strong"><strong>slope-intercept form</strong></span> similar to <span class="emphasis"><em>y = a + bx</em></span>. In this form, the letter <span class="emphasis"><em>y</em></span> indicates the dependent variable and <span class="emphasis"><em>x</em></span> indicates the independent variable. The <a id="id459" class="indexterm"/>
<span class="strong"><strong>slope</strong></span> term <span class="emphasis"><em>b</em></span> specifies how much the line rises for each increase in <span class="emphasis"><em>x</em></span>. Positive values define lines that slope upward while negative values define lines that slope downward. The term <span class="emphasis"><em>a</em></span> is known as the <span class="strong"><strong>intercept</strong></span> because <a id="id460" class="indexterm"/>it specifies the point where the line crosses, or intercepts, the vertical <span class="emphasis"><em>y</em></span> axis. It indicates the value of <span class="emphasis"><em>y</em></span> when <span class="emphasis"><em>x = 0</em></span>.</p><div class="mediaobject"><img src="graphics/B03905_06_01.jpg" alt="Understanding regression"/></div><p>Regression equations <a id="id461" class="indexterm"/>model data using a similar slope-intercept format. The machine's job is to identify values of <span class="emphasis"><em>a</em></span> and <span class="emphasis"><em>b</em></span> so that the specified line is best able to relate the supplied <span class="emphasis"><em>x</em></span> values to the values of <span class="emphasis"><em>y</em></span>. There may not always be a single function that perfectly relates the values, so the machine must also have some way to quantify the margin of error. We'll discuss this in depth shortly.</p><p>Regression analysis is commonly used for modeling complex relationships among data elements, estimating the impact of a treatment on an outcome, and extrapolating into the future. Although it can <a id="id462" class="indexterm"/>be applied to nearly any task, some specific use cases include:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Examining how populations and individuals vary by their measured characteristics, for use in scientific research across fields as diverse as economics, sociology, psychology, physics, and ecology</li><li class="listitem" style="list-style-type: disc">Quantifying the causal relationship between an event and the response, such as those in clinical drug trials, engineering safety tests, or marketing research</li><li class="listitem" style="list-style-type: disc">Identifying patterns that can be used to forecast future behavior given known criteria, such as predicting insurance claims, natural disaster damage, election results, and crime rates</li></ul></div><p>Regression methods are <a id="id463" class="indexterm"/>also used for <span class="strong"><strong>statistical hypothesis testing</strong></span>, which determines whether a premise is likely to be true or false in light of the observed data. The regression model's estimates of the strength and consistency of a relationship provide information that can be used to assess whether the observations are due to chance alone.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note17"/>Note</h3><p>Hypothesis testing is extremely nuanced and falls outside the scope of machine learning. If you are interested in this topic, an introductory statistics textbook is a good place to get started.</p></div></div><p>Regression analysis is not synonymous with a single algorithm. Rather, it is an umbrella for a large number of methods that can be adapted to nearly any machine learning task. If you were limited to choosing only a single method, regression would be a good choice. One could devote an entire career to nothing else and perhaps still have much to learn.</p><p>In this chapter, we'll <a id="id464" class="indexterm"/>focus only on the most basic <span class="strong"><strong>linear regression</strong></span> models—those that use straight lines. When there is only a single independent variable it is <a id="id465" class="indexterm"/>known as <span class="strong"><strong>simple linear regression</strong></span>. In the case of two or more independent variables, this is known as <span class="strong"><strong>multiple linear regression</strong></span>, or <a id="id466" class="indexterm"/>simply "multiple regression". Both of these techniques assume that the dependent variable is measured on a continuous scale.</p><p>Regression can also be used <a id="id467" class="indexterm"/>for other types of dependent variables and even for some classification tasks. For instance, <span class="strong"><strong>logistic regression</strong></span> is used to <a id="id468" class="indexterm"/>model a binary categorical outcome, while <span class="strong"><strong>Poisson regression</strong></span>—named after the French mathematician Siméon Poisson—models integer count data. The method known as <span class="strong"><strong>multinomial logistic regression</strong></span> models a <a id="id469" class="indexterm"/>categorical outcome; thus, it can be used for classification. The same basic principles apply across all the regression methods, so after understanding the linear case, it is fairly simple to learn the others.</p><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip70"/>Tip</h3><p>Many of the specialized <a id="id470" class="indexterm"/>regression methods fall into a class of <span class="strong"><strong>Generalized Linear Models</strong></span> (<span class="strong"><strong>GLM</strong></span>). Using a GLM, linear models can be <a id="id471" class="indexterm"/>generalized to other patterns via the use of a <span class="strong"><strong>link function</strong></span>, which specifies more complex forms for the relationship between <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y</em></span>. This allows regression to be applied to almost any type of data.</p></div></div><p>We'll begin with the basic case of simple linear regression. Despite the name, this method is not too simple to address complex problems. In the next section, we'll see how the use of a simple linear regression model might have averted a tragic engineering disaster.</p><div class="section" title="Simple linear regression"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec62"/>Simple linear regression</h2></div></div></div><p>On January 28, 1986, seven crew members of the United States space shuttle <span class="emphasis"><em>Challenger</em></span> were killed when <a id="id472" class="indexterm"/>a rocket booster failed, causing a catastrophic <a id="id473" class="indexterm"/>disintegration. In the aftermath, experts focused on the launch temperature as a potential culprit. The rubber O-rings responsible for sealing the rocket joints had never been tested below 40ºF (4ºC) and the weather on the launch day was unusually cold and below freezing.</p><p>With the benefit of hindsight, the accident has been a case study for the importance of data analysis and visualization. Although it is unclear what information was available to the rocket engineers and decision makers leading up to the launch, it is undeniable that better data, utilized carefully, might very well have averted this disaster.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note18"/>Note</h3><p>This section's analysis is based on data presented in Dalal SR, Fowlkes EB, Hoadley B. <span class="emphasis"><em>Risk analysis of the space shuttle: pre-Challenger prediction of failure</em></span>. Journal of the American Statistical Association. 1989; 84:945-957. For one perspective on how data may have changed the result, see Tufte ER. <span class="emphasis"><em>Visual Explanations: Images and Quantities, Evidence and Narrative</em></span>. Graphics Press; 1997. For a counterpoint, see Robison W, Boisioly R, Hoeker D, Young, S. <span class="emphasis"><em>Representation and misrepresentation: Tufte and the Morton Thiokol engineers on the Challenger</em></span>. Science and Engineering Ethics. 2002; 8:59-81.</p></div></div><p>The rocket engineers almost certainly knew that cold temperatures could make the components more brittle and less able to seal properly, which would result in a higher chance of a dangerous fuel leak. However, given the political pressure to continue with the launch, they needed data to support this hypothesis. A regression model that demonstrated a link between temperature and O-ring failure, and could forecast the chance of failure given the expected temperature at launch, might have been very helpful.</p><p>To build the regression model, scientists might have used the data on launch temperature and component distresses from 23 previous successful shuttle launches. A component distress indicates <a id="id474" class="indexterm"/>one of the two types of problems. The first problem, called erosion, occurs when excessive heat burns up the O-ring. The second problem, called blowby, occurs <a id="id475" class="indexterm"/>when hot gases leak through or "blow by" a poorly sealed O-ring. Since the shuttle has a total of six primary O-rings, up to six distresses can occur per <a id="id476" class="indexterm"/>flight. Though the rocket can survive one or more <a id="id477" class="indexterm"/>distress events, or fail with as few as one, each additional distress increases the probability of a catastrophic failure.</p><p>The following scatterplot shows a plot of primary O-ring distresses detected for the previous 23 launches, as compared to the temperature at launch:</p><div class="mediaobject"><img src="graphics/B03905_06_02.jpg" alt="Simple linear regression"/></div><p>Examining the plot, there is an apparent trend. Launches occurring at higher temperatures tend to have fewer O-ring distress events. </p><p>Additionally, the coldest launch (53º F) had two distress events, a level which had only been reached in one other launch. With this information at hand, the fact that the Challenger was scheduled to launch at a temperature over 20 degrees colder seems concerning. But exactly how concerned should we be? To answer this question, we can turn to simple linear regression.</p><p>A simple linear regression model <a id="id478" class="indexterm"/>defines the relationship between a <a id="id479" class="indexterm"/>dependent variable and a single independent predictor variable using a line defined by an equation in the following form:</p><div class="mediaobject"><img src="graphics/B03905_06_03.jpg" alt="Simple linear regression"/></div><p>Don't be alarmed by the Greek characters, this equation can still be understood using the slope-intercept form described previously. The intercept, <span class="emphasis"><em>α</em></span> (alpha), describes where the line crosses the <span class="emphasis"><em>y</em></span> axis, while the slope, <span class="emphasis"><em>β</em></span> (beta), describes the change in <span class="emphasis"><em>y</em></span> given an increase of <span class="emphasis"><em>x</em></span>. For the shuttle launch data, the slope would tell us the expected reduction in the number of O-ring failures for each degree the launch temperature increases.</p><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip71"/>Tip</h3><p>Greek characters are often used in the field of statistics to indicate variables that are parameters of a statistical function. Therefore, performing a regression analysis involves finding <span class="strong"><strong>parameter estimates</strong></span> for <span class="emphasis"><em>α</em></span> and <span class="emphasis"><em>β</em></span>. The parameter estimates for alpha and beta are often denoted using <span class="emphasis"><em>a</em></span> and <span class="emphasis"><em>b</em></span>, although you may find that some of this terminology and notation is used interchangeably.</p></div></div><p>Suppose we know that the estimated regression parameters in the equation for the shuttle launch data are: <span class="emphasis"><em>a = 3.70</em></span> and <span class="emphasis"><em>b = -0.048</em></span>.</p><p>Hence, the full linear <a id="id480" class="indexterm"/>equation is <span class="emphasis"><em>y = 3.70 – 0.048x</em></span>. Ignoring for a <a id="id481" class="indexterm"/>moment how these numbers were obtained, we can plot the line on the scatterplot like this:</p><div class="mediaobject"><img src="graphics/B03905_06_04.jpg" alt="Simple linear regression"/></div><p>As the line shows, at 60 degrees Fahrenheit, we predict just under one O-ring distress. At 70 degrees Fahrenheit, we expect around 0.3 failures. If we extrapolate our model, all the way to 31 degrees—the forecasted temperature for the Challenger launch—we would expect about <span class="emphasis"><em>3.70 - 0.048 * 31 = 2.21</em></span> O-ring distress events. Assuming that each O-ring failure is equally likely to cause a catastrophic fuel leak means that the Challenger launch at 31 degrees was nearly three times <a id="id482" class="indexterm"/>more risky than the typical launch at 60 degrees, and over eight times more risky than a launch at 70 degrees.</p><p>Notice that the line doesn't <a id="id483" class="indexterm"/>pass through each data point exactly. Instead, it <a id="id484" class="indexterm"/>cuts through the data somewhat evenly, with some predictions lower or higher than the line. In the next section, we will learn about why this particular line was chosen.</p></div><div class="section" title="Ordinary least squares estimation"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec63"/>Ordinary least squares estimation</h2></div></div></div><p>In order to determine <a id="id485" class="indexterm"/>the optimal estimates of <span class="emphasis"><em>α</em></span> and <span class="emphasis"><em>β</em></span>, an estimation method known as <span class="strong"><strong>Ordinary Least Squares</strong></span> (<span class="strong"><strong>OLS</strong></span>) was used. In OLS <a id="id486" class="indexterm"/>regression, the slope and intercept are chosen so that they minimize the sum of the squared errors, that is, the vertical distance between the predicted <span class="emphasis"><em>y</em></span> value and the actual <span class="emphasis"><em>y</em></span> value. These errors are known as <span class="strong"><strong>residuals</strong></span>, and <a id="id487" class="indexterm"/>are illustrated for several points in the following diagram:</p><div class="mediaobject"><img src="graphics/B03905_06_05.jpg" alt="Ordinary least squares estimation"/></div><p>In mathematical terms, the goal of OLS regression can be expressed as the task of minimizing the following equation:</p><div class="mediaobject"><img src="graphics/B03905_06_06.jpg" alt="Ordinary least squares estimation"/></div><p>In plain language, this <a id="id488" class="indexterm"/>equation defines <span class="emphasis"><em>e</em></span> (the error) as the difference between the actual <span class="emphasis"><em>y</em></span> value and the predicted <span class="emphasis"><em>y</em></span> value. The error values are squared and summed across all the points in the data.</p><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip72"/>Tip</h3><p>The caret character (<code class="literal">^</code>) above the <span class="emphasis"><em>y</em></span> term is a commonly used feature of statistical notation. It indicates that the term is an estimate for the true <span class="emphasis"><em>y</em></span> value. This is referred to as the <span class="emphasis"><em>y</em></span>-hat, and is pronounced exactly like the hat you'd wear on your head.</p></div></div><p>The solution for <span class="emphasis"><em>a</em></span> <a id="id489" class="indexterm"/>depends on the value of <span class="emphasis"><em>b</em></span>. It can be obtained using the following formula:</p><div class="mediaobject"><img src="graphics/B03905_06_07.jpg" alt="Ordinary least squares estimation"/></div><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip73"/>Tip</h3><p>To understand these equations, you'll need to know another bit of statistical notation. The horizontal bar appearing over the <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y</em></span> terms indicates the mean value of <span class="emphasis"><em>x</em></span> or <span class="emphasis"><em>y</em></span>. This is referred to as the <span class="emphasis"><em>x</em></span>-bar or <span class="emphasis"><em>y</em></span>-bar, and is pronounced just like the establishment you'd go to for an alcoholic drink.</p></div></div><p>Though the proof is beyond <a id="id490" class="indexterm"/>the scope of this book, it can be shown using calculus that the value of <span class="emphasis"><em>b</em></span> that results in the minimum squared error is:</p><div class="mediaobject"><img src="graphics/B03905_06_08.jpg" alt="Ordinary least squares estimation"/></div><p>If we break this equation apart into its component pieces, we can simplify it a bit. The denominator for <span class="emphasis"><em>b</em></span> should look familiar; it is very similar to the variance of <span class="emphasis"><em>x</em></span>, which is denoted as <span class="emphasis"><em>Var(x)</em></span>. As we learned in <a class="link" href="ch02.html" title="Chapter 2. Managing and Understanding Data">Chapter 2</a>, <span class="emphasis"><em>Managing and Understanding Data</em></span>, the variance involves finding the average squared deviation from the mean of <span class="emphasis"><em>x</em></span>. This can be expressed as:</p><div class="mediaobject"><img src="graphics/B03905_06_09.jpg" alt="Ordinary least squares estimation"/></div><p>The numerator involves taking the sum of each data point's deviation from the mean <span class="emphasis"><em>x</em></span> value multiplied by that point's deviation away from the mean <span class="emphasis"><em>y</em></span> value. This is similar to the <span class="strong"><strong>covariance</strong></span> function for <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y</em></span>, denoted as <span class="emphasis"><em>Cov(x, y)</em></span>. The covariance formula is:</p><div class="mediaobject"><img src="graphics/B03905_06_10.jpg" alt="Ordinary least squares estimation"/></div><p>If we divide the covariance function by the variance function, the <span class="emphasis"><em>n</em></span> terms get cancelled and we can rewrite the formula for <span class="emphasis"><em>b</em></span> as:</p><div class="mediaobject"><img src="graphics/B03905_06_11.jpg" alt="Ordinary least squares estimation"/></div><p>Given this restatement, it is easy to calculate the value of <span class="emphasis"><em>b</em></span> using built-in R functions. Let's apply it to the rocket <a id="id491" class="indexterm"/>launch data to estimate the <a id="id492" class="indexterm"/>regression line.</p><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip74"/>Tip</h3><p>If you would like to follow along with these examples, download the <code class="literal">challenger.csv</code> file from the Packt Publishing website and load to a data frame using the <code class="literal">launch &lt;- read.csv("challenger.csv")</code> command.</p></div></div><p>Assume that our shuttle launch data is stored in a data frame named <code class="literal">launch</code>, the independent variable <span class="emphasis"><em>x</em></span> is temperature, and the dependent variable <span class="emphasis"><em>y</em></span> is <code class="literal">distress_ct</code>. We can then use R's <code class="literal">cov()</code> and <code class="literal">var()</code> functions to estimate <span class="emphasis"><em>b</em></span>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; b &lt;- cov(launch$temperature, launch$distress_ct) /</strong></span>
<span class="strong"><strong>         var(launch$temperature)</strong></span>
<span class="strong"><strong>&gt; b</strong></span>
<span class="strong"><strong>[1] -0.04753968</strong></span>
</pre></div><p>From here we can estimate <span class="emphasis"><em>a</em></span> using the <code class="literal">mean()</code> function:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; a &lt;- mean(launch$distress_ct) - b * mean(launch$temperature)</strong></span>
<span class="strong"><strong>&gt; a</strong></span>
<span class="strong"><strong>[1] 3.698413</strong></span>
</pre></div><p>Estimating the regression equation by hand is not ideal, so R provides functions for performing this calculation automatically. We will use such methods shortly. First, we will expand our <a id="id493" class="indexterm"/>understanding of regression by learning a method for measuring the strength of a linear relationship, and then we will see how linear regression can be applied to data having more than one independent variable.</p></div><div class="section" title="Correlations"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec64"/>Correlations</h2></div></div></div><p>The <span class="strong"><strong>correlation</strong></span> <a id="id494" class="indexterm"/>between two variables is a number that indicates how <a id="id495" class="indexterm"/>closely their relationship follows a straight line. Without additional qualification, correlation typically refers to <span class="strong"><strong>Pearson's correlation coefficient</strong></span>, which was developed by the 20th century mathematician Karl Pearson. The <a id="id496" class="indexterm"/>correlation ranges between -1 and +1. The extreme values indicate a perfectly linear relationship, while a correlation close to zero indicates the absence of a linear relationship.</p><p>The following formula defines Pearson's correlation:</p><div class="mediaobject"><img src="graphics/B03905_06_12.jpg" alt="Correlations"/></div><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip75"/>Tip</h3><p>More Greek notation has been introduced here. The first symbol (which looks like a lowercase p) is <span class="emphasis"><em>rho</em></span>, and it is used to denote the Pearson correlation statistic. The characters that look like q turned sideways are the Greek letter <span class="emphasis"><em>sigma</em></span>, and they indicate the standard deviation of <span class="emphasis"><em>x</em></span> or <span class="emphasis"><em>y</em></span>.</p></div></div><p>Using this formula, we <a id="id497" class="indexterm"/>can calculate the correlation between the launch temperature and the number of O-ring distress events. Recall that the covariance function is <code class="literal">cov()</code> and the standard deviation function is <code class="literal">sd()</code>. We'll store the result in <code class="literal">r</code>, a letter that is commonly used to indicate the estimated correlation:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; r &lt;- cov(launch$temperature, launch$distress_ct) /</strong></span>
<span class="strong"><strong>         (sd(launch$temperature) * sd(launch$distress_ct))</strong></span>
<span class="strong"><strong>&gt; r</strong></span>
<span class="strong"><strong>[1] -0.5111264</strong></span>
</pre></div><p>Alternatively, we can use R's correlation function, <code class="literal">cor()</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; cor(launch$temperature, launch$distress_ct)</strong></span>
<span class="strong"><strong>[1] -0.5111264</strong></span>
</pre></div><p>The correlation between the temperature and the number of distressed O-rings is -0.51. The negative correlation implies that increases in temperature are related to decreases in the number of distressed O-rings. To the NASA engineers studying the O-ring data, this would have been a very clear indicator that a low temperature launch could be problematic. The correlation also tells us about the relative strength of the relationship between temperature and O-ring distress. Because -0.51 is halfway to the maximum negative correlation of -1, this implies that there is a moderately strong negative linear association.</p><p>There are various <a id="id498" class="indexterm"/>rules of thumb used to interpret correlation strength. One method assigns a status of "weak" to values between 0.1 and 0.3, "moderate" to the range of 0.3 to 0.5, and "strong" to values above 0.5 (these also apply to similar ranges of negative correlations). However, these thresholds may be too lax for some purposes. Often, the correlation must be interpreted in context. For data involving human beings, a correlation of 0.5 may be considered extremely high, while for data generated by mechanical processes, a correlation of 0.5 may be weak.</p><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip76"/>Tip</h3><p>You have probably heard the expression "correlation does not imply causation." This is rooted in the fact that a correlation only describes the association between a pair of variables, yet there could be other unmeasured explanations. For example, there may be a strong association between  mortality and time per day spent matching movies, but before doctors should start recommending that we all watch more movies, we need to rule out another explanation—younger people watch more movies and are less likely to die.</p></div></div><p>Measuring the correlation between two variables gives us a way to quickly gauge the relationships among the independent and dependent variables. This will be increasingly important as we start defining the regression models with a larger number of predictors.</p></div><div class="section" title="Multiple linear regression"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec65"/>Multiple linear regression</h2></div></div></div><p>Most real-world <a id="id499" class="indexterm"/>analyses have more than one independent variable. Therefore, it is likely that you will be using <span class="strong"><strong>multiple linear regression</strong></span> for most <a id="id500" class="indexterm"/>numeric prediction tasks. The strengths and weaknesses of multiple linear regression are shown in the following table:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Strengths</p>
</th><th style="text-align: left" valign="bottom">
<p>Weaknesses</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">By far the most common approach for modeling numeric data</li><li class="listitem" style="list-style-type: disc">Can be adapted to model almost any modeling task</li><li class="listitem" style="list-style-type: disc">Provides estimates of both the strength and size of the relationships among features and the outcome</li></ul></div>
</td><td style="text-align: left" valign="top">
<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Makes strong assumptions about the data</li><li class="listitem" style="list-style-type: disc">The model's form must be specified by the user in advance</li><li class="listitem" style="list-style-type: disc">Does not handle missing data</li><li class="listitem" style="list-style-type: disc">Only works with numeric features, so categorical data requires extra processing</li><li class="listitem" style="list-style-type: disc">Requires some knowledge of statistics to understand <a id="id501" class="indexterm"/>the model</li></ul></div>
</td></tr></tbody></table></div><p>We can understand multiple regression as an extension of simple linear regression. The goal in both cases is similar—find values of beta coefficients that minimize the prediction error of a linear equation. The key difference is that there are additional terms for additional independent variables.</p><p>Multiple regression <a id="id502" class="indexterm"/>equations generally follow the form of the following equation. The dependent variable <span class="emphasis"><em>y</em></span> is specified as the sum of an intercept term <span class="emphasis"><em>α</em></span> plus the product of the estimated <span class="emphasis"><em>β</em></span> value and the <span class="emphasis"><em>x</em></span> values for each of the <span class="emphasis"><em>i</em></span> features. An error term (denoted by the Greek letter <span class="emphasis"><em>epsilon</em></span>) has been added here as a reminder that the predictions are not perfect. This represents the <span class="strong"><strong>residual</strong></span> term noted previously:</p><div class="mediaobject"><img src="graphics/B03905_06_13.jpg" alt="Multiple linear regression"/></div><p>Let's consider for a moment the interpretation of the estimated regression parameters. You will note that in the preceding equation, a coefficient is provided for each feature. This allows each feature to have a separate estimated effect on the value of <span class="emphasis"><em>y</em></span>. In other words, <span class="emphasis"><em>y</em></span> changes by the amount <span class="emphasis"><em>β<sub>i</sub></em></span> for each unit increase in <span class="emphasis"><em>x<sub>i</sub></em></span>. The intercept <span class="emphasis"><em>α</em></span> is then the expected value of <span class="emphasis"><em>y</em></span> when the independent variables are all zero.</p><p>Since the intercept term <span class="emphasis"><em>α</em></span> is really no different than any other regression parameter, it is also sometimes denoted as <span class="emphasis"><em>β<sub>0</sub></em></span> (pronounced beta-naught), as shown in the following equation:</p><div class="mediaobject"><img src="graphics/B03905_06_14.jpg" alt="Multiple linear regression"/></div><p>Just like before, the intercept is unrelated to any of the independent <span class="emphasis"><em>x</em></span> variables. However, for reasons that will become clear shortly, it helps to imagine <span class="emphasis"><em>β<sub>0</sub></em></span> as if it were being multiplied by a term <span class="emphasis"><em>x<sub>0</sub></em></span>, which is a constant with the value 1:</p><div class="mediaobject"><img src="graphics/B03905_06_15.jpg" alt="Multiple linear regression"/></div><p>In order to estimate the values of the regression parameters, each observed value of the dependent variable <span class="emphasis"><em>y</em></span> must be related to the observed values of the independent <span class="emphasis"><em>x</em></span> variables using the regression <a id="id503" class="indexterm"/>equation in the previous form. The <a id="id504" class="indexterm"/>following figure illustrates this structure:</p><div class="mediaobject"><img src="graphics/B03905_06_16.jpg" alt="Multiple linear regression"/></div><p>The many rows and columns of data illustrated in the preceding figure can be described in a condensed formulation using <a id="id505" class="indexterm"/>bold font <span class="strong"><strong>matrix notation</strong></span> to indicate that each of the <a id="id506" class="indexterm"/>terms represents multiple values:</p><div class="mediaobject"><img src="graphics/B03905_06_17.jpg" alt="Multiple linear regression"/></div><p>The dependent variable is now a vector, <span class="strong"><strong>Y</strong></span>, with a row for every example. The independent variables have been combined into a matrix, <span class="strong"><strong>X</strong></span>, with a column for each feature plus an additional column of '1' values for the intercept term. Each column has a row for every example. The regression coefficients <span class="strong"><strong>β</strong></span> and residual errors <span class="strong"><strong>ε</strong></span> are also now vectors.</p><p>The goal is now to solve for <span class="strong"><strong>β</strong></span>, the vector of regression coefficients that minimizes the sum of the squared errors between the predicted and actual <span class="strong"><strong>Y</strong></span> values. Finding the optimal solution requires the use of matrix algebra; therefore, the derivation deserves more careful attention than can be provided in this text. However, if you're willing to trust the work of others, the best estimate of the vector <span class="strong"><strong>β</strong></span> can be computed as:</p><div class="mediaobject"><img src="graphics/B03905_06_18.jpg" alt="Multiple linear regression"/></div><p>This solution uses a pair of <a id="id507" class="indexterm"/>matrix operations—the <span class="strong"><strong>T</strong></span> indicates the <span class="strong"><strong>transpose</strong></span> of matrix <span class="strong"><strong>X</strong></span>, while the negative exponent indicates the <span class="strong"><strong>matrix inverse</strong></span>. Using R's built-in matrix operations, we can thus implement a simple multiple regression <a id="id508" class="indexterm"/>learner. Let's apply this formula to the Challenger launch data.</p><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip77"/>Tip</h3><p>If you are unfamiliar with the preceding matrix operations, the Wikipedia pages for transpose and matrix inverse provide a thorough introduction and are quite understandable, even without a strong mathematics background.</p></div></div><p>Using the following code, we can create a basic regression function named <code class="literal">reg()</code>, which takes a parameter <code class="literal">y</code> and a parameter <code class="literal">x</code> and returns a vector of estimated beta coefficients:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>reg &lt;- function(y, x) {</strong></span>
<span class="strong"><strong>  x &lt;- as.matrix(x)</strong></span>
<span class="strong"><strong>  x &lt;- cbind(Intercept = 1, x)</strong></span>
<span class="strong"><strong>  b &lt;- solve(t(x) %*% x) %*% t(x) %*% y</strong></span>
<span class="strong"><strong>  colnames(b) &lt;- "estimate"</strong></span>
<span class="strong"><strong>  print(b)</strong></span>
<span class="strong"><strong>}</strong></span>
</pre></div><p>The <code class="literal">reg()</code> function created here uses several R commands that we have not used previously. First, since we will be using the function with sets of columns from a data frame, the <code class="literal">as.matrix()</code> function is used to convert the data frame into matrix form. Next, the <code class="literal">cbind()</code> function is used to bind an additional column onto the <code class="literal">x</code> matrix; the command <code class="literal">Intercept = 1</code> instructs R to name the new column <code class="literal">Intercept</code> and to fill the column with repeating 1 values. Then, a number of matrix operations are performed on the <code class="literal">x</code> and <code class="literal">y</code> objects:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">solve()</code> takes the inverse of a matrix</li><li class="listitem" style="list-style-type: disc"><code class="literal">t()</code> is used to transpose a matrix</li><li class="listitem" style="list-style-type: disc"><code class="literal">%*%</code> multiplies two matrices</li></ul></div><p>By combining these as shown, our function will return a vector <code class="literal">b</code>, which contains the estimated parameters for the linear model relating <code class="literal">x</code> to <code class="literal">y</code>. The final two lines in the function give the <code class="literal">b</code> vector a name and print the result on screen.</p><p>Let's apply our function to the <a id="id509" class="indexterm"/>shuttle launch data. As shown in the following code, the dataset includes three features and the distress count (<code class="literal">distress_ct</code>), which is the outcome of interest:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; str(launch)</strong></span>
<span class="strong"><strong>'data.frame':      23 obs. of  4 variables:</strong></span>
<span class="strong"><strong> $ distress_ct         : int  0 1 0 0 0 0 0 0 1 1 ...</strong></span>
<span class="strong"><strong> $ temperature         : int  66 70 69 68 67 72 73 70 57 63 ...</strong></span>
<span class="strong"><strong> $ field_check_pressure: int  50 50 50 50 50 50 100 100 200 ...</strong></span>
<span class="strong"><strong> $ flight_num          : int  1 2 3 4 5 6 7 8 9 10 ...</strong></span>
</pre></div><p>We can confirm that our function is working correctly by comparing its result to the simple linear regression model of O-ring failures versus temperature, which we found earlier to have parameters <span class="emphasis"><em>a = 3.70</em></span> and <span class="emphasis"><em>b = -0.048</em></span>. Since temperature is in the third column of the launch data, we can run the <code class="literal">reg()</code> function as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; reg(y = launch$distress_ct, x = launch[2])</strong></span>
<span class="strong"><strong>               estimate</strong></span>
<span class="strong"><strong>Intercept    3.69841270</strong></span>
<span class="strong"><strong>temperature -0.04753968</strong></span>
</pre></div><p>These values exactly match our <a id="id510" class="indexterm"/>prior result, so let's use the function to build a multiple regression model. We'll apply it just as before, but this time specifying three columns of data instead of just one:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; reg(y = launch$distress_ct, x = launch[2:4])</strong></span>
<span class="strong"><strong>                         estimate</strong></span>
<span class="strong"><strong>Intercept             3.527093383</strong></span>
<span class="strong"><strong>temperature          -0.051385940</strong></span>
<span class="strong"><strong>field_check_pressure  0.001757009</strong></span>
<span class="strong"><strong>flight_num            0.014292843</strong></span>
</pre></div><p>This model predicts the number of O-ring distress events versus temperature, field check pressure, and the launch ID number. As with the simple linear regression model, the coefficient for the temperature variable is negative, which suggests that as temperature increases, the number of expected O-ring events decreases. The field check pressure refers to the amount of pressure applied to the O-ring to test it prior to launch. Although the check pressure had originally been 50 psi, it was raised to 100 and 200 psi for some launches, which led some to believe that it may be responsible for O-ring erosion. The coefficient is positive, but small. The flight number is included to account for the shuttle's age. As it gets older, its parts may be more brittle or prone to fail. The small positive association between flight number and distress count may reflect this fact.</p><p>So far we've only scratched the surface of linear regression modeling. Although our work was useful to help us <a id="id511" class="indexterm"/>understand exactly how regression models are built, R's functions also include some additional functionality necessary for the more complex <a id="id512" class="indexterm"/>modeling tasks and diagnostic output that are needed to aid model interpretation and assess fit. Let's apply our knowledge of regression to a more challenging learning task.</p></div></div></div>
<div class="section" title="Example &#x2013; predicting medical expenses using linear regression"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec30"/>Example – predicting medical expenses using linear regression</h1></div></div></div><p>In order for a <a id="id513" class="indexterm"/>health insurance company to make money, it needs to collect more in yearly premiums than it spends on medical care to its beneficiaries. As a result, insurers invest a great deal of time and money in developing models that accurately forecast medical expenses for the insured population.</p><p>Medical expenses are difficult to estimate because the most costly conditions are rare and seemingly random. Still, some conditions are more prevalent for certain segments of the population. For instance, lung cancer is more likely among smokers than non-smokers, and heart disease may be more likely among the obese.</p><p>The goal of this analysis is to use patient data to estimate the average medical care expenses for such population segments. These estimates can be used to create actuarial tables that set the price of yearly premiums higher or lower, depending on the expected treatment costs.</p><div class="section" title="Step 1 – collecting data"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec66"/>Step 1 – collecting data</h2></div></div></div><p>For <a id="id514" class="indexterm"/>this analysis, we will use a simulated dataset containing hypothetical medical expenses for patients in the United States. This data was created for this book using demographic statistics from the US Census Bureau, and thus, approximately reflect real-world conditions.</p><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip78"/>Tip</h3><p>If you would like to follow along interactively, download the <code class="literal">insurance.csv</code> file from the Packt Publishing website and save it to your R working folder.</p></div></div><p>The <code class="literal">insurance.csv</code> file includes 1,338 examples of beneficiaries currently enrolled in the insurance plan, with features indicating characteristics of the patient as well as the total medical expenses charged to the plan for the calendar year. The features are:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">age</code>: An integer indicating the age of the primary beneficiary (excluding those above 64 years, since they are generally covered by the government).</li><li class="listitem" style="list-style-type: disc"><code class="literal">sex</code>: The policy holder's gender, either male or female.</li><li class="listitem" style="list-style-type: disc"><code class="literal">bmi</code>: The body mass index (BMI), which provides a sense of how over- or under-weight a <a id="id515" class="indexterm"/>person is relative to their height. BMI is equal to weight (in kilograms) divided by height (in meters) squared. An ideal BMI is within the range of 18.5 to 24.9.</li><li class="listitem" style="list-style-type: disc"><code class="literal">children</code>: An integer indicating the number of children/dependents covered by the insurance plan.</li><li class="listitem" style="list-style-type: disc"><code class="literal">smoker</code>: A yes or no categorical variable that indicates whether the insured regularly smokes tobacco.</li><li class="listitem" style="list-style-type: disc"><code class="literal">region</code>: The beneficiary's place of residence in the US, divided into four geographic regions: northeast, southeast, southwest, or northwest.</li></ul></div><p>It is important to give some thought to how these variables may be related to billed medical expenses. For instance, we might expect that older people and smokers are at higher risk of large <a id="id516" class="indexterm"/>medical expenses. Unlike many other machine learning methods, in regression analysis, the relationships among the features are typically specified by the user rather than being detected automatically. We'll explore some of these potential relationships in the next section.</p></div><div class="section" title="Step 2 – exploring and preparing the data"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec67"/>Step 2 – exploring and preparing the data</h2></div></div></div><p>As we <a id="id517" class="indexterm"/>have done <a id="id518" class="indexterm"/>before, we will use the <code class="literal">read.csv()</code> function to load the data for analysis. We can safely use <code class="literal">stringsAsFactors = TRUE</code> because it is appropriate to convert the three nominal variables to factors:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; insurance &lt;- read.csv("insurance.csv", stringsAsFactors = TRUE)</strong></span>
</pre></div><p>The <code class="literal">str()</code> function confirms that the data is formatted as we had expected:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; str(insurance)</strong></span>
<span class="strong"><strong>'data.frame':     1338 obs. of  7 variables:</strong></span>
<span class="strong"><strong> $ age     : int  19 18 28 33 32 31 46 37 37 60 ...</strong></span>
<span class="strong"><strong> $ sex     : Factor w/ 2 levels "female","male": 1 2 2 2 2 1 ...</strong></span>
<span class="strong"><strong> $ bmi     : num  27.9 33.8 33 22.7 28.9 25.7 33.4 27.7 ...</strong></span>
<span class="strong"><strong> $ children: int  0 1 3 0 0 0 1 3 2 0 ...</strong></span>
<span class="strong"><strong> $ smoker  : Factor w/ 2 levels "no","yes": 2 1 1 1 1 1 1 1 ...</strong></span>
<span class="strong"><strong> $ region  : Factor w/ 4 levels "northeast","northwest",..: ...</strong></span>
<span class="strong"><strong> $ expenses: num  16885 1726 4449 21984 3867 ...</strong></span>
</pre></div><p>Our model's dependent variable is <code class="literal">expenses</code>, which measures the medical costs each person charged to the insurance plan for the year. Prior to building a regression model, it is often helpful to check for normality. Although linear regression does not strictly require a <a id="id519" class="indexterm"/>normally distributed dependent variable, the model often fits better when this is true. Let's take a look at the summary statistics:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; summary(insurance$expenses)</strong></span>
<span class="strong"><strong>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.</strong></span>
<span class="strong"><strong>   1122    4740    9382   13270   16640   63770</strong></span>
</pre></div><p>Because the mean value is greater than the median, this implies that the distribution of insurance expenses is right-skewed. We can confirm this visually using a histogram:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; hist(insurance$expenses)</strong></span>
</pre></div><p>The output is shown as follows:</p><div class="mediaobject"><img src="graphics/B03905_06_19.jpg" alt="Step 2 – exploring and preparing the data"/></div><p>As expected, the figure shows a right-skewed distribution. It also shows that the majority of people in our data have yearly medical expenses between zero and $15,000, in spite of the fact that the tail of the distribution extends far past these peaks. Although this distribution is not ideal for a linear regression, knowing this weakness ahead of time may help us design a better-fitting model later on.</p><p>Before we address that issue, another problem is at hand. Regression models require that every feature <a id="id520" class="indexterm"/>is numeric, yet <a id="id521" class="indexterm"/>we have three factor-type features in our data frame. For instance, the sex variable is divided into male and female levels, while smoker is divided into yes and no. From the <code class="literal">summary()</code> output, we know that the <code class="literal">region</code> variable has four levels, but we need to take a closer look to see how they are distributed:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; table(insurance$region)</strong></span>
<span class="strong"><strong>northeast northwest southeast southwest</strong></span>
<span class="strong"><strong>      324       325       364       325</strong></span>
</pre></div><p>Here, we see that the data has been divided nearly evenly among four geographic regions. We will see how R's linear regression function handles these factor variables shortly.</p><div class="section" title="Exploring relationships among features – the correlation matrix"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec33"/>Exploring relationships among features – the correlation matrix</h3></div></div></div><p>Before <a id="id522" class="indexterm"/>fitting a regression model to data, it can be useful to determine how the independent variables are related to the dependent variable and each other. A <span class="strong"><strong>correlation matrix</strong></span> provides a quick overview of these relationships. Given a set of variables, it provides a correlation for each pairwise relationship.</p><p>To create a correlation matrix for the four numeric variables in the insurance data frame, use the <code class="literal">cor()</code> command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; cor(insurance[c("age", "bmi", "children", "expenses")])</strong></span>
<span class="strong"><strong>               age        bmi   children   expenses</strong></span>
<span class="strong"><strong>age      1.0000000 0.10934101 0.04246900 0.29900819</strong></span>
<span class="strong"><strong>bmi      0.1093410 1.00000000 0.01264471 0.19857626</strong></span>
<span class="strong"><strong>children 0.0424690 0.01264471 1.00000000 0.06799823</strong></span>
<span class="strong"><strong>expenses 0.2990082 0.19857626 0.06799823 1.00000000</strong></span>
</pre></div><p>At the intersection of each row and column pair, the correlation is listed for the variables indicated by that row and column. The diagonal is always <code class="literal">1.0000000</code> since there is always a perfect correlation between a variable and itself. The values above and below the diagonal are identical since correlations are symmetrical. In other words, <code class="literal">cor(x, y)</code> is equal to <code class="literal">cor(y, x)</code>.</p><p>None of the correlations in the matrix are considered strong, but there are some notable associations. For instance, <code class="literal">age</code> and <code class="literal">bmi</code> appear to have a weak positive correlation, meaning that as someone ages, their body mass tends to increase. There is also a moderate positive correlation between <code class="literal">age</code> and <code class="literal">expenses</code>, <code class="literal">bmi</code> and <code class="literal">expenses</code>, and <code class="literal">children</code> and <code class="literal">expenses</code>. These associations imply that as age, body mass, and number of children <a id="id523" class="indexterm"/>increase, the expected cost of insurance goes up. We'll try to tease out these relationships more clearly when we build our final regression model.</p></div><div class="section" title="Visualizing relationships among features – the scatterplot matrix"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec34"/>Visualizing relationships among features – the scatterplot matrix</h3></div></div></div><p>It can also <a id="id524" class="indexterm"/>be helpful to visualize the relationships among numeric features by using <a id="id525" class="indexterm"/>a scatterplot. Although we could create a scatterplot for each possible relationship, doing so for a large number of features might become tedious.</p><p>An alternative <a id="id526" class="indexterm"/>is to create a <span class="strong"><strong>scatterplot matrix</strong></span> (sometimes abbreviated as <span class="strong"><strong>SPLOM</strong></span>), which is simply a collection of scatterplots arranged in a grid. It is used to detect patterns among three or more variables. The scatterplot matrix is not a true multidimensional visualization because only two features are examined at a time. Still, it provides a general sense of how the data may be interrelated.</p><p>We can use R's graphical <a id="id527" class="indexterm"/>capabilities to create a scatterplot matrix for the four numeric features: <code class="literal">age</code>, <code class="literal">bmi</code>, <code class="literal">children</code>, and <code class="literal">expenses</code>. The <code class="literal">pairs()</code> function is provided in a default R installation and provides basic functionality for producing scatterplot matrices. To invoke the function, simply provide it the data frame to present. Here, we'll limit the <code class="literal">insurance</code> data frame to the four numeric variables of interest:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; pairs(insurance[c("age", "bmi", "children", "expenses")])</strong></span>
</pre></div><p>This produces the following diagram:</p><div class="mediaobject"><img src="graphics/B03905_06_20.jpg" alt="Visualizing relationships among features – the scatterplot matrix"/></div><p>In the scatterplot matrix, the intersection of each row and column holds the scatterplot of the variables indicated by the row and column pair. The diagrams above and below the diagonal are transpositions since the <span class="emphasis"><em>x</em></span> axis and <span class="emphasis"><em>y</em></span> axis have been swapped.</p><p>Do you notice any patterns in these plots? Although some look like random clouds of points, a few seem to display some trends. The relationship between <code class="literal">age</code> and <code class="literal">expenses</code> displays several <a id="id528" class="indexterm"/>relatively straight lines, while the <code class="literal">bmi</code> versus <code class="literal">expenses</code> plot has two distinct groups of points. It is difficult to detect trends in any of the other plots.</p><p>If we add more information to the plot, it can be even more useful. An enhanced scatterplot matrix can be <a id="id529" class="indexterm"/>created with the <code class="literal">pairs.panels()</code> function in the <code class="literal">psych</code> package. If you do not have this package installed, type <code class="literal">install.packages("psych")</code> to install it on your system and load it using the <code class="literal">library(psych)</code> command. Then, we can create a scatterplot matrix as we had done previously:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; pairs.panels(insurance[c("age", "bmi", "children", "expenses")])</strong></span>
</pre></div><p>This produces a slightly more informative scatterplot matrix, as shown here:</p><div class="mediaobject"><img src="graphics/B03905_06_21.jpg" alt="Visualizing relationships among features – the scatterplot matrix"/></div><p>Above the diagonal, the scatterplots have been replaced with a correlation matrix. On the diagonal, a histogram depicting the distribution of values for each feature is shown. Finally, the scatterplots below the diagonal are now presented with additional visual information.</p><p>The <a id="id530" class="indexterm"/>oval-shaped object on each scatterplot is a <span class="strong"><strong>correlation ellipse</strong></span>. It provides a visualization of correlation strength. The dot at the center of the ellipse indicates the point at the mean values for the <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y</em></span> axis variables. The correlation between the two variables is indicated by the shape of the ellipse; the more it is stretched, the stronger the correlation. An almost perfectly round oval, as with <code class="literal">bmi</code> and <code class="literal">children</code>, indicates a very weak correlation (in this case, it is 0.01).</p><p>The curve drawn on the <a id="id531" class="indexterm"/>scatterplot is called a <span class="strong"><strong>loess curve</strong></span>. It indicates the general relationship between the <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y</em></span> axis variables. It is best understood by example. The curve for <code class="literal">age</code> and <code class="literal">children</code> is an upside-down U, peaking around middle age. This means that the oldest and youngest people in the sample have fewer children on the insurance plan than those around middle age. Because this trend is non-linear, this finding could <a id="id532" class="indexterm"/>not have been inferred from the correlations alone. On the other hand, the loess curve for <code class="literal">age</code> and <code class="literal">bmi</code> is a line sloping gradually up, implying that body mass increases with age, but we had already inferred this from the correlation matrix.</p></div></div><div class="section" title="Step 3 – training a model on the data"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec68"/>Step 3 – training a model on the data</h2></div></div></div><p>To fit <a id="id533" class="indexterm"/>a linear regression model to data with R, the <code class="literal">lm()</code> function can be used. This is included in the <code class="literal">stats</code> package, which should be included and loaded by default with your R installation. The <code class="literal">lm()</code> syntax is as follows:</p><div class="mediaobject"><img src="graphics/B03905_06_22.jpg" alt="Step 3 – training a model on the data"/></div><p>The following command fits a linear regression model relating the six independent variables to the total medical expenses. The R formula syntax uses the tilde character <code class="literal">~</code> to describe the model; the dependent variable <code class="literal">expenses</code> goes to the left of the tilde while the independent <a id="id534" class="indexterm"/>variables go to the right, separated by <code class="literal">+</code> signs. There is no need to specify the regression model's intercept term as it is assumed by default:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; ins_model &lt;- lm(expenses ~ age + children + bmi + sex +</strong></span>
<span class="strong"><strong>    smoker + region, data = insurance)</strong></span>
</pre></div><p>Because the <code class="literal">.</code> character can be used to specify all the features (excluding those already specified in the formula), the following command is equivalent to the preceding command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; ins_model &lt;- lm(expenses ~ ., data = insurance)</strong></span>
</pre></div><p>After building the model, simply type the name of the model object to see the estimated beta coefficients:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; ins_model</strong></span>

<span class="strong"><strong>Call:</strong></span>
<span class="strong"><strong>lm(formula = expenses ~ ., data = insurance)</strong></span>

<span class="strong"><strong>Coefficients:</strong></span>
<span class="strong"><strong>    (Intercept)              age          sexmale  </strong></span>
<span class="strong"><strong>       -11941.6            256.8           -131.4  </strong></span>
<span class="strong"><strong>            bmi         children        smokeryes  </strong></span>
<span class="strong"><strong>          339.3            475.7          23847.5  </strong></span>
<span class="strong"><strong>regionnorthwest  regionsoutheast  regionsouthwest  </strong></span>
<span class="strong"><strong>         -352.8          -1035.6           -959.3</strong></span>
</pre></div><p>Understanding the regression coefficients is fairly straightforward. The intercept is the predicted value of <code class="literal">expenses</code> when the independent variables are equal to zero. As is the case here, quite often the intercept is of little value alone because it is impossible to have values of zero for all features. For example, since no person exists with age zero and BMI zero, the intercept has no real-world interpretation. For this reason, in practice, the intercept is often ignored.</p><p>The beta coefficients indicate the estimated increase in expenses for an increase of one in each of the features, assuming all other values are held constant. For instance, for each additional year of age, we would expect $256.80 higher medical expenses on average, assuming everything else is equal. Similarly, each additional child results in an average of $475.70 in additional medical expenses each year, and each unit increase in BMI is associated with an average increase of $339.30 in yearly medical expenses, all else equal.</p><p>You might notice that although we only specified six features in our model formula, there are eight coefficients reported in addition to the intercept. This happened because the <code class="literal">lm()</code> function <a id="id535" class="indexterm"/>automatically <a id="id536" class="indexterm"/>applied a technique known as <span class="strong"><strong>dummy coding</strong></span> to each of the factor-type variables we included in the model.</p><p>Dummy coding allows a nominal feature to be treated as numeric by creating a binary variable, often called a <span class="strong"><strong>dummy </strong></span><a id="id537" class="indexterm"/>
<span class="strong"><strong>variable</strong></span>, for each category of the feature. The dummy variable is set to <code class="literal">1</code> if the observation falls into the specified category or <code class="literal">0</code> otherwise. For instance, the <code class="literal">sex</code> feature has two categories: <code class="literal">male</code> and <code class="literal">female</code>. This will be split into two binary variables, which R names <code class="literal">sexmale</code> and <code class="literal">sexfemale</code>. For observations where <code class="literal">sex = male</code>, then <code class="literal">sexmale = 1</code> and <code class="literal">sexfemale = 0</code>; conversely, if <code class="literal">sex = female</code>, then <code class="literal">sexmale = 0</code> and <code class="literal">sexfemale = 1</code>. The same coding applies to variables with three or more categories. For example, R split the four-category feature <code class="literal">region</code> into four dummy variables: <code class="literal">regionnorthwest</code>, <code class="literal">regionsoutheast</code>, <code class="literal">regionsouthwest</code>, and <code class="literal">regionnortheast</code>.</p><p>When adding a dummy variable to a regression model, one category is always left out to serve as the reference category. The estimates are then interpreted relative to the reference. In our model, R automatically held out the <code class="literal">sexfemale</code>, <code class="literal">smokerno</code>, and <code class="literal">regionnortheast</code> variables, making female non-smokers in the northeast region the reference group. Thus, males have $131.40 less medical expenses each year relative to females and smokers cost an average of $23,847.50 more than non-smokers per year. The coefficient for each of the three regions in the model is negative, which implies that the reference group, the northeast region, tends to have the highest average expenses.</p><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip79"/>Tip</h3><p>By default, R uses the first level of the factor variable as the reference. If you would prefer to use another level, the <code class="literal">relevel()</code> function can be used to specify the reference group manually. Use the <code class="literal">?relevel</code> command in R for more information.</p></div></div><p>The results of the linear regression model make logical sense: old age, smoking, and obesity tend to be linked to additional health issues, while additional family member dependents may result in an increase in physician visits and preventive care such as vaccinations and yearly physical exams. However, we currently have no sense of how well the model is fitting the data. We'll answer this question in the next section.</p></div><div class="section" title="Step 4 – evaluating model performance"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec69"/>Step 4 – evaluating model performance</h2></div></div></div><p>The parameter <a id="id538" class="indexterm"/>estimates we obtained by typing <code class="literal">ins_model</code> tell us about how the independent variables are related to the dependent variable, but they tell us nothing about how well the model fits our data. To evaluate the model performance, we can use the <code class="literal">summary()</code> command on the stored model:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; summary(ins_model)</strong></span>
</pre></div><p>This produces the following output. Note that the output has been labeled for illustrative purposes:</p><div class="mediaobject"><img src="graphics/B03905_06_23.jpg" alt="Step 4 – evaluating model performance"/></div><p>The <code class="literal">summary()</code> output <a id="id539" class="indexterm"/>may seem confusing at first, but the basics are easy to pick up. As indicated by the numbered labels in the preceding output, the output provides three key ways to evaluate the performance, or fit, of our model:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">The <span class="strong"><strong>residuals</strong></span> section provides summary statistics for the errors in our predictions, some of which are apparently quite substantial. Since a residual is equal to the true value minus the predicted value, the maximum error of 29981.7 suggests that the model under-predicted expenses by nearly $30,000 for at least one observation. On the other hand, 50 percent of errors fall within the 1Q and 3Q values (the first and third quartile), so the majority of predictions were between $2,850.90 over the true value and $1,383.90 under the true value.</li><li class="listitem">For each estimated regression coefficient, the <span class="strong"><strong>p-value</strong></span>, denoted <code class="literal">Pr(&gt;|t|)</code>, provides an estimate of the probability that the true coefficient is zero given the value of the estimate. Small p-values suggest that the true coefficient is very unlikely to be zero, which means that the feature is extremely unlikely to have no <a id="id540" class="indexterm"/>relationship with the dependent variable. Note that some of the p-values have stars (<code class="literal">***</code>), which correspond to the footnotes to indicate the <span class="strong"><strong>significance level</strong></span> met by the estimate. This level is a threshold, chosen prior to building the model, which will be used to indicate "real" findings, as opposed to those due to chance alone; p-values less than the significance level are considered <span class="strong"><strong>statistically significant</strong></span>. If the model had few such terms, it may be cause for concern, since this would indicate that the features used are not very predictive of the outcome. Here, our model has several highly significant variables, and they seem to be related to the outcome in logical ways.</li><li class="listitem">The <span class="strong"><strong>multiple R-squared value</strong></span> (also called the coefficient of determination) provides a <a id="id541" class="indexterm"/>measure of how well our model as a whole explains the values of the dependent variable. It is similar to the correlation coefficient, in that the closer the value is to 1.0, the better the model perfectly explains the data. Since the R-squared value is 0.7494, we know that the model explains nearly 75 percent of the variation in the dependent variable. Because models with more features <a id="id542" class="indexterm"/>always explain more variation, the <span class="strong"><strong>adjusted R-squared value</strong></span> corrects R-squared by penalizing models with a large number of independent variables. It is useful for comparing the performance of models with different numbers of explanatory variables.</li></ol></div><p>Given the preceding three <a id="id543" class="indexterm"/>performance indicators, our model is performing fairly well. It is not uncommon for regression models of real-world data to have fairly low R-squared values; a value of 0.75 is actually quite good. The size of some of the errors is a bit concerning, but not surprising given the nature of medical expense data. However, as shown in the next section, we may be able to improve the model's performance by specifying the model in a slightly different way.</p></div><div class="section" title="Step 5 – improving model performance"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec70"/>Step 5 – improving model performance</h2></div></div></div><p>As mentioned <a id="id544" class="indexterm"/>previously, a key difference between the regression modeling and other machine learning approaches is that regression typically leaves feature selection and model <a id="id545" class="indexterm"/>specification to the user. Consequently, if we have subject matter knowledge about how a feature is related to the outcome, we can use this information to inform the model specification and potentially improve the model's performance.</p><div class="section" title="Model specification – adding non-linear relationships"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec35"/>Model specification – adding non-linear relationships</h3></div></div></div><p>In linear regression, the relationship between an independent variable and the dependent variable is <a id="id546" class="indexterm"/>assumed to be linear, yet this may not necessarily be true. For example, the effect of age on medical expenditure may not be constant throughout all the age values; the treatment may become disproportionately expensive for oldest populations.</p><p>If you recall, a typical regression equation follows a form similar to this:</p><div class="mediaobject"><img src="graphics/B03905_06_24.jpg" alt="Model specification – adding non-linear relationships"/></div><p>To account for a non-linear relationship, we can add a higher order term to the regression model, treating the model as a polynomial. In effect, we will be modeling a relationship like this:</p><div class="mediaobject"><img src="graphics/B03905_06_25.jpg" alt="Model specification – adding non-linear relationships"/></div><p>The difference between these two models is that an additional beta will be estimated, which is intended to capture the effect of the <span class="emphasis"><em>x</em></span>-squared term. This allows the impact of age to be measured as a function of age squared.</p><p>To add the non-linear age to the model, we simply need to create a new variable:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; insurance$age2 &lt;- insurance$age^2</strong></span>
</pre></div><p>Then, when we produce our improved model, we'll add both <code class="literal">age</code> and <code class="literal">age2</code> to the <code class="literal">lm()</code> formula using the <code class="literal">expenses ~ age + age2</code> form. This will allow the model to separate the linear and non-linear impact of age on medical expenses.</p></div><div class="section" title="Transformation – converting a numeric variable to a binary indicator"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec36"/>Transformation – converting a numeric variable to a binary indicator</h3></div></div></div><p>Suppose we have a <a id="id547" class="indexterm"/>hunch that the effect of a feature is not cumulative, rather it has an effect only after a specific threshold has been reached. For instance, BMI may have zero impact on medical expenditures for individuals in the normal weight range, but it may be strongly related to higher costs for the obese (that is, BMI of 30 or above).</p><p>We can model this relationship by creating a binary obesity indicator variable that is 1 if the BMI is at least 30, and 0 if less. The estimated beta for this binary feature would then indicate the average net impact on medical expenses for individuals with BMI of 30 or above, relative to those with BMI less than 30.</p><p>To create the feature, we can use the <code class="literal">ifelse()</code> function, which for each element in a vector tests a specified condition and returns a value depending on whether the condition is true or false. For BMI greater than or equal to 30, we will return <code class="literal">1</code>, otherwise <code class="literal">0</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; insurance$bmi30 &lt;- ifelse(insurance$bmi &gt;= 30, 1, 0)</strong></span>
</pre></div><p>We can then include the <code class="literal">bmi30</code> variable in our improved model, either replacing the original <code class="literal">bmi</code> variable or in addition, depending on whether or not we think the effect of obesity occurs in addition to a separate linear BMI effect. Without good reason to do otherwise, we'll include both in our final model.</p><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip80"/>Tip</h3><p>If you have trouble <a id="id548" class="indexterm"/>deciding whether or not to include a variable, a common practice is to include it and examine the p-value. If the variable is not statistically significant, you have evidence to support excluding it in the future.</p></div></div></div><div class="section" title="Model specification – adding interaction effects"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec37"/>Model specification – adding interaction effects</h3></div></div></div><p>So far, we <a id="id549" class="indexterm"/>have only considered each feature's individual contribution to the outcome. What if certain features have a combined impact on the dependent variable? For instance, smoking and obesity may have harmful effects separately, but it is reasonable to assume that their combined effect may be worse than the sum of each one alone.</p><p>When two features have a combined effect, this is known as an <span class="strong"><strong>interaction</strong></span>. If we suspect that two variables interact, we can test this hypothesis by adding their interaction to the model. Interaction effects are specified using the R formula syntax. To have the obesity indicator (<code class="literal">bmi30</code>) and the smoking indicator (<code class="literal">smoker</code>) interact, we would write a formula in the form <code class="literal">expenses ~ bmi30*smoker</code>.</p><p>The <code class="literal">*</code> operator is shorthand that instructs R to model <code class="literal">expenses ~ bmi30 + smokeryes + bmi30:smokeryes</code>. The <code class="literal">:</code> (colon) operator in the expanded form indicates that <code class="literal">bmi30:smokeryes</code> is the interaction between the two variables. Note that the expanded <a id="id550" class="indexterm"/>form also automatically included the <code class="literal">bmi30</code> and <code class="literal">smoker</code> variables as well as the interaction.</p><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip81"/>Tip</h3><p>Interactions should never be included in a model without also adding each of the interacting variables. If you always create interactions using the <code class="literal">*</code> operator, this will not be a problem since R will add the required components automatically.</p></div></div></div><div class="section" title="Putting it all together – an improved regression model"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec38"/>Putting it all together – an improved regression model</h3></div></div></div><p>Based on <a id="id551" class="indexterm"/>a bit of subject matter knowledge of how medical costs may be related to patient characteristics, we developed what we think is a more accurately specified regression formula. To summarize the improvements, we:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Added a non-linear term for age</li><li class="listitem" style="list-style-type: disc">Created an indicator for obesity</li><li class="listitem" style="list-style-type: disc">Specified an interaction between obesity and smoking</li></ul></div><p>We'll train the model using the <code class="literal">lm()</code> function as before, but this time we'll add the newly constructed variables and the interaction term:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; ins_model2 &lt;- lm(expenses ~ age + age2 + children + bmi + sex +</strong></span>
<span class="strong"><strong>                     bmi30*smoker + region, data = insurance)</strong></span>
</pre></div><p>Next, we summarize the results:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; summary(ins_model2)</strong></span>
</pre></div><p>The output is shown as follows:</p><div class="mediaobject"><img src="graphics/B03905_06_26.jpg" alt="Putting it all together – an improved regression model"/></div><p>The model fit statistics help to determine whether our changes improved the performance of the regression model. Relative to our first model, the R-squared value has improved from 0.75 to about 0.87. Similarly, the adjusted R-squared value, which takes into account the <a id="id552" class="indexterm"/>fact that the model grew in complexity, also improved from 0.75 to 0.87. Our model is now explaining 87 percent of the variation in medical treatment costs. Additionally, our theories about the model's functional form seem to be validated. The higher-order <code class="literal">age2</code> term is statistically significant, as is the obesity indicator, <code class="literal">bmi30</code>. The interaction between obesity and smoking suggests a massive effect; in addition to the increased costs of over $13,404 for smoking alone, obese smokers spend another $19,810 per year. This may suggest that smoking exacerbates diseases associated with obesity.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note19"/>Note</h3><p>Strictly speaking, regression modeling makes some strong assumptions about the data. These assumptions are not as important for numeric forecasting, as the model's worth is not based upon whether it truly captures the underlying process—we simply care about the accuracy of its predictions. However, if you would like to make firm inferences from the regression model coefficients, it is necessary to run diagnostic tests to ensure that the regression assumptions have not been <a id="id553" class="indexterm"/>violated. For an excellent introduction to this topic, see Allison PD<span class="emphasis"><em>. Multiple regression: A primer</em></span>. Pine Forge Press; 1998.</p></div></div></div></div></div>
<div class="section" title="Understanding regression trees and model trees"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec31"/>Understanding regression trees and model trees</h1></div></div></div><p>If you recall from <a class="link" href="ch05.html" title="Chapter 5. Divide and Conquer – Classification Using Decision Trees and Rules">Chapter 5</a>, <span class="emphasis"><em>Divide and Conquer – Classification Using Decision Trees and Rules</em></span>, a decision tree builds a model much like a flowchart in which decision nodes, leaf nodes, and branches define a series of decisions that are used to classify examples. Such trees can also be used for numeric prediction by making only small adjustments to the tree-growing algorithm. In this section, we will consider only the ways in which trees for numeric prediction differ from trees used for classification.</p><p>Trees for numeric <a id="id554" class="indexterm"/>prediction fall into two categories. The first, known as <span class="strong"><strong>regression trees</strong></span>, were introduced in the 1980s as part of the seminal <span class="strong"><strong>Classification and Regression Tree</strong></span> (<span class="strong"><strong>CART</strong></span>) algorithm. Despite the name, regression trees do not use <a id="id555" class="indexterm"/>linear regression methods as described earlier in this chapter, rather they make predictions based on the average value of examples that reach a leaf.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note20"/>Note</h3><p>The CART algorithm is described in detail in Breiman L, Friedman JH, Stone CJ, Olshen RA. <span class="emphasis"><em>Classification and Regression Trees</em></span>. Belmont, CA: Chapman and Hall; 1984.</p></div></div><p>The second type of trees for numeric prediction are known as <span class="strong"><strong>model trees</strong></span>. Introduced several years later than regression trees, they are lesser-known, but perhaps more powerful. Model trees are grown in much the same way as regression trees, but at each leaf, a multiple <a id="id556" class="indexterm"/>linear regression model is built from the examples reaching that node. Depending on the number of leaf nodes, a model tree may build tens or even hundreds of such models. This may make model trees more difficult to understand than the equivalent regression tree, with the benefit that they may result in a more accurate model.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note21"/>Note</h3><p>The earliest model tree algorithm, <span class="strong"><strong>M5</strong></span>, is described in Quinlan JR. <span class="emphasis"><em>Learning with continuous classes</em></span>. Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. 1992:343-348.</p></div></div><div class="section" title="Adding regression to trees"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec71"/>Adding regression to trees</h2></div></div></div><p>Trees that can <a id="id557" class="indexterm"/>perform numeric prediction offer a compelling yet often <a id="id558" class="indexterm"/>overlooked alternative to regression modeling. The strengths and weaknesses of regression trees and model trees relative to the more common regression methods are listed in the following table:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Strengths</p>
</th><th style="text-align: left" valign="bottom">
<p>Weaknesses</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Combines the strengths of decision trees with the ability to model numeric data</li><li class="listitem" style="list-style-type: disc">Does not require the user to specify the model in advance</li><li class="listitem" style="list-style-type: disc">Uses automatic feature selection, which allows the approach to be used with a very large number of features</li><li class="listitem" style="list-style-type: disc">May fit some types of data much better than linear regression</li><li class="listitem" style="list-style-type: disc">Does not require knowledge of statistics to interpret the model</li></ul></div>
</td><td style="text-align: left" valign="top">
<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Not as well-known as linear regression</li><li class="listitem" style="list-style-type: disc">Requires a large amount of training data</li><li class="listitem" style="list-style-type: disc">Difficult to determine the overall net effect of individual features on the outcome</li><li class="listitem" style="list-style-type: disc">Large trees can become more difficult to interpret than a regression model</li></ul></div>
</td></tr></tbody></table></div><p>Though traditional regression methods are typically the first choice for numeric prediction tasks, in some cases, numeric decision trees offer distinct advantages. For instance, decision trees may be better suited for tasks with many features or many complex, non-linear relationships among features and outcome. These situations present challenges for regression. Regression modeling also makes assumptions about how numeric data is distributed that are often violated in real-world data. This is not the case for trees.</p><p>Trees for numeric prediction are built in much the same way as they are for classification. Beginning at the root node, the data is partitioned using a divide-and-conquer strategy according to the feature that will result in the greatest increase in homogeneity in the outcome after a split is performed. In classification trees, you will recall that homogeneity is measured by entropy, which is undefined for numeric data. Instead, for numeric decision trees, homogeneity is measured by statistics such as variance, standard deviation, or absolute deviation from the mean.</p><p>One common <a id="id559" class="indexterm"/>splitting criterion is called the <span class="strong"><strong>Standard Deviation Reduction</strong></span> (<span class="strong"><strong>SDR</strong></span>). It is defined by the following formula:</p><div class="mediaobject"><img src="graphics/B03905_06_27.jpg" alt="Adding regression to trees"/></div><p>In this formula, the <span class="emphasis"><em>sd(T)</em></span> function refers to the standard deviation of the values in set <span class="emphasis"><em>T</em></span>, while <span class="emphasis"><em>T<sub>1</sub></em></span>, <span class="emphasis"><em>T<sub>2</sub></em></span>, ..., <span class="emphasis"><em>T<sub>n</sub></em></span> are the sets of values resulting from a split on a feature. The <span class="emphasis"><em>|T|</em></span> term refers to the number of <a id="id560" class="indexterm"/>observations in set <span class="emphasis"><em>T</em></span>. Essentially, the formula measures the reduction in standard deviation by comparing the standard deviation <a id="id561" class="indexterm"/>pre-split to the weighted standard deviation post-split.</p><p>For example, consider the following case in which a tree is deciding whether or not to perform a split on binary feature A or B:</p><div class="mediaobject"><img src="graphics/B03905_06_28.jpg" alt="Adding regression to trees"/></div><p>Using the groups that would result from the proposed splits, we can compute the SDR for A and B as follows. The <code class="literal">length()</code> function used here returns the number of elements in a vector. Note that the overall group T is named <code class="literal">tee</code> to avoid overwriting R's built-in <code class="literal">T()</code> and <code class="literal">t()</code> functions:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; tee &lt;- c(1, 1, 1, 2, 2, 3, 4, 5, 5, 6, 6, 7, 7, 7, 7)</strong></span>
<span class="strong"><strong>&gt; at1 &lt;- c(1, 1, 1, 2, 2, 3, 4, 5, 5)</strong></span>
<span class="strong"><strong>&gt; at2 &lt;- c(6, 6, 7, 7, 7, 7)</strong></span>
<span class="strong"><strong>&gt; bt1 &lt;- c(1, 1, 1, 2, 2, 3, 4)</strong></span>
<span class="strong"><strong>&gt; bt2 &lt;- c(5, 5, 6, 6, 7, 7, 7, 7)</strong></span>
<span class="strong"><strong>&gt; sdr_a &lt;- sd(tee) - (length(at1) / length(tee) * sd(at1) +</strong></span>
<span class="strong"><strong>             length(at2) / length(tee) * sd(at2))</strong></span>
<span class="strong"><strong>&gt; sdr_b &lt;- sd(tee) - (length(bt1) / length(tee) * sd(bt1) +</strong></span>
<span class="strong"><strong>             length(bt2) / length(tee) * sd(bt2))</strong></span>
</pre></div><p>Let's compare the SDR of A against the SDR of B:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; sdr_a</strong></span>
<span class="strong"><strong>[1] 1.202815</strong></span>
<span class="strong"><strong>&gt; sdr_b</strong></span>
<span class="strong"><strong>[1] 1.392751</strong></span>
</pre></div><p>The SDR for the split on feature A was about 1.2 versus 1.4 for the split on feature B. Since the standard deviation was reduced more for the split on B, the decision tree would use B first. It results in slightly more homogeneous sets than with A.</p><p>Suppose that the tree stopped growing here using this one and only split. A regression tree's work is done. It <a id="id562" class="indexterm"/>can make predictions for new examples depending on whether the example's value on feature B places the example into group <span class="emphasis"><em>T<sub>1</sub></em></span> or <span class="emphasis"><em>T<sub>2</sub></em></span>. If the example ends up in <span class="emphasis"><em>T<sub>1</sub></em></span>, the model would predict <span class="emphasis"><em>mean(bt1) = 2</em></span>, otherwise it would predict <span class="emphasis"><em>mean(bt2) = 6.25</em></span>.</p><p>In contrast, a model tree <a id="id563" class="indexterm"/>would go one step further. Using the seven training examples falling in group <span class="emphasis"><em>T<sub>1</sub></em></span> and the eight in <span class="emphasis"><em>T<sub>2</sub></em></span>, the model tree could build a linear regression model of the outcome versus feature A. Note that Feature B is of no help in building the regression model because all examples at the leaf have the same value of B—they were placed into <span class="emphasis"><em>T<sub>1</sub></em></span> or <span class="emphasis"><em>T<sub>2</sub></em></span> according to their value of B. The model tree can then make predictions for new examples using either of the two linear models.</p><p>To further illustrate the differences between these two approaches, let's work through a real-world example.</p></div></div>
<div class="section" title="Example &#x2013; estimating the quality of wines with regression trees and model trees"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec32"/>Example – estimating the quality of wines with regression trees and model trees</h1></div></div></div><p>Winemaking <a id="id564" class="indexterm"/>is a challenging and competitive business that offers the potential for great profit. However, there are numerous factors that contribute to the profitability of a winery. As an agricultural product, variables as diverse as the weather and the growing environment impact the quality of a varietal. The bottling and manufacturing can also affect the flavor for better or worse. Even the way the product is marketed, from the bottle design to the price point, can affect the customer's perception of taste.</p><p>As a consequence, the winemaking industry has heavily invested in data collection and machine learning methods that may assist with the decision science of winemaking. For example, machine learning has been used to discover key differences in the chemical composition of wines from different regions, or to identify the chemical factors that lead a wine to taste sweeter.</p><p>More recently, machine learning has been employed to assist with rating the quality of wine—a notoriously difficult task. A review written by a renowned wine critic often determines whether the product ends up on the top or bottom shelf, in spite of the fact that even the expert judges are inconsistent when rating a wine in a blinded test.</p><p>In this case study, we will use regression trees and model trees to create a system capable of mimicking expert ratings of wine. Because trees result in a model that is readily understood, this can <a id="id565" class="indexterm"/>allow the winemakers to identify the key factors that contribute to better-rated wines. Perhaps more importantly, the system does not suffer from the human elements of tasting, such as the rater's mood or palate fatigue. Computer-aided wine testing may therefore result in a better product as well as more objective, consistent, and fair ratings.</p><div class="section" title="Step 1 – collecting data"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec72"/>Step 1 – collecting data</h2></div></div></div><p>To develop <a id="id566" class="indexterm"/>the wine rating <a id="id567" class="indexterm"/>model, we will use data donated to the UCI Machine Learning Data Repository (<a class="ulink" href="http://archive.ics.uci.edu/ml">http://archive.ics.uci.edu/ml</a>) by P. Cortez, A. Cerdeira, F. Almeida, T. Matos, and J. Reis. The data include examples of red and white Vinho Verde wines from Portugal—one of the world's leading wine-producing countries. Because the factors that contribute to a highly rated wine may differ between the red and white varieties, for this analysis we will examine only the more popular white wines.</p><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip82"/>Tip</h3><p>To follow along with this example, download the <code class="literal">whitewines.csv</code> file from the Packt Publishing website and save it to your R working directory. The <code class="literal">redwines.csv</code> file is also available in case you would like to explore this data on your own.</p></div></div><p>The white wine data includes information on 11 chemical properties of 4,898 wine samples. For each wine, a laboratory analysis measured characteristics such as acidity, sugar content, chlorides, sulfur, alcohol, pH, and density. The samples were then rated in a blind tasting by panels of no less than three judges on a quality scale ranging from zero (very bad) to 10 (excellent). In the case of judges disagreeing on the rating, the median value was used.</p><p>The study by Cortez evaluated the ability of three machine learning approaches to model the wine data: multiple regression, artificial neural networks, and support vector machines. We covered multiple regression earlier in this chapter, and we will learn about neural networks and support vector machines in <a class="link" href="ch07.html" title="Chapter 7. Black Box Methods – Neural Networks and Support Vector Machines">Chapter 7</a>, <span class="emphasis"><em>Black Box Methods – Neural Networks and Support Vector Machines</em></span>. The study found that the support vector machine offered significantly better results than the linear regression model. However, unlike regression, the support vector machine model is difficult to interpret. Using regression trees and model trees, we may be able to improve the regression results while still having a model <a id="id568" class="indexterm"/>that is easy to understand.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note22"/>Note</h3><p>To read more about the wine study described here, please refer to Cortez P, Cerdeira A, Almeida F, Matos T, Reis J. <span class="emphasis"><em>Modeling wine preferences by data mining from physicochemical properties</em></span>. Decision Support Systems<span class="emphasis"><em>.</em></span> 2009; 47:547-553.</p></div></div></div><div class="section" title="Step 2 – exploring and preparing the data"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec73"/>Step 2 – exploring and preparing the data</h2></div></div></div><p>As usual, we <a id="id569" class="indexterm"/>will use the <code class="literal">read.csv()</code> function to load the data into R. Since all of the features are numeric, we <a id="id570" class="indexterm"/>can safely ignore the <code class="literal">stringsAsFactors</code> parameter:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; wine &lt;- read.csv("whitewines.csv")</strong></span>
</pre></div><p>The wine data includes 11 features and the quality outcome, as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; str(wine)</strong></span>
<span class="strong"><strong>'data.frame':  4898 obs. of  12 variables:</strong></span>
<span class="strong"><strong> $ fixed.acidity       : num  6.7 5.7 5.9 5.3 6.4 7 7.9 ...</strong></span>
<span class="strong"><strong> $ volatile.acidity    : num  0.62 0.22 0.19 0.47 0.29 0.12 ...</strong></span>
<span class="strong"><strong> $ citric.acid         : num  0.24 0.2 0.26 0.1 0.21 0.41 ...</strong></span>
<span class="strong"><strong> $ residual.sugar      : num  1.1 16 7.4 1.3 9.65 0.9 ...</strong></span>
<span class="strong"><strong> $ chlorides           : num  0.039 0.044 0.034 0.036 0.041 ...</strong></span>
<span class="strong"><strong> $ free.sulfur.dioxide : num  6 41 33 11 36 22 33 17 34 40 ...</strong></span>
<span class="strong"><strong> $ total.sulfur.dioxide: num  62 113 123 74 119 95 152 ...</strong></span>
<span class="strong"><strong> $ density             : num  0.993 0.999 0.995 0.991 0.993 ...</strong></span>
<span class="strong"><strong> $ pH                  : num  3.41 3.22 3.49 3.48 2.99 3.25 ...</strong></span>
<span class="strong"><strong> $ sulphates           : num  0.32 0.46 0.42 0.54 0.34 0.43 ...</strong></span>
<span class="strong"><strong> $ alcohol             : num  10.4 8.9 10.1 11.2 10.9 ...</strong></span>
<span class="strong"><strong> $ quality             : int  5 6 6 4 6 6 6 6 6 7 ...</strong></span>
</pre></div><p>Compared with other types of machine learning models, one of the advantages of trees is that they can handle many types of data without preprocessing. This means we do not need to normalize or standardize the features.</p><p>However, a bit of effort to examine the distribution of the outcome variable is needed to inform our evaluation of the model's performance. For instance, suppose that there was a very little variation in quality from wine-to-wine, or that wines fell into a bimodal distribution: either very good or very bad. To check for such extremes, we can examine the distribution of quality using a histogram:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; hist(wine$quality)</strong></span>
</pre></div><p>This <a id="id571" class="indexterm"/>produces the following figure:</p><div class="mediaobject"><img src="graphics/B03905_06_29.jpg" alt="Step 2 – exploring and preparing the data"/></div><p>The wine quality values appear to follow a fairly normal, bell-shaped distribution, centered around a value of six. This makes sense intuitively because most wines are of average quality; few are particularly bad or good. Although the results are not shown here, it is also useful to examine the <code class="literal">summary(wine)</code> output for outliers or other potential data <a id="id572" class="indexterm"/>problems. Even though trees are fairly robust with messy data, it is always prudent to check for severe problems. For now, we'll assume that the data is reliable.</p><p>Our last step then is to divide into training and testing datasets. Since the <code class="literal">wine</code> data set was already sorted into random order, we can partition into two sets of contiguous rows as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; wine_train &lt;- wine[1:3750, ]</strong></span>
<span class="strong"><strong>&gt; wine_test &lt;- wine[3751:4898, ]</strong></span>
</pre></div><p>In order to mirror the conditions used by Cortez, we used sets of 75 percent and 25 percent for training and testing, respectively. We'll evaluate the performance of our tree-based models <a id="id573" class="indexterm"/>on the testing data <a id="id574" class="indexterm"/>to see if we can obtain results comparable to the prior research study.</p></div><div class="section" title="Step 3 – training a model on the data"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec74"/>Step 3 – training a model on the data</h2></div></div></div><p>We will <a id="id575" class="indexterm"/>begin by training a regression tree model. Although almost any implementation of decision trees can be used to perform regression tree modeling, the <code class="literal">rpart</code> (recursive partitioning) package offers the most faithful implementation of regression trees as they were described by the CART team. As the classic R implementation of CART, the <code class="literal">rpart</code> package is also well-documented and supported with functions for visualizing and evaluating the <code class="literal">rpart</code> models.</p><p>Install the <code class="literal">rpart</code> package using the <code class="literal">install.packages("rpart")</code> command. It can then be loaded into your R session using the <code class="literal">library(rpart)</code> command. The following syntax will train a tree using the default settings, which typically work fairly well. If you need more finely-tuned settings, refer to the documentation for the control parameters using the <code class="literal">?rpart.control</code> command.</p><div class="mediaobject"><img src="graphics/B03905_06_30.jpg" alt="Step 3 – training a model on the data"/></div><p>Using the R <a id="id576" class="indexterm"/>formula interface, we can specify <code class="literal">quality</code> as the outcome variable and use the dot notation to allow all the other columns in the <code class="literal">wine_train</code> data frame to be used as predictors. The resulting regression tree model object is named <code class="literal">m.rpart</code> to distinguish it from the model tree that we will train later:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; m.rpart &lt;- rpart(quality ~ ., data = wine_train)</strong></span>
</pre></div><p>For basic <a id="id577" class="indexterm"/>information about the tree, simply type the name of the model object:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; m.rpart</strong></span>
<span class="strong"><strong>n= 3750</strong></span>

<span class="strong"><strong>node), split, n, deviance, yval</strong></span>
<span class="strong"><strong>      * denotes terminal node</strong></span>

<span class="strong"><strong> 1) root 3750 2945.53200 5.870933  </strong></span>
<span class="strong"><strong>   2) alcohol&lt; 10.85 2372 1418.86100 5.604975  </strong></span>
<span class="strong"><strong>     4) volatile.acidity&gt;=0.2275 1611  821.30730 5.432030  </strong></span>
<span class="strong"><strong>       8) volatile.acidity&gt;=0.3025 688  278.97670 5.255814 *</strong></span>
<span class="strong"><strong>       9) volatile.acidity&lt; 0.3025 923  505.04230 5.563380 *</strong></span>
<span class="strong"><strong>     5) volatile.acidity&lt; 0.2275 761  447.36400 5.971091 *</strong></span>
<span class="strong"><strong>   3) alcohol&gt;=10.85 1378 1070.08200 6.328737  </strong></span>
<span class="strong"><strong>     6) free.sulfur.dioxide&lt; 10.5 84   95.55952 5.369048 *</strong></span>
<span class="strong"><strong>     7) free.sulfur.dioxide&gt;=10.5 1294  892.13600 6.391036  </strong></span>
<span class="strong"><strong>      14) alcohol&lt; 11.76667 629  430.11130 6.173291  </strong></span>
<span class="strong"><strong>        28) volatile.acidity&gt;=0.465 11   10.72727 4.545455 *</strong></span>
<span class="strong"><strong>        29) volatile.acidity&lt; 0.465 618  389.71680 6.202265 *</strong></span>
<span class="strong"><strong>      15) alcohol&gt;=11.76667 665  403.99400 6.596992 *</strong></span>
</pre></div><p>For each node in the tree, the number of examples reaching the decision point is listed. For instance, all 3,750 examples begin at the root node, of which 2,372 have <code class="literal">alcohol &lt; 10.85</code> and 1,378 have <code class="literal">alcohol &gt;= 10.85</code>. Because alcohol was used first in the tree, it is the single most important predictor of wine quality.</p><p>Nodes indicated by <code class="literal">*</code> are terminal or leaf nodes, which means that they result in a prediction (listed here as <code class="literal">yval</code>). For example, node 5 has a <code class="literal">yval</code> of 5.971091. When the tree is used for predictions, any wine samples with <code class="literal">alcohol &lt; 10.85</code> and <code class="literal">volatile.acidity &lt; 0.2275</code> would therefore be predicted to have a quality value of 5.97.</p><p>A more detailed summary of the tree's fit, including the mean squared error for each of the nodes and an overall measure of feature importance, can be obtained using the <code class="literal">summary(m.rpart)</code> command.</p><div class="section" title="Visualizing decision trees"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec39"/>Visualizing decision trees</h3></div></div></div><p>Although <a id="id578" class="indexterm"/>the tree can be understood using only the preceding output, it is often more readily understood using visualization. The <code class="literal">rpart.plot</code> package by Stephen Milborrow provides an easy-to-use function that produces publication-quality decision trees.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note23"/>Note</h3><p>For more information on <code class="literal">rpart.plot</code>, including additional examples of the types of decision <a id="id579" class="indexterm"/>tree diagrams that the function can produce, refer to the author's website at <a class="ulink" href="http://www.milbo.org/rpart-plot/">http://www.milbo.org/rpart-plot/</a>.</p></div></div><p>After installing <a id="id580" class="indexterm"/>the package using the <code class="literal">install.packages("rpart.plot")</code> command, the <code class="literal">rpart.plot()</code> function produces a tree diagram from any <code class="literal">rpart</code> model object. The following commands plot the regression tree we built earlier:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; library(rpart.plot)</strong></span>
<span class="strong"><strong>&gt; rpart.plot(m.rpart, digits = 3)</strong></span>
</pre></div><p>The resulting tree diagram is as follows:</p><div class="mediaobject"><img src="graphics/B03905_06_31.jpg" alt="Visualizing decision trees"/></div><p>In addition to the <code class="literal">digits</code> parameter that controls the number of numeric digits to include in the diagram, many other aspects of the visualization can be adjusted. The following command shows just a few of the useful options: The <code class="literal">fallen.leaves</code> parameter forces the leaf nodes to be aligned at the bottom of the plot, while the <code class="literal">type</code> and <code class="literal">extra</code> parameters affect the way the decisions and nodes are labeled:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; rpart.plot(m.rpart, digits = 4, fallen.leaves = TRUE,</strong></span>
<span class="strong"><strong>             type = 3, extra = 101)</strong></span>
</pre></div><p>The result of <a id="id581" class="indexterm"/>these changes is a very different looking tree diagram:</p><div class="mediaobject"><img src="graphics/B03905_06_32.jpg" alt="Visualizing decision trees"/></div><p>Visualizations like these may assist with the dissemination of regression tree results, as they are readily understood even without a mathematics background. In both cases, the numbers shown in the leaf nodes are the predicted values for the examples reaching that node. Showing the diagram to the wine producers may thus help to identify the key factors that predict the higher rated wines.</p></div></div><div class="section" title="Step 4 – evaluating model performance"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec75"/>Step 4 – evaluating model performance</h2></div></div></div><p>To use the <a id="id582" class="indexterm"/>regression tree model to make predictions on the test data, we use the <code class="literal">predict()</code> function. By default, this returns the estimated numeric value for the outcome variable, which we'll save in a vector named <code class="literal">p.rpart</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; p.rpart &lt;- predict(m.rpart, wine_test)</strong></span>
</pre></div><p>A quick look at the summary statistics of our predictions suggests a potential problem; the predictions fall on a much narrower range than the true values:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; summary(p.rpart)</strong></span>
<span class="strong"><strong>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.</strong></span>
<span class="strong"><strong>  4.545   5.563   5.971   5.893   6.202   6.597</strong></span>
<span class="strong"><strong>&gt; summary(wine_test$quality)</strong></span>
<span class="strong"><strong>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.</strong></span>
<span class="strong"><strong>  3.000   5.000   6.000   5.901   6.000   9.000</strong></span>
</pre></div><p>This finding suggests that the model is not correctly identifying the extreme cases, in particular the <a id="id583" class="indexterm"/>best and worst wines. On the other hand, between the first and third quartile, we may be doing well.</p><p>The correlation between the predicted and actual quality values provides a simple way to gauge the model's performance. Recall that the <code class="literal">cor()</code> function can be used to measure the relationship between two equal-length vectors. We'll use this to compare how well the predicted values correspond to the true values:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; cor(p.rpart, wine_test$quality)</strong></span>
<span class="strong"><strong>[1] 0.5369525</strong></span>
</pre></div><p>A correlation of 0.54 is certainly acceptable. However, the correlation only measures how strongly the predictions are related to the true value; it is not a measure of how far off the predictions were from the true values.</p><div class="section" title="Measuring performance with the mean absolute error"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec40"/>Measuring performance with the mean absolute error</h3></div></div></div><p>Another way to <a id="id584" class="indexterm"/>think about the model's performance is to consider how far, on average, its <a id="id585" class="indexterm"/>prediction was from the true value. This measurement is called the <span class="strong"><strong>mean absolute error</strong></span> (<span class="strong"><strong>MAE</strong></span>). The equation for MAE is as follows, where <span class="emphasis"><em>n</em></span> indicates the number of predictions and <span class="emphasis"><em>e<sub>i</sub></em></span> indicates the error for prediction <span class="emphasis"><em>i</em></span>:</p><div class="mediaobject"><img src="graphics/B03905_06_33.jpg" alt="Measuring performance with the mean absolute error"/></div><p>As the name implies, this equation takes the mean of the absolute value of the errors. Since the error is just the difference between the predicted and actual values, we can create a simple <code class="literal">MAE()</code> function as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; MAE &lt;- function(actual, predicted) {</strong></span>
<span class="strong"><strong>    mean(abs(actual - predicted))</strong></span>
<span class="strong"><strong>}</strong></span>
</pre></div><p>The MAE for our predictions is then:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; MAE(p.rpart, wine_test$quality)</strong></span>
<span class="strong"><strong>[1] 0.5872652</strong></span>
</pre></div><p>This implies that, on average, the difference between our model's predictions and the true quality score was about 0.59. On a quality scale from zero to 10, this seems to suggest that our model is doing fairly well.</p><p>On the other hand, recall that most wines were neither very good nor very bad; the typical quality score was around five to six. Therefore, a classifier that did nothing but predict the mean value may still do fairly well according to this metric.</p><p>The mean quality <a id="id586" class="indexterm"/>rating in the training data is as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; mean(wine_train$quality)</strong></span>
<span class="strong"><strong>[1] 5.870933</strong></span>
</pre></div><p>If we predicted the value 5.87 for every wine sample, we would have a mean absolute error of only about 0.67:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; MAE(5.87, wine_test$quality)</strong></span>
<span class="strong"><strong>[1] 0.6722474</strong></span>
</pre></div><p>Our regression tree (<span class="emphasis"><em>MAE = 0.59</em></span>) comes closer on average to the true quality score than the imputed mean (<span class="emphasis"><em>MAE = 0.67</em></span>), but not by much. In comparison, Cortez reported an MAE of 0.58 for the neural network model and an MAE of 0.45 for the support vector machine. This suggests that there is room for improvement.</p></div></div><div class="section" title="Step 5 – improving model performance"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec76"/>Step 5 – improving model performance</h2></div></div></div><p>To improve the <a id="id587" class="indexterm"/>performance of our learner, let's try to build a model tree. Recall that a model tree improves on regression trees by replacing the leaf nodes with regression models. This often results in more accurate results than regression trees, which use only a single value for prediction at the leaf nodes.</p><p>The current state-of-the-art in model trees is the <span class="strong"><strong>M5' algorithm</strong></span> (<span class="strong"><strong>M5-prime</strong></span>) by Y. Wang and I.H. Witten, which is a variant of the original M5 model tree algorithm proposed by J.R. Quinlan in 1992.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note24"/>Note</h3><p>For more information on the M5' algorithm, see Wang Y, Witten IH. <span class="emphasis"><em>Induction of model trees for predicting continuous classes</em></span>. Proceedings of the Poster Papers of the European Conference on Machine Learning. 1997.</p></div></div><p>The M5 algorithm is <a id="id588" class="indexterm"/>available in R via the <code class="literal">RWeka</code> package and the <code class="literal">M5P()</code> function. The syntax of this function is shown in the following table. Be sure to install the <code class="literal">RWeka</code> package if you haven't already. Because of its dependence on Java, the installation instructions are included in <a class="link" href="ch01.html" title="Chapter 1. Introducing Machine Learning">Chapter 1</a>, <span class="emphasis"><em>Introducing Machine Learning</em></span>.</p><div class="mediaobject"><img src="graphics/B03905_06_34.jpg" alt="Step 5 – improving model performance"/></div><p>We'll fit the model <a id="id589" class="indexterm"/>tree using essentially the same syntax as we used for the regression tree:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; library(RWeka)</strong></span>
<span class="strong"><strong>&gt; m.m5p &lt;- M5P(quality ~ ., data = wine_train)</strong></span>
</pre></div><p>The tree itself can be examined by typing its name. In this case, the tree is very large and only the first few lines of output are shown:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; m.m5p</strong></span>
<span class="strong"><strong>M5 pruned model tree:</strong></span>
<span class="strong"><strong>(using smoothed linear models)</strong></span>

<span class="strong"><strong>alcohol &lt;= 10.85 :</strong></span>
<span class="strong"><strong>|   volatile.acidity &lt;= 0.238 :</strong></span>
<span class="strong"><strong>|   |   fixed.acidity &lt;= 6.85 : LM1 (406/66.024%)</strong></span>
<span class="strong"><strong>|   |   fixed.acidity &gt;  6.85 :</strong></span>
<span class="strong"><strong>|   |   |   free.sulfur.dioxide &lt;= 24.5 : LM2 (113/87.697%)</strong></span>
</pre></div><p>You will note that the splits are very similar to the regression tree that we built earlier. Alcohol is the most important variable, followed by volatile acidity and free sulfur dioxide. A key difference, however, is that the nodes terminate not in a numeric prediction, but a linear model (shown here as <code class="literal">LM1</code> and <code class="literal">LM2</code>).</p><p>The linear models themselves are shown later in the output. For instance, the model for <code class="literal">LM1</code> is shown in the forthcoming output. The <a id="id590" class="indexterm"/>values can be interpreted exactly the same as the multiple regression models we built earlier in this chapter. Each number is the net effect of the associated feature on the predicted wine quality. The coefficient of <code class="literal">0.266</code> for fixed acidity implies that for an increase of 1 unit of acidity, the wine quality is expected to increase by <code class="literal">0.266</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>LM num: 1</strong></span>
<span class="strong"><strong>quality =</strong></span>
<span class="strong"><strong>  0.266 * fixed.acidity</strong></span>
<span class="strong"><strong>  - 2.3082 * volatile.acidity</strong></span>
<span class="strong"><strong>  - 0.012 * citric.acid</strong></span>
<span class="strong"><strong>  + 0.0421 * residual.sugar</strong></span>
<span class="strong"><strong>  + 0.1126 * chlorides</strong></span>
<span class="strong"><strong>  + 0 * free.sulfur.dioxide</strong></span>
<span class="strong"><strong>  - 0.0015 * total.sulfur.dioxide</strong></span>
<span class="strong"><strong>  - 109.8813 * density</strong></span>
<span class="strong"><strong>  + 0.035 * pH</strong></span>
<span class="strong"><strong>  + 1.4122 * sulphates</strong></span>
<span class="strong"><strong>  - 0.0046 * alcohol</strong></span>
<span class="strong"><strong>  + 113.1021</strong></span>
</pre></div><p>It is important to note that the effects estimated by <code class="literal">LM1</code> apply only to wine samples reaching this node; a total of 36 linear models were built in this model tree, each with different estimates of the impact of fixed acidity and the other 10 features.</p><p>For statistics on how well the model fits the training data, the <code class="literal">summary()</code> function can be applied to the M5P model. However, note that since these statistics are based on the training data, they should be used only as a rough diagnostic:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; summary(m.m5p)</strong></span>

<span class="strong"><strong>=== Summary ===</strong></span>

<span class="strong"><strong>Correlation coefficient                  0.6666</strong></span>
<span class="strong"><strong>Mean absolute error                      0.5151</strong></span>
<span class="strong"><strong>Root mean squared error                  0.6614</strong></span>
<span class="strong"><strong>Relative absolute error                 76.4921 %</strong></span>
<span class="strong"><strong>Root relative squared error             74.6259 %</strong></span>
<span class="strong"><strong>Total Number of Instances             3750     </strong></span>
</pre></div><p>Instead, we'll look at <a id="id591" class="indexterm"/>how well the model performs on the unseen test data. The <code class="literal">predict()</code> function gets us a vector of predicted values:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; p.m5p &lt;- predict(m.m5p, wine_test)</strong></span>
</pre></div><p>The model tree appears to be predicting a wider range of values than the regression tree:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; summary(p.m5p)</strong></span>
<span class="strong"><strong>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.</strong></span>
<span class="strong"><strong>  4.389   5.430   5.863   5.874   6.305   7.437</strong></span>
</pre></div><p>The correlation also seems to be substantially higher:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; cor(p.m5p, wine_test$quality)</strong></span>
<span class="strong"><strong>[1] 0.6272973</strong></span>
</pre></div><p>Furthermore, the model has slightly reduced the mean absolute error:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; MAE(wine_test$quality, p.m5p)</strong></span>
<span class="strong"><strong>[1] 0.5463023</strong></span>
</pre></div><p>Although we did not improve a great deal beyond the regression tree, we surpassed the performance of the neural network model published by Cortez, and we are getting closer to the published mean absolute error value of 0.45 for the support vector machine model, all by using a <a id="id592" class="indexterm"/>much simpler learning method.</p><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip83"/>Tip</h3><p>Not surprisingly, we have confirmed that predicting the quality of wines is a difficult problem; wine tasting, after all, is inherently subjective. If you would like additional practice, you may try revisiting this problem after reading <a class="link" href="ch11.html" title="Chapter 11. Improving Model Performance">Chapter 11</a>, <span class="emphasis"><em>Improving Model Performance</em></span>, which covers additional techniques that may lead to better results.</p></div></div></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec33"/>Summary</h1></div></div></div><p>In this chapter, we studied two methods for modeling numeric data. The first method, linear regression, involves fitting straight lines to data. The second method uses decision trees for numeric prediction. The latter comes in two forms: regression trees, which use the average value of examples at leaf nodes to make numeric predictions; and model trees, which build a regression model at each leaf node in a hybrid approach that is, in some ways, the best of both worlds.</p><p>We used linear regression modeling to calculate the expected medical costs for various segments of the population. Because the relationship between the features and the target variable are well-described by the estimated regression model, we were able to identify certain demographics, such as smokers and the obese, who may need to be charged higher insurance rates to cover the higher-than-average medical expenses.</p><p>Regression trees and model trees were used to model the subjective quality of wines from measureable characteristics. In doing so, we learned how regression trees offer a simple way to explain the relationship between features and a numeric outcome, but the more complex model trees may be more accurate. Along the way, we learned several methods for evaluating the performance of numeric models.</p><p>In stark contrast to this chapter, which covered machine learning methods that result in a clear understanding of the relationships between the input and the output, the next chapter covers methods that result in nearly-incomprehensible models. The upside is that they are extremely powerful techniques—among the most powerful stock classifiers—that can be applied to both classification and numeric prediction problems.</p></div></body></html>