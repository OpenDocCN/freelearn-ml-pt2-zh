["```py\n#Build the SVD based Collaborative filter\nfrom surprise import SVD, Reader, Dataset\n\nreader = Reader()\nratings = pd.read_csv('../data/ratings_small.csv')\ndata = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\ndata.split(n_folds=5)\nsvd = SVD()\ntrainset = data.build_full_trainset()\nsvd.train(trainset)\n```", "```py\n#Build title to ID and ID to title mappings\nid_map = pd.read_csv('../data/movie_ids.csv')\nid_to_title = id_map.set_index('id')\ntitle_to_id = id_map.set_index('title')\n```", "```py\ndef hybrid(userId, title):\n    #Extract the cosine_sim index of the movie\n    idx = cosine_sim_map[title]\n\n    #Extract the TMDB ID of the movie\n    tmdbId = title_to_id.loc[title]['id']\n\n    #Extract the movie ID internally assigned by the dataset\n    movie_id = title_to_id.loc[title]['movieId']\n\n    #Extract the similarity scores and their corresponding index for every movie from the cosine_sim matrix\n    sim_scores = list(enumerate(cosine_sim[str(int(idx))]))\n\n    #Sort the (index, score) tuples in decreasing order of similarity scores\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n\n    #Select the top 25 tuples, excluding the first \n    #(as it is the similarity score of the movie with itself)\n    sim_scores = sim_scores[1:26]\n\n    #Store the cosine_sim indices of the top 25 movies in a list\n    movie_indices = [i[0] for i in sim_scores]\n\n    #Extract the metadata of the aforementioned movies\n    movies = smd.iloc[movie_indices][['title', 'vote_count', 'vote_average', 'year', 'id']]\n\n    #Compute the predicted ratings using the SVD filter\n    movies['est'] = movies['id'].apply(lambda x: svd.predict(userId, id_to_title.loc[x]['movieId']).est)\n\n    #Sort the movies in decreasing order of predicted rating\n    movies = movies.sort_values('est', ascending=False)\n\n    #Return the top 10 movies as recommendations\n    return movies.head(10)\n```", "```py\nhybrid(1, 'Avatar')\n```", "```py\nhybrid(2, 'Avatar')\n```"]