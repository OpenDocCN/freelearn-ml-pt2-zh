- en: Chapter 1. Introducing Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If science fiction stories are to be believed, the invention of artificial intelligence
    inevitably leads to apocalyptic wars between machines and their makers. In the
    early stages, computers are taught to play simple games of tic-tac-toe and chess.
    Later, machines are given control of traffic lights and communications, followed
    by military drones and missiles. The machines' evolution takes an ominous turn
    once the computers become sentient and learn how to teach themselves. Having no
    more need for human programmers, humankind is then "deleted."
  prefs: []
  type: TYPE_NORMAL
- en: Thankfully, at the time of this writing, machines still require user input.
  prefs: []
  type: TYPE_NORMAL
- en: Though your impressions of machine learning may be colored by these mass media
    depictions, today's algorithms are too application-specific to pose any danger
    of becoming self-aware. The goal of today's machine learning is not to create
    an artificial brain, but rather to assist us in making sense of the world's massive
    data stores.
  prefs: []
  type: TYPE_NORMAL
- en: Putting popular misconceptions aside, by the end of this chapter, you will gain
    a more nuanced understanding of machine learning. You also will be introduced
    to the fundamental concepts that define and differentiate the most commonly used
    machine learning approaches.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will learn:'
  prefs: []
  type: TYPE_NORMAL
- en: The origins and practical applications of machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How computers turn data into knowledge and action
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to match a machine learning algorithm to your data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The field of machine learning provides a set of algorithms that transform data
    into actionable knowledge. Keep reading to see how easy it is to use R to start
    applying machine learning to real-world problems.
  prefs: []
  type: TYPE_NORMAL
- en: The origins of machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since birth, we are inundated with data. Our body's sensors—the eyes, ears,
    nose, tongue, and nerves—are continually assailed with raw data that our brain
    translates into sights, sounds, smells, tastes, and textures. Using language,
    we are able to share these experiences with others.
  prefs: []
  type: TYPE_NORMAL
- en: From the advent of written language, human observations have been recorded.
    Hunters monitored the movement of animal herds, early astronomers recorded the
    alignment of planets and stars, and cities recorded tax payments, births, and
    deaths. Today, such observations, and many more, are increasingly automated and
    recorded systematically in the ever-growing computerized databases.
  prefs: []
  type: TYPE_NORMAL
- en: The invention of electronic sensors has additionally contributed to an explosion
    in the volume and richness of recorded data. Specialized sensors see, hear, smell,
    taste, and feel. These sensors process the data far differently than a human being
    would. Unlike a human's limited and subjective attention, an electronic sensor
    never takes a break and never lets its judgment skew its perception.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although sensors are not clouded by subjectivity, they do not necessarily report
    a single, definitive depiction of reality. Some have an inherent measurement error,
    due to hardware limitations. Others are limited by their scope. A black and white
    photograph provides a different depiction of its subject than one shot in color.
    Similarly, a microscope provides a far different depiction of reality than a telescope.
  prefs: []
  type: TYPE_NORMAL
- en: 'Between databases and sensors, many aspects of our lives are recorded. Governments,
    businesses, and individuals are recording and reporting information, from the
    monumental to the mundane. Weather sensors record temperature and pressure data,
    surveillance cameras watch sidewalks and subway tunnels, and all manner of electronic
    behaviors are monitored: transactions, communications, friendships, and many others.'
  prefs: []
  type: TYPE_NORMAL
- en: This deluge of data has led some to state that we have entered an era of **Big
    Data**, but this may be a bit of a misnomer. Human beings have always been surrounded
    by large amounts of data. What makes the current era unique is that we have vast
    amounts of *recorded* data, much of which can be directly accessed by computers.
    Larger and more interesting data sets are increasingly accessible at the tips
    of our fingers, only a web search away. This wealth of information has the potential
    to inform action, given a systematic way of making sense from it all.
  prefs: []
  type: TYPE_NORMAL
- en: The field of study interested in the development of computer algorithms to transform
    data into intelligent action is known as **machine learning**. This field originated
    in an environment where available data, statistical methods, and computing power
    rapidly and simultaneously evolved. Growth in data necessitated additional computing
    power, which in turn spurred the development of **statistical methods** to analyze
    large datasets. This created a cycle of advancement, allowing even larger and
    more interesting data to be collected.
  prefs: []
  type: TYPE_NORMAL
- en: '![The origins of machine learning](img/B03905_01_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A closely related sibling of machine learning, **data mining**, is concerned
    with the generation of novel insights from large databases. As the implies, data
    mining involves a systematic hunt for nuggets of actionable intelligence. Although
    there is some disagreement over how widely machine learning and data mining overlap,
    a potential point of distinction is that machine learning focuses on teaching
    computers how to use data to solve a problem, while data mining focuses on teaching
    computers to identify patterns that humans then use to solve a problem.
  prefs: []
  type: TYPE_NORMAL
- en: Virtually all data mining involves the use of machine learning, but not all
    machine learning involves data mining. For example, you might apply machine learning
    to data mine automobile traffic data for patterns related to accident rates; on
    the other hand, if the computer is learning how to drive the car itself, this
    is purely machine learning without data mining.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The phrase "data mining" is also sometimes used as a pejorative to describe
    the deceptive practice of cherry-picking data to support a theory.
  prefs: []
  type: TYPE_NORMAL
- en: Uses and abuses of machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most people have heard of the chess-playing computer **Deep Blue**—the first
    to win a game against a world champion—or **Watson**, the computer that defeated
    two human opponents on the television trivia game show Jeopardy. Based on these
    stunning accomplishments, some have speculated that computer intelligence will
    replace humans in many information technology occupations, just as machines replaced
    humans in the fields, and robots replaced humans on the assembly line.
  prefs: []
  type: TYPE_NORMAL
- en: The truth is that even as machines reach such impressive milestones, they are
    still relatively limited in their ability to thoroughly understand a problem.
    They are pure intellectual horsepower without direction. A computer may be more
    capable than a human of finding subtle patterns in large databases, but it still
    needs a human to motivate the analysis and turn the result into meaningful action.
  prefs: []
  type: TYPE_NORMAL
- en: Machines are not good at asking questions, or even knowing what questions to
    ask. They are much better at answering them, provided the question is stated in
    a way the computer can comprehend. Present-day machine learning algorithms partner
    with people much like a bloodhound partners with its trainer; the dog's sense
    of smell may be many times stronger than its master's, but without being carefully
    directed, the hound may end up chasing its tail.
  prefs: []
  type: TYPE_NORMAL
- en: '![Uses and abuses of machine learning](img/B03905_01_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: To better understand the real-world applications of machine learning, we'll
    now consider some cases where it has been used successfully, some places where
    it still has room for improvement, and some situations where it may do more harm
    than good.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning successes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Machine learning is most successful when it augments rather than replaces the
    specialized knowledge of a subject-matter expert. It works with medical doctors
    at the forefront of the fight to eradicate cancer, assists engineers and programmers
    with our efforts to create smarter homes and automobiles, and helps social scientists
    build knowledge of how societies function. Toward these ends, it is employed in
    countless businesses, scientific laboratories, hospitals, and governmental organizations.
    Any organization that generates or aggregates data likely employs at least one
    machine learning algorithm to help make sense of it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Though it is impossible to list every use case of machine learning, a survey
    of recent success stories includes several prominent applications:'
  prefs: []
  type: TYPE_NORMAL
- en: Identification of unwanted spam messages in e-mail
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Segmentation of customer behavior for targeted advertising
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Forecasts of weather behavior and long-term climate changes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduction of fraudulent credit card transactions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Actuarial estimates of financial damage of storms and natural disasters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prediction of popular election outcomes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Development of algorithms for auto-piloting drones and self-driving cars
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimization of energy use in homes and office buildings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Projection of areas where criminal activity is most likely
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discovery of genetic sequences linked to diseases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this book, you will understand the basic machine learning algorithms
    that are employed to teach computers to perform these tasks. For now, it suffices
    to say that no matter what the context is, the machine learning process is the
    same. Regardless of the task, an algorithm takes data and identifies patterns
    that form the basis for further action.
  prefs: []
  type: TYPE_NORMAL
- en: The limits of machine learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although machine learning is used widely and has tremendous potential, it is
    important to understand its limits. Machine learning, at this time, is not in
    any way a substitute for a human brain. It has very little flexibility to extrapolate
    outside of the strict parameters it learned and knows no common sense. With this
    in mind, one should be extremely careful to recognize exactly what the algorithm
    has learned before setting it loose in the real-world settings.
  prefs: []
  type: TYPE_NORMAL
- en: Without a lifetime of past experiences to build upon, computers are also limited
    in their ability to make simple common sense inferences about logical next steps.
    Take, for instance, the banner advertisements seen on many web sites. These may
    be served, based on the patterns learned by data mining the browsing history of
    millions of users. According to this data, someone who views the websites selling
    shoes should see advertisements for shoes, and those viewing websites for mattresses
    should see advertisements for mattresses. The problem is that this becomes a never-ending
    cycle in which additional shoe or mattress advertisements are served rather than
    advertisements for shoelaces and shoe polish, or bed sheets and blankets.
  prefs: []
  type: TYPE_NORMAL
- en: 'Many are familiar with the deficiencies of machine learning''s ability to understand
    or translate language or to recognize speech and handwriting. Perhaps the earliest
    example of this type of failure is in a 1994 episode of the television show, *The
    Simpsons*, which showed a parody of the Apple Newton tablet. For its time, the
    Newton was known for its state-of-the-art handwriting recognition. Unfortunately
    for Apple, it would occasionally fail to great effect. The television episode
    illustrated this through a sequence in which a bully''s note to **Beat up Martin**
    was misinterpreted by the Newton as **Eat up Martha**, as depicted in the following
    screenshots:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The limits of machine learning](img/B03905_01_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshots from "Lisa on Ice" The Simpsons, 20th Century Fox (1994)
  prefs: []
  type: TYPE_NORMAL
- en: Machines' ability to understand language has improved enough since 1994, such
    that Google, Apple, and Microsoft are all confident enough to offer virtual concierge
    services operated via voice recognition. Still, even these services routinely
    struggle to answer relatively simple questions. Even more, online translation
    services sometimes misinterpret sentences that a toddler would readily understand.
    The predictive text feature on many devices has also led to a number of humorous
    *autocorrect fail* sites that illustrate the computer's ability to understand
    basic language but completely misunderstand context.
  prefs: []
  type: TYPE_NORMAL
- en: Some of these mistakes are to be expected, for sure. Language is complicated
    with multiple layers of text and subtext and even human beings, sometimes, understand
    the context incorrectly. This said, these types of failures in machines illustrate
    the important fact that machine learning is only as good as the data it learns
    from. If the context is not directly implicit in the input data, then just like
    a human, the computer will have to make its best guess.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning ethics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At its core, machine learning is simply a tool that assists us in making sense
    of the world's complex data. Like any tool, it can be used for good or evil. Machine
    learning may lead to problems when it is applied so broadly or callously that
    humans are treated as lab rats, automata, or mindless consumers. A process that
    may seem harmless may lead to unintended consequences when automated by an emotionless
    computer. For this reason, those using machine learning or data mining would be
    remiss not to consider the ethical implications of the art.
  prefs: []
  type: TYPE_NORMAL
- en: Due to the relative youth of machine learning as a discipline and the speed
    at which it is progressing, the associated legal issues and social norms are often
    quite uncertain and constantly in flux. Caution should be exercised while obtaining
    or analyzing data in order to avoid breaking laws, violating terms of service
    or data use agreements, and abusing the trust or violating the privacy of customers
    or the public.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The informal corporate motto of Google, an organization that collects perhaps
    more data on individuals than any other, is "don't be evil." While this seems
    clear enough, it may not be sufficient. A better approach may be to follow the
    *Hippocratic Oath*, a medical principle that states "above all, do no harm."
  prefs: []
  type: TYPE_NORMAL
- en: Retailers routinely use machine learning for advertising, targeted promotions,
    inventory management, or the layout of the items in the store. Many have even
    equipped checkout lanes with devices that print coupons for promotions based on
    the customer's buying history. In exchange for a bit of personal data, the customer
    receives discounts on the specific products he or she wants to buy. At first,
    this appears relatively harmless. But consider what happens when this practice
    is taken a little bit further.
  prefs: []
  type: TYPE_NORMAL
- en: One possibly apocryphal tale concerns a large retailer in the U.S. that employed
    machine learning to identify expectant mothers for coupon mailings. The retailer
    hoped that if these mothers-to-be received substantial discounts, they would become
    loyal customers, who would later purchase profitable items like diapers, baby
    formula, and toys.
  prefs: []
  type: TYPE_NORMAL
- en: Equipped with machine learning methods, the retailer identified items in the
    customer purchase history that could be used to predict with a high degree of
    certainty, not only whether a woman was pregnant, but also the approximate timing
    for when the baby was due.
  prefs: []
  type: TYPE_NORMAL
- en: After the retailer used this data for a promotional mailing, an angry man contacted
    the chain and demanded to know why his teenage daughter received coupons for maternity
    items. He was furious that the retailer seemed to be encouraging teenage pregnancy!
    As the story goes, when the retail chain's manager called to offer an apology,
    it was the father that ultimately apologized because, after confronting his daughter,
    he discovered that she was indeed pregnant!
  prefs: []
  type: TYPE_NORMAL
- en: Whether completely true or not, the lesson learned from the preceding tale is
    that common sense should be applied before blindly applying the results of a machine
    learning analysis. This is particularly true in cases where sensitive information
    such as health data is concerned. With a bit more care, the retailer could have
    foreseen this scenario, and used greater discretion while choosing how to reveal
    the pattern its machine learning analysis had discovered.
  prefs: []
  type: TYPE_NORMAL
- en: Certain jurisdictions may prevent you from using racial, ethnic, religious,
    or other protected class data for business reasons. Keep in mind that excluding
    this data from your analysis may not be enough, because machine learning algorithms
    might inadvertently learn this information independently. For instance, if a certain
    segment of people generally live in a certain region, buy a certain product, or
    otherwise behave in a way that uniquely identifies them as a group, some machine
    learning algorithms can infer the protected information from these other factors.
    In such cases, you may need to fully "de-identify" these people by excluding any
    *potentially* identifying data in addition to the protected information.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from the legal consequences, using data inappropriately may hurt the bottom
    line. Customers may feel uncomfortable or become spooked if the aspects of their
    lives they consider private are made public. In recent years, several high-profile
    web applications have experienced a mass exodus of users who felt exploited when
    the applications' terms of service agreements changed, and their data was used
    for purposes beyond what the users had originally agreed upon. The fact that privacy
    expectations differ by context, age cohort, and locale adds complexity in deciding
    the appropriate use of personal data. It would be wise to consider the cultural
    implications of your work before you begin your project.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The fact that you *can* use data for a particular end does not always mean that
    you *should*.
  prefs: []
  type: TYPE_NORMAL
- en: How machines learn
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A formal definition of machine learning proposed by computer scientist Tom M.
    Mitchell states that a machine learns whenever it is able to utilize its an experience
    such that its performance improves on similar experiences in the future. Although
    this definition is intuitive, it completely ignores the process of exactly how
    experience can be translated into future action—and of course learning is always
    easier said than done!
  prefs: []
  type: TYPE_NORMAL
- en: While human brains are naturally capable of learning from birth, the conditions
    necessary for computers to learn must be made explicit. For this reason, although
    it is not strictly necessary to understand the theoretical basis of learning,
    this foundation helps understand, distinguish, and implement machine learning
    algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As you compare machine learning to human learning, you may discover yourself
    examining your own mind in a different light.
  prefs: []
  type: TYPE_NORMAL
- en: 'Regardless of whether the learner is a human or machine, the basic learning
    process is similar. It can be divided into four interrelated components:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data storage** utilizes observation, memory, and recall to provide a factual
    basis for further reasoning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Abstraction** involves the translation of stored data into broader representations
    and concepts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generalization** uses abstracted data to create knowledge and inferences
    that drive action in new contexts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Evaluation** provides a feedback mechanism to measure the utility of learned
    knowledge and inform potential improvements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following figure illustrates the steps in the learning process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How machines learn](img/B03905_01_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Keep in mind that although the learning process has been conceptualized as four
    distinct components, they are merely organized this way for illustrative purposes.
    In reality, the entire learning process is inextricably linked. In human beings,
    the process occurs subconsciously. We recollect, deduce, induct, and intuit with
    the confines of our mind's eye, and because this process is hidden, any differences
    from person to person are attributed to a vague notion of subjectivity. In contrast,
    with computers these processes are explicit, and because the entire process is
    transparent, the learned knowledge can be examined, transferred, and utilized
    for future action.
  prefs: []
  type: TYPE_NORMAL
- en: Data storage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All learning must begin with data. Humans and computers alike utilize **data
    storage** as a foundation for more advanced reasoning. In a human being, this
    consists of a brain that uses electrochemical signals in a network of biological
    cells to store and process observations for short- and long-term future recall.
    Computers have similar capabilities of short- and long-term recall using hard
    disk drives, flash memory, and random access memory (RAM) in combination with
    a central processing unit (CPU).
  prefs: []
  type: TYPE_NORMAL
- en: It may seem obvious to say so, but the ability to store and retrieve data alone
    is not sufficient for learning. Without a higher level of understanding, knowledge
    is limited exclusively to recall, meaning exclusively what is seen before and
    nothing else. The data is merely ones and zeros on a disk. They are stored memories
    with no broader meaning.
  prefs: []
  type: TYPE_NORMAL
- en: To better understand the nuances of this idea, it may help to think about the
    last time you studied for a difficult test, perhaps for a university final exam
    or a career certification. Did you wish for an eidetic (photographic) memory?
    If so, you may be disappointed to learn that perfect recall is unlikely to be
    of much assistance. Even if you could memorize material perfectly, your rote learning
    is of no use, unless you know in advance the exact questions and answers that
    will appear in the exam. Otherwise, you would be stuck in an attempt to memorize
    answers to every question that could conceivably be asked. Obviously, this is
    an unsustainable strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, a better approach is to spend time selectively, memorizing a small
    set of representative ideas while developing strategies on how the ideas relate
    and how to use the stored information. In this way, large ideas can be understood
    without needing to memorize them by rote.
  prefs: []
  type: TYPE_NORMAL
- en: Abstraction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This work of assigning meaning to stored data occurs during the **abstraction**
    process, in which raw data comes to have a more abstract meaning. This type of
    connection, say between an object and its representation, is exemplified by the
    famous René Magritte painting *The Treachery of Images*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Abstraction](img/B03905_01_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: http://collections.lacma.org/node/239578'
  prefs: []
  type: TYPE_NORMAL
- en: The painting depicts a tobacco pipe with the caption *Ceci n'est pas une pipe*
    ("this is not a pipe"). The point Magritte was illustrating is that a representation
    of a pipe is not truly a pipe. Yet, in spite of the fact that the pipe is not
    real, anybody viewing the painting easily recognizes it as a pipe. This suggests
    that the observer's mind is able to connect the *picture* of a pipe to the *idea*
    of a pipe, to a memory of a *physical* pipe that could be held in the hand. Abstracted
    connections like these are the basis of **knowledge representation**, the formation
    of logical structures that assist in turning raw sensory information into a meaningful
    insight.
  prefs: []
  type: TYPE_NORMAL
- en: During a machine's process of knowledge representation, the computer summarizes
    stored raw data using a **model**, an explicit description of the patterns within
    the data. Just like Magritte's pipe, the model representation takes on a life
    beyond the raw data. It represents an idea greater than the sum of its parts.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many different types of models. You may be already familiar with
    some. Examples include:'
  prefs: []
  type: TYPE_NORMAL
- en: Mathematical equations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Relational diagrams such as trees and graphs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logical if/else rules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Groupings of data known as clusters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The choice of model is typically not left up to the machine. Instead, the learning
    task and data on hand inform model selection. Later in this chapter, we will discuss
    methods to choose the type of model in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: The process of fitting a model to a dataset is known as **training**. When the
    model has been trained, the data is transformed into an abstract form that summarizes
    the original information.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You might wonder why this step is called training rather than learning. First,
    note that the process of learning does not end with data abstraction; the learner
    must still generalize and evaluate its training. Second, the word training better
    connotes the fact that the human teacher trains the machine student to understand
    the data in a specific way.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note that a learned model does not itself provide new data,
    yet it does result in new knowledge. How can this be? The answer is that imposing
    an assumed structure on the underlying data gives insight into the unseen by supposing
    a concept about how data elements are related. Take for instance the discovery
    of gravity. By fitting equations to observational data, Sir Isaac Newton inferred
    the concept of gravity. But the force we now know as gravity was always present.
    It simply wasn't recognized until Newton recognized it as an abstract concept
    that relates some data to others—specifically, by becoming the *g* term in a model
    that explains observations of falling objects.
  prefs: []
  type: TYPE_NORMAL
- en: '![Abstraction](img/B03905_01_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Most models may not result in the development of theories that shake up scientific
    thought for centuries. Still, your model might result in the discovery of previously
    unseen relationships among data. A model trained on genomic data might find several
    genes that, when combined, are responsible for the onset of diabetes; banks might
    discover a seemingly innocuous type of transaction that systematically appears
    prior to fraudulent activity; and psychologists might identify a combination of
    personality characteristics indicating a new disorder. These underlying patterns
    were always present, but by simply presenting information in a different format,
    a new idea is conceptualized.
  prefs: []
  type: TYPE_NORMAL
- en: Generalization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The learning process is not complete until the learner is able to use its abstracted
    knowledge for future action. However, among the countless underlying patterns
    that might be identified during the abstraction process and the myriad ways to
    model these patterns, some will be more useful than others. Unless the production
    of abstractions is limited, the learner will be unable to proceed. It would be
    stuck where it started—with a large pool of information, but no actionable insight.
  prefs: []
  type: TYPE_NORMAL
- en: The term **generalization** describes the process of turning abstracted knowledge
    into a form that can be utilized for future action, on tasks that are similar,
    but not identical, to those it has seen before. Generalization is a somewhat vague
    process that is a bit difficult to describe. Traditionally, it has been imagined
    as a search through the entire set of models (that is, theories or inferences)
    that could be abstracted during training. In other words, if you can imagine a
    hypothetical set containing every possible theory that could be established from
    the data, generalization involves the reduction of this set into a manageable
    number of important findings.
  prefs: []
  type: TYPE_NORMAL
- en: In generalization, the learner is tasked with limiting the patterns it discovers
    to only those that will be most relevant to its future tasks. Generally, it is
    not feasible to reduce the number of patterns by examining them one-by-one and
    ranking them by future utility. Instead, machine learning algorithms generally
    employ shortcuts that reduce the search space more quickly. Toward this end, the
    algorithm will employ **heuristics**, which are educated guesses about where to
    find the most useful inferences.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Because heuristics utilize approximations and other rules of thumb, they do
    not guarantee to find the single best model. However, without taking these shortcuts,
    finding useful information in a large dataset would be infeasible.
  prefs: []
  type: TYPE_NORMAL
- en: Heuristics are routinely used by human beings to quickly generalize experience
    to new scenarios. If you have ever utilized your gut instinct to make a snap decision
    prior to fully evaluating your circumstances, you were intuitively using mental
    heuristics.
  prefs: []
  type: TYPE_NORMAL
- en: The incredible human ability to make quick decisions often relies not on computer-like
    logic, but rather on heuristics guided by emotions. Sometimes, this can result
    in illogical conclusions. For example, more people express fear of airline travel
    versus automobile travel, despite automobiles being statistically more dangerous.
    This can be explained by the availability heuristic, which is the tendency of
    people to estimate the likelihood of an event by how easily its examples can be
    recalled. Accidents involving air travel are highly publicized. Being traumatic
    events, they are likely to be recalled very easily, whereas car accidents barely
    warrant a mention in the newspaper.
  prefs: []
  type: TYPE_NORMAL
- en: The folly of misapplied heuristics is not limited to human beings. The heuristics
    employed by machine learning algorithms also sometimes result in erroneous conclusions.
    The algorithm is said to have a **bias** if the conclusions are systematically
    erroneous, or wrong in a predictable manner.
  prefs: []
  type: TYPE_NORMAL
- en: For example, suppose that a machine learning algorithm learned to identify faces
    by finding two dark circles representing eyes, positioned above a straight line
    indicating a mouth. The algorithm might then have trouble with, or be *biased
    against*, faces that do not conform to its model. Faces with glasses, turned at
    an angle, looking sideways, or with various skin tones might not be detected by
    the algorithm. Similarly, it could be *biased toward* faces with certain skin
    tones, face shapes, or other characteristics that do not conform to its understanding
    of the world.
  prefs: []
  type: TYPE_NORMAL
- en: '![Generalization](img/B03905_01_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In modern usage, the word bias has come to carry quite negative connotations.
    Various forms of media frequently claim to be free from bias, and claim to report
    the facts objectively, untainted by emotion. Still, consider for a moment the
    possibility that a little bias might be useful. Without a bit of arbitrariness,
    might it be a bit difficult to decide among several competing choices, each with
    distinct strengths and weaknesses? Indeed, some recent studies in the field of
    psychology have suggested that individuals born with damage to portions of the
    brain responsible for emotion are ineffectual in decision making, and might spend
    hours debating simple decisions such as what color shirt to wear or where to eat
    lunch. Paradoxically, bias is what blinds us from some information while also
    allowing us to utilize other information for action. It is how machine learning
    algorithms choose among the countless ways to understand a set of data.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Bias is a necessary evil associated with the abstraction and generalization
    processes inherent in any learning task. In order to drive action in the face
    of limitless possibility, each learner must be biased in a particular way. Consequently,
    each learner has its weaknesses and there is no single learning algorithm to rule
    them all. Therefore, the final step in the generalization process is to **evaluate**
    or measure the learner's success in spite of its biases and use this information
    to inform additional training if needed.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Once you''ve had success with one machine learning technique, you might be
    tempted to apply it to everything. It is important to resist this temptation because
    no machine learning approach is the best for every circumstance. This fact is
    described by the *No Free Lunch* theorem, introduced by David Wolpert in 1996\.
    For more information, visit: [http://www.no-free-lunch.org](http://www.no-free-lunch.org).'
  prefs: []
  type: TYPE_NORMAL
- en: Generally, evaluation occurs after a model has been trained on an initial training
    dataset. Then, the model is evaluated on a new test dataset in order to judge
    how well its characterization of the training data generalizes to new, unseen
    data. It's worth noting that it is exceedingly rare for a model to perfectly generalize
    to every unforeseen case.
  prefs: []
  type: TYPE_NORMAL
- en: 'In parts, models fail to perfectly generalize due to the problem of **noise**,
    a term that describes unexplained or unexplainable variations in data. Noisy data
    is caused by seemingly random events, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Measurement error due to imprecise sensors that sometimes add or subtract a
    bit from the readings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Issues with human subjects, such as survey respondents reporting random answers
    to survey questions, in order to finish more quickly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data quality problems, including missing, null, truncated, incorrectly coded,
    or corrupted values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Phenomena that are so complex or so little understood that they impact the data
    in ways that appear to be unsystematic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trying to model noise is the basis of a problem called **overfitting**. Because
    most noisy data is unexplainable by definition, attempting to explain the noise
    will result in erroneous conclusions that do not generalize well to new cases.
    Efforts to explain the noise will also typically result in more complex models
    that will miss the true pattern that the learner tries to identify. A model that
    seems to perform well during training, but does poorly during evaluation, is said
    to be overfitted to the training dataset, as it does not generalize well to the
    test dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '![Evaluation](img/B03905_01_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Solutions to the problem of overfitting are specific to particular machine learning
    approaches. For now, the important point is to be aware of the issue. How well
    the models are able to handle noisy data is an important source of distinction
    among them.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning in practice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So far, we''ve focused on how machine learning works in theory. To apply the
    learning process to real-world tasks, we''ll use a five-step process. Regardless
    of the task at hand, any machine learning algorithm can be deployed by following
    these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data collection**: The data collection step involves gathering the learning
    material an algorithm will use to generate actionable knowledge. In most cases,
    the data will need to be combined into a single source like a text file, spreadsheet,
    or database.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Data exploration and preparation**: The quality of any machine learning project
    is based largely on the quality of its input data. Thus, it is important to learn
    more about the data and its nuances during a practice called data exploration.
    Additional work is required to prepare the data for the learning process. This
    involves fixing or cleaning so-called "messy" data, eliminating unnecessary data,
    and recoding the data to conform to the learner''s expected inputs.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Model training**: By the time the data has been prepared for analysis, you
    are likely to have a sense of what you are capable of learning from the data.
    The specific machine learning task chosen will inform the selection of an appropriate
    algorithm, and the algorithm will represent the data in the form of a model.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Model evaluation**: Because each machine learning model results in a biased
    solution to the learning problem, it is important to evaluate how well the algorithm
    learns from its experience. Depending on the type of model used, you might be
    able to evaluate the accuracy of the model using a test dataset or you may need
    to develop measures of performance specific to the intended application.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Model improvement**: If better performance is needed, it becomes necessary
    to utilize more advanced strategies to augment the performance of the model. Sometimes,
    it may be necessary to switch to a different type of model altogether. You may
    need to supplement your data with additional data or perform additional preparatory
    work as in step two of this process.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After these steps are completed, if the model appears to be performing well,
    it can be deployed for its intended task. As the case may be, you might utilize
    your model to provide score data for predictions (possibly in real time), for
    projections of financial data, to generate useful insight for marketing or research,
    or to automate tasks such as mail delivery or flying aircraft. The successes and
    failures of the deployed model might even provide additional data to train your
    next generation learner.
  prefs: []
  type: TYPE_NORMAL
- en: Types of input data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The practice of machine learning involves matching the characteristics of input
    data to the biases of the available approaches. Thus, before applying machine
    learning to real-world problems, it is important to understand the terminology
    that distinguishes among input datasets.
  prefs: []
  type: TYPE_NORMAL
- en: The phrase **unit of observation** is used to describe the smallest entity with
    measured properties of interest for a study. Commonly, the unit of observation
    is in the form of persons, objects or things, transactions, time points, geographic
    regions, or measurements. Sometimes, units of observation are combined to form
    units such as person-years, which denote cases where the same person is tracked
    over multiple years; each person-year comprises of a person's data for one year.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The unit of observation is related, but not identical, to the **unit of analysis**,
    which is the smallest unit from which the inference is made. Although it is often
    the case, the observed and analyzed units are not always the same. For example,
    data observed from people might be used to analyze trends across countries.
  prefs: []
  type: TYPE_NORMAL
- en: 'Datasets that store the units of observation and their properties can be imagined
    as collections of data consisting of:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Examples**: Instances of the unit of observation for which properties have
    been recorded'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Features**: Recorded properties or attributes of examples that may be useful
    for learning'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is easiest to understand features and examples through real-world cases.
    To build a learning algorithm to identify spam e-mail, the unit of observation
    could be e-mail messages, the examples would be specific messages, and the features
    might consist of the words used in the messages. For a cancer detection algorithm,
    the unit of observation could be patients, the examples might include a random
    sample of cancer patients, and the features may be the genomic markers from biopsied
    cells as well as the characteristics of patient such as weight, height, or blood
    pressure.
  prefs: []
  type: TYPE_NORMAL
- en: While examples and features do not have to be collected in any specific form,
    they are commonly gathered in **matrix format**, which means that each example
    has exactly the same features.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following spreadsheet shows a dataset in matrix format. In matrix data,
    each row in the spreadsheet is an example and each column is a feature. Here,
    the rows indicate examples of automobiles, while the columns record various each
    automobile''s features, such as price, mileage, color, and transmission type.
    Matrix format data is by far the most common form used in machine learning. Though,
    as you will see in the later chapters, other forms are used occasionally in specialized
    cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Types of input data](img/B03905_01_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Features also come in various forms. If a feature represents a characteristic
    measured in numbers, it is unsurprisingly called **numeric**. Alternatively, if
    a feature is an attribute that consists of a set of categories, the feature is
    called **categorical** or **nominal**. A special case of categorical variables
    is called **ordinal**, which designates a nominal variable with categories falling
    in an ordered list. Some examples of ordinal variables include clothing sizes
    such as small, medium, and large; or a measurement of customer satisfaction on
    a scale from "not at all happy" to "very happy." It is important to consider what
    the features represent, as the type and number of features in your dataset will
    assist in determining an appropriate machine learning algorithm for your task.
  prefs: []
  type: TYPE_NORMAL
- en: Types of machine learning algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Machine learning algorithms are divided into categories according to their purpose.
    Understanding the categories of learning algorithms is an essential first step
    towards using data to drive the desired action.
  prefs: []
  type: TYPE_NORMAL
- en: A **predictive model** is used for tasks that involve, as the name implies,
    the prediction of one value using other values in the dataset. The learning algorithm
    attempts to discover and model the relationship between the **target** feature
    (the feature being predicted) and the other features. Despite the common use of
    the word "prediction" to imply forecasting, predictive models need not necessarily
    foresee events in the future. For instance, a predictive model could be used to
    predict past events, such as the date of a baby's conception using the mother's
    present-day hormone levels. Predictive models can also be used in real time to
    control traffic lights during rush hours.
  prefs: []
  type: TYPE_NORMAL
- en: Because predictive models are given clear instruction on what they need to learn
    and how they are intended to learn it, the process of training a predictive model
    is known as **supervised learning**. The supervision does not refer to human involvement,
    but rather to the fact that the target values provide a way for the learner to
    know how well it has learned the desired task. Stated more formally, given a set
    of data, a supervised learning algorithm attempts to optimize a function (the
    model) to find the combination of feature values that result in the target output.
  prefs: []
  type: TYPE_NORMAL
- en: 'The often used supervised machine learning task of predicting which category
    an example belongs to is known as **classification**. It is easy to think of potential
    uses for a classifier. For instance, you could predict whether:'
  prefs: []
  type: TYPE_NORMAL
- en: An e-mail message is spam
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A person has cancer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A football team will win or lose
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An applicant will default on a loan
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In classification, the target feature to be predicted is a categorical feature
    known as the **class**, and is divided into categories called **levels**. A class
    can have two or more levels, and the levels may or may not be ordinal. Because
    classification is so widely used in machine learning, there are many types of
    classification algorithms, with strengths and weaknesses suited for different
    types of input data. We will see examples of these later in this chapter and throughout
    this book.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learners can also be used to predict numeric data such as income,
    laboratory values, test scores, or counts of items. To predict such numeric values,
    a common form of **numeric prediction** fits linear regression models to the input
    data. Although regression models are not the only type of numeric models, they
    are, by far, the most widely used. Regression methods are widely used for forecasting,
    as they quantify in exact terms the association between inputs and the target,
    including both, the magnitude and uncertainty of the relationship.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since it is easy to convert numbers into categories (for example, ages 13 to
    19 are teenagers) and categories into numbers (for example, assign 1 to all males,
    0 to all females), the boundary between classification models and numeric prediction
    models is not necessarily firm.
  prefs: []
  type: TYPE_NORMAL
- en: A **descriptive model** is used for tasks that would benefit from the insight
    gained from summarizing data in new and interesting ways. As opposed to predictive
    models that predict a target of interest, in a descriptive model, no single feature
    is more important than any other. In fact, because there is no target to learn,
    the process of training a descriptive model is called **unsupervised learning**.
    Although it can be more difficult to think of applications for descriptive models—after
    all, what good is a learner that isn't learning anything in particular—they are
    used quite regularly for data mining.
  prefs: []
  type: TYPE_NORMAL
- en: For example, the descriptive modeling task called **pattern discovery** is used
    to identify useful associations within data. Pattern discovery is often used for
    **market basket analysis** on retailers' transactional purchase data. Here, the
    goal is to identify items that are frequently purchased together, such that the
    learned information can be used to refine marketing tactics. For instance, if
    a retailer learns that swimming trunks are commonly purchased at the same time
    as sunglasses, the retailer might reposition the items more closely in the store
    or run a promotion to "up-sell" customers on associated items.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Originally used only in retail contexts, pattern discovery is now starting to
    be used in quite innovative ways. For instance, it can be used to detect patterns
    of fraudulent behavior, screen for genetic defects, or identify hot spots for
    criminal activity.
  prefs: []
  type: TYPE_NORMAL
- en: The descriptive modeling task of dividing a dataset into homogeneous groups
    is called **clustering**. This is sometimes used for **segmentation analysis**
    that identifies groups of individuals with similar behavior or demographic information,
    so that advertising campaigns could be tailored for particular audiences. Although
    the machine is capable of identifying the clusters, human intervention is required
    to interpret them. For example, given five different clusters of shoppers at a
    grocery store, the marketing team will need to understand the differences among
    the groups in order to create a promotion that best suits each group.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, a class of machine learning algorithms known as **meta-learners** is
    not tied to a specific learning task, but is rather focused on learning how to
    learn more effectively. A meta-learning algorithm uses the result of some learnings
    to inform additional learning. This can be beneficial for very challenging problems
    or when a predictive algorithm's performance needs to be as accurate as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Matching input data to algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following table lists the general types of machine learning algorithms covered
    in this book. Although this covers only a fraction of the entire set of machine
    learning algorithms, learning these methods will provide a sufficient foundation
    to make sense of any other method you may encounter in the future.
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Learning task | Chapter |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **Supervised Learning Algorithms** |'
  prefs: []
  type: TYPE_TB
- en: '| Nearest Neighbor | Classification | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| Naive Bayes | Classification | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| Decision Trees | Classification | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| Classification Rule Learners | Classification | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| Linear Regression | Numeric prediction | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| Regression Trees | Numeric prediction | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| Model Trees | Numeric prediction | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| Neural Networks | Dual use | 7 |'
  prefs: []
  type: TYPE_TB
- en: '| Support Vector Machines | Dual use | 7 |'
  prefs: []
  type: TYPE_TB
- en: '| **Unsupervised Learning Algorithms** |'
  prefs: []
  type: TYPE_TB
- en: '| Association Rules | Pattern detection | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| k-means clustering | Clustering | 9 |'
  prefs: []
  type: TYPE_TB
- en: '| **Meta-Learning Algorithms** |'
  prefs: []
  type: TYPE_TB
- en: '| Bagging | Dual use | 11 |'
  prefs: []
  type: TYPE_TB
- en: '| Boosting | Dual use | 11 |'
  prefs: []
  type: TYPE_TB
- en: '| Random Forests | Dual use | 11 |'
  prefs: []
  type: TYPE_TB
- en: 'To begin applying machine learning to a real-world project, you will need to
    determine which of the four learning tasks your project represents: classification,
    numeric prediction, pattern detection, or clustering. The task will drive the
    choice of algorithm. For instance, if you are undertaking pattern detection, you
    are likely to employ association rules. Similarly, a clustering problem will likely
    utilize the k-means algorithm, and numeric prediction will utilize regression
    analysis or regression trees.'
  prefs: []
  type: TYPE_NORMAL
- en: For classification, more thought is needed to match a learning problem to an
    appropriate classifier. In these cases, it is helpful to consider various distinctions
    among algorithms—distinctions that will only be apparent by studying each of the
    classifiers in depth. For instance, within classification problems, decision trees
    result in models that are readily understood, while the models of neural networks
    are notoriously difficult to interpret. If you were designing a credit-scoring
    model, this could be an important distinction because law often requires that
    the applicant must be notified about the reasons he or she was rejected for the
    loan. Even if the neural network is better at predicting loan defaults, if its
    predictions cannot be explained, then it is useless for this application.
  prefs: []
  type: TYPE_NORMAL
- en: To assist with the algorithm selection, in every chapter, the key strengths
    and weaknesses of each learning algorithm are listed. Although you will sometimes
    find that these characteristics exclude certain models from consideration, in
    many cases, the choice of algorithm is arbitrary. When this is true, feel free
    to use whichever algorithm you are most comfortable with. Other times, when predictive
    accuracy is primary, you may need to test several algorithms and choose the one
    that fits the best, or use a meta-learning algorithm that combines several different
    learners to utilize the strengths of each.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning with R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many of the algorithms needed for machine learning with R are not included as
    part of the base installation. Instead, the algorithms needed for machine learning
    are available via a large community of experts who have shared their work freely.
    These must be installed on top of base R manually. Thanks to R's status as free
    open source software, there is no additional charge for this functionality.
  prefs: []
  type: TYPE_NORMAL
- en: A collection of R functions that can be shared among users is called a **package**.
    Free packages exist for each of the machine learning algorithms covered in this
    book. In fact, this book only covers a small portion of all of R's machine learning
    packages.
  prefs: []
  type: TYPE_NORMAL
- en: If you are interested in the breadth of R packages, you can view a list at **Comprehensive
    R Archive Network** (**CRAN**), a collection of web and FTP sites located around
    the world to provide the most up-to-date versions of R software and packages.
    If you obtained the R software via download, it was most likely from CRAN at [http://cran.r-project.org/index.html](http://cran.r-project.org/index.html).
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you do not already have R, the CRAN website also provides installation instructions
    and information on where to find help if you have trouble.
  prefs: []
  type: TYPE_NORMAL
- en: The **Packages** link on the left side of the page will take you to a page where
    you can browse packages in an alphabetical order or sorted by the publication
    date. At the time of writing this, a total 6,779 packages were available—a jump
    of over 60% in the time since the first edition was written, and this trend shows
    no sign of slowing!
  prefs: []
  type: TYPE_NORMAL
- en: The **Task** **Views** link on the left side of the CRAN page provides a curated
    list of packages as per the subject area. The task view for machine learning,
    which lists the packages covered in this book (and many more), is available at
    [http://cran.r-project.org/web/views/MachineLearning.html](http://cran.r-project.org/web/views/MachineLearning.html).
  prefs: []
  type: TYPE_NORMAL
- en: Installing R packages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Despite the vast set of available R add-ons, the package format makes installation
    and use a virtually effortless process. To demonstrate the use of packages, we
    will install and load the `RWeka` package, which was developed by Kurt Hornik,
    Christian Buchta, and Achim Zeileis (see *Open-Source Machine Learning: R Meets
    Weka* in Computational Statistics 24: 225-232 for more information). The `RWeka`
    package provides a collection of functions that give R access to the machine learning
    algorithms in the Java-based Weka software package by Ian H. Witten and Eibe Frank.
    More information on Weka is available at [http://www.cs.waikato.ac.nz/~ml/weka/](http://www.cs.waikato.ac.nz/~ml/weka/).'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To use the `RWeka` package, you will need to have Java installed (many computers
    come with Java preinstalled). Java is a set of programming tools available for
    free, which allow for the use of cross-platform applications such as Weka. For
    more information, and to download Java on your system, you can visit [http://java.com](http://java.com).
  prefs: []
  type: TYPE_NORMAL
- en: 'The most direct way to install a package is via the `install.packages()` function.
    To install the `RWeka` package, at the R command prompt, simply type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: R will then connect to CRAN and download the package in the correct format for
    your OS. Some packages such as `RWeka` require additional packages to be installed
    before they can be used (these are called dependencies). By default, the installer
    will automatically download and install any dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first time you install a package, R may ask you to choose a CRAN mirror.
    If this happens, choose the mirror residing at a location close to you. This will
    generally provide the fastest download speed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The default installation options are appropriate for most systems. However,
    in some cases, you may want to install a package to another location. For example,
    if you do not have root or administrator privileges on your system, you may need
    to specify an alternative installation path. This can be accomplished using the
    `lib` option, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The installation function also provides additional options for installation
    from a local file, installation from source, or using experimental versions. You
    can read about these options in the help file, by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: More generally, the question mark operator can be used to obtain help on any
    R function. Simply type `?` before the name of the function.
  prefs: []
  type: TYPE_NORMAL
- en: Loading and unloading R packages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to conserve memory, R does not load every installed package by default.
    Instead, packages are loaded by users as they are needed, using the `library()`
    function.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The name of this function leads some people to incorrectly use the terms library
    and package interchangeably. However, to be precise, a library refers to the location
    where packages are installed and never to a package itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'To load the `RWeka` package we installed previously, you can type the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Aside from `RWeka`, there are several other R packages that will be used in
    the later chapters. Installation instructions will be provided as additional packages
    are used.
  prefs: []
  type: TYPE_NORMAL
- en: 'To unload an R package, use the `detach()` function. For example, to unload
    the `RWeka` package shown previously use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This will free up any resources used by the package.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Machine learning originated at the intersection of statistics, database science,
    and computer science. It is a powerful tool, capable of finding actionable insight
    in large quantities of data. Still, caution must be used in order to avoid common
    abuses of machine learning in the real world.
  prefs: []
  type: TYPE_NORMAL
- en: Conceptually, learning involves the abstraction of data into a structured representation,
    and the generalization of this structure into action that can be evaluated for
    utility. In practical terms, a machine learner uses data containing examples and
    features of the concept to be learned, and summarizes this data in the form of
    a model, which is then used for predictive or descriptive purposes. These purposes
    can be grouped into tasks, including classification, numeric prediction, pattern
    detection, and clustering. Among the many options, machine learning algorithms
    are chosen on the basis of the input data and the learning task.
  prefs: []
  type: TYPE_NORMAL
- en: R provides support for machine learning in the form of community-authored packages.
    These powerful tools are free to download, but need to be installed before they
    can be used. Each chapter in this book will introduce such packages as they are
    needed.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will further introduce the basic R commands that are
    used to manage and prepare data for machine learning. Though you might be tempted
    to skip this step and jump directly into thick of things, a common rule of thumb
    suggests that 80 percent or more of the time spent on typical machine learning
    projects is devoted to this step. As a result, investing in this early work will
    pay dividends later on.
  prefs: []
  type: TYPE_NORMAL
