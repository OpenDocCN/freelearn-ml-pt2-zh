<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Building a Chatbot</h1>
                </header>
            
            <article>
                
<p><span class="HeaderFooterPACKT">Imagine for a moment that you're sitting alone in a quiet, spacious room. To your right is a small table with a stack of white printer paper and a single black pen. In front of you is what seems to be a large, red cube with a tiny opening—slightly smaller than the size of a mail slot. An inscription just above the slot invites you to write down a question and pass it through the slot. As it happens, you speak Mandarin; so, you write down your question in Mandarin on one of the sheets and insert it into the opening. A few moments pass, and then slowly, an answer emerges. It's also written in Chinese and is the just the sort of answer you might have expected. So, what did you ask? <em>Are you a person or a computer?</em> And the response? <em>Why yes, yes I am</em></span>.</p>
<p><span class="HeaderFooterPACKT">This thought experiment is based on philosopher John Searle's Chinese Room Argument. The premise of the experiment is that if there were a person in the room who spoke no Chinese, but had a set of rules that allowed them to perfectly map English characters to Chinese characters, they could appear to the questioner to understand Chinese without actually having any understanding of it. Searle's argument was that algorithmic procedures that produce an intelligible output can't be said to have an <em>understanding</em> of that output. They lack a <em>mind</em>. His thought experiment was an attempt to combat the ideas of <em>strong AI</em></span>, <span class="HeaderFooterPACKT">or the notion that the human brain is essentially just a <em>wet machine</em>. Searle didn't believe that AI could be said to have consciousness, no matter how sophisticated its behavior appeared to an outside observer.</span></p>
<p><span class="HeaderFooterPACKT">Searle published this experiment in 1980. 31 years later, Siri would be released on the iPhone 4S. For anyone who has used Siri, it's clear that we have a long way to go before we might be confronted with uncertainty of whether the agent we are speaking to has a mind (though we might doubt it in people we know to be human). Despite the clunkiness these agents, or chatbots, have demonstrated in the past, the field is rapidly advancing.</span></p>
<p><span class="HeaderFooterPACKT">In this chapter, we're going to learn how to construct a chatbot from scratch. Along the way, we'll learn more about the history of the field and its future prospects.</span></p>
<p class="mce-root"/>
<p><span class="HeaderFooterPACKT">We'll cover the following topics in this chapter:</span></p>
<ul>
<li>The Turing Test</li>
<li>The history of chatbots</li>
<li>The design of chatbots</li>
<li>Building a chatbot</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Turing Test</h1>
                </header>
            
            <article>
                
<p>30 years before Searle's Chinese Room, Alan Turing posed the question, <em>can machines think?</em> in one of his more famous papers. Being the practical genius he was, he decided not to tackle that question head on, but to instead pose it in the framework of the <em>problem of other minds</em>. This problem asks, <em>how do we truly know that other people have minds like our own?</em> Since we can only observe their behavior—and not the inner workings of their mind—we must take it on faith that they are like us. Turing proposed that if a machine could behave as if it were intelligent, then we should view it as such. This, in a nutshell, is the <em>Turing Test</em>. Passing the test means convincing humans that a machine is a fellow human.</p>
<p>You might be wondering at this point, <em>has a program ever successfully passed the Turing Test?</em> And the answer is that there really is no official Turing Test. The closest thing to an official test is the Loebner Prize. This is a contest held yearly that awards modest prizes to those chatbots that appear the most convincingly human to a panel of judges. If this sounds rigorous and academic, it has been described as anything but. Loebner himself is said to be quite the character, frequently professing his love of wine, marijuana, and prostitutes. His sponsorship for the contest is said to have been a product of his total distain for labor of any kind.</p>
<p>Hopefully, by this point, you'll have realized that any claims about <em>passing the Turing Test </em>are more spectacle than actual science. Despite this, Turing's original concept is a useful construct.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The history of chatbots</h1>
                </header>
            
            <article>
                
<p>I still remember the day my father sat me down in front of his IBM XT with its black-and-green flickering monitor and asked me to talk to <em>it</em>. The conversation went something like the following:</p>
<p><span class="ScreenTextPACKT">&gt;Hello. How are you feeling today?</span></p>
<p><span class="ScreenTextPACKT">&gt;Hi. Who is this?</span></p>
<p><span class="ScreenTextPACKT">&gt;Hi there... How are you today?</span></p>
<p><span class="ScreenTextPACKT">&gt;I'm fine. You didn't tell me who you are.</span></p>
<p><span class="ScreenTextPACKT">&gt;We should be discussing you, not me.</span></p>
<p><span class="ScreenTextPACKT">&gt;We should? Why?</span></p>
<p><span class="ScreenTextPACKT">&gt;Let's change focus a bit... Tell me about your family.</span></p>
<p><span class="ScreenTextPACKT">&gt;You are impossible to have a conversation with.</span></p>
<p><span class="ScreenTextPACKT">&gt;Can you elaborate on that?</span></p>
<p><span class="ScreenTextPACKT">&gt;You are killing me.</span></p>
<p><span class="ScreenTextPACKT">&gt;Perhaps you would like me to be killing you.</span></p>
<p><span class="ScreenTextPACKT">&gt;OK, you are freaking me out.</span></p>
<p><span class="ScreenTextPACKT">&gt;Perhaps you're really talking about yourself?</span></p>
<p><span class="ScreenTextPACKT">&gt;What?? That makes no sense.</span></p>
<p><span class="ScreenTextPACKT">&gt;How would an answer to that help you?</span></p>
<p><span class="ScreenTextPACKT">&gt;END</span></p>
<p><span class="ScreenTextPACKT">&gt;Very interesting.</span></p>
<p><span class="ScreenTextPACKT">&gt;QUIT</span></p>
<p><span class="ScreenTextPACKT">&gt;Thank you for talking with me.</span></p>
<p><span class="ScreenTextPACKT">&gt;#$###$#@@....</span></p>
<p>The <em>it</em> I was talking to was a program called <strong>ELIZA</strong>. Written in the mid-1960s at MIT's Artificial Intelligence Lab by Joseph Weizenbaum, ELIZA was created to mimic the responses of a Rogerian psychotherapist. Though nearly comical when examined in any depth, the program was capable of convincing some users that they were chatting to an actual human—a remarkable feat considering it was a scant 200 lines of code that used randomization and regular expressions to parrot back responses. Even today, this simple program remains a staple of popular culture. If you ask Siri who ELIZA is, she'll tell you she's a friend and a brilliant psychiatrist.</p>
<p>If ELIZA was an early example of chatbots, what have we seen since that time? In recent years, there has been an explosion of new chatbots. The most notable of these is Cleverbot.</p>
<p>Cleverbot was released to the world using the web in 1997. In the years since, the bot has racked up hundreds of millions of conversions, and, unlike early chatbots, Cleverbot, as its name suggests, appears to become more intelligent with each conversion. Though the exact details of the workings of the algorithm are difficult to find, it's said to work by recording all conversations in a database and finding the most appropriate response by identifying the most similar questions and responses in the database.</p>
<p>I made up a nonsensical question, shown as follows, and you can see that it found something similar to the object of my question in terms of a string match:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/c726d9f1-a00b-4a60-a52c-0909e423500b.png" style="width:29.00em;height:15.67em;"/></div>
<p>I persisted:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/1ee74215-5384-4f54-83c4-1c1df46de9ca.png" style="width:28.67em;height:23.33em;"/></div>
<p>And, again, I got something... similar?</p>
<p>You'll also notice that topics can persist across the conversation. In response, I was asked to go into more detail and justify my answer. This is one of the things that appears to make Cleverbot, well, clever.</p>
<p>While chatbots that learn from humans can be quite amusing, they can also have a darker side.</p>
<p>Several years ago, Microsoft released a chatbot named Tay on to Twitter. People were invited to ask Tay questions, and Tay would respond in accordance with her <em>personality</em>. Microsoft had apparently programmed the bot to appear to be a 19-year-old American girl. She was intended to be your virtual <em>bestie</em>; the only problem was that she started tweeting out extremely racist remarks.</p>
<p class="mce-root"/>
<p>As a result of these unbelievably inflammatory tweets, Microsoft was forced to pull Tay off Twitter and issue an apology.</p>
<div class="packt_quote">"As many of you know by now, on Wednesday we launched a chatbot called Tay. We are deeply sorry for the unintended offensive and hurtful tweets from Tay, which do not represent who we are or what we stand for, nor how we designed Tay. Tay is now offline and we'll look to bring Tay back only when we are confident we can better anticipate malicious intent that conflicts with our principles and values."</div>
<div class="packt_quote" style="padding-left: 240px">-March 25, 2016 Official Microsoft Blog</div>
<p>Clearly, brands that want to release chatbots into the wild in the future should take a lesson from this debacle and plan for users to attempt to manipulate them to display the worst of human behavior.</p>
<p>There's no doubt that brands are embracing chatbots. Everyone from Facebook to Taco Bell is getting in on the game.</p>
<p>Witness the TacoBot:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/99d3a529-9e70-49f4-9478-89c70df123e8.png" style="width:41.58em;height:25.75em;"/></div>
<p>Yes, it's a real thing. And, despite the stumbles, like Tay, there's a good chance the future of UI looks a lot like TacoBot. One last example might even help explain why.</p>
<p>Quartz recently launched an app that turns news into a conversation. Rather than lay out the day's stories as a flat list, you are engaged in a chat as if you were getting news from a friend:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/230650be-ef8d-4ccb-b59f-00e15d4e6267.png" style="width:25.50em;height:45.25em;"/></div>
<p>David Gasca, a PM at Twitter, describes his experience using the app in a post on Medium. He describes how the conversational nature invoked feelings normally only triggered in human relationships:</p>
<div class="packt_quote">"Unlike a simple display ad, in a conversational relationship with my app I feel like I owe something to it: I want to click. At the most subconscious level I feel the need to reciprocate and not let the app down: "The app has given me this content. It's been very nice so far and I enjoyed the GIFs. I should probably click since it's asking nicely."</div>
<p>If that experience is universal—and I expect it is—this could be the next big thing in advertising, and I have no doubt that advertising profits will drive UI design:</p>
<div class="packt_quote">"The more the bot acts like a human, the more it will be treated like a human."</div>
<div class="packt_quote" style="padding-left: 180px">-Mat Webb, Technologist and Co-Author of Mind Hacks</div>
<p>At this point, you're probably dying to know how these things work, so let's get on with it!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The design of chatbots</h1>
                </header>
            
            <article>
                
<p>The original ELIZA application was 200-odd lines of code. The Python NLTK implementation is similarly short. An excerpt is provided from NLTK's website (<span class="URLPACKT"><a href="http://www.nltk.org/_modules/nltk/chat/eliza.html">http://www.nltk.org/_modules/nltk/chat/eliza.html</a>):</span></p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1164 image-border" src="assets/cd034e74-d600-432f-8611-380af2fee11e.png" style="width:34.75em;height:50.50em;"/></div>
<p class="mce-root"/>
<p>As you can see from the code, input text was parsed and then matched against a series of regular expressions. Once the input was matched, a randomized response (that sometimes echoed back a portion of the input) was returned. So, something such as, <em>I need a taco</em> would trigger a response of, <em>Would it really help you to get a taco?</em> Obviously, the answer is yes, and, fortunately, we have advanced to the point that technology can provide you one (bless you, TacoBot), but this was early days still. Shockingly, some people actually believed ELIZA was a real human.</p>
<p>But what about more advanced bots? How are they built?</p>
<p>Surprisingly, most chatbots you're likely to encounter aren't even using <strong>machine learning</strong> (<strong>ML</strong>); they're what's known as <strong>retrieval-based</strong> models. This means responses are predefined according to the question and the context. The most common architecture for these bots is something called <strong>Artificial Intelligence Markup Language</strong> (<strong>AIML</strong>). AIML is an XML-based schema for representing how the bot should interact given the user's input. It's really just a more advanced version of how ELIZA works.</p>
<p><span>Let's take a look at how responses are generated using AIML. First, all input are preprocessed to normalize them. This means when you input <em>Waaazzup???</em> it's mapped to <em>WHAT IS UP</em>. This preprocessing step funnels down the myriad ways of saying the same thing into one input that can run against a single rule. Punctuation and other extraneous input are removed as well at this point. Once that's complete, the input is matched against the appropriate rule. The following is a sample template:</span></p>
<pre>&lt;category&gt; 
&lt;pattern&gt;WHAT IS UP&lt;/pattern&gt; 
&lt;template&gt;The sky, duh. Pfft. Humans...&lt;/template&gt; 
&lt;/category&gt; </pre>
<p>That is the basic setup, but you can also layer in wildcards, randomization, and prioritization schemes. For example, the following pattern uses wildcard matching:</p>
<pre>&lt;category&gt; 
&lt;pattern&gt;* FOR ME&lt;pattern&gt; 
&lt;template&gt;I'm a bot. I don't &lt;star/&gt;. Ever.&lt;/template&gt; 
&lt;/category&gt; </pre>
<p>Here, the <kbd>*</kbd> wildcard matches one or more words before <kbd>FOR ME</kbd> and then repeats those back in the output template. If the user were to type in <kbd>Dance for me!</kbd>, the response would be <kbd>I'm a bot. I don't dance. Ever</kbd>.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>As you can see, these rules don't make for anything that approximates any type of real intelligence, but there are a few tricks that strengthen the illusion. One of the better ones is the ability to generate responses conditioned on a topic.</p>
<p>For example, here's a rule that invokes a topic:</p>
<pre>&lt;category&gt; 
&lt;pattern&gt;I LIKE TURTLES&lt;/pattern&gt; 
&lt;template&gt;I feel like this whole &lt;set name="topic"&gt;turtle&lt;/set&gt; thing could be a problem. What do you like about them? &lt;/template&gt; 
&lt;/category&gt; </pre>
<p>Once the topic is set, the rules specific to that context can be matched:</p>
<pre>&lt;topic name="turtles"&gt; 
 
&lt;category&gt; 
&lt;pattern&gt;* SHELL IS *&lt;/pattern&gt; 
&lt;template&gt;I dislike turtles primarily because of their shells. What other creepy things do you like about turtles? &lt;/template&gt; 
&lt;/category&gt; 
 
&lt;category&gt; 
&lt;pattern&gt;* HIDE *&lt;/pattern&gt; 
&lt;template&gt;I wish, like a turtle, that I could hide from this conversation. &lt;/template&gt; 
&lt;/category&gt; 
 
 
&lt;/topic&gt; </pre>
<p>Let's see what this interaction might look like:</p>
<p><span class="ScreenTextPACKT">&gt;I like turtles!</span></p>
<p><span class="ScreenTextPACKT">&gt;I feel like this whole turtle thing could be a problem. What do you like about them?</span></p>
<p><span class="ScreenTextPACKT">&gt;I like how they hide in their shell.</span></p>
<p><span class="ScreenTextPACKT">&gt;I wish, like a turtle, I could hide from this conversation.</span></p>
<p>You can see that the continuity across the conversation adds a measure of realism.</p>
<p>You're probably thinking that this can't be state of the art in this age of deep learning, and you're right. While most bots are rule-based, the next generation of chatbots are emerging, and they're based on neural networks.</p>
<p>In 2015, Oriol Vinyas and Quoc Le of Google published a paper, <a href="https://arxiv.org/pdf/1506.05869v1.pdf" target="_blank"><span class="URLPACKT">http://arxiv.org/pdf/1506.05869v1.pdf</span></a>, that described the construction of a neural network based on sequence-to-sequence models. This type of model maps an input sequence, such as <em>ABC</em>, to and output sequence, such as <em>XYZ</em>. These inputs and outputs might be translations from one language to another, for example. In the case of their work here, the training data was not language translation, but rather tech support transcripts and movie dialogues. While the results from both models are interesting, it was the interactions based on the movie model that stole the headlines.</p>
<p>The following are sample interactions taken from the paper:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/0dce3fa1-0caf-44b3-bfec-863d7afe8cb6.png" style="width:19.75em;height:17.33em;"/></div>
<p>None of this was explicitly encoded by humans or present in the training set as asked, and, yet, looking at this, it's frighteningly like speaking with a human. But let's see more:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/591bc3ed-fb58-47f6-ac3e-77da623bd8ad.png" style="width:19.50em;height:13.08em;"/></div>
<p>Notice that the model is responding with what appears to be knowledge of gender (<strong>he</strong>, <strong>she</strong>), <strong>place</strong> (England), and career (<strong>player</strong>). Even questions of meaning, ethics, and morality are fair game:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/7d841798-609f-4249-8237-a9b8092442e4.png" style="width:20.58em;height:5.58em;"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/7dc81f71-3e26-4ae0-8cd0-2f5652b4ad62.png" style="width:20.58em;height:15.08em;"/></div>
<p>If that transcript doesn't give you a slight chill, there's a chance you might already be some sort of AI.</p>
<p>I wholeheartedly recommend reading the entire paper. It isn't overly technical, and it will definitely give you a glimpse of where the technology is headed.</p>
<p>We've talked a lot about the history, types, and design of chatbots, but let's now move on to building our own. We'll take two approaches to this. This first will use a technique we saw in previously, cosine similarity, and the second will leverage sequence-to-sequence learning.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building a chatbot</h1>
                </header>
            
            <article>
                
<p>Now, having seen what's possible in terms of chatbots, you most likely want to build the best, most state-of-the-art, Google-level bot out there, right? Well, just put that out of your mind for now because we're going start by doing the exact opposite. We're going to build the most amazingly awful bot ever!</p>
<p>This may sound disappointing, but if your goal is just to build something very cool and engaging (that doesn't take hours and hours to construct), this is a great place to start.</p>
<p class="mce-root"/>
<p>We're going to leverage the training data derived from a set of real conversations with Cleverbot. The data was collected from <a href="http://notsocleverbot.jimrule.com" target="_blank"><span class="URLPACKT">http://notsocleverbot.jimrule.com</span></a>. This site is perfect, as it has people submit the most absurd conversations they had with Cleverbot.</p>
<p>Let's take a look at a sample conversation between Cleverbot and a user from the site:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/6d9fb676-13dc-4bb1-b64c-9a172256926b.png" style="width:23.83em;height:27.25em;"/></div>
<p>While you are free to use the techniques for web scraping that we used in earlier chapters to collect the data, you can find a <kbd>.csv</kbd> of the data in the GitHub repo for this chapter.</p>
<p>We'll start again in our Jupyter Notebook. We'll load, parse, and examine the data. We'll first import pandas and the Python regular expressions library, <kbd>re</kbd>. We're also going to set the option in pandas to widen our column width so we can see the data better:</p>
<pre>import pandas as pd 
import re 
pd.set_option('display.max_colwidth',200) </pre>
<p>Now we'll load in our data:</p>
<pre>df = pd.read_csv('nscb.csv') 
df.head() </pre>
<p class="mce-root"/>
<p>The preceding code results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1165 image-border" src="assets/a48abdb7-bcff-42f5-9d55-c7da9f2aed78.png" style="width:71.75em;height:43.42em;"/></div>
<p>Since we're only interested in the first column, the conversation data, we'll parse that out:</p>
<pre>convo = df.iloc[:,0] 
convo </pre>
<p>The preceding code results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1166 image-border" src="assets/63ee8de3-1c46-4190-afb9-bad34daa3a40.png" style="width:83.58em;height:23.25em;"/></div>
<p class="mce-root"/>
<p>You should be able to make out that we have interactions between <strong>User</strong> and <strong>Cleverbot</strong>, and that either can initiate the conversation. To get the data in the format we need, we'll have to parse it into question-and-response pairs. We aren't necessarily concerned with who says what, but with matching up each response to each question. You'll see why in a bit. Let's now do a bit of regular expression magic on the text:</p>
<pre>clist = [] 
def qa_pairs(x): 
    cpairs = re.findall(": (.*?)(?:$|\n)", x) 
    clist.extend(list(zip(cpairs, cpairs[1:]))) 
 
convo.map(qa_pairs); 
convo_frame = pd.Series(dict(clist)).to_frame().reset_index() 
convo_frame.columns = ['q', 'a'] </pre>
<p>The preceding code results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1167 image-border" src="assets/b8069791-f4f5-4908-851f-585e4ef3b2d7.png" style="width:59.33em;height:19.33em;"/></div>
<p>OK, lots of code there. What just happened? We first created a list to hold our question-and-response tuples. We then passed our conversations through a function to split them into those pairs using regular expressions.</p>
<p>Finally, we set it all into a pandas DataFrame with columns labelled <kbd>q</kbd> and <kbd>a</kbd>.</p>
<p>We're now going to apply a bit of algorithm magic to match up the closest question to the one a user inputs:</p>
<pre>from sklearn.feature_extraction.text import TfidfVectorizer 
from sklearn.metrics.pairwise import cosine_similarity 
 
vectorizer = TfidfVectorizer(ngram_range=(1,3)) 
vec = vectorizer.fit_transform(convo_frame['q']) </pre>
<p>In the preceding code, we imported our tf-idf vectorization library and the cosine similarity library. We then used our training data to create a tf-idf matrix. We can now use this to transform our own new questions and measure the similarity to existing questions in our training set. Let's do that now:</p>
<pre>my_q = vectorizer.transform(['Hi. My name is Alex.']) 
 
cs = cosine_similarity(my_q, vec) 
 
rs = pd.Series(cs[0]).sort_values(ascending=False) 
top5 = rs.iloc[0:5] 
top5 </pre>
<p>The preceding code results in the following output:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/66fa20ef-b27f-44e2-8af5-bae861983084.png" style="width:11.25em;height:7.67em;"/></div>
<p>What are we looking at here? This is the cosine similarity between the question I asked and the top-five closest questions. On the left is the index, and on the right is the cosine similarity. Let's take a look at those:</p>
<pre>convo_frame.iloc[top5.index]['q'] </pre>
<p>This results in the following output:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/e0f4a09b-d60c-4db2-a958-9e0b0ee6411a.png" style="width:20.75em;height:7.50em;"/></div>
<p>As you can see, nothing is exactly the same, but there are definitely some similarities.</p>
<p>Let's now take a look at the response:</p>
<pre>rsi = rs.index[0] 
rsi 
 
convo_frame.iloc[rsi]['a'] </pre>
<p>The preceding code results in the following output:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/6f020de1-b522-4912-ba1e-52f45a718d23.png" style="width:20.75em;height:2.25em;"/></div>
<p>OK, so our bot seems to have an attitude already. Let's push further.</p>
<p>We'll create a handy function so that we can test a number of statements easily:</p>
<pre>def get_response(q): 
    my_q = vectorizer.transform([q]) 
    cs = cosine_similarity(my_q, vec) 
    rs = pd.Series(cs[0]).sort_values(ascending=False) 
    rsi = rs.index[0] 
    return convo_frame.iloc[rsi]['a'] 
 
get_response('Yes, I am clearly more clever than you will ever be!') </pre>
<p>This results in the following output:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/c9a792e9-1f44-42d2-946b-9b3736c2d8b0.png" style="width:12.08em;height:2.17em;"/></div>
<p>We have clearly created a monster, so we'll continue:</p>
<pre>get_response('You are a stupid machine. Why must I prove anything to    <br/>              you?') </pre>
<p>This results in the following output:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/9377dd8e-c551-4e69-8e32-709f149a06c1.png" style="width:11.17em;height:1.92em;"/></div>
<p>I'm enjoying this. Let's keep rolling with it:</p>
<pre>get_response('Did you eat tacos?') </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/beab46df-ae86-4fba-9292-b72e5ce81c0d.png" style="width:13.75em;height:2.00em;"/></div>
<pre>get_response('With beans on top?') </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/15082c21-bd1f-4d20-ad70-d46420b6a5db.png" style="width:7.83em;height:2.00em;"/></div>
<pre>get_response('What else do you like to do?') </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/265ec47e-43b4-4108-8508-f84206c682d4.png" style="width:21.00em;height:2.08em;"/></div>
<pre>get_response('What do you like about it?') </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/4b18b671-7d88-47a2-aee5-9ee79c643ede.png" style="width:17.42em;height:2.08em;"/></div>
<pre>get_response('Me, random?') </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/25bd083c-6922-4dd8-a00b-390058199df7.png" style="width:14.25em;height:2.00em;"/></div>
<pre>get_response('I think you mean you\'re') </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/f9571b10-2ff4-4cba-bb2b-d493ba9a961e.png" style="width:11.58em;height:1.92em;"/></div>
<p>Remarkably, this may be one of the best conversations I've had in a while, bot or not.</p>
<p>Now while this was a fun little project, let's now move on to a more advanced modeling technique using sequence-to-sequence modeling.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sequence-to-sequence modeling for chatbots</h1>
                </header>
            
            <article>
                
<p><span>For this next task, we'll leverage a couple libraries discussed in <a href="5df6fae8-a5c0-4fab-8508-baef0085b4f5.xhtml" target="_blank">Chapter 8</a>, <em>Classifying Images with Convolutional Neural Networks</em></span>, <span><span class="KeyWordPACKT">TensorFlow</span> and <span class="KeyWordPACKT">Keras</span>. Both can be <kbd>pip</kbd> installed if you haven't done that already.</span></p>
<p class="mce-root"/>
<p>We're also going to use the type of advanced modeling discussed earlier in the chapter; it's a type of deep learning called <strong>sequence-to-sequence modeling</strong>. This is frequently used in machine translation and question-answering applications, as it allows us to map an input sequence of any length to an output sequence of any length:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/2b04592c-6902-4403-870e-4266daf360c7.png" style="width:31.08em;height:10.50em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Source: https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html</div>
<p>Francois Chollet has an excellent introduction to this type of model on the blog for Keras: <a href="https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html"><span class="URLPACKT">https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html</span></a>. It's worth a read.</p>
<p>We're going to make heavy use of his example code to build out our model. While his example uses machine translation, English to French, we're going to repurpose it for question-answering using our Cleverbot dataset:</p>
<ol>
<li>Set the imports:</li>
</ol>
<pre style="padding-left: 60px">from keras.models import Model 
from keras.layers import Input, LSTM, Dense 
import numpy as np </pre>
<ol start="2">
<li>Set up the training parameters:</li>
</ol>
<pre style="padding-left: 60px">batch_size = 64  # Batch size for training. 
epochs = 100  # Number of epochs to train for. 
latent_dim = 256  # Latent dimensionality of the encoding space. 
num_samples = 1000  # Number of samples to train on. </pre>
<p>We'll use these to start. We can examine the success of our model and then adjust as necessary.</p>
<p>The first step in data processing will be to take our data, get it in the proper format, and then vectorize it. We'll go step by step:</p>
<pre>input_texts = [] 
target_texts = [] 
input_characters = set() 
target_characters = set() </pre>
<p>This creates lists for our questions and answers (the targets) as well as sets for the individual characters in our questions and answers. This model will actually work by generating one character at a time:</p>
<ol>
<li>Let's limit our question-and-answer pairs to 50 characters or fewer. This will help speed up our training:</li>
</ol>
<pre style="padding-left: 60px">convo_frame['q len'] = convo_frame['q'].astype('str').apply(lambda  <br/>                       x: len(x)) 
convo_frame['a len'] = convo_frame['a'].astype('str').apply(lambda <br/>                       x: len(x)) 
convo_frame = convo_frame[(convo_frame['q len'] &lt; 50)&amp;<br/>                          (convo_frame['a len'] &lt; 50)] </pre>
<ol start="2">
<li>Let's set up our input and target text lists:</li>
</ol>
<pre style="padding-left: 60px">input_texts = list(convo_frame['q'].astype('str')) 
target_texts = list(convo_frame['a'].map(lambda x: '\t' + x + <br/>                    '\n').astype('str')) </pre>
<p>The preceding code gets our data in the proper format. Note that we add a tab (<kbd>\t</kbd>) and a newline (<kbd>\n</kbd>) character to the target texts. This will serve as our start and stop tokens for the decoder.</p>
<ol start="3">
<li>Let's take a look at the input texts and the target texts:</li>
</ol>
<pre style="padding-left: 60px">input_texts </pre>
<p>The preceding code generates the following output:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/3318e65a-0fc7-4a07-8620-8d81902c6079.png" style="width:37.33em;height:13.00em;"/></div>
<pre>target_texts </pre>
<p>The preceding code generates the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1191 image-border" src="assets/0e4cad67-bd2e-41bf-a7d0-19bb870fe629.png" style="width:36.42em;height:14.50em;"/></div>
<p>Let's take a look at those input and target-character sets now:</p>
<pre>input_characters </pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The preceding code generates the following output:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/32be9bf4-34e1-4e41-bc29-af5e999cf409.png" style="width:5.17em;height:23.00em;"/></div>
<pre>target_characters </pre>
<p>The preceding code generates the following output:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/a1f54278-2513-40d3-ae69-42a7a06014d5.png" style="width:4.75em;height:22.75em;"/></div>
<p class="mce-root"/>
<p>Next, we'll do some additional preparation for the data that will feed into the model. Although data can be fed in any length and returned in any length, we need to add padding up to the max length of the data for the model to work:</p>
<pre>input_characters = sorted(list(input_characters)) 
target_characters = sorted(list(target_characters)) 
num_encoder_tokens = len(input_characters) 
num_decoder_tokens = len(target_characters) 
max_encoder_seq_length = max([len(txt) for txt in input_texts]) 
max_decoder_seq_length = max([len(txt) for txt in target_texts]) 
 
print('Number of samples:', len(input_texts)) 
print('Number of unique input tokens:', num_encoder_tokens) 
print('Number of unique output tokens:', num_decoder_tokens) 
print('Max sequence length for inputs:', max_encoder_seq_length) 
print('Max sequence length for outputs:', max_decoder_seq_length) </pre>
<p>The preceding code generates the following output:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/34094ae5-2198-4796-afd4-066b044361a9.png" style="width:22.08em;height:6.67em;"/></div>
<p>Next, we'll vectorize our data using one-hot encoding:</p>
<pre>input_token_index = dict( 
    [(char, i) for i, char in enumerate(input_characters)]) 
target_token_index = dict( 
    [(char, i) for i, char in enumerate(target_characters)]) 
 
encoder_input_data = np.zeros( 
    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), 
    dtype='float32') 
decoder_input_data = np.zeros( 
    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), 
    dtype='float32') 
decoder_target_data = np.zeros( 
    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), 
    dtype='float32') 
 
for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)): 
    for t, char in enumerate(input_text): 
        encoder_input_data[i, t, input_token_index[char]] = 1. 
    for t, char in enumerate(target_text): 
        # decoder_target_data is ahead of decoder_input_data by one <br/>        # timestep 
        decoder_input_data[i, t, target_token_index[char]] = 1. 
        if t &gt; 0: 
            # decoder_target_data will be ahead by one timestep 
            # and will not include the start character. 
            decoder_target_data[i, t - 1, target_token_index[char]] = <br/>                                1. </pre>
<p>Let's take a look at one of these vectors:</p>
<pre>Decoder_input_data </pre>
<p>The preceding code generates the following output:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/bc180728-de1a-4d09-bc5d-68c4f6a3e34b.png" style="width:22.58em;height:12.92em;"/></div>
<p>From the preceding figure, you'll notice that we have a one-hot encoded vector of our character data, which will be used in our model.</p>
<p>We now set up our sequence-to-sequence model-encoder and -decoder LSTMs:</p>
<pre># Define an input sequence and process it. 
encoder_inputs = Input(shape=(None, num_encoder_tokens)) 
encoder = LSTM(latent_dim, return_state=True) 
encoder_outputs, state_h, state_c = encoder(encoder_inputs) 
# We discard `encoder_outputs` and only keep the states. 
encoder_states = [state_h, state_c] 
 
# Set up the decoder, using `encoder_states` as initial state. 
decoder_inputs = Input(shape=(None, num_decoder_tokens)) 
 
# We set up our decoder to return full output sequences, 
# and to return internal states as well. We don't use the 
# return states in the training model, but we will use them in  <br/># inference. 
decoder_lstm = LSTM(latent_dim, return_sequences=True,  <br/>               return_state=True) 
decoder_outputs, _, _ = decoder_lstm(decoder_inputs, 
                                     initial_state=encoder_states) 
decoder_dense = Dense(num_decoder_tokens, activation='softmax') 
decoder_outputs = decoder_dense(decoder_outputs) </pre>
<p>Then we move on to the model itself:</p>
<pre># Define the model that will turn 
# `encoder_input_data` &amp; `decoder_input_data` into `decoder_target_data` 
model = Model([encoder_inputs, decoder_inputs], decoder_outputs) 
 
# Run training 
model.compile(optimizer='rmsprop', loss='categorical_crossentropy') 
model.fit([encoder_input_data, decoder_input_data], <br/>           decoder_target_data, 
           batch_size=batch_size, 
           epochs=epochs, 
           validation_split=0.2) 
# Save model 
model.save('s2s.h5') </pre>
<p>In the preceding code, we defined our model using our encoder and decoder input and our decoder output. We then compile it, fit it, and save it.</p>
<p>We set up the model to use 1,000 samples. Here, we also split the data 80/20 to training and validation, respectively. We also set our epochs at 100, so this will essentially run for 100 cycles. On a standard MacBook Pro, this may take around an hour to complete.</p>
<p>Once that cell is run, the following output will be generated:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/ad208163-5986-4a4d-b6d4-95b800737727.png" style="width:48.42em;height:18.50em;"/></div>
<p>The next step is our inference step. We'll use the states generated from this model to feed into our next model to generate our output:</p>
<pre># Next: inference mode (sampling). 
# Here's the drill: 
# 1) encode input and retrieve initial decoder state 
# 2) run one step of decoder with this initial state 
# and a "start of sequence" token as target. 
# Output will be the next target token 
# 3) Repeat with the current target token and current states 
 
# Define sampling models 
encoder_model = Model(encoder_inputs, encoder_states) 
 
decoder_state_input_h = Input(shape=(latent_dim,)) 
decoder_state_input_c = Input(shape=(latent_dim,)) 
decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c] 
decoder_outputs, state_h, state_c = decoder_lstm( 
    decoder_inputs, initial_state=decoder_states_inputs) 
decoder_states = [state_h, state_c] 
decoder_outputs = decoder_dense(decoder_outputs) 
decoder_model = Model( 
    [decoder_inputs] + decoder_states_inputs, 
    [decoder_outputs] + decoder_states) 
 
# Reverse-lookup token index to decode sequences back to 
# something readable. 
reverse_input_char_index = dict( 
    (i, char) for char, i in input_token_index.items()) 
reverse_target_char_index = dict( 
    (i, char) for char, i in target_token_index.items()) 
 
 
def decode_sequence(input_seq): 
    # Encode the input as state vectors. 
    states_value = encoder_model.predict(input_seq) 
 
    # Generate empty target sequence of length 1. 
    target_seq = np.zeros((1, 1, num_decoder_tokens)) 
    # Populate the first character of target sequence with the start character. 
    target_seq[0, 0, target_token_index['\t']] = 1. 
 
    # Sampling loop for a batch of sequences 
    # (to simplify, here we assume a batch of size 1). 
    stop_condition = False 
    decoded_sentence = '' 
    while not stop_condition: 
        output_tokens, h, c = decoder_model.predict( 
            [target_seq] + states_value) 
 
        # Sample a token 
        sampled_token_index = np.argmax(output_tokens[0, -1, :]) 
        sampled_char = reverse_target_char_index[sampled_token_index] 
        decoded_sentence += sampled_char 
 
        # Exit condition: either hit max length 
        # or find stop character. 
        if (sampled_char == '\n' or 
           len(decoded_sentence) &gt; max_decoder_seq_length): 
            stop_condition = True 
 
        # Update the target sequence (of length 1). 
        target_seq = np.zeros((1, 1, num_decoder_tokens)) 
        target_seq[0, 0, sampled_token_index] = 1. 
 
        # Update states 
        states_value = [h, c] 
 
    return decoded_sentence 
 
 
for seq_index in range(100): 
    # Take one sequence (part of the training set) 
    # for trying out decoding. 
    input_seq = encoder_input_data[seq_index: seq_index + 1] 
    decoded_sentence = decode_sequence(input_seq) 
    print('-') 
    print('Input sentence:', input_texts[seq_index]) 
    print('Decoded sentence:', decoded_sentence) </pre>
<p>The preceding code generates the following output:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/57a91f41-a7da-468e-a92a-7589eb73593c.png" style="width:32.50em;height:22.17em;"/></div>
<p>As you can see, the results of our model are quite repetitive. But then we only used 1,000 samples and the responses were generated one character at a time, so this is actually fairly impressive.</p>
<p>If you want better results, rerun the model using more sample data and more epochs.</p>
<p>Here, I have provide some of the more humorous output I've noted from much longer training periods:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/e99022f7-f9da-4cf0-8a12-fb58d03c72ff.png" style="width:36.17em;height:3.67em;"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/6936b02e-4137-4c66-ad25-1e9291112554.png" style="width:24.42em;height:3.42em;"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/7ed8edd3-c574-482d-9d93-d184a8e3f59e.png" style="width:42.67em;height:3.42em;"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/4096f414-dfd7-46c7-a6e0-efb90b3712bd.png" style="width:38.75em;height:3.08em;"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/78e8de23-1a8e-488e-b326-a2e01a4bbf44.png" style="width:21.00em;height:3.33em;"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/c60b8d01-7f73-4862-b039-3ae1cbcea5c3.png" style="width:20.08em;height:3.33em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we took a full tour of the chatbot landscape. It's clear that we're on the cusp of an explosion of these types of applications. The <em>Conversational UI</em> revolution is just about to begin. Hopefully, this chapter has inspired you to create your own bot, but if not, we hope you have a much richer understanding of how these applications work and how they'll shape our future.</p>
<p>I'll let the app say the final words:</p>
<pre>get_response("This is the end, Cleverbot. Say goodbye.") </pre>


            </article>

            
        </section>
    </body></html>