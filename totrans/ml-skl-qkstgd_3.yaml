- en: Predicting Categories with Logistic Regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The logistic regression algorithm is one of the most interpretable algorithms
    in the world of machine learning, and although the word "regression" implies predicting
    a numerical outcome, the logistic regression algorithm is, used to predict categories
    and solve classification machine learning problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will learn about the following:'
  prefs: []
  type: TYPE_NORMAL
- en: How the logistic regression algorithm works mathematically
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing and evaluating your first logistic regression algorithm with scikit-learn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fine-tuning the hyperparameters using `GridSearchCV`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling your data for a potential improvement in accuracy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interpreting the results of the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logistic regression has a wide range of applications, especially in the field
    of finance, where building interpretable machine learning models is key in convincing
    both investors and regulators alike that your model makes intuitive and logical
    sense.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will be required to have Python 3.6 or greater, Pandas ≥ 0.23.4, Scikit-learn
    ≥ 0.20.0, and Matplotlib ≥ 3.0.0 installed on your system.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code files of this chapter can be found on GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Machine-Learning-with-scikit-learn-Quick-Start-Guide/blob/master/Chapter_03.ipynb](https://github.com/PacktPublishing/Machine-Learning-with-scikit-learn-Quick-Start-Guide/blob/master/Chapter_03.ipynb)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the code in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://bit.ly/2DaTNgQ](http://bit.ly/2DaTNgQ)'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding logistic regression mathematically
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As the name implies, logistic regression is fundamentally derived from the
    linear regression algorithm. The linear regression algorithm will be discussed
    in depth in the upcoming chapters. For now, let''s consider a hypothetical case
    in which we want to predict the probability that a particular loan will default
    based on the loan''s interest rate. Using linear regression, the following equation
    can be constructed:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Default = (Interest Rate × x) + c`'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding equation, *c* is the intercept and *x* is a coefficient that
    will be the output from the logistic regression model. The intercept and the coefficient
    will have numeric values. For the purpose of this example, let''s assume *c* is
    5 and *x* is -0.2\. The equation now becomes this:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Default = (Interest Rate × -0.2) + 5`'
  prefs: []
  type: TYPE_NORMAL
- en: 'The equation can be represented in a two-dimensional plot using the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/62295c65-377b-4206-a2a8-cc7052c49232.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Assuming that the interest rate is 10%, the value of default produced by the
    equation is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Default = (10 × -0.2) + 5*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Default = 3*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The logistic regression model now uses the `logit` function to transform this
    value of 3 into a probability between 0 and 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8355ffed-7009-4f68-b1c7-896eba1d6313.png)'
  prefs: []
  type: TYPE_IMG
- en: After evaluating the preceding equation, we get an answer of 0.95\. In other
    words, using the logistic regression model that we just built mathematically,
    we obtained a probability of 95% that the loan would default if the interest rate
    was 10%.
  prefs: []
  type: TYPE_NORMAL
- en: 'After applying the `logit` function to the linear equation, the two-dimensional
    plot shown previously changes to the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding diagram, the following is happening:'
  prefs: []
  type: TYPE_NORMAL
- en: The function approaches 1 as the interest rate nears infinity along the *x*-axis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The function approaches 0 as the interest rate nears 0 along the *x*-axis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing logistic regression using scikit-learn
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, you will learn how you can implement and quickly evaluate
    a logistic regression model for your dataset. We will be using the same dataset
    that we have already cleaned and prepared for the purpose of predicting whether
    a particular transaction was fraudulent. In the previous chapter, we saved this
    dataset as `fraud_detection.csv`. The first step is to load this dataset into
    your Jupyter Notebook. This can be done by using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Splitting the data into training and test sets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first step to building any machine learning model with scikit-learn is
    to split the data into training and test sets. This can be done by using the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to implement a base logistic regression classifier and evaluate
    its accuracy score. This can be done by using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, the `linear_model`package is imported from `sklearn`
    and is used to initialize the logistic regression algorithm by calling the `LogisticRegression()`method.
    This logistic regression algorithm is then fit into the training data.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to extract the accuracy score, we use the following code on the test
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This model has produced an accuracy of 58.9% on the test data. This means that
    the base logistic regression model only performs slightly better than an algorithm
    that randomly guesses the output.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning the hyperparameters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From the output of the logistic regression model implemented in the preceding
    section, it is clear that the model performs slightly better than random guessing.
    Such a model fails to provide value to us. In order to optimize the model, we
    are going to optimize the hyperparameters of the logistic regression model by
    using the `GridSearchCV` algorithm that we used in the previous chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The hyperparameter that is used by the logistic regression model is known as
    the inverse regularization strength. This is because we are implementing a type
    of linear regression known as **l1** regression. This type of linear regression
    will explained in detail in [Chapter 5](589b9373-c8dd-4243-aec8-9d6c4851f987.xhtml),
    *Predicting Numeric Outcomes with Linear Regression*.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to optimize the inverse regularization strength, or **C** as it is
    called in short, we use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces an output as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2c9f6a51-729a-4cab-99c4-ba716af3bc17.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding code, we first initialize a logistic regression model with
    the penalty argument set to **l1**, indicating that we are using **l1** regression.
    We then initialize a grid with the possible values of inverse regularization strengths
    that go from 0.0001 to 10\.
  prefs: []
  type: TYPE_NORMAL
- en: The number of values that you initialize in a grid object for the hyperparameter
    of a model is arbitrary. However, the more values, the longer it takes for `GridSearchCV`
    to give you the optimal value of the hyperparameter, therby making the process
    computationally expensive.
  prefs: []
  type: TYPE_NORMAL
- en: 'The grid object with the possible values of the inverse regularization strengths
    are then fit into the training data and the optimal value is printed out, which
    in this case is 10\. We can now build a new logistic regression model with this
    newly obtained optimal hyperparameter value by using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Evaluating the model on the test data by using the following code, we obtain
    an accuracy score of 99.6%! That's quite the improvement.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'One way to check whether `GridSearchCV` is giving us accurate results is to
    plot the accuracy scores along the *y*-axis for different values of the inverse
    regularization strengths along the x-axis. This can be done by using the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in a plot as illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/822b690d-6fec-4165-9de9-1df7f8a6939b.png)'
  prefs: []
  type: TYPE_IMG
- en: From the preceding plot, it is clear that an inverse regularization strength
    of 10 provides a high value of accuracy for both the training and testing sets.
    Such plots are also used to determine whether a particular value of the hyperparameter
    is overfitting the data by giving us a high accuracy score on the training set,
    but low accuracy scores on the test set. Conversely, they can also be used to
    check whether a model is undercutting the data by giving us low values of accuracy
    on the training set itself.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Although the model has performed extremely well, scaling the data is still
    a useful step in building machine learning models with logistic regression, as
    it standardizes your data across the same range of values. In order to scale your
    data, we will use the same `StandardScaler()`function that we used in the previous
    chapter. This is done by using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code resulted in the improvement in the accuracy score of the
    model by 0.1%, which is good considering how the model had a very high accuracy
    score in the first place. The code is similar to the pipeline for scaling we built
    in the previous chapter for the k-NN algorithm, and there are no changes except
    for the fact that we have used a logistic regression model instead of the k-NN
    model.
  prefs: []
  type: TYPE_NORMAL
- en: Interpreting the logistic regression model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the key benefits of the logistic regression algorithm is that it is highly
    interpretable. This means that the outcome of the model can be interpreted as
    a function of the input variables. This allows us to understand how each variable
    contributes to the eventual outcome of the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the first section, we understood that the logistic regression model consists
    of coefficients for each variable and an intercept that can be used to explain
    how the model works. In order to extract the coefficients for each variable in
    the model, we use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in an output as illustrated by the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7076338c-7f04-40e8-bb96-4965b1ce2713.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The coefficients are in the order in which the variables were in the dataset
    that was input into the model. In order to extract the intercept from the model,
    we use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in an output as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b59cf245-50ce-4030-9eb7-92a0fc145adc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now that we have the coefficients for each variable along with the intercept,
    we can construct an equation in the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eab80713-884d-44a2-b5ab-9908a296763f.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you have learned how the logistic regression model works on
    a mathematical level. Although simplistic, the model proves to be formidable in
    terms of interpretability, which is highly beneficial in the financial industry.
  prefs: []
  type: TYPE_NORMAL
- en: You have also learned how to build and evaluate logistic regression algorithms
    using scikit-learn, and looked at hyperparameter optimization using the `GridSearchCV`
    algorithm. Additionally, you have learned to verify whether the results provided
    to you by the `GridSearchCV` algorithm are accurate by plotting the accuracy scores
    for different values of the hyperparameter.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you have scaled your data in order make it standardized and learned
    how to interpret your model on a mathematical level.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn how to implement tree-based algorithms,
    such as decision trees, random forests, and gradient-boosted trees, using scikit-learn.
  prefs: []
  type: TYPE_NORMAL
