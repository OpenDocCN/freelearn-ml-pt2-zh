<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Building an IMDB Top 250 Clone with Pandas</h1>
                </header>
            
            <article>
                
<p class="mce-root">The <strong>Internet Movie</strong> <strong>Database</strong> (<strong>IMDB</strong>) maintains a chart called the IMDB Top 250<em>, </em>which is a ranking of the top 250 movies according to a certain scoring metric. All the movies in this list are non-documentary, theatrical releases with a runtime of at least 45 minutes and over 250,000 ratings:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/5a3b1cb6-d956-475b-ad1a-7e9a353820e8.png" style="width:39.58em;height:32.08em;"/></div>
<p>This chart can be considered the simplest of recommenders. It doesn't take into consideration the tastes of a particular user, nor does it try to deduce similarities between different movies. It simply calculates a score for every movie based on a predefined metric and outputs a sorted list of movies based on that score.</p>
<p>In this chapter, we will be covering the following:</p>
<ul>
<li>Building a clone of the IMDB Top 250<em> </em>chart <span>(henceforth referred to as the simple recommender).</span></li>
<li>Taking the functionalities of the chart one step further and building a knowledge-based recommender. This model takes <span>user preferences with regards to genre, timeframe, runtime, language, and so on, and recommends movies that satisfy all co</span>nditions.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>You will be required to have Python installed on a system. Finally, to use the Git repository of this book, the user needs to install Git.</p>
<p>The code files of this chapter can be found on GitHub:<br/>
<a href="https://github.com/PacktPublishing/Hands-On-Recommendation-Systems-with-Python">https://github.com/PacktPublishing/Hands-On-Recommendation-Systems-with-Python</a>.</p>
<p>Check out the following video to see the code in action:</p>
<p><a href="http://bit.ly/2v7SZD4">http://bit.ly/2v7SZD4</a><a href="http://bit.ly/2v7SZD4">.</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The simple recommender</h1>
                </header>
            
            <article>
                
<p class="mce-root">The first step in building our simple recommender is setting up our workspace. Let's create a new directory named <kbd>Chapter3</kbd><em>.</em> Create a Jupyter Notebook in this directory named <kbd>Simple Recommender</kbd><em> </em>and open it in the browser.</p>
<p>Let's now load the dataset we used in the previous chapter into our notebook.</p>
<div class="packt_infobox">In case you have not downloaded it already, the dataset is available at<br/>
<a href="https://www.kaggle.com/rounakbanik/the-movies-dataset/downloads/movies_metadata.csv/7">https://www.kaggle.com/rounakbanik/the-movies-dataset/downloads/movies_metadata.csv/7</a>.</div>
<pre>import pandas as pd<br/>import numpy as np<br/><br/>#Load the dataset into a pandas dataframe<br/>df = pd.read_csv('../data/movies_')<br/><br/>#Display the first five movies in the dataframe<br/>df.head()</pre>
<p>Upon running the cell, you should see a familiar table-like structure output in the notebook.</p>
<p>Building the simple recommender is fairly straightforward. The steps are as follows:</p>
<ol>
<li>Choose a metric (or score) to rate the movies on</li>
<li>Decide on the prerequisites for the movie to be featured on the chart</li>
<li>Calculate the score for every movie that satisfies the conditions</li>
<li>Output the list of movies in decreasing order of their scores</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The metric</h1>
                </header>
            
            <article>
                
<p>The metric is the numeric quantity based on which we rank movies. A movie is considered to be better<em> </em>than another movie if it has a higher metric score than the other movie. It is very important that we have a robust and a reliable metric to build our chart upon to ensure a good quality of recommendations.</p>
<p>The choice of a metric is arbitrary. One of the simplest metrics that can be used is the movie rating. However, this suffers from a variety of disadvantages. In the first place, the movie rating does not take the popularity of a movie into consideration. Therefore, a movie rated 9 by 100,000 users will be placed below a movie rated 9.5 by 100 users.<br/>
This is not desirable as it is highly likely that a movie watched and rated only by 100 people caters to a very specific niche and may not appeal as much to the average person as the former.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>It is also a well-known fact that as the number of voters increase, the rating of a movie normalizes and it approaches a value that is reflective of the movie's quality and popularity with the general populace. To put it another way, movies with very few ratings are not very reliable. A movie rated 10/10 by five users doesn't necessarily mean that it's a good movie.</p>
<p>Therefore, what we need is a metric that can, to an extent, take into account the movie rating and the number of votes it has garnered (a proxy for popularity). This would give a greater preference to a blockbuster movie rated 8 by 100,000 users over an art house movie rated 9 by 100 users.</p>
<p>Fortunately, we do not have to brainstorm a mathematical formula for the metric. As the title of this chapter states, we are building an IMDB top 250 clone. Therefore, we shall use IMDB's weighted rating formula as our metric. Mathematically, it can be represented as follows:</p>
<div class="CDPAlignCenter CDPAlign"><em>Weighted Rating (WR) =</em> <img class="fm-editor-equation" src="assets/4489b75d-977e-4557-895a-2aeff1f98725.png" style="width:10.83em;height:1.75em;"/></div>
<p>The following apply:</p>
<ul>
<li><em>v</em> is the number of votes garnered by the movie</li>
<li><em>m</em> is the minimum number of votes required for the movie to be in the chart (the prerequisite)</li>
<li><em>R</em> is the mean rating of the movie</li>
<li><em>C</em> is the mean rating of all the movies in the dataset</li>
</ul>
<p>We already have the values for <em>v</em> and <em>R </em>for every movie in the form of the <kbd>vote_count</kbd> and <kbd>vote_average</kbd><em> </em>features respectively. Calculating <em>C </em>is extremely trivial, as we have already seen in the previous chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The prerequisties</h1>
                </header>
            
            <article>
                
<p>The IMDB weighted formula also has a variable <em>m </em>, which it requires to compute its score. This variable is in place to make sure that only movies that are above a certain threshold of popularity are considered for the rankings. Therefore, the value of <em>m </em>determines the movies that qualify to be in the chart and also, by being part of the formula, determines the final value of the score.</p>
<p>Just like the metric, the choice of the value of <em>m </em>is arbitrary. In other words, there is no right value for <em>m. </em>It is a good idea to experiment with different values of <em>m </em>and then choose the one that you (and your audience) think gives the best recommendations. The only thing to be kept in mind is that the higher the value of <em>m, </em>the higher the emphasis on the popularity of a movie, and therefore the higher the selectivity.</p>
<p>For our recommender, we will use the number of votes garnered by the 80th percentile movie as our value for <em>m. </em>In other words, for a movie to be considered in the rankings, it must have garnered more votes than at least 80% of the movies present in our dataset. Additionally, the number of votes garnered by the 80th percentile movie is used in the weighted formula described previously to come up with the value for the scores.</p>
<p>Let us now calculate the value of <em>m</em>:</p>
<pre>#Calculate the number of votes garnered by the 80th percentile movie<br/>m = df['vote_count'].quantile(0.80)<br/>m<br/><br/><strong>OUTPUT:<br/></strong><strong>50.0</strong></pre>
<p>We can see that only 20% of the movies have gained more than 50 votes. Therefore, our value of <em>m</em> is<em> </em><kbd>50</kbd>.</p>
<p>Another prerequisite that we want in place is the runtime. We will only consider movies that are greater than <kbd>45 minutes</kbd> and less than <kbd>300 minutes</kbd> in length. Let us define a new DataFrame, <kbd>q_movies</kbd>,<em> </em>which will hold all the movies that qualify to appear in the chart:</p>
<pre>#Only consider movies longer than 45 minutes and shorter than 300 minutes<br/>q_movies = df[(df['runtime'] &gt;= 45) &amp; (df['runtime'] &lt;= 300)]<br/><br/>#Only consider movies that have garnered more than m votes<br/>q_movies = q_movies[q_movies['vote_count'] &gt;= m]<br/><br/>#Inspect the number of movies that made the cut<br/>q_movies.shape<br/><br/><strong>OUTPUT:<br/>(8963, 24)</strong></pre>
<p>We see that from our dataset of 45,000 movies approximately 9,000 movies (or 20%) made the cut. </p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Calculating the score</h1>
                </header>
            
            <article>
                
<p>The final value that we need to discover before we calculate our scores is <em>C, </em>the mean rating for all the movies in the dataset:</p>
<pre># Calculate C<br/>C = df['vote_average'].mean()<br/>C<br/><br/><strong>OUTPUT:<br/>5.6182072151341851</strong></pre>
<p>We can see that the average rating of a movie is approximately 5.6/10. It seems that IMDB happens to be particularly strict with their ratings. Now that we have the value of <em>C, </em>we can go about calculating our score for each movie.</p>
<p>First, let us define a function that computes the rating for a movie, given its features and the values of <em>m </em>and <em>C</em>:</p>
<pre># Function to compute the IMDB weighted rating for each movie<br/>def weighted_rating(x, m=m, C=C):<br/>    v = x['vote_count']<br/>    R = x['vote_average']<br/>    # Compute the weighted score<br/>    return (v/(v+m) * R) + (m/(m+v) * C)</pre>
<p>Next, we will use the familiar <kbd>apply</kbd> function on our <kbd>q_movies</kbd> DataFrame to construct a new feature score<em>. </em>Since the calculation is done for every row, we will set the axis to <kbd>1</kbd> to denote row-wise operation:</p>
<pre># Compute the score using the weighted_rating function defined above<br/>q_movies['score'] = q_movies.apply(weighted_rating, axis=1)</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sorting and output</h1>
                </header>
            
            <article>
                
<p>There is just one step left. We now need to sort our DataFrame on the basis of the score we just computed and output the list of top movies:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/a0667c30-199a-4342-b2c3-6181e3e3aa19.png" style="width:38.00em;height:50.58em;"/></div>
<p>And voila! You have just built your very first recommender. Congratulations!</p>
<p>We can see that the Bollywood film <em>Dilwale Dulhania Le Jayenge </em>figures at the top of the list. We can also see that it has a noticeably smaller number of votes than the other Top 25 movies. This strongly suggests that we should probably explore a higher value of <em>m. </em>This is left as an exercise for the reader; experiment with different values of <em>m </em>and observe how the movies in the chart change.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The knowledge-based recommender</h1>
                </header>
            
            <article>
                
<p>In this section, we are going to go ahead and build a knowledge-based recommender on top of our IMDB Top 250 clone. This will be a simple function that will perform the following tasks:</p>
<ol>
<li>Ask the user for the genres of movies he/she is looking for</li>
<li>Ask the user for the duration</li>
<li>Ask the user for the timeline of the movies recommended</li>
<li>Using the information collected, recommend movies to the user that have a high weighted rating (according to the IMDB formula) and that satisfy the preceding conditions</li>
</ol>
<p>The data that we have has information on the duration, genres, and timelines, but it isn't currently in a form that is directly usable. In other words, our data needs to be wrangled before it can be put to use to build this recommender.</p>
<p>In our <kbd>Chapter3</kbd><em> </em>folder, let's create a new Jupyter Notebook named <kbd>Knowledge Recommender</kbd><em>. </em>This notebook will contain all the code that we write as part of this section.</p>
<p>As usual, let us load our packages and the data into our notebook. Let's also take a look at the features that we have and decide on the ones that will be useful for this task:</p>
<pre>import pandas as pd<br/>import numpy as np<br/><br/>df = pd.read_csv('../data/movies_metadata.csv')<br/><br/>#Print all the features (or columns) of the DataFrame<br/>df.columns<br/><br/><strong>OUTPUT:<br/>Index(['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id',<br/>       'imdb_id', 'original_language', 'original_title', 'overview',<br/>       'popularity', 'poster_path', 'production_companies',<br/>       'production_countries', 'release_date', 'revenue', 'runtime',<br/>       'spoken_languages', 'status', 'tagline', 'title', 'video',<br/>       'vote_average', 'vote_count'],<br/>      dtype='object')</strong></pre>
<p>From our output, it is quite clear which features we do and do not require. Now, let's reduce our DataFrame to only contain features that we need for our model:</p>
<pre>#Only keep those features that we require <br/>df = df[['title','genres', 'release_date', 'runtime', 'vote_average', 'vote_count']]<br/><br/>df.head()</pre>
<p>Next, let us extract the year of release from our <kbd>release_date</kbd><em> </em>feature:</p>
<pre>#Convert release_date into pandas datetime format<br/>df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')<br/><br/>#Extract year from the datetime<br/>df['year'] = df['release_date'].apply(lambda x: str(x).split('-')[0] if x != np.nan else np.nan)</pre>
<p>Our <kbd>year</kbd><em> </em>feature is still an <kbd>object</kbd> and is riddled with <kbd>NaT</kbd><em> </em>values, which are a type of null value used by Pandas. Let's convert these values to an integer, <kbd>0</kbd>, and convert the datatype of the <kbd>year</kbd><em> </em>feature into <kbd>int</kbd><em>.</em></p>
<p>To do this, we will define a helper function, <kbd>convert_int</kbd>,<em> </em>and apply it to the <kbd>year</kbd><em> </em>feature:</p>
<pre>#Helper function to convert NaT to 0 and all other years to integers.<br/>def convert_int(x):<br/>    try:<br/>        return int(x)<br/>    except:<br/>        return 0<br/><br/>#Apply convert_int to the year feature<br/>df['year'] = df['year'].apply(convert_int)</pre>
<p>We do not require the <kbd>release_date</kbd><em> </em>feature anymore. So let's go ahead and remove it:</p>
<pre>#Drop the release_date column<br/>df = df.drop('release_date', axis=1)<br/><br/>#Display the dataframe<br/>df.head()</pre>
<p>The <kbd>runtime</kbd><em> </em>feature is already in a form that is usable. It doesn't require any additional wrangling. Let us now turn our attention to <kbd>genres</kbd><em>.</em></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Genres</h1>
                </header>
            
            <article>
                
<p>Upon preliminary inspection, we can observe that the genres are in a format that looks like a JSON object (or a Python dictionary). Let us take a look at the <kbd>genres</kbd><em> </em>object of one of our movies:</p>
<pre>#Print genres of the first movie<br/>df.iloc[0]['genres']<br/><br/><strong>OUTPUT:<br/>"[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]"</strong></pre>
<p>We can observe that the output is a stringified dictionary. In order for this feature to be usable, it is important that we convert this string into a native Python dictionary. Fortunately, Python gives us access to a function called <kbd>literal_eval</kbd><em> </em>(available in the <kbd>ast</kbd><em> </em>library) which does exactly that. <kbd>literal_eval</kbd><em> </em>parses any string passed into it and converts it into its corresponding Python object:</p>
<pre>#Import the literal_eval function from ast<br/>from ast import literal_eval<br/><br/>#Define a stringified list and output its type<br/>a = "[1,2,3]"<br/>print(type(a))<br/><br/>#Apply literal_eval and output type<br/>b = literal_eval(a)<br/>print(type(b))<br/><br/><strong>OUTPUT:<br/>&lt;class 'str'&gt;<br/>&lt;class 'list'&gt;</strong></pre>
<p>We now have all the tools required to convert the <em>genres </em>feature into the Python dictionary format.</p>
<p>Also, each dictionary represents a genre and has two keys: <kbd>id</kbd><em> </em>and <kbd>name</kbd><em>. </em>However, for this exercise (as well as all subsequent exercises), we only require the <kbd>name</kbd><em>. </em>Therefore, we shall convert our list of dictionaries into a list of strings, where each string is a genre name:</p>
<pre>#Convert all NaN into stringified empty lists<br/>df['genres'] = df['genres'].fillna('[]')<br/><br/>#Apply literal_eval to convert to the list object<br/>df['genres'] = df['genres'].apply(literal_eval)<br/><br/>#Convert list of dictionaries to a list of strings<br/>df['genres'] = df['genres'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])<br/><br/>df.head()</pre>
<p>Printing the head of the DataFrame should show you a new <kbd>genres</kbd><em> </em>feature, which is a list of genre names. However, we're still not done yet. The last step is to <kbd>explode</kbd><em> </em>the genres column. In other words, if a particular movie has multiple genres, we will create multiple copies of the movie, with each movie having one of the genres.</p>
<p>For example, if there is a movie called <em>Just Go With It </em>that has <em>romance </em>and <em>comedy </em>as its genres, we will <kbd>explode</kbd><em> </em>this movie into two rows. One row will be <em>Just Go With It </em>as a <em>romance </em>movie. The other will be a <em>comedy</em><em> </em>movie:</p>
<pre>#Create a new feature by exploding genres<br/>s = df.apply(lambda x: pd.Series(x['genres']),axis=1).stack().reset_index(level=1, drop=True)<br/><br/>#Name the new feature as 'genre'<br/>s.name = 'genre'<br/><br/>#Create a new dataframe gen_df which by dropping the old 'genres' feature and adding the new 'genre'.<br/>gen_df = df.drop('genres', axis=1).join(s)<br/><br/>#Print the head of the new gen_df<br/>gen_df.head()</pre>
<div class="CDPAlignCenter CDPAlign"><img src="assets/3e28d632-7f07-410c-be80-0fdada09bdf3.png" style="width:27.08em;height:10.58em;"/></div>
<p>You should be able to see three <em>Toy Story </em>rows now; one each to represent <em>animation</em>, <em>family</em>,<em> </em>and <em>comedy. </em>This <kbd>gen_df</kbd><em> </em>DataFrame is what we will use to build our knowledge-based recommender.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The build_chart function</h1>
                </header>
            
            <article>
                
<p>We are finally in a position to write the function that will act as our recommender. We cannot use our computed values of <em>m </em>and <em>C </em>from earlier, as we will not be considering every movie just the ones that qualify. In other words, these are three main steps:</p>
<ol>
<li>Get user input on their preferences</li>
<li>Extract all movies that match the conditions set by the user</li>
<li>Calculate the values of <em>m </em>and <em>C </em>for only these movies and proceed to build the chart as in the previous section</li>
</ol>
<p>Therefore, the <kbd>build_chart</kbd><em> </em>function will accept only two inputs: our <kbd>gen_df</kbd><em> </em>DataFrame and the percentile used to calculate the value of <em>m. </em>By default, let's set this to 80%, or <kbd>0.8</kbd>:</p>
<pre>def build_chart(gen_df, percentile=0.8):<br/>    #Ask for preferred genres<br/>    print("Input preferred genre")<br/>    genre = input()<br/>    <br/>    #Ask for lower limit of duration<br/>    print("Input shortest duration")<br/>    low_time = int(input())<br/>    <br/>    #Ask for upper limit of duration<br/>    print("Input longest duration")<br/>    high_time = int(input())<br/>    <br/>    #Ask for lower limit of timeline<br/>    print("Input earliest year")<br/>    low_year = int(input())<br/>    <br/>    #Ask for upper limit of timeline<br/>    print("Input latest year")<br/>    high_year = int(input())<br/>    <br/>    #Define a new movies variable to store the preferred movies. Copy the contents of gen_df to movies<br/>    movies = gen_df.copy()<br/>    <br/>    #Filter based on the condition<br/>    movies = movies[(movies['genre'] == genre) &amp; <br/>                    (movies['runtime'] &gt;= low_time) &amp; <br/>                    (movies['runtime'] &lt;= high_time) &amp; <br/>                    (movies['year'] &gt;= low_year) &amp; <br/>                    (movies['year'] &lt;= high_year)]<br/>    <br/>    #Compute the values of C and m for the filtered movies<br/>    C = movies['vote_average'].mean()<br/>    m = movies['vote_count'].quantile(percentile)<br/>    <br/>    #Only consider movies that have higher than m votes. Save this in a new dataframe q_movies<br/>    q_movies = movies.copy().loc[movies['vote_count'] &gt;= m]<br/>    <br/>    #Calculate score using the IMDB formula<br/>    q_movies['score'] = q_movies.apply(lambda x: (x['vote_count']/(x['vote_count']+m) * x['vote_average']) <br/>                                       + (m/(m+x['vote_count']) * C)<br/>                                       ,axis=1)<br/><br/>    #Sort movies in descending order of their scores<br/>    q_movies = q_movies.sort_values('score', ascending=False)<br/>    <br/>    return q_movies</pre>
<p>Time to put our model into action!</p>
<p>We want recommendations for animated movies between 30 minutes and 2 hours in length, and released anywhere between 1990 and 2005. Let's see the results:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/2ffa5654-3666-43b8-b4a0-af1a897ab647.png" style="width:46.50em;height:26.42em;"/></div>
<p>We can see that the movies <span><span>that it outputs </span></span>satisfy all the conditions we passed in as input. Since we applied IMDB's metric, we can also observe that our movies are very highly rated and popular at the same time. The top 5 also includes <em>The Lion King, </em>which is my favorite animated movie of all time! I, for one, would be very happy with the results of this list.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we built a simple recommender, which was a clone of the IMDB Top 250 chart. We then proceeded to build an improved knowledge-based recommender, which asked the user for their preferred genres, duration, and time. In the process of building these models, we also learned to perform some advanced data wrangling with the Pandas library.</p>
<p>In the next chapter, we will use more advanced features and techniques to build a content-based recommender. This model will be able to detect similar movies based on their plots and recommend movies by identifying similarities in genre, cast, crew, plot, and so on. </p>


            </article>

            
        </section>
    </body></html>