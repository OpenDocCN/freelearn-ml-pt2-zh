- en: '*Appendix*'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: About
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section is included to assist the students to perform the activities in
    the book. It includes detailed steps that are to be performed by the students
    to achieve the objectives of the activities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Chapter 1: Python Machine Learning Toolkit'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Activity 1: pandas Functions'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Solution**'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use pandas to load the Titanic dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `head()` function on the dataset as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.65: First five rows'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_01_65.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.65: First five rows'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Use the `describe` function as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.66: Output of describe()'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_01_66.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.66: Output of describe()'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We don''t need the `Unnamed: 0` column. We can remove the column without using
    the `del` command, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.67: First five rows after deleting the Unnamed: 0 column'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_01_67.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.67: First five rows after deleting the Unnamed: 0 column'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Compute the mean, standard deviation, minimum, and maximum values for the columns
    of the DataFrame without using `describe`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'What about the 33, 66, and 99% quartiles? Use the `quantile` method as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'How many passengers were from each class? Let''s see, using the `groupby` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'How many passengers were from each class? You can find the answer by using
    selecting/indexing methods to count the members of each class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The answers to *Step 6* and *Step 7* do match.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Determine who the eldest passenger in third class was:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.68: Eldest passenger in third class'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_01_68.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.68: Eldest passenger in third class'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'For a number of machine learning problems, it is very common to scale the numerical
    values between 0 and 1\. Use the `agg` method with Lambda functions to scale the
    `Fare` and `Age` columns between 0 and 1:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.69: Scaling numerical values between 0 and 1'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_01_69.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.69: Scaling numerical values between 0 and 1'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'There is one individual in the dataset without a listed `Fare` value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This is the output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.70: Individual without a listed Fare value'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12622_01_70.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.70: Individual without a listed Fare value'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Replace the `NaN` values of this row in the main DataFrame with the mean `Fare`
    value for those corresponding with the same class and `Embarked` location using
    the `groupby` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Chapter 2: Exploratory Data Analysis and Visualization'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Activity 2: Summary Statistics and Missing Values'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Solution**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps to complete this activity are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Read the data. Use pandas'' `.read_csv` method to read the CSV file into a
    pandas DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use pandas'' `.info()` and `.describe()` methods to view the summary statistics
    of the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of `info()` will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.39: The output of the info() method'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_02_39.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.39: The output of the info() method'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The output of `describe()` will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.40: The output of the describe() method'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_02_40.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.40: The output of the describe() method'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Find the total count and total percentage of missing values in each column of
    the DataFrame and display them for columns having at least one null value, in
    descending order of missing percentages.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As we did in *Exercise 12: Visualizing Missing Values*, we will use the `.isnull()`
    function on the DataFrame to get a mask, find the count of null values in each
    column by using the `.sum()` function over the mask DataFrame and the fraction
    of null values by using `.mean()` over the mask DataFrame and multiply by 100
    to convert it to a percentage. Then, we use `pd.concat()` to combine the total
    and percentage of null values into a single DataFrame and sort the rows by percentage
    of missing values:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.41: Total count and percentage of missing values in each column'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_02_41.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.41: Total count and percentage of missing values in each column'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Plot the nullity matrix and nullity correlation heatmap. First, we find the
    list of column names for those having at least one null value. Then, we use the
    `missingno` library to plot the nullity matrix (as we did in *Exercise 12: Visualizing
    Missing Values*) for a sample of 500 points, and the nullity correlation heatmap
    for the data in those columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The nullity matrix will look like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.42: Nullity matrix'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_02_42.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.42: Nullity matrix'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The nullity correlation heatmap will look like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.43: Nullity correlation heatmap'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_02_43.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.43: Nullity correlation heatmap'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Delete the columns having more than 80% of values missing. Use the `.loc` operator
    on the DataFrame we created in *Step 3* to select only those columns that had
    less than 80% of values missing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Replace null values in the `FireplaceQu` column with NA values. Use the `.fillna()`
    method to replace null values with the `NA` string:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Activity 3: Visually Representing the Distribution of Values'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Solution**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Plot a histogram using Matplotlib for the target variable, `SalePrice`. First,
    we initialize the figure using the `plt.figure` command and set the figure size.
    Then, we use Matplotlib''s `.hist()` function as our primary plotting function,
    to which we pass the `SalePrice` series object for plotting the histogram. Lastly,
    we specify the axes labels and show the plot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.44: Histogram for the target variable'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_02_44.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.44: Histogram for the target variable'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Find the number of unique values within each column having the object type.
    Create a new DataFrame called `object_variables` by using the `.select_dtypes`
    function on the original DataFrame to select those columns with the `numpy.object`
    data type. Then, find the number of unique values for each column in this DataFrame
    by using the `.nunique()` function, and sort the resultant series:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.45: Number of unique values within each column having the object
    type'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_02_45.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.45: Number of unique values within each column having the object type'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Create a DataFrame representing the number of occurrences for each categorical
    value in the `HouseStyle` column. Use the `.value_counts()` function to calculate
    the frequencies of each value in decreasing order in the form of a pandas series,
    then reset the index to give us a DataFrame and sort the values by the index:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.46: Number of occurrences for each categorical value in the HouseStyle
    column'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_02_46.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.46: Number of occurrences for each categorical value in the HouseStyle
    column'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Plot a pie chart representing these counts. As in *Step 1*, we initialize the
    image using `plt.figure()` and use the `plt.title()` and `plt.show()` methods
    to set the figure title and display it respectively. The primary plotting function
    used is `plt.pie()`, to which we pass the series we created in the previous step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.47: Pie chart representing the counts'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_02_47.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.47: Pie chart representing the counts'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Find the number of unique values within each column having the number type.
    As done in *Step 2*, now select columns having the `numpy.number` data type and
    find the number of unique values in each column using `.nunique()`. Sort the resultant
    series in descending order:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.48: Number of unique values within each column having the number
    type'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_02_48.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.48: Number of unique values within each column having the number type'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Plot a histogram using Seaborn for the `LotArea` variable. Use Seaborn''s `.distplot()`
    function as the primary plotting function, to which the `LotArea` series in the
    DataFrame needs to be passed (without any null values; use `.dropna()` on the
    series to remove them). To improve the plot view, also set the `bins` parameter
    and specify the *X* axis limits using `plt.xlim()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.49: Histogram for the LotArea variable'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_02_49.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.49: Histogram for the LotArea variable'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Calculate the skew and kurtosis values for the values in each column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output for skew values will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.50: Skew values for each column'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12622_02_50.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.50: Skew values for each column'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The output for kurtosis values will be:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.51: Kurtosis values for each column'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12622_02_51.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.51: Kurtosis values for each column'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Activity 4: Relationships Within the Data'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Solution**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Plot the correlation heatmap for the dataset. As we did in *Exercise 23: Correlation
    Heatmap*, plot the heatmap using Seaborn''s `.heatmap()` function and pass the
    feature correlation matrix (as determined by using pandas'' `.corr()` function
    on the DataFrame). Additionally, set the color map to `RdBu` using the `cmap`
    parameter and the minimum and maximum values on the color scale to `-1` and `1`
    using the `vmin` and `vmax` parameters respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.52: Heatmap for the dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_02_52.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.52: Heatmap for the dataset'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Plot a more compact heatmap having annotations for correlation values using
    the following subset of features:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now do the same as in the previous step, this time selecting only the above
    columns in the dataset, and adding an `annot` parameter with the `True` value
    to the primary plotting function, all else remaining the same:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.53: Heatmap with annotations for correlation values'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_02_53.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.53: Heatmap with annotations for correlation values'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Display the pairplot for the same subset of features, with the KDE plot on
    the diagonals and scatter plot elsewhere. Use Seaborn''s `.pairplot()` function
    to plot the pairplot for the non-null values in the selected columns of the DataFrame.
    To make the diagonal plots KDE plots, pass `kde` to the `diag_kind` parameter
    and to set all other plots as scatter plots, pass `scatter` to the `kind` parameter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.54: Pairplot for the same subset of features'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_02_54.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.54: Pairplot for the same subset of features'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Create a boxplot to show the variation in `SalePrice` for each category of
    `GarageCars`. The primary plotting function used here will be Seaborn''s `.boxplot()`
    function, to which we pass the DataFrame along with parameters `x` and `y`, the
    former is the categorical variable and the latter is the continuous variable over
    which we want to see the variation within each category, that is, `GarageCars`
    and `SalePrice` respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.55: Boxplot showing variation in SalePrice for each category of
    GarageCars'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_02_55.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.55: Boxplot showing variation in SalePrice for each category of GarageCars'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Plot a line graph using Seaborn to show the variation in `SalePrice` for older
    and more recently built flats. Here, we will plot a line plot using Seaborn''s
    `.lineplot()` function. Since we want to see the variation in `SalePrice`, we
    take this as the *y* variable, and as the variation is across a period of time,
    we take `YearBuilt` as the *x* variable. Keeping this in mind, we pass the respective
    series as values to the `y` and `x` parameters for the primary plotting function.
    We also pass a `ci=None` parameter to hide the standard deviation indicator around
    the line in the plot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.56: Line graph showing the variation in SalePrice for older and
    more recently built flats'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12622_02_56.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.56: Line graph showing the variation in SalePrice for older and more
    recently built flats'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Chapter 3: Regression Analysis'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Activity 5: Plotting Data with a Moving Average'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Solution**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load the dataset into a pandas DataFrame from the CSV file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will show the initial five rows of the `austin_weather.csv` file:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.74: The first five rows of the Austin weather data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_03_74.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.74: The first five rows of the Austin weather data'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Since we only need the `Date` and `TempAvgF` columns, we''ll remove all others
    from the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.75: Date and TempAvgF columns of the Austin weather data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_03_75.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.75: Date and TempAvgF columns of the Austin weather data'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Initially, we are only interested in the first year''s data, so we need to
    extract that information only. Create a column in the DataFrame for the year value,
    extract the year value as an integer from the strings in the `Date` column, and
    assign these values to the `Year` column. Note that temperatures are recorded
    daily:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.76: Extracting the year'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_03_76.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.76: Extracting the year'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Repeat this process to extract the month values and store the values as integers
    in a `Month` column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.77: Extracting the month'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_03_77.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.77: Extracting the month'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Copy the first year''s worth of data to a DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.78: Copied data to new dataframe'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_03_78.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.78: Copied data to new DataFrame'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Compute a 20-day moving average filter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the raw data and the moving average signal, with the *x* axis as the day
    number in the year:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.79: Scatter plot of temperature throughout the year'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12622_03_79.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.79: Scatter plot of temperature throughout the year'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Activity 6: Linear Regression Using the Least Squares Method'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Solution**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Visualize the measurements:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.80: First five rows of activity2_measurements.csv dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_03_80.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.80: First five rows of activity2_measurements.csv dataset'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Visualize the rolling average values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.81: Rolling head average'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_03_81.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.81: Rolling head average'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Create a linear regression model using the default parameters; that is, calculate
    a *y* intercept for the model and do not normalize the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now fit the model, where the input data is the day number for the year (1 to
    365) and the output is the average temperature. To make later calculations easier,
    insert a column (`DayOfYear`) that corresponds with the day of the year for that
    measurement:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.82: Adding day of year column'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_03_82.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.82: Adding day of year column'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Fit the model with the `DayOfYear` values as the input and `df_first_year.TempAvgF`
    as the output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the parameters of the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can calculate the trendline values by using the first, middle, and last
    values (days in years) in the linear equation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot these values with the trendline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.83: Scatterplot of temperature thought the year with the predicted
    trendline'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_03_83.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.83: Scatterplot of temperature thought the year with the predicted
    trendline'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Evaluate the performance of the model. How well does the model fit the data?
    Calculate the r2 score to find out:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Activity 7: Dummy Variables'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Solution**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Plot the raw data (`df`) and moving average (`rolling`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.84: Scatterplot of Temperature throughout the year'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_03_84.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.84: Scatterplot of Temperature throughout the year'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Looking at the preceding plot, there seems to be an inflection point around
    day 250\. Create a dummy variable to introduce this feature into the linear model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check the first and last samples to confirm that the dummy variable is correct.
    Check the first five samples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.85: First five columns'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_03_85.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.85: First five columns'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Then, check the last five samples:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.86: Last five columns'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_03_86.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.86: Last five columns'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Use a least squares linear regression model and fit the model to the `DayOfYear`
    values and the dummy variable to predict `TempAvgF`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compute the r2 score:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using the `DayOfYear` values, create a set of predictions using the model to
    construct a trendline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the trendline against the data and the moving average:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.87: Predicted trendline'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12622_03_87.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.87: Predicted trendline'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Activity 8: Other Model Types with Linear Regression'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Solution**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use a sine curve function as the basis of the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.88: First five rows'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_03_88.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.88: First five rows'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Fit the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the parameters of the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compute the r2 value to measure the performance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Construct the trendline values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the trendline with the raw data and the moving average:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.89: Predicted trendline'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12622_03_89.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.89: Predicted trendline'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Activity 9: Gradient Descent'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Solution**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a generic gradient descent model and normalize the day of year values
    as between 0 and 1:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the details of the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Prepare the *x* (`_trend_x`) trendline values by dividing them by the maximum.
    Predict `y_trend_values` using the gradient descent model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the data and the moving average with the trendline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.90: Gradient descent predicted trendline'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12622_03_90.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.90: Gradient descent predicted trendline'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Activity 10: Autoregressors'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Solution**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Plot the complete set of average temperature values (`df.TempAvgF`) with years
    on the *x* axis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.91: Plot of temperature through the year'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_03_91.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.91: Plot of temperature through the year'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Create a 20-day lag and plot the lagged data on the original dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.92: Plot of temperature through the years with a 20-day lag'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_03_92.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.92: Plot of temperature through the years with a 20-day lag'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Construct an autocorrelation plot to see whether the average temperature can
    be used with an autoregressor. Where is the lag acceptable and where is it not
    for an autoregressor?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We''ll get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.93: Plot of autocorrelation versus lag'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_03_93.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.93: Plot of autocorrelation versus lag'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: The lag is acceptable only when the autocorrelation line lies outside the 99%
    confidence bounds, as represented by the dashed lines.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Chose an acceptable lag and an unacceptable lag and construct lag plots using
    these values for acceptable lag:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We''ll get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.94: Plot of acceptable lag'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_03_94.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.94: Plot of acceptable lag'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Use these values for unacceptable lag:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We''ll get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.95: Plot of unacceptable lag'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_03_95.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.95: Plot of unacceptable lag'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Create an autoregressor model, note the selected lag, calculate the R2 value,
    and plot the autoregressor model with the original plot. The model is to project
    past the available data by 1,000 samples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the model to the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a set of predictions for 1,000 days after the last sample:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the predictions, as well as the original dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.96: Plot of temperature through the years'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_03_96.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.96: Plot of temperature through the years'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Enhance the view to look for differences by showing the 100th to 200th samples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We''ll get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.97: Plot of predictions with the original dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12622_03_97.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.97: Plot of predictions with the original dataset'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Chapter 4: Classification'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Activity 11: Linear Regression Classifier â€“ Two-Class Classifier'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Solution**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the required dependencies:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the MNIST data into memory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Visualize a sample of the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We''ll get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.76: Sample data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_04_76.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.76: Sample data'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Construct a linear classifier model to classify the digits zero and one. The
    model we are going to create is to determine whether the samples are either the
    digits zero or one. To do this, we first need to select only those samples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Visualize the selected information. Here''s the code for zero:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.77: First sample data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_04_77.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.77: First sample data'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Here''s the code for one:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.78: Second sample data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_04_78.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.78: Second sample data'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In order to provide the image information to the model, we must first flatten
    the data out so that each image is 1 x 784 pixels in shape:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s construct the model; use the `LinearRegression` API and call the `fit`
    function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Determine the R2 score against the training set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Determine the label predictions for each of the training samples, using a threshold
    of 0.5\. Values greater than 0.5 classify as one; values less than or equal to
    0.5 classify as zero:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compute the classification accuracy of the predicted training values versus
    the ground truth:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compare the performance against the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Activity 12: Iris Classification Using Logistic Regression'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Solution**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the required packages. For this activity, we will require the pandas
    package for loading the data, the Matplotlib package for plotting, and scikit-learn
    for creating the logistic regression model. Import all the required packages and
    relevant modules for these tasks:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the Iris dataset using pandas and examine the first five rows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.79: The first five rows of the Iris dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_04_79.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.79: The first five rows of the Iris dataset'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The next step is feature engineering. We need to select the most appropriate
    features that will provide the most powerful classification model. Plot a number
    of different features versus the allocated species classifications, for example,
    sepal length versus petal length and species. Visually inspect the plots and look
    for any patterns that could indicate separation between each of the species:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.80: Species classification plot'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_04_80.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.80: Species classification plot'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Select the features by writing the column names in the following list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Before we can construct the model, we must first convert the `species` values
    into labels that can be used within the model. Replace the `Iris-setosa` species
    string with the value `0`, the `Iris-versicolor` species string with the value
    `1`, and the `Iris-virginica` species string with the value `2`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the model using the `selected_features` and the assigned `species` labels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compute the accuracy of the model against the training set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Construct another model using your second choice `selected_features` and compare
    the performance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE123]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Construct another model using all available information and compare the performance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE125]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Activity 13: K-NN Multiclass Classifier'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Solution**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the following packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE126]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Load the MNIST data into memory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Training images:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE127]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Training labels:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Test images:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Test labels:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE130]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Visualize a sample of the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE131]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.81: Sample images'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_04_81.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.81: Sample images'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Construct a K-NN classifier, with three nearest neighbors to classify the MNIST
    dataset. Again, to save processing power, randomly sample 5,000 images for use
    in training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In order to provide the image information to the model, we must first flatten
    the data out so that each image is 1 x 784 pixels in shape:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE133]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Build the three-neighbor KNN model and fit the data to the model. Note that,
    in this activity, we are providing 784 features or dimensions to the model, not
    simply 2:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Determine the score against the training set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE137]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Display the first two predictions for the model against the training data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE139]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.82: First predicted values'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_04_82.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.82: First predicted values'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Compare the performance against the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE140]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE141]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Chapter 5: Ensemble Modeling'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Activity 14: Stacking with Standalone and Ensemble Algorithms'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Solution**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the relevant libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE142]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Read the data and print the first five rows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE143]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.19: The first 5 rows'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_05_19.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.19: The first 5 rows'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Preprocess the dataset to remove null values and one-hot encode categorical
    variables to prepare the data for modeling.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: First, we remove all columns where more than 10% of the values are null. To
    do this, calculate the fraction of missing values by using the `.isnull()` method
    to get a mask DataFrame and apply the `.mean()` method to get the fraction of
    null values in each column. Multiply the result by 100 to get the series as percentage
    values.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Then, find the subset of the series having a percentage value lower than 10
    and save the index (which will give us the column names) as a list. Print the
    list to see the columns we get:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE144]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.20: Output of preprocessing the dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_05_20.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.20: Output of preprocessing the dataset'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: As the first column is `id`, we will exclude this column as well, since it will
    not add any value to the model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We will subset the data to include all columns in the `col` list except the
    first element, which is `id`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE145]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For the categorical variables, we replace null values with a string, `NA`,
    and one-hot encode the columns using pandas'' `.get_dummies()` method, while for
    the numerical variables we will replace the null values with `-1`. Then, we combine
    the numerical and categorical columns to get the final DataFrame:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE146]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Divide the dataset into train and validation DataFrames.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We use scikit-learn''s `train_test_split()` method to divide the final DataFrame
    into training and validation sets in the ratio 4:1\. We further split each of
    the two sets into their respective `x` and `y` values to represent the features
    and target variable respectively:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE147]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Initialize dictionaries in which to store train and validation MAE values.
    We will create two dictionaries, in which we will store the MAE values on the
    train and validation datasets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE148]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Train a decision tree model and save the scores. We will use scikit-learn''s
    `DecisionTreeRegressor` class to train a regression model using a single decision
    tree:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE149]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Train a k-nearest neighbors model and save the scores. We will use scikit-learn''s
    `kNeighborsRegressor` class to train a regression model with *k=5*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE150]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Train a Random Forest model and save the scores. We will use scikit-learn''s
    `RandomForestRegressor` class to train a regression model using bagging:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE151]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Train a gradient boosting model and save the scores. We will use scikit-learn''s
    `GradientBoostingRegressor` class to train a boosted regression model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE152]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Prepare the training and validation datasets with the four meta estimators having
    the same hyperparameters that were used in the previous steps. We will create
    a `num_base_predictors` variable that represents the number of base estimators
    we have in the stacked model to help calculate the shape of the datasets for training
    and validation. This step can be coded almost identically to the exercise in the
    chapter, with a different number (and type) of base estimators.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, we create a new training set with additional columns for predictions
    from base predictors, in the same way as was done previously:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE153]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we train the base models using the k-fold strategy. We save the predictions
    in each iteration in a list, and iterate over the list to assign the predictions
    to the columns in that fold:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE154]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After that, we create a new validation set with additional columns for predictions
    from base predictors:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE155]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Lastly, we fit the base models on the complete training set to get meta features
    for the validation set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE156]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Train a linear regression model as the stacked model. To train the stacked
    model, we train the logistic regression model on all the columns of the training
    dataset, plus the meta predictions from the base estimators. We then use the final
    predictions to calculate the MAE values, which we store in the same `train_mae_values`
    and `val_mae_values` dictionaries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE157]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Visualize the train and validation errors for each individual model and the
    stacked model. Then, we will convert the dictionaries into two series and combine
    them to form two columns of a Pandas DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE158]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.21: The train and validation errors for each individual model and
    the stacked model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_05_21.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.21: The train and validation errors for each individual model and
    the stacked model'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We then plot a bar chart from this DataFrame to visualize the MAE values for
    the train and validation sets using each model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE159]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.22: Bar chart visualizing the MAE values'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12622_05_22.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.22: Bar chart visualizing the MAE values'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As we can see in the plot, the linear regression stacked model has the lowest
    value of mean absolute error on both training and validation datasets, even compared
    to the other ensemble models (Random Forest and gradient boosted regressor).
  prefs: []
  type: TYPE_NORMAL
- en: 'Chapter 6: Model Evaluation'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Activity 15: Final Test Project'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Solution**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the relevant libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE160]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Read the `attrition_train.csv` dataset. Read the CSV file into a DataFrame
    and print the `.info()` of the DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE161]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.33: Output of info()'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_06_33.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.33: Output of info()'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Read the JSON file with the details of the categorical variables. The JSON
    file contains a dictionary, where the keys are the column names of the categorical
    features and the corresponding values are the list of categories in the feature.
    This file will help us one-hot encode the categorical features into numerical
    features. Use the `json` library to load the file object into a dictionary, and
    print the dictionary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE162]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.34: The JSON file'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_06_34.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.34: The JSON file'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Process the dataset to convert all features to numerical values. First, find
    the number of columns that will stay in their original form (that is, numerical
    features) and that need to be one-hot encoded (that is, the categorical features).
    `data.shape[1]` gives us the number of columns in `data`, and we subtract `len(cat_values_dict)`
    from it to get the number of numerical columns. To find the number of categorical
    columns, we simply count the total number of categories across all categorical
    variables from the `cat_values_dict` dictionary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE163]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE164]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a NumPy array of zeros as a placeholder, with a shape equal to the total
    number of columns, as determined previously, minus one (because the `Attrition`
    target variable is also included here). For the numerical columns, we then create
    a mask that selects the numerical columns from the DataFrame and assigns them
    to the first `num_orig_cols-1` columns in the array, `X`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE165]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we initialize the `OneHotEncoder` class from scikit-learn with a list
    containing the list of values in each categorical column. Then, we transform the
    categorical columns to one-hot encoded columns and assign them to the remaining
    columns in `X`, and save the values of the target variable in the `y` variable:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE166]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE167]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Choose a base model and define the range of hyperparameter values corresponding
    to the model to be searched over for hyperparameter tuning. Let''s use a gradient
    boosted classifier as our model. We then define ranges of values for all hyperparameters
    we want to tune in the form of a dictionary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE168]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the parameters with which to initialize the `RandomizedSearchCV` object
    and use K-fold cross-validation to find the best model hyperparameters. Define
    the parameters required for random search, including `cv` as `5`, indicating that
    the hyperparameters should be chosen by evaluating the performance using 5-fold
    cross-validation. Then, initialize the `RandomizedSearchCV` object and use the
    `.fit()` method to begin the optimization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE169]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.35: Output of the optimization process'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_06_35.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.35: Output of the optimization process'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Once the tuning is complete, find the position (iteration number) at which
    the highest mean test score was obtained. Find the corresponding hyperparameters
    and save them to a dictionary:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE170]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.36: The hyperparameters dictionary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_06_36.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.36: The hyperparameters dictionary'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Split the dataset into training and validation sets and train a new model using
    the final hyperparameters on the training dataset. Use scikit-learn''s `train_test_split()`
    method to split `X` and `y` into train and test components, with test comprising
    15% of the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE171]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE172]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Train the gradient boosted classification model using the final hyperparameters
    and make predictions on the training and validation sets. Also calculate the probability
    on the validation set:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE173]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calculate the accuracy, precision, and recall for predictions on the validation
    set, and print the confusion matrix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE174]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.37: Accuracy, precision, recall, and the confusion matrix'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_06_37.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.37: Accuracy, precision, recall, and the confusion matrix'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Experiment with varying thresholds to find the optimal point with high recall.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Plot the precision-recall curve:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE175]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.38: The precision-recall curve'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_06_38.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.38: The precision-recall curve'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Plot the variation in precision and recall with increasing threshold values:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE176]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.39: Variation in precision and recall with increasing threshold
    values'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12622_06_39.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.39: Variation in precision and recall with increasing threshold values'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Finalize a threshold that will be used for predictions on the test dataset.
    Let''s finalize a value, say, 0.3\. This value is entirely dependent on what you
    feel would be optimal based on your exploration in the previous step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE177]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Read and process the test dataset to convert all features to numerical values.
    This will be done in a manner similar to that in *step 4*, with the only difference
    that we don''t need to account for the target variable column, as the dataset
    does not contain it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE178]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Predict the final values on the test dataset and save them to a file. Use the
    final threshold value determined in *step 10* to find the classes for each value
    in the training set. Then, write the final predictions to the `final_predictions.csv`
    file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE179]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be a CSV file, as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.40: The CSV file](img/C12622_06_40.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.40: The CSV file'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
