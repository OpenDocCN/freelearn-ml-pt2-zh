["```py\nconda install -c anaconda pandas-datareader\n```", "```py\nfrom `pandas-datareader` import data\n```", "```py\n%matplotlib inline\n\nfrom pandas_datareader import data\nimport pandas as pd\n\ntickers = [\"F\", \"TM\", \"GM\", \"TSLA\"]\n\nfirst_date = '2009-01-01'\nlast_date = '2016-12-31'\n```", "```py\nstock_panel = data.DataReader(tickers, 'google', first_date, last_date)\n```", "```py\nstock_df = stock_panel.Close.dropna()\nstock_df.plot(figsize=(12, 5))\n```", "```py\n#this dataframe indicates if the stock was higher in 180 days\nclasses = (stock_df.shift(-180) > stock_df).astype(int)\n```", "```py\nX = stock_panel.to_frame()\nclasses = classes.unstack()\nclasses = classes.swaplevel(0, 1).sort_index()\nclasses = classes.to_frame()\nclasses.index.names = ['Date', 'minor']\ndata = X.join(classes).dropna()\ndata.rename(columns={0: 'is_higher'}, inplace=True)\ndata.head()\n```", "```py\nimport patsy\nX = patsy.dmatrix(\"Open + High + Low + Close + Volume + is_higher - 1\", data.reset_index(),return_type='dataframe')\nX.head()\n```", "```py\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nlda = LDA()\nlda.fit(X.iloc[:, :-1], X.iloc[:, -1]);\n```", "```py\nfrom sklearn.metrics import classification_report\nprint classification_report(X.iloc[:, -1].values,\nlda.predict(X.iloc[:, :-1]))\n\n precision    recall  f1-score   support\n\n 0.0       0.64      0.81      0.72      3432\n 1.0       0.64      0.42      0.51      2727\n\navg / total       0.64      0.64      0.62      6159\n```", "```py\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\nqda = QDA()\n\nqda.fit(X.iloc[:, :-1], X.iloc[:, -1])\npredictions = qda.predict(X.iloc[:, :-1])\npredictions.sum()\n\n2686.0\n\nfrom sklearn.metrics import classification_report\nprint classification_report(X.iloc[:, -1].values, predictions)\n             precision    recall  f1-score   support\n\n 0.0       0.65      0.66      0.65      3432\n 1.0       0.56      0.55      0.56      2727\n\navg / total       0.61      0.61      0.61      6159\n```", "```py\nfrom sklearn.model_selection import ShuffleSplit\nimport scipy.stats as sp\n\nshuffle_split_inst = ShuffleSplit()\n\nfor test, train in shuffle_split_inst.split(X):\n train_set = X.iloc[train]\n train_close = train_set.Close\n\n train_0 = train_close[~train_set.is_higher.astype(bool)]\n train_1 = train_close[train_set.is_higher.astype(bool)]\n\n test_set = X.iloc[test]\n test_close = test_set.Close.values\n\nll_0 = sp.norm.pdf(test_close, train_0.mean())\nll_1 = sp.norm.pdf(test_close, train_1.mean())\n```", "```py\n(ll_0 > ll_1).mean()\n\n0.14486740032473389\n```", "```py\nfrom sklearn import datasets\nX, y = datasets.make_classification(n_samples = 500)\n```", "```py\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y)\n```", "```py\nfrom sklearn import linear_model\nsgd_clf = linear_model.SGDClassifier()\n#As usual, we'll fit the model:\nsgd_clf.fit(X_train, y_train)\n```", "```py\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_test,sgd_clf.predict(X_test))\n\n0.80000000000000004\n```", "```py\nimport numpy as np\nfrom sklearn.datasets import fetch_20newsgroups\ncategories = [\"rec.autos\", \"rec.motorcycles\"]\nnewgroups = fetch_20newsgroups(categories=categories)\n#take a look\nprint \"\\n\".join(newgroups.data[:1])\n\nFrom: gregl@zimmer.CSUFresno.EDU (Greg Lewis)\nSubject: Re: WARNING.....(please read)...\nKeywords: BRICK, TRUCK, DANGER\nNntp-Posting-Host: zimmer.csufresno.edu\nOrganization: CSU Fresno\nLines: 33\n...\n\nnewgroups.target_names\n\n['rec.autos', 'rec.motorcycles']\n```", "```py\nfrom sklearn.feature_extraction.text import CountVectorizer\ncount_vec = CountVectorizer()\nbow = count_vec.fit_transform(newgroups.data)\n```", "```py\nbow\n\n<1192x19177 sparse matrix of type '<type 'numpy.int64'>'\n with 164296 stored elements in Compressed Sparse Row format>\n```", "```py\nbow = np.array(bow.todense())\n```", "```py\nwords = np.array(count_vec.get_feature_names())\nwords[bow[0] > 0][:5]\n\narray([u'10pm', u'1qh336innfl5', u'33', u'93740',\n u'___________________________________________________________________'], \n dtype='<U79')\n```", "```py\n'10pm' in newgroups.data[0].lower()\n\nTrue\n\n'1qh336innfl5' in newgroups.data[0].lower()\n\nTrue\n```", "```py\nfrom sklearn import naive_bayes\nclf = naive_bayes.GaussianNB().fit(X_train, y_train)\n```", "```py\nX = bow\ny = newgroups.target\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5,stratify=y)\n```", "```py\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_test,clf.predict(X_test) )\n\n0.94630872483221473\n```", "```py\nfrom sklearn.datasets import fetch_20newsgroups\nmn_categories = [\"rec.autos\", \"rec.motorcycles\", \"talk.politics.guns\"]\nmn_newgroups = fetch_20newsgroups(categories=mn_categories)\n```", "```py\nmn_bow = count_vec.fit_transform(mn_newgroups.data)\nmn_bow = np.array(mn_bow.todense())\n```", "```py\nX = mn_bow\ny = mn_newgroups.target\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5,stratify=y)\n\nfrom sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB().fit(X_train, y_train)\n```", "```py\nfrom sklearn.metrics import accuracy_score\n accuracy_score(y_test,clf.predict(X_test) )\n\n0.96317606444188719\n```", "```py\nfrom sklearn import datasets\nd = datasets.load_iris()\n```", "```py\nX = d.data.copy()\ny = d.target.copy()\nnames = d.target_names.copy()\nnames = np.append(names, ['unlabeled'])\nnames\n\narray(['setosa', 'versicolor', 'virginica', 'unlabeled'], \n dtype='|S10')\n```", "```py\ny[np.random.choice([True, False], len(y))] = -1\n```", "```py\ny[:10]\n\narray([ 0, -1, -1, 0, 0, 0, 0, -1, 0, -1])\n\nnames[y[:10]]\n\narray(['setosa', 'unlabeled', 'unlabeled', 'setosa', 'setosa', 'setosa',\n 'setosa', 'unlabeled', 'setosa', 'unlabeled'], \n dtype='|S10')\n```", "```py\nfrom sklearn import semi_supervised\nlp = semi_supervised.LabelPropagation()\nlp.fit(X, y)\n\nLabelPropagation(alpha=1, gamma=20, kernel='rbf', max_iter=30, n_jobs=1,\n n_neighbors=7, tol=0.001)\n```", "```py\npreds = lp.predict(X)\n(preds == d.target).mean()\n\n0.97333333333333338\n```", "```py\nls = semi_supervised.LabelSpreading()\n```", "```py\nls.fit(X, y)\n\nLabelSpreading(alpha=0.2, gamma=20, kernel='rbf', max_iter=30, n_jobs=1,\n n_neighbors=7, tol=0.001)\n```", "```py\n(ls.predict(X) == d.target).mean()\n\n0.96666666666666667\n```"]