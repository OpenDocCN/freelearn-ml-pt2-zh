- en: Clustering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚类
- en: 'One of the most widely used unsupervised learning methods is clustering. Clustering
    aims to uncover structure in unlabeled data. The aim is to group together data
    instances, such that there is great similarity between instances of the same cluster,
    and little similarity between instances of different clusters. As with supervised
    learning methods, clustering can benefit from combining many base learners. In
    this chapter, we present k-means; a simple and widely used clustering algorithm.
    Furthermore, we discuss how ensembles can be used to improve the algorithm''s
    performance. Finally, we use OpenEnsembles, a scikit-learn compatible Python library
    that implements ensemble clustering. The main topics covered in this chapter are
    as follows:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一种最广泛使用的无监督学习方法是聚类。聚类旨在揭示未标记数据中的结构。其目标是将数据实例分组，使得同一聚类中的实例之间相似度高，而不同聚类之间的实例相似度低。与有监督学习方法类似，聚类也能通过结合多个基本学习器来受益。在本章中，我们将介绍
    K-means 聚类算法；这是一种简单且广泛使用的聚类算法。此外，我们还将讨论如何通过集成方法来提升该算法的性能。最后，我们将使用 OpenEnsembles，这是一个兼容
    scikit-learn 的 Python 库，能够实现集成聚类。本章的主要内容如下：
- en: How the K-means algorithm works
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K-means 算法的工作原理
- en: Its strengths and weaknesses
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优势与劣势
- en: How ensembles can improve its performance
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成方法如何提升其性能
- en: Utilizing OpenEnsembles to create clustering ensembles
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 OpenEnsembles 创建聚类集成方法
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will require basic knowledge of machine learning techniques and algorithms.
    Furthermore, a knowledge of python conventions and syntax is required. Finally,
    familiarity with the NumPy library will greatly help the reader to understand
    some custom algorithm implementations.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要具备机器学习技术和算法的基础知识。此外，还需要了解 Python 的约定和语法。最后，熟悉 NumPy 库将极大帮助读者理解一些自定义算法实现。
- en: 'The code files of this chapter can be found on GitHub:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可以在 GitHub 上找到：
- en: '[https://github.com/PacktPublishing/Hands-On-Ensemble-Learning-with-Python/tree/master/Chapter08](https://github.com/PacktPublishing/Hands-On-Ensemble-Learning-with-Python/tree/master/Chapter08)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Hands-On-Ensemble-Learning-with-Python/tree/master/Chapter08](https://github.com/PacktPublishing/Hands-On-Ensemble-Learning-with-Python/tree/master/Chapter08)'
- en: Check out the following video to see the Code in Action: [http://bit.ly/2YYzniq](http://bit.ly/2YYzniq).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，了解代码的实际操作：[http://bit.ly/2YYzniq](http://bit.ly/2YYzniq)。
- en: Consensus clustering
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 共识聚类
- en: Consensus clustering is an alias for ensemble learning when it is applied to
    clustering methods. In clustering, each base learner assigns a label to each instance,
    although it is not conditioned on a specific target. Instead, the base learner
    generates a number of clusters and assigns each instance to a cluster. The label
    is the cluster itself. As will be demonstrated later, two base learners, produced
    by the same algorithm, can generate different clusters. Thus, it is not as straightforward
    to combine their cluster predictions as it is to combine regression or classification
    predictions.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 共识聚类是集成学习在聚类方法中应用时的别名。在聚类中，每个基本学习器都会为每个实例分配一个标签，尽管这个标签并不依赖于特定的目标。相反，基本学习器会生成多个聚类，并将每个实例分配到一个聚类中。标签就是聚类本身。如后面所示，由同一算法生成的两个基本学习器可能会生成不同的聚类。因此，将它们的聚类预测结果结合起来并不像回归或分类预测结果的结合那么直接。
- en: Hierarchical clustering
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 层次聚类
- en: 'Hierarchical clustering initially creates as many clusters as there are instances
    in the dataset. Each cluster contains only a single instance. Following this,
    it repeatedly finds the two clusters with the minimum distance between them (for
    example, the Euclidean distance), and merges them together into a new cluster.
    The process ends when there is only a single cluster. The method''s output is
    a dendrogram, which indicates how instances are hierarchically organized. An example
    is depicted in the following figure:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 层次聚类最初会根据数据集中实例的数量创建相同数量的聚类。每个聚类仅包含一个实例。之后，算法会反复找到两个距离最小的聚类（例如，欧几里得距离），并将它们合并为一个新的聚类。直到只剩下一个聚类时，过程结束。该方法的输出是一个树状图，展示了实例是如何按层次组织的。以下图示为例：
- en: '![](img/e40c693f-709a-4126-ad88-1a66df010ba0.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e40c693f-709a-4126-ad88-1a66df010ba0.png)'
- en: Dendrogram example
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 树状图示例
- en: K-means clustering
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K-means 聚类
- en: 'K-means is a relatively simple and effective way to cluster data. The main
    idea is that by starting with a number of *K* points as the initial cluster centers,
    each instance is assigned to the nearest cluster center. Then, the centers are
    re-calculated as the mean point of their respective members. This process repeats
    until the cluster centers no longer change. The main steps are as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: K-means 是一种相对简单有效的聚类数据的方法。其主要思想是，从*K*个点开始作为初始聚类中心，然后将每个实例分配给最近的聚类中心。接着，重新计算这些中心，作为各自成员的均值。这个过程会重复，直到聚类中心不再变化。主要步骤如下：
- en: Select the number of clusters, *K*
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择聚类的数量，*K*
- en: Select *K* random instances as the initial cluster centers
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择*K*个随机实例作为初始聚类中心
- en: Assign each instance to the closest cluster center
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将每个实例分配给最近的聚类中心
- en: Re-calculate the cluster centers as the mean of each cluster's members
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新计算聚类中心，作为每个聚类成员的均值
- en: If the new centers differ from the previous, go back to *Step 3*
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果新的中心与上一个不同，则返回到*步骤3*
- en: 'A graphical example is depicted as follows. After four iterations, the algorithm
    converges:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如下所示是一个图形示例。经过四次迭代，算法收敛：
- en: '![](img/0da7eaa9-db67-4a6a-a122-453ddd902ad6.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0da7eaa9-db67-4a6a-a122-453ddd902ad6.png)'
- en: The first four iterations on a toy dataset. Stars represent the cluster centers
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对一个玩具数据集进行的前四次迭代。星号表示聚类中心
- en: Strengths and weaknesses
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优势与劣势
- en: 'K-means is a simple algorithm, both to understand, as well as to implement.
    Furthermore, it usually converges relatively fast, requiring small computing power.
    Nonetheless, it has some disadvantages. The first one is its sensitivity to the
    initial conditions. Depending on the examples chosen as the first cluster centers,
    it can require more iterations in order to converge. For example, in the following
    diagram we present three initial points that put the algorithm at a disadvantage.
    In fact, in the third iteration, two cluster centers happen to coincide:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: K-means 是一个简单的算法，既容易理解，也容易实现。此外，它通常会比较快速地收敛，所需的计算资源较少。然而，它也有一些缺点。第一个缺点是对初始条件的敏感性。根据选择作为初始聚类中心的样本，可能需要更多的迭代才能收敛。例如，在以下图示中，我们呈现了三个初始点，它使得算法处于不利位置。事实上，在第三次迭代中，两个聚类中心恰好重合：
- en: '![](img/c931f880-88ab-426c-ac8b-40fa0b478679.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c931f880-88ab-426c-ac8b-40fa0b478679.png)'
- en: An example of unfortunate initial cluster centers
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一个不幸的初始聚类中心的示例
- en: Thus, the algorithm does not produce clusters deterministically. Another major
    problem is the number of clusters. This is a parameter that the data analyst must
    choose. There are usually three different solutions to this problem. The first
    concerns problems where some prior knowledge about the problem exists. Such examples
    are datasets where there is a need to uncover the structure of something that
    is known, for example, what is the driving factor behind athletes who improve
    their performance during a season, given their statistics? In this example, a
    sports coach could advise that athletes actually either improve drastically, stay
    the same, or deteriorate. Thus, the analyst could choose 3 as the number of clusters.
    Another possible solution is to experiment with different values of *K*, and measure
    the appropriateness of each value. This approach does not require any prior knowledge
    about the problem domain, but introduces the problem of measuring the appropriateness
    of each solution. We will see how we can solve these problems in the rest of this
    chapter.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，算法不会确定性地生成聚类。另一个主要问题是聚类的数量。这是一个需要数据分析师选择的参数。通常这个问题有三种不同的解决方案。第一种是针对一些有先验知识的问题。例如，数据集需要揭示一些已知事物的结构，比如，如何根据运动员的统计数据，找出哪些因素导致他们在一个赛季中表现的提高？在这个例子中，运动教练可能会建议，运动员的表现实际上要么大幅提升，要么保持不变，要么恶化。因此，分析师可以选择3作为聚类的数量。另一种可能的解决方案是通过实验不同的*K*值，并衡量每个值的适用性。这种方法不需要关于问题领域的任何先验知识，但引入了衡量每个解决方案适用性的问题。我们将在本章的其余部分看到如何解决这些问题。
- en: Using scikit-learn
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 scikit-learn
- en: 'The scikit-learn has a number of clustering techniques available for use. Here,
    we briefly present how to use K-means. The algorithm is implemented in the `KMeans`
    class, which is contained in the `sklearn.cluster` package. This package contains
    all the clustering algorithms that are available in scikit-learn. In this chapter,
    we will use mainly K-means, as it is one of the most intuitive algorithms. Furthermore,
    the techniques used in this chapter can be applied to almost any clustering algorithm.
    For this experiment, we will try to cluster breast cancer data, in order to explore
    the possibility of distinguishing malignant cases from benign cases. In order
    to better visualize the results, we will first perform a **t-Distributed Stochastic
    Neighbor Embedding** (**t-SNE**) decomposition, and use the two-dimensional embeddings
    as features. In order to proceed, we first load the required data and libraries,
    as well as set the seed for the NumPy random number generator:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: You can read more about t-SNE at [https://lvdmaaten.github.io/tsne/](https://lvdmaaten.github.io/tsne/).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Following this, we instantiate t-SNE, and transform our data. We plot the data
    in order to visually inspect and examine the data structure:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The preceding code generates the following plot. We observe two distinct areas.
    The area populated by the blue points denotes embedding values that imply a high
    risk that the tumor is malignant:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0ed097e9-49f9-42ea-a391-f349b0fa5e68.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: Plot of the two embeddings (components) of the breast cancer data
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: 'As we have identified that there exists some structure in the data, we will
    try to use K-means clustering in order to model it. By intuition, we assume that
    two clusters would suffice, as we try to separate two distinct regions, and we
    know that there are two classes in the dataset. Nonetheless, we will also experiment
    with four and six clusters, as they might provide more insight on the data. We
    will measure the percentage of each class assigned to each cluster, in order to
    gauge their quality. We do this by populating the `classified` dictionary. Each
    key corresponds to a cluster. Each key also points to a second dictionary, where
    the number of malignant and benign cases are recorded for the specific cluster.
    Furthermore, we plot the cluster assignments, as we want to see how the data is
    distributed among the clusters:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The results are depicted on the following table and figure:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '| **Cluster** | **Malignant** | **Benign** | **Malignant percentage** |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
- en: '| **2 clusters** |  |  |  |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
- en: '| **0** | 206 | 97 | 0.68 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
- en: '| **1** | 6 | 260 | 0.023 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
- en: '| **4 clsuters** |  |  |  |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
- en: '| **0** | 2 | 124 | 0.016 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
- en: '| **1** | 134 | 1 | 0.993 |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
- en: '| **2** | 72 | 96 | 0.429 |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
- en: '| **3** | 4 | 136 | 0.029 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
- en: '| **6 clusters** |  |  |  |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
- en: '| **0** | 2 | 94 | 0.021 |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
- en: '| **1** | 81 | 10 | 0.89 |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
- en: '| **2** | 4 | 88 | 0.043 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
- en: '| **3** | 36 | 87 | 0.0293 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
- en: '| **4** | 0 | 78 | 0 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
- en: '| **5** | 89 | 0 | 1 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
- en: Distribution of malignant and benign cases among the clusters
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: 'We observe that the algorithm is able to separate the instances belonging to
    each class quite effectively, even though it has no information about the labels:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/15320348-66ea-44be-b485-b046e535cca0.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
- en: Cluster assignment of each instance; 2, 4, and 6 clusters
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, we see that as we increase the number of clusters, the instances
    assigned to dominantly malignant or benign clusters does not increase, but the
    regions are better separated. This enables greater granularity and a more accurate
    prediction of probability that a selected instance belongs to either class. If
    we repeat the experiment without transforming the data, we get the following results:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '| **Cluster** | **Malignant** | **Benign** | **Malignant percentage** |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
- en: '| **2 clusters** |  |  |  |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
- en: '| **0** | 82 | 356 | 0.187 |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
- en: '| **1** | 130 | 1 | 0.992 |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
- en: '| **4 clusters** |  |  |  |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
- en: '| **0** | 6 | 262 | 0.022 |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
- en: '| **1** | 100 | 1 | 0.99 |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
- en: '| **2** | 19 | 0 | 1 |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
- en: '| **3** | 87 | 94 | 0.481 |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
- en: '| **6 clusters** |  |  |  |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
- en: '| **0** | 37 | 145 | 0.203 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
- en: '| **1** | 37 | 0 | 1 |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
- en: '| **2** | 11 | 0 | 1 |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
- en: '| **3** | 62 | 9 | 0.873 |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
- en: '| **4** | 5 | 203 | 0.024 |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
- en: '| **5** | 60 | 0 | 1 |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
- en: Clustering results on the data without t-sne transform
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: There are also two metrics that can be used in order to determine cluster quality.
    For data where the ground truth is known (essentially, labeled data), homogeneity
    measures the rate by which each cluster is dominated by a single class. For data
    where the ground truth is not known, the silhouette coefficient measures the intra-cluster
    cohesiveness and the inter-cluster separability. These metrics are implemented
    in scikit-learn under the `metrics` package, by the `silhouette_score` and `homogeneity_score`
    functions. The two metrics for each method are depicted in the following table.
    Homogeneity is higher for the transformed data, but the silhouette score is lower.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: 'This is expected, as the transformed data has only two dimensions, thus making
    the possible distance between the instances themselves smaller:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '| **Metric** | **Clusters** | **Raw data** | **Transformed data** |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
- en: '| **Homogeneity** | 2 | 0.422 | 0.418 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
- en: '| 4 | 0.575 | 0.603 |  |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
- en: '| 6 | 0.620 | 0.648 |  |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
- en: '| **Silhouette** | 2 | 0.697 | 0.500 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
- en: '| 4 | 0.533 | 0.577 |  |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
- en: '| 6 | 0.481 | 0.555 |  |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
- en: Homogeneity and silhouette scores for clusterings of the raw and transformed
    data
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Using voting
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Voting can be utilized in order to combine different clusterings of the same
    dataset. It is similar to voting for supervised learning, as each model (base
    learner) contributes to the final result with a vote. Here arises a problem of
    linking two clusters originating from two different clusterings. As each model
    will produce different clusters with different centers, we have to link similar
    clusters originating from different models. This is accomplished by linking together
    clusters that share the greatest number of instances. For example, assume that
    the following table and figure clusterings have occurred for a particular dataset:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7cf15245-bc15-4d72-a42f-9c14cc35d94e.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
- en: Three distinct clustering results
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: The following table depicts each instance's cluster assignments for the three
    different clusterings.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '| **Instance** | **1** | **2** | **3** | **4** | **5** | **6** | **7** | **8**
    | **9** | **10** |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
- en: '| **Clustering 1** | 0 | 0 | 2 | 2 | 2 | 0 | 0 | 1 | 0 | 2 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
- en: '| **Clustering 2** | 1 | 1 | 2 | 2 | 2 | 1 | 0 | 1 | 1 | 2 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
- en: '| **Clustering 3** | 0 | 0 | 2 | 2 | 2 | 1 | 0 | 1 | 1 | 2 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
- en: Cluster membership of each instance
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the preceding mapping, we can calculate the co-association matrix for
    each instance. This matrix indicates how many times a pair of instances has been
    assigned to the same cluster:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '| **Instances** | **1** | **2** | **3** | **4** | **5** | **6** | **7** | **8**
    | **9** | **10** |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
- en: '| **1** | 3 | 3 | 0 | 0 | 0 | 2 | 2 | 1 | 2 | 0 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
- en: '| **2** | 3 | 3 | 0 | 0 | 0 | 2 | 2 | 1 | 2 | 0 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
- en: '| **3** | 0 | 0 | 3 | 3 | 3 | 0 | 0 | 0 | 0 | 3 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
- en: '| **4** | 0 | 0 | 3 | 3 | 3 | 0 | 0 | 0 | 0 | 3 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
- en: '| **5** | 0 | 0 | 3 | 3 | 3 | 0 | 0 | 0 | 0 | 3 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
- en: '| **6** | 2 | 2 | 0 | 0 | 0 | 3 | 1 | 0 | 3 | 0 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
- en: '| **7** | 2 | 2 | 0 | 0 | 0 | 1 | 3 | 0 | 1 | 0 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
- en: '| **8** | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 3 | 2 | 0 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
- en: '| **9** | 2 | 2 | 0 | 0 | 0 | 3 | 1 | 2 | 3 | 0 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
- en: '| **10** | 0 | 0 | 3 | 3 | 3 | 0 | 0 | 0 | 0 | 3 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
- en: Co-association matrix for the previous example
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: 'By dividing each element with the number of base learners in the ensemble,
    and clustering together samples that have a value greater than 0.5, we get the
    following cluster assignments:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '| **Instance** | **1** | **2** | **3** | **4** | **5** | **6** | **7** | **8**
    | **9** | **10** |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
- en: '| **Voting clustering** | 0 | 0 | 1 | 1 | 1 | 0 | 0 | 0 | 0 | 1 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
- en: The voting cluster memberships
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 'As it is evident, the clustering is more stable. Furthermore, it is apparent
    that two clusters are sufficient for this dataset. By plotting the data and their
    cluster membership, we can see that there are two distinct groups, which is exactly
    what the voting ensemble was able to model, although each base learner generated
    three distinct cluster centers:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fc93b6c8-3fc2-4663-9673-7b5421a6e4c1.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
- en: Final cluster memberships for the voting ensemble
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Using OpenEnsembles
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'OpenEnsembles is a Python library that is dedicated to ensemble methods for
    clustering. In this section, we will present its usage and utilize it in order
    to cluster some of our example datasets. In order to install the library, the
    `pip install openensembles` command must be executed in the Terminal. Although
    it leverages scikit-learn, its interface is different. One major difference is
    that data must be passed as a `data` class, implemented by OpenEnsembles. The
    constructor has two input parameters: a pandas `DataFrame` which contains the
    data, and a list which contains the feature names:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In order to create a `cluster` ensemble, a `cluster` class object is created,
    passing the data as the parameter:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In this example, we will calculate the homogeneity score for a number of *K*
    values and ensemble sizes. In order to add a base learner to the ensemble, the
    `cluster` method of the `cluster` class must be called. The method accepts as
    arguments, `source_name`, which denotes the source data matrix name, `algorithm`.
    This dictates what algorithm the base learners will utilize, `output_name`, which
    will be the dictionary key for accessing the results of the specific base learner
    and `K`, the number of clusters for the specific base learner. Finally, in order
    to compute the final cluster memberships through majority voting, the `finish_majority_vote`
    method must be called. The only parameter that must be specified is the `threshold`
    value:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'It is evident that five clusters produce the best results for all three ensemble
    sizes. The results are summarized in the following table:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '| **K** | **Size** | **Homogeneity** |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
- en: '| 2 | 3 | 0.42 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
- en: '| 2 | 4 | 0.42 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
- en: '| 2 | 5 | 0.42 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
- en: '| 3 | 3 | 0.45 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
- en: '| 3 | 4 | 0.47 |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
- en: '| 3 | 5 | 0.47 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
- en: '| 4 | 3 | 0.58 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
- en: '| 4 | 4 | 0.58 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
- en: '| 4 | 5 | 0.58 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
- en: '| 5 | 3 | 0.6 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
- en: '| 5 | 4 | 0.61 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
- en: '| 5 | 5 | 0.6 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
- en: '| 6 | 3 | 0.35 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
- en: '| 6 | 4 | 0.47 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
- en: '| 6 | 5 | 0.35 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
- en: '| 7 | 3 | 0.27 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
- en: '| 7 | 4 | 0.63 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
- en: '| 7 | 5 | 0.37 |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
- en: OpenEnsembles majority vote cluster homogeneity for the breast cancer dataset
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: 'If we transform the data into two embeddings with t-SNE, and repeat the experiment,
    we get the following homogeneity scores:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '| **K** | **Size** | **Homogeneity** |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
- en: '| 2 | 3 | 0.42 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
- en: '| 2 | 4 | 0.42 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
- en: '| 2 | 5 | 0.42 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
- en: '| 3 | 3 | 0.59 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
- en: '| 3 | 4 | 0.59 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
- en: '| 3 | 5 | 0.59 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
- en: '| 4 | 3 | 0.61 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
- en: '| 4 | 4 | 0.61 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
- en: '| 4 | 5 | 0.61 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
- en: '| 5 | 3 | 0.61 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
- en: '| 5 | 4 | 0.61 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
- en: '| 5 | 5 | 0.61 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
- en: '| 6 | 3 | 0.65 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
- en: '| 6 | 4 | 0.65 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
- en: '| 6 | 5 | 0.65 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
- en: '| 7 | 3 | 0.66 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
- en: '| 7 | 4 | 0.66 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
- en: '| 7 | 5 | 0.66 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
- en: Majority vote cluster homogeneity for the transformed breast cancer dataset
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Using graph closure and co-occurrence linkage
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Two other methods that can be used to combine cluster results are graph closure
    and co-occurrence linkage. Here, we demonstrate how to use OpenEnsembles to create
    both types of ensembles.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Graph closure
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Graph closure creates a graph from the co-occurrence matrix. Every element
    (instance pair) is treated as a node. Pairs that have a higher value than the
    threshold are connected by an edge. Following this, a clique formation occurs,
    according to a specified size (specified by the number of nodes in the clique).
    Cliques are subsets of the graph''s nodes, such that every two nodes of the clique
    are neighbors. Finally, the cliques are combined to form unique clusters. In OpenEnsembles,
    it is implemented by the `finish_graph_closure` function, in the `cluster` class.
    The `clique_size` parameter determines the number of nodes in each clique. The
    `threshold` parameter determines the minimum co-occurrence that a pair must have
    in order to be connected by an edge in the graph. Similar to the previous example,
    we will use graph closure in order to cluster the breast cancer dataset. Notice
    that the only change in the code will be the usage of `finish_graph_closure`,
    instead of `finish_majority_vote`. First, we load the libraries and the dataset,
    and create the OpenEnsembles data object:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Then, we create the ensemble and use `graph_closure` in order to combine the
    cluster results. Notice that the dictionary key also changes to `''graph_closure''`:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The effect of *K* and the ensemble size on the clustering quality is similar
    to majority voting, although it does not achieve the same level of performance. The
    results are depicted in the following table:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '| **K** | **Size** | **Homogeneity** |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
- en: '| 2 | 3 | 0.42 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
- en: '| 2 | 4 | 0.42 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
- en: '| 2 | 5 | 0.42 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
- en: '| 3 | 3 | 0.47 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
- en: '| 3 | 4 | 0 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
- en: '| 3 | 5 | 0.47 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
- en: '| 4 | 3 | 0.58 |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
- en: '| 4 | 4 | 0.58 |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
- en: '| 4 | 5 | 0.58 |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
- en: '| 5 | 3 | 0.6 |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
- en: '| 5 | 4 | 0.5 |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
- en: '| 5 | 5 | 0.5 |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
- en: '| 6 | 3 | 0.6 |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
- en: '| 6 | 4 | 0.03 |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
- en: '| 6 | 5 | 0.62 |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
- en: '| 7 | 3 | 0.63 |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
- en: '| 7 | 4 | 0.27 |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
- en: '| 7 | 5 | 0.27 |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
- en: Homogeneity for graph closure clustering on the raw breast cancer data
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Co-occurrence matrix linkage
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Co-occurrence matrix linkage treats the co-occurrence matrix as a distance
    matrix between instances, and utilizes the distances in order to perform hierarchical
    clustering. The clustering stops when there is no element on the matrix with a
    value greater than the threshold. Again, we repeat the example. We use the `finish_co_occ_linkage`
    function to utilize co-occurrence matrix linkage with `threshold=0.5`, and use
    the `''co_occ_linkage''` key to access the results:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following table summarizes the results. Notice that it outperforms the
    other two methods. Furthermore, the results are more stable, and less time is
    required to execute it than either of the other two methods:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '| **K** | **Size** | **Homogeneity** |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
- en: '| 2 | 3 | 0.42 |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
- en: '| 2 | 4 | 0.42 |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
- en: '| 2 | 5 | 0.42 |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
- en: '| 3 | 3 | 0.47 |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
- en: '| 3 | 4 | 0.47 |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
- en: '| 3 | 5 | 0.45 |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
- en: '| 4 | 3 | 0.58 |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
- en: '| 4 | 4 | 0.58 |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
- en: '| 4 | 5 | 0.58 |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
- en: '| 5 | 3 | 0.6 |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
- en: '| 5 | 4 | 0.6 |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
- en: '| 5 | 5 | 0.6 |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
- en: '| 6 | 3 | 0.59 |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
- en: '| 6 | 4 | 0.62 |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
- en: '| 6 | 5 | 0.62 |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
- en: '| 7 | 3 | 0.62 |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
- en: '| 7 | 4 | 0.63 |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
- en: '| 7 | 5 | 0.63 |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
- en: Homogeneity results for co-occurrence cluster linkage on the raw breast cancer
    dataset
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 原始乳腺癌数据集上共现聚类连接的同质性结果
- en: Summary
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 小结
- en: In this chapter, we presented the K-means clustering algorithm and clustering
    ensemble methods. We explained how majority voting can be used in order to combine
    cluster assignments from an ensemble, and how it can outperform the individual
    base learners. Furthermore, we presented the OpenEnsembles Python library, which
    is dedicated to clustering ensembles. The chapter can be summarized as follows.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了 K-means 聚类算法和聚类集成方法。我们解释了如何使用多数投票方法来结合集成中的聚类分配，并如何使其超越单个基础学习器。此外，我们还介绍了专门用于聚类集成的
    OpenEnsembles Python 库。本章可以总结如下。
- en: '**K-means** creates *K* clusters, and assigns instances to each cluster by
    iteratively considering the cluster center to be the mean of its members. It can
    be sensitive to the initial conditions, and the selected number of clusters. Majority
    voting can help to overcome the algorithm''s disadvantages. **Majority voting**
    clusters together instances that have a high co-occurrence. **Co-occurrence matrices**
    show how frequently a pair of instances has been assigned to the same cluster
    by the same base learner. **Graph closure** uses co-occurrence matrices in order
    to create graphs, and clusters the data based on cliques. **Co-occurrence linkage**
    uses a specific clustering algorithm, hierarchical (agglomerative) clustering,
    by treating the co-occurrence matrix as a pairwise distance matrix. In the next
    chapter, we will try to utilize all the ensemble learning techniques that we have
    covered in this book, in order to classify fraudulent credit card transactions.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '**K-means** 创建 *K* 个聚类，并通过迭代地将每个实例分配到各个聚类中，使得每个聚类的中心成为其成员的均值。它对初始条件和选定的聚类数目敏感。多数投票可以帮助克服该算法的缺点。**多数投票**
    将具有高共现的实例聚集在一起。**共现矩阵** 显示了一对实例被同一基础学习器分配到同一聚类的频率。**图闭包** 使用共现矩阵来创建图，并基于团簇对数据进行聚类。**共现连接**
    使用一种特定的聚类算法——层次聚类（聚合型），将共现矩阵视为成对距离矩阵。在下一章中，我们将尝试利用本书中介绍的所有集成学习技术，以对欺诈信用卡交易进行分类。'
