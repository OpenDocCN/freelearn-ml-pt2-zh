- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Probabilistic Models for Time-Series
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Probability is a measure of how likely something is to occur. In sales forecasting,
    an estimate of uncertainty is crucial because these forecasts, providing insights
    into cash flow, margin, and revenue, drive business decisions on which depend
    the financial stability and the livelihoods of employees. This is where probabilistic
    models for time-series come in. They help us make decisions when an estimate of
    certainty is important.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, I'll introduce Prophet, Markov models, and Fuzzy time-series
    models. At the end, we'll go through an applied exercise with these methods.
  prefs: []
  type: TYPE_NORMAL
- en: Another application for probabilistic modeling is estimating counterfactuals,
    where we can estimate treatment effects in experiments. We'll discuss the concept
    of Bayesian Structural Time-Series Models, and we'll run through a practical example
    with a time-series in the practice section.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''re going to cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Probabilistic Models for Time-Series
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prophet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Markov Models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fuzzy Modeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bayesian Structural Time-Series Models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Python Exercise:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prophet
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Markov Switching Model
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Fuzzy Time-Series
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Bayesian Structural Time-Series Models
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We'll start with an introduction to probabilistic time-series predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Probabilistic Models for Time-Series
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned in the introduction, probabilistic models can help us make decisions
    under uncertainty, and in situations where estimates have to come with quantified
    confidence, such as in financial forecasting, this can be crucial. For predictions
    of sales or cash flow, attaching probabilities to model predictions can make it
    easier for financial controllers and managers to act on the new information.
  prefs: []
  type: TYPE_NORMAL
- en: Some well-known algorithms include Prophet, explicitly designed for monitoring
    operational metrics and **key** **performance indicators** (**KPIs**), and Markov
    models. Others are stochastic deep learning models such as **DeepAR** and **DeepState**.
    Since we are dealing with deep learning models in *Chapter 10*, *Deep Learning
    Models*, we'll not deal with them in detail in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The Prophet model comes from Facebook (Taylor and Letham, 2017) and is based
    on a decomposable model with interpretable parameters. A guiding design principle
    was that parameters can be intuitively adjusted by analysts.
  prefs: []
  type: TYPE_NORMAL
- en: Both Prophet and the Silverkite algorithm, which we introduced in *Chapter 7*,
    *Machine Learning Models for Time-Series*, aim for accurate predictions with time-series
    that can have changing trends, seasonality, and recurring events (such as holidays),
    and short-term effects, and are therefore well suited for many applications in
    data science, where the focus is on tasks such as resource planning, optimizing
    financial decisions, and tracking progress for operational analysis – typical
    tasks for operations research.
  prefs: []
  type: TYPE_NORMAL
- en: Other types of models of particular interest within the application of time-series
    include Markov models, which we'll discuss in a dedicated section.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bayesian Structural Time-Series** (**BSTS**) models, which we mentioned in
    *Chapter 6*, *Unsupervised Models for Time-Series*, allow the quantification of
    the posterior uncertainty of the individual components, control the variance of
    the components, and impose prior beliefs on the model. The BSTS model is a technique
    that can be used for feature selection, time-series forecasting, and inferring
    causal relationships. This last point, causal inference, is another use case for
    probabilistic models in time-series. Understanding the impact of interventions
    can be important, for example, with A/B tests.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following plot illustrates the popularity of a few selected probabilistic
    libraries suitable for time-series predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![probabilistic-star_history.png](img/B17577_09_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.1: Libraries for the probabilistic modeling of time-series'
  prefs: []
  type: TYPE_NORMAL
- en: You can see that, of these three libraries, `pyFTS` outranks the other two.
    I haven't included the `statsmodels` library, which includes a few probabilistic
    models. Neither have I included Prophet. Both `statsmodels` and Prophet would
    have outstripped HMMs by far, a library for Hidden Markov Models, and Pints, a
    library for noisy time-series.
  prefs: []
  type: TYPE_NORMAL
- en: Neither have I included neural network or deep learning libraries such as TensorFlow
    Probability or Gluon-TS. Deep learning will be the topic of *Chapter 10*, *Deep
    Learning for Time-Series*.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start with a forecasting model in Prophet!
  prefs: []
  type: TYPE_NORMAL
- en: Prophet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Facebook's Prophet is both a Python/R library and the algorithm that comes with
    it. The algorithm was published in 2017 ("Forecasting at Scale" by Sean Taylor
    and Benjamin Letham). The authors write that the problems of forecasting and anomaly
    detection in practice involve the complexity of handling a variety of idiosyncratic
    forecasting problems at Facebook with piecewise trends, multiple seasonalities,
    and floating holidays, and building trust across the organization in these forecasts.
  prefs: []
  type: TYPE_NORMAL
- en: With these goals in mind, Prophet was designed to be scalable to many time-series,
    flexible enough for a wide range of business-relevant, possibly idiosyncratic
    time-series, and at the same time intuitive enough to be configurable by domain
    experts who might have little knowledge of time-series methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Prophet algorithm is similar to the **Generalized Additive Model** (**GAM**)
    and formalizes the relationship between the forecast for the three model components,
    trend (growth), seasonality, and holiday, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17577_09_001.png)'
  prefs: []
  type: TYPE_IMG
- en: The error term epsilon represents the residual—idiosyncratic changes not accommodated
    by the model. All functions use time as the regressor. The three effects are additive;
    however, Sean Taylor and Benjamin Letham advise that multiplicative seasonality,
    where the seasonal effect is a factor that multiplies g(t), can be accomplished
    through a log transform.
  prefs: []
  type: TYPE_NORMAL
- en: The trend or growth function can be linear or logistic for saturating growth.
    Both can incorporate piecewise effects through change points. The seasonality
    models periodic effects based on the Fourier series.
  prefs: []
  type: TYPE_NORMAL
- en: Change point selection in Prophet is automated. Parameters are optimized via
    the Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm, as implemented in the Stan
    platform for statistical modeling.
  prefs: []
  type: TYPE_NORMAL
- en: Probabilistic models bring the advantage of providing a measure of certainty
    with the prediction; however, their predictions are not necessarily better than
    those of non-probabilistic models. Benchmark results of Prophet against other
    models have seen mixed results.
  prefs: []
  type: TYPE_NORMAL
- en: In their 2020 paper "*A Worrying Analysis of Probabilistic Time-Series Models
    for Sales Forecasting*", Seungjae Jung and others validated probabilistic time-series
    models on a large-scale dataset. The univariate time-series consists of the daily
    sales from an e-commerce website.
  prefs: []
  type: TYPE_NORMAL
- en: They compared two deep-learning probabilistic models, DeepAR and DeepState,
    and Prophet to baseline models that comprised a **moving average** (**MA**), **linear
    regression** (**LR**), a **multi-layer perceptron** (**MLP**), and **Seasonal
    ARIMA** (**SARIMA**). You should remember from *Chapter 5*, *Moving Averages and
    Autoregressive Models*, that the MA is a simple unweighted mean of preceding days.
    They tried 72 different hyperparameters for prophet and all baseline models.
  prefs: []
  type: TYPE_NORMAL
- en: They found that probabilistic models in their test failed to outperform even
    the simplest baseline models such as MLP and LR in terms of **root mean squared
    error** (**RMSE**) and **mean absolute percentage error** (**MAPE**). Overall,
    Prophet performed the worst of all models. As always, model performance depends
    on the dataset and the task at hand—there's no silver bullet.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see how Markov Models work!
  prefs: []
  type: TYPE_NORMAL
- en: Markov Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Markov chain is a probabilistic model describing a sequence of possible events
    that satisfies the Markov property.
  prefs: []
  type: TYPE_NORMAL
- en: '**Markov property**: In a sequence or stochastic process that possesses the
    Markov property, the probability of each event depends only on the immediately
    preceding state (rather than earlier states). These sequences or processes can
    also be called **Markovian**, or a **Markov Process**.'
  prefs: []
  type: TYPE_NORMAL
- en: Named after Russian mathematician Andrey Markov, the Markov property is very
    desirable since it significantly reduces the complexity of a problem. In forecasting,
    instead of taking into account all previous states, t-1, t-2, …, 0, only t-1 is
    considered.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, the **Markov assumption**, for a mathematical or machine learning
    model is that the sequence satisfies the Markov property. In models such as the
    Markov chain and Hidden Markov model, the process or sequence is assumed to be
    a Markov process.
  prefs: []
  type: TYPE_NORMAL
- en: In a **discrete-time Markov chain** (**DTMC**), the sequence (or chain) transitions
    between states at discrete time steps. Markov chains can also be operating at
    continuous time steps. This less common model is called a **continuous-time Markov
    chain** (**CTMC**).
  prefs: []
  type: TYPE_NORMAL
- en: In a **hidden Markov model** (**HMM**), it is assumed that the process X follows
    unobservable states Y, which is another process whose behavior depends on X. The
    HMM models this latent or hidden process Y based on X.
  prefs: []
  type: TYPE_NORMAL
- en: 'Yet another Markov-type model is the nonlinear regime-switching model (also:
    Markov switching model). Invented by James Hamilton in 1989, the regime-switching
    model specifically addresses situations of abrupt changes, where more conventional
    linear models would struggle to capture distinct behaviors. The regime-switching
    model is an autoregressive model, where the mean of the process switches between
    regimes.'
  prefs: []
  type: TYPE_NORMAL
- en: For the practical example, we'll follow a `statsmodels` library implementation
    and build a model to replicate Hamilton's 1989 model. Hamilton modeled a time-series
    of the real gross national product (RGNP), a macroeconomic measure of the value
    of economic output adjusted for price changes, between 1951 and 1984\.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll use a Markov switching model of order 4, which can be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17577_09_002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For each state (or period), the regime transitions according to the following
    matrix of transition probabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17577_09_003.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/B17577_09_004.png) is the probability of transitioning from regime
    i to regime j.'
  prefs: []
  type: TYPE_NORMAL
- en: In this case, we are modeling two regimes.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we'll discuss a Fuzzy approach to time-series modeling.
  prefs: []
  type: TYPE_NORMAL
- en: Fuzzy Modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Fuzzy logic and fuzzy set theory were developed by Lotfi Zadeh in the 1960s
    and 70s while a professor at the University of California, Berkeley. Born to Persian
    and Jewish Russian parents in Baku, Azerbaijan, he completed his schooling in
    Tehran, Iran, and later moved to the USA, where he studied at MIT and Columbia.
    As a result, he was familiar with how concepts are understood in different cultures
    and expressed in different languages. This inspired his research approach to approximate
    reasoning and linguistic variables that he formalized as fuzzy theory.
  prefs: []
  type: TYPE_NORMAL
- en: '**Fuzzy set theory** is an approach that can deal with problems relating to
    ambiguous, subjective, and imprecise judgments. Vagueness is inherent in everyday
    language, and fuzziness was invented to express this and work with it in an intuitive
    manner. Fuzzy logic expresses subjective belief and vagueness. It can and has
    been claimed that probability theory is a subset of fuzzy logic.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Fuzzy sets** are sets whose elements have degrees of membership. In Fuzzy
    logic, instead of binary (Boolean) truth values, True and False, the unit interval
    [0, 1] is used as a basis for rules of inference. More formally, the membership
    function, which expresses the degree of certainty that an element belongs to the
    set, is characterized by a membership mapping function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17577_09_005.png)'
  prefs: []
  type: TYPE_IMG
- en: For example, a well-known algorithm, **fuzzy c-means** (James Bezdek, 1981),
    based on k-means, returns degrees of membership to clusters. This means that each
    point can belong to each cluster, but to varying degrees. This fuzzy set membership
    is in contrast to the so-called crisp partitioning typically returned by other
    clustering algorithms, where a point is either a member of a cluster or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'For fuzzy logic, all set operations, such as equality, sub- and superset, union,
    and intersection, had to be redefined. The union between two fuzzy sets (or relations)
    is defined as the max operation on each point, while the intersection is defined
    as the min operation. More formally, the union between two sets A and B, ![](img/B17577_09_006.png),
    is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17577_09_007.png)'
  prefs: []
  type: TYPE_IMG
- en: where ![](img/B17577_09_008.png) is the membership function for point x.
  prefs: []
  type: TYPE_NORMAL
- en: 'Song and Chissom (1993) proposed a first-order, time-invariant fuzzy time-series
    model to forecast enrollments at the University of Alabama. This is formalized
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17577_09_009.png)'
  prefs: []
  type: TYPE_IMG
- en: where ![](img/B17577_09_010.png) is the enrollment in year t, *R* is the union
    of fuzzy relations, and ![](img/B17577_09_011.png) is the fuzzy Max-Min composition
    operator.
  prefs: []
  type: TYPE_NORMAL
- en: The **Max-Min composition operation**, ![](img/B17577_09_012.png), is obtained
    by taking the minimum term-by-term of the ith row of A and the jth column of B,
    and taking the maximum of these n minimums.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is illustrated in the diagram below (from the Matrix Multiplication page
    on Wikipedia):'
  prefs: []
  type: TYPE_NORMAL
- en: '![atrix multiplication diagram 2.svg](img/B17577_09_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.2: The Max-Min composition operator'
  prefs: []
  type: TYPE_NORMAL
- en: 'The values at the positions marked with circles are calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17577_09_013.png)![](img/B17577_09_014.png)'
  prefs: []
  type: TYPE_IMG
- en: In Song and Chissom's approach, relations between values at time t and values
    preceding it are extracted and carried forward for the forecast. A necessary preprocessing
    step in their algorithm is the conversion of time-series X into a fuzzy time-series
    Y. This is called fuzzification and consists of constraining an input from the
    set of real values to fuzzy memberships of a discrete set. This quantization can
    be performed by vector quantization methods such as Kohonen Self-Organizing Maps
    (SOM), an unsupervised machine learning method that produces a low-dimensional
    representation.
  prefs: []
  type: TYPE_NORMAL
- en: While fuzzy time-series models have not enjoyed widespread application, they
    have been shown to be competitive in some applications to more traditional approaches,
    such as SARIMA (for example, Maria Elena et al., 2012). They work on discrete
    and continuous time-series and produce interpretable models for forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we'll do a few practice examples for probabilistic
    time-series predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian Structural Time-Series Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In causal inference, we want to analyze the effect of a treatment. The treatment
    can be any action that interacts with the system or environment that we care about,
    from changing the colors of a button on a website to the release of a product.
    We have the choice of taking the action (for example, releasing the product),
    thereby observing the outcome under treatment, or not taking the action, where
    we observe the outcome under no treatment. This is illustrated in the diagram
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![../causal%20(1).png](img/B17577_09_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.3: Causal effect of a treatment'
  prefs: []
  type: TYPE_NORMAL
- en: In the diagram, an action is taken or not (medicine is administered to a patient),
    and depending on whether the action is taken we see the patient recovering (cycling)
    or going into intensive care.
  prefs: []
  type: TYPE_NORMAL
- en: A causal effect is the difference between what happens under treatment and what
    happens under no treatment. The problem with this is that we can't observe both
    potential outcomes at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: However, we can run an experiment to observe both potential outcomes under treatment
    and potential outcomes under no treatment, such as in an A/B test, where the treatment
    is given only to a subset of the total population and the treatment condition
    B can be compared against the control condition A.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can tabulate potential outcomes like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Unit | Treatment status, ![](img/B17577_09_015.png) | Outcome under treatment,
    ![](img/B17577_09_016.png) | Outcome under no treatment, ![](img/B17577_09_017.png)
    | Covariates, ![](img/B17577_09_018.png) |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | ![heck mark, Segoe UI Symbol font, character code 2714 hex.](img/B17577_09_04.png)
    | estimate | ![heck mark, Segoe UI Symbol font, character code 2714 hex.](img/B17577_09_04.png)
    |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 1 | ![heck mark, Segoe UI Symbol font, character code 2714 hex.](img/B17577_09_04.png)
    | estimate | ![heck mark, Segoe UI Symbol font, character code 2714 hex.](img/B17577_09_04.png)
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 0 | estimate | ![heck mark, Segoe UI Symbol font, character code 2714
    hex.](img/B17577_09_04.png) | ![heck mark, Segoe UI Symbol font, character code
    2714 hex.](img/B17577_09_04.png) |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 0 | estimate | ![heck mark, Segoe UI Symbol font, character code 2714
    hex.](img/B17577_09_04.png) | ![heck mark, Segoe UI Symbol font, character code
    2714 hex.](img/B17577_09_04.png) |'
  prefs: []
  type: TYPE_TB
- en: 'Figure 9.4: Potential outcomes from an experiment'
  prefs: []
  type: TYPE_NORMAL
- en: In the first column, *Unit*, we see the sample indexes. Each row refers to a
    separate unit or sample in the population. The second column (*Treatment status*)
    encodes if the treatment was administered (1) or not (0). In the third and fourth
    columns, *Outcome under treatment* and *Outcome under no treatment*, respectively,
    are registered.
  prefs: []
  type: TYPE_NORMAL
- en: 'The marks show what should be obvious: when there is a treatment, we can observe
    the outcomes under treatment, but not the outcomes under no treatment. Inversely,
    when there is no treatment, we can observe the outcomes under no treatment, but
    not the outcomes under treatment.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, in the last column, there are additional variables that can help us
    in our model that are available irrespective of treatment or no treatment.
  prefs: []
  type: TYPE_NORMAL
- en: With **Bayesian Structural Time-Series** (**BSTS**), the focus is on estimating
    the treatment effect in the absence of an experiment. We can estimate or impute
    the counterfactuals, which are the unknown potential outcomes of an experiment.
    This allows to compare the outcomes under treatment against outcomes under no
    treatment, and therefore to quantify the causal treatment effect.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model consists of three main components:'
  prefs: []
  type: TYPE_NORMAL
- en: Kalman filter
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Variable selection
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Bayesian model averaging
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Kalman filters are used for time-series decomposition. This allows the modeling
    of trends, seasonality, and holidays. In the Bayesian variable selection step
    (the spike-and-slab technique), the most important regression predictors are selected.
    Finally, in the model averaging, the prediction results are combined.
  prefs: []
  type: TYPE_NORMAL
- en: The application of BSTS models for change point and anomaly detection was described
    in the paper "*Predicting the Present with Bayesian Structural Time-Series*" (2013),
    by Steven L. Scott and Hal Varian.
  prefs: []
  type: TYPE_NORMAL
- en: A paper outlining the application of BSTS for estimating the causal effect of
    interventions was published in 2015 by Google Research ("*Inferring causal impact
    using Bayesian structural time-series models*", by Kay H. Brodersen, Fabian Gallusser,
    Jim Koehler, Nicolas Remy, and Steven L. Scott).
  prefs: []
  type: TYPE_NORMAL
- en: The mathematical details of this are beyond the scope of this chapter. Fortunately,
    we can use a Python library to apply BSTS models. We'll run through an example
    in a practice section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: We can practice now some of the theory that we have learned so far in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Python Exercise
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's put into practice what we've learned in this chapter so far. We'll be
    doing a model in Prophet, a Markov Switching model, a Fuzzy time-series model,
    and a BSTS model.
  prefs: []
  type: TYPE_NORMAL
- en: Let's get started with Prophet!
  prefs: []
  type: TYPE_NORMAL
- en: Prophet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, let''s make sure we have everything installed that we need. Let''s quickly
    install the required libraries. We can do this from the terminal (or similarly
    from the Anaconda navigator):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You'll need a recent version of pandas-datareader, otherwise you might get a
    `RemoteDataError`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll use the Prophet model through Facebook''s Prophet library. Let''s install
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Once this is done, we are set to go.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we'll use the daily Yahoo closing stock values in this chapter
    that we used in several examples in *Chapter 7*, *Machine Learning Models for
    Time-Series*.
  prefs: []
  type: TYPE_NORMAL
- en: 'To recap, we can download the daily Yahoo stock history from 2001 to 2021 in
    pandas-datareader as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us a pandas DataFrame with two columns, the adjusted daily closing
    value and the date. Let''s quickly check the datatypes of these two columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'These are the datatypes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The `Date` column is datetime in nanoseconds. `Adj Close` is of type float.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll feed this into the `fit()` method for training:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We have to rename our columns `ds` and `y` in order to stick to the Prophet
    conventions. We have a trained Prophet model now.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll then create a new DataFrame that will have future dates. We''ll be able
    to stick this DataFrame into the `predict()` method of the Prophet model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The forecast is calling the `predict()` method with this new DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `forecast` DataFrame contains the upper and lower confidence intervals alongside
    the forecast. The `ds` columns is the date corresponding to the forecast.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s plot the forecasts against the actual data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s the plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17577_09_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.5: Forecast versus actual time-series (Prophet)'
  prefs: []
  type: TYPE_NORMAL
- en: You might want to compare this plot to the one in *Chapter 7*,*Machine Learning
    Models for Time-Series*. The actual data is thick and bold, while the forecast
    is thinner. The upper and lower confidence intervals are around the forecast.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can inspect the forecasts by looking at the DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17577_09_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.6: Table of forecasts (Prophet)'
  prefs: []
  type: TYPE_NORMAL
- en: It is quite easy to get a first model, and there are many ways to tweak it.
  prefs: []
  type: TYPE_NORMAL
- en: Markov Switching Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For the Markov Switching model, we''ll use the `statsmodels` library. If you
    don''t have it installed yet, you can install it like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll use a dataset with `statsmodels` in this example. This is based on the
    `statsmodels` tutorial on Markov switching autoregression models. We can get the
    dataset from the Stata Press publishing house on their website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us a pandas series of the RGNP, and the index annotates the dates.
    Let''s quickly plot this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![RGNP.png](img/B17577_09_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.7: Growth rate of RGNP'
  prefs: []
  type: TYPE_NORMAL
- en: We'll model domestic recessions and expansions. The model will include transition
    probabilities between these two regimes and predict probabilities of expansion
    or recession at each time point.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s fit the 4^(th) order Markov switching model. We''ll specify two regimes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We now have the model fitted via maximum likelihood estimation to the RGNP data.
    We've set `switching_ar=False` because the `statsmodels` implementation defaults
    to switching autoregressive coefficients.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s have a look at the `statsmodels` model summary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following output (truncated):'
  prefs: []
  type: TYPE_NORMAL
- en: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_qPxkLo/Screenshot
    2021-07-11 at 18.36.54.png](img/B17577_09_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.8: Markov Switching Model Results'
  prefs: []
  type: TYPE_NORMAL
- en: We can see that we have two sets of parameters, one each for the two regimes.
    We also get measures of the statistical model quality (such as AIC and BIC).
  prefs: []
  type: TYPE_NORMAL
- en: 'At the bottom of the same output, we can see the regime transition parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![../../Desktop/Screenshot%202021-07-11%20at%2018.40.01.pn](img/B17577_09_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.9: Regime transition parameters'
  prefs: []
  type: TYPE_NORMAL
- en: These are the regime transitions we mentioned in the theory section on Markov
    Switching models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see the lengths of recession and expansion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The output `array([ 4.07604793, 10.4258926 ])` is in financial quarters. Therefore,
    a recession is expected to take about four quarters (1 year) and an expansion
    10 quarters (two and a half years).
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we''ll plot the probability of recession at each point in time. However,
    this is more informative if we overlay indicators of recession by the National
    Bureau of Economic Research (NBER), which we can load up with pandas-dataloader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us a DataFrame in which recessions are indicated. Here are the first
    five rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_P2RnuW/Screenshot
    2021-07-11 at 19.00.46.png](img/B17577_09_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.10: Recession indicators by NBER'
  prefs: []
  type: TYPE_NORMAL
- en: In the first five rows, there was no recession according to NBER indicators.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll now plot NBER recession indicators against the model regime predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us actual recession data against model predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![filtered_probability_of_recession.png](img/B17577_09_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.11: Filtered probability of recession'
  prefs: []
  type: TYPE_NORMAL
- en: We can see there seems to be quite a good match between the model predictions
    and actual recession indicators.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, the `statsmodels` implementation doesn't provide the functionality
    for forecasting or out-of-sample prediction, so we'll end the brief demo here.
  prefs: []
  type: TYPE_NORMAL
- en: '`Statsmodels` includes other datasets for regime-switching models to play around
    with.'
  prefs: []
  type: TYPE_NORMAL
- en: In the following practice section, we'll apply Song and Chissom's model to a
    time-series forecasting problem using the `pyFTS` library for fuzzy time-series
    developed in the MINDS laboratory at the Universidade Federal de Minas Gerais
    (UFMG), Brazil.
  prefs: []
  type: TYPE_NORMAL
- en: Fuzzy Time-Series
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we'll load two time-series of ticker symbols, the NASDAQ and
    the S&P 500 indices, over time and forecast them using Song and Chissom's 1993
    algorithm. This follows closely the example tutorial in the library.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we''ll install the library from the terminal (or similarly from the
    Anaconda navigator):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we''ll define our datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Both datasets, the entries in our `datasets` dictionary, are vectors of roughly
    4,000 scalar values. We''ll take about 50% of these points for training, and we''ll
    set this as a constant:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The model assumes a stationary process, so we'll need to preprocess our time-series
    by temporal differencing as discussed in *Chapter 2*, *Exploratory Time-Series
    Analysis with Time-Series*.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll define a first-order differencing operation for preprocessing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s plot our time-series and the transformation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The plots of the original and transformed time-series look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![nasdaq_sp500.png](img/B17577_09_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.12: NASDAQ and S&P 500—the original and transformed time-series'
  prefs: []
  type: TYPE_NORMAL
- en: In the GitHub repository for this, you can see the Augmented Dickey-Fuller unit
    root test applied to the transformed time-series. This test for stationarity gives
    us the green light, and we continue with our model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step is training our models for the two transformed (differenced)
    time-series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We iterate over the datasets and train a separate model for each, which we save
    into a dictionary, `models`. The training consists of extracting relations from
    the training set.
  prefs: []
  type: TYPE_NORMAL
- en: As part of the model training, the preprocessed time-series is quantized as
    discussed in the theory section on fuzzy time-series models of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can plot our forecasts from the two models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Again, we iterate over the two datasets. This time, we plot the original values
    in the test set (200 points) against estimated values predicted one step ahead.
    Please note that the models are not updated based on new data during the prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is our plot comparing the forecasts against the actual values in the test
    set:'
  prefs: []
  type: TYPE_NORMAL
- en: '![fuzzy_predicted_actual.png](img/B17577_09_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.13: Fuzzy time-series forecast versus actual (S&P 500, NASDAQ).'
  prefs: []
  type: TYPE_NORMAL
- en: Looking at these charts, the predictions look quite promising, but let's look
    at some hard numbers!
  prefs: []
  type: TYPE_NORMAL
- en: '`PyFTS` has a convenience function to extract RMSE, MAPE, and finally, Theil''s
    U, a measure of correlation. We introduced these measures in *Chapter 2*, *Exploratory
    Time-Series Analysis with Time-Series*.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We get these statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_PJYAmO/Screenshot
    2021-07-11 at 23.36.47.png](img/B17577_09_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.14: Model statistics for fuzzy time-series modeling of NASDAQ and
    S&P 500'
  prefs: []
  type: TYPE_NORMAL
- en: I'll leave it as an exercise for the reader to compare these two models with
    others based on these error metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian Structural Time-Series Modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this example, we'll apply BSTS modeling to understand the causal effect of treatment
    in time-series.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we''ll install the library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Now, we'll load a dataset, and we'll estimate the consequence of a treatment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we''ll be estimating the impact of the emissions scandal of September
    2015 for Volkswagen. We''ll work with the stock values of three big companies,
    Volkswagen, BMW, and Allianz. The dataset comes with the Python Causal Impact
    (tfcausalimpact) library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we have the stock values. Let''s plot them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are the stocks over time:'
  prefs: []
  type: TYPE_NORMAL
- en: '![emission_scandal_stocks.png](img/B17577_09_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.15: Stock values of three big companies (Volkswagen, BMW, Allianz)'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see a sharp drop in the value of Volkswagen shares in late 2015\. Let''s
    try to find out the actual impact of the emission scandal. We can build our model
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The model statistics provide us with the causal impact estimate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'We see these stats here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Figure 9.16: Causal impact estimates and model statistics'
  prefs: []
  type: TYPE_NORMAL
- en: As discussed before, the Causal Impact model developed by Google works by fitting
    a BSTS model to observed data, which is later used to predict what the results
    would be had no intervention happened in a given time period.
  prefs: []
  type: TYPE_NORMAL
- en: 'The total estimated effect is about 44 points—the stock price would be 44 points
    higher if not for the emissions scandal. The impact summary report gives us this
    analysis (excerpt):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Figure 9.17: Causal impact analysis report'
  prefs: []
  type: TYPE_NORMAL
- en: This gives us a very good idea of what the model estimates.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can plot the effect as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_OzvijR/Screenshot
    2021-07-18 at 17.03.38.png](img/B17577_09_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.18: Causal impact graph'
  prefs: []
  type: TYPE_NORMAL
- en: Again, we see the original time-series against the predicted counterfactual
    value.
  prefs: []
  type: TYPE_NORMAL
- en: The emissions scandal wiped out a massive amount of value from Volkswagen. The
    44 points can give us a monetary value of how much cheating emissions tests cost
    Volkswagen.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we've discussed how probabilistic models for time-series can
    help us make decisions with an estimate of uncertainty in the context of financial
    forecasting. These forecasts drive business decisions for financial planning.
  prefs: []
  type: TYPE_NORMAL
- en: I've introduced Prophet, Markov models, and Fuzzy time-series models. We've
    discussed the components of Facebook's Prophet model. For Markov models, we've
    discussed the main ideas, such as the Markov property, and we've discussed more
    details regarding Switching Models. Then I've explained some basics of fuzzy set
    theory and how this is applied to time-series.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we've delved into the intuition and some of the theory of BSTS models
    in the context of estimating treatment effects in experiments.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we went through an applied exercise with each method. In the BSTS practice,
    we've looked at the effect of the Volkswagen emissions scandal.
  prefs: []
  type: TYPE_NORMAL
