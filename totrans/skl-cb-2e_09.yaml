- en: Tree Algorithms and Ensembles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Doing basic classifications with decision trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizing a decision tree with pydot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tuning a decision tree
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using decision trees for regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reducing overfitting with cross-validation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing random forest regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bagging regression with nearest neighbor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tuning gradient boosting trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tuning an AdaBoost regressor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing a stacking aggregator with scikit-learn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we focus on decision trees and ensemble algorithms. Decision
    algorithms are easy to interpret and visualize as they are outlines of the decision
    making process we are familiar with. Ensembles can be partially interpreted and
    visualized, but they have many parts (base estimators), so we cannot always read
    them easily.
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal of ensemble learning is that several estimators can work better than
    a single one. There are two families of ensemble methods implemented in scikit-learn:
    averaging methods and boosting methods. Averaging methods (random forest, bagging,
    extra trees) reduce variance by averaging the predictions of several estimators.
    Boosting methods (gradient boost and AdaBoost) reduce bias by sequential building
    base estimators with the goal of reducing the bias of the whole ensemble.'
  prefs: []
  type: TYPE_NORMAL
- en: A common characteristic of many ensemble constructions is using randomness to
    build predictors. Random forest, for example, uses randomness (as its name implies),
    and we will use a search through many model parameters using randomness. Use the
    ideas of randomness in this chapter to build on them at work, reduce the computational
    cost, and produce better-scoring algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: We finish the chapter with a stacking aggregator, which is an ensemble of potentially
    very different models. Part of the data analysis in stacking is taking predictions
    of several machine learning algorithms as input.
  prefs: []
  type: TYPE_NORMAL
- en: A lot of data science is computationally intensive. If possible, use a multi-core
    computer. Throughout, there is a parameter called `n_jobs` set to `-1`, which
    utilizes all of your computer's cores.
  prefs: []
  type: TYPE_NORMAL
- en: Doing basic classifications with decision trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here, we perform basic classification with decision trees. Decision trees for
    classification are sequences of decisions that determine a classification, or
    a categorical outcome. Additionally, the decision tree can be examined in SQL
    by other individuals within the same company looking at the data.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Start by loading the iris dataset once again and dividing the data into training
    and testing sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Import the decision tree classifier and train it on the training set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Then measure the accuracy on the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The decision tree appears to be accurate. Let's examine it further.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing a decision tree with pydot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you would like to produce graphs, install the `pydot` library. Unfortunately,
    for Windows this installation could be non-trivial. Please focus on looking at
    the graphs rather than reproducing them if you struggle to install `pydot`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Within an IPython Notebook, perform several imports and type the following
    script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/7a0cd685-1f72-4a14-a1d9-540000655e0e.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is the decision tree that was produced with the training; calling the
    `fit` method on `X_train` and `y_train`. Look at it closely, starting at the top
    of the tree. You have 105 samples in the training set. The training set is split
    into three sets of 35 each: *value = [35, 35, 35]*. Explicitly, these are 35 Setosa,
    35 Versicolor, and 35 Virginica flowers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7757355c-4e94-45fc-b93c-339e725fbeee.png)'
  prefs: []
  type: TYPE_IMG
- en: The first decision is whether the petal length of the flower is less than or
    equal to 2.45\. If the answer is true, or yes, the flower is classified as being
    in the first category, *value = [35, 0, 0]*. The flower is classified as being
    a Setosa flower. In several examples of the iris dataset classification, this
    one was the easiest to classify.
  prefs: []
  type: TYPE_NORMAL
- en: Otherwise, if the petal length is greater than 2.45, the first decision leads
    to a smaller decision tree. The smaller decision tree only has flowers of the
    last two types, Versicolour and Virginica, and the *value = [0, 35, 35]*.
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm proceeds to produce a complete tree of four levels, depth 4 (note
    that the top node is not included in counting the levels). With formal language,
    the three nodes characterizing a decision in the picture are called a **split**.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You might wonder what the gini reference is within the visualization of the
    decision tree. Gini refers to the gini function, which measures the quality of
    a split, with three nodes representing a decision. When the algorithm runs, a
    few splits that optimize the gini function are considered. The split that produces
    the best gini impurity measure is chosen.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another option is to measure entropy to determine how to split the tree. You
    can try both options and determine which is best using cross-validation. Change
    the criterion in the decision tree as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This leads to the following diagram of the tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e4ace225-9883-4ac8-8f24-e5ebc5898b95.png)'
  prefs: []
  type: TYPE_IMG
- en: You can examine how this criterion performs under cross-validation using `GridSearchCV`
    and vary the criterion parameter in the parameter grid. We will do this in the
    next section.
  prefs: []
  type: TYPE_NORMAL
- en: Tuning a decision tree
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will continue to explore the iris dataset further by focusing on the first
    two features (sepal length and sepal width), optimizing the decision tree, and
    creating some visualizations.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Load the iris dataset, focusing on the first two features. Additionally, split
    the data into training and testing sets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'View the data with pandas:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/9ced7bac-4256-4fee-a792-e3b1bb470662.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Before optimizing the decision tree, let''s try a single decision tree with
    default parameters. Instantiate and train a decision tree:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Measure the accuracy score:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Visualizing the tree with `graphviz` reveals a very complex tree with many
    nodes and levels (the image is for representational purposes only: it is OK if
    you cannot read it! It is a very deep tree with lots of overfitting!):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0efa05a9-d506-4952-a84f-518c4df1f233.png)'
  prefs: []
  type: TYPE_IMG
- en: This is a case of overfitting. The decision tree is very elaborate. The whole
    iris dataset consists of 150 samples, and a very complex tree is undesirable.
    Recall that in previous chapters we have used linear SVMs, which split space in
    a simple way with a few straight lines.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before continuing, visualize the training data points using matplotlib:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/4ad4b828-df97-4c91-a8d9-74837a60dacc.png)'
  prefs: []
  type: TYPE_IMG
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To optimize the decision tree''s performance, use `GridSearchCV`. Start by
    instantiating a decision tree:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, instantiate and train `GridSearchCV`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Note how in the parameter grid, `param_grid`, we vary the split scoring criterion
    between `gini` and `entropy` and vary the `max_depth` of a tree.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now try to score the accuracy on the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The accuracy improved slightly. Let's look at `GridSearchCV` more closely.
  prefs: []
  type: TYPE_NORMAL
- en: 'View the scores of all the decision trees tried in the grid search:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Note that this method will be unavailable in future versions of scikit-learn.
    Feel free to use `zip(gs_inst.cv_results_['mean_test_score'],gs_inst.cv_results_['params'])`
    to produce similar results.
  prefs: []
  type: TYPE_NORMAL
- en: 'From this list of scores, you can see that deeper trees perform worse than
    shallow trees. In detail, the data in the training set is split into five parts.
    Training occurs in four parts while testing happens in one of the five parts.
    Very deep trees overfit: they perform well on the training sets, but on the five
    testing sets of the cross-validation, they perform badly.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Select the best performing tree with the `best_estimator_` attribute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Visualize the tree with `graphviz`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/159231ba-c3cb-4edc-9af6-7bf024922a4f.png)'
  prefs: []
  type: TYPE_IMG
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For additional insight, we will create an additional visualization. Start by
    creating a NumPy mesh grid as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the `best_estimator_` attribute in the grid search, predict the scenarios
    on the NumPy grid that was just created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Look at the visualization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/f77dc2dd-a3ae-4675-96f4-90964fdb18b9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Using this type of visualization, you can see that decision trees try to construct
    rectangles to classify the type of iris flower. Every split creates a line perpendicular
    to one of the features. In the following graph there is a vertical line depicting
    the first decision, whether sepal length is greater (right of the line) or less
    than (left of the line) the number 5.45\. Typing `plt.axvline(x = 5.45, color=''black'')`
    with the preceding code yields the following result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/9c2c6061-57fb-45ab-8eb1-af1d5a8e6848.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Visualize the first three lines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/b9258f26-c92f-4f73-9efa-ae817d71e8f1.png)'
  prefs: []
  type: TYPE_IMG
- en: The horizontal line, `sepal_width = 2.8`, is shorter and ends at `x = 5.45`
    because it does not apply to the case of *sepal_length >= 5.45*. In the end, several
    rectangular regions are created.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following graph shows the same type of visualization applied to the very
    large decision tree that overfits. The decision tree classifier attempts to place
    a rectangle around many specific samples of the iris dataset, which shows how
    it generalizes poorly with new samples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a71c1714-82ac-4921-aa81-2175af88ac99.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, you could also plot how max depth influences the cross-validation
    score. Script a grid search with a max depth range from 2 to 51:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/893f5599-9588-48ed-b239-2366de550aac.png)'
  prefs: []
  type: TYPE_IMG
- en: The plot shows, from a different perspective, that a higher max depth tends
    to decrease the cross-validation score.
  prefs: []
  type: TYPE_NORMAL
- en: Using decision trees for regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Decision trees for regression are very similar to decision trees for classification.
    The procedure for developing a regression model consists of four parts:'
  prefs: []
  type: TYPE_NORMAL
- en: Load the dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Split the set into training/testing subsets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instantiate a decision tree regressor and train it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Score the model on the test subset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this example, load scikit-learn''s diabetes dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have loaded the dataset, we must split the data into training and
    testing subsets. Before doing that, however, visualize the target variable using
    pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/3bc25907-7251-40db-9078-684918673037.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is a regression example, and we cannot use `stratify=y` when splitting
    the dataset. Instead, we will bin the target variable: we will keep track of whether
    the target variable is less than 50, or between 50 and 100, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create bins of width 50:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Using `np.digitize`, bin the target variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Visualize the `binned_y` variable with pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/bd0bf5d3-85e4-41ab-b633-2d7d0a022fcc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The NumPy array `binned_y` keeps track of which bin each element of `y` belongs
    to. Now, split the set into training and testing sets and stratify the `binned_y`
    array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To create a decision tree regressor, instantiate the decision tree and train
    it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'To measure the model''s accuracy, make predictions for the target variable
    using the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Use an error metric to compare `y_test` (ground truth) and `y_pred` (model
    predictions). Here, use the `mean_absolute_error`, which is the average of the
    absolute value of the differences between the elements of `y_test` and `y_pred`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'As an alternative, measure the mean absolute percentage error, which is the
    average of the absolute value of the differences divided by the size of elements
    of the ground truth. This measures the magnitude of the error relative to the
    size of the element of the ground truth:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Thus, we have established a baseline of performance with regard to the diabetes
    dataset. Every change to the model will possibly affect the error measurements.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With pandas, you can quickly visualize the distribution of the errors. Turn
    the difference between the ground truth, `y_test`, and the predictions, `y_pred`,
    into a histogram:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/9e7ef642-acbc-4a03-823e-aad3a466bbc8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can do the same for the percentage error:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/3ff52f44-dd66-481d-a32a-d5fcbfa8effa.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, using code from previous sections, look at the tree of decisions itself.
    Note that we did not optimize for max depth:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8050a13b-249b-4d5d-9498-f20fa1f80cdd.png)'
  prefs: []
  type: TYPE_IMG
- en: The tree is very elaborate and very likely to overfit.
  prefs: []
  type: TYPE_NORMAL
- en: Reducing overfitting with cross-validation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here, we will use cross-validation on the diabetes dataset from the previous
    recipe to improve performance. Start by loading the dataset, as in the previous
    recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Use grid search to reduce overfitting. Import a decision tree and instantiate
    it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, import `GridSearchCV` and instantiate this class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'View the best estimator with the `best_estimator_` attribute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The best estimator has `max_depth` of `3`. Now check the error metrics:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the mean percentage error:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Finally, visualize the best regression tree with `graphviz`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/fabe4e5a-52da-425e-93e4-d28b1f202181.png)'
  prefs: []
  type: TYPE_IMG
- en: The tree has a better accuracy metrics and has been cross-validated to minimize
    overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing random forest regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Random forests is an ensemble algorithm. Ensemble algorithms use several algorithms
    together to improve predictions. Scikit-learn has several ensemble algorithms,
    most of which use trees to predict. Let's start by expanding on decision tree
    regression with several decision trees working together in a random forest.
  prefs: []
  type: TYPE_NORMAL
- en: A random forest is a mixture of several decision trees, where each tree provides
    a single vote toward the final prediction. The final random forest calculates
    a final output by averaging the results of all the trees it is composed of.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Load the diabetes regression dataset as we did with decision trees. Split all
    of the data into training and testing sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s dive in and import and instantiate a random forest. Train the random
    forest:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Measure prediction error. Try the random forest on the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: The errors have gone down slightly compared to a single decision tree.
  prefs: []
  type: TYPE_NORMAL
- en: 'To access any of the trees that make up the random forest, use the `estimators_`
    attribute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'To view the first tree on the list in `graphviz`, refer to the first element
    in the list, `rft.estimators_[0]`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/78e9e1e5-64ef-446d-9643-e599d5302e4f.png)'
  prefs: []
  type: TYPE_IMG
- en: To view the second tree, use `best_rft.estimators_[1]`. To view the last tree,
    use `best_rft.estimators_[9]` because there are, by default, 10 trees, indexed
    0 to 9, that make up the random forest.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'An additional feature of the random forest is determining feature importance
    through the `feature_importances_` attribute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'You can visualize feature importance as well:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/8d795ad3-455b-4d75-9b22-dc44156e6c5d.png)'
  prefs: []
  type: TYPE_IMG
- en: The most influential features are **body mass index** (**BMI**), followed by
    `bl_4` (the fourth of six blood serum measurements), and then average blood pressure.
  prefs: []
  type: TYPE_NORMAL
- en: Bagging regression with nearest neighbors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Bagging is an additional ensemble type that, interestingly, does not necessarily
    involve trees. It builds several instances of a base estimator acting on random
    subsets of the first training set. In this section, we try **k-nearest neighbors**
    (**KNN**) as the base estimator.
  prefs: []
  type: TYPE_NORMAL
- en: Pragmatically, bagging estimators are great for reducing the variance of a complex
    base estimator, for example, a decision tree with many levels. On the other hand,
    boosting reduces the bias of weak models, such as decision trees of very few levels,
    or linear models.
  prefs: []
  type: TYPE_NORMAL
- en: 'To try out bagging, we will find the best parameters, a hyperparameter search,
    using scikit-learn''s random grid search. As we have done previously, we will
    go through the following process:'
  prefs: []
  type: TYPE_NORMAL
- en: Figure out which parameters to optimize in the algorithm (these are the parameters
    researchers view as the best to optimize in the literature).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a parameter distribution where the most important parameters are varied.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform a random grid search. If you're using an ensemble, keep the number of
    estimators low at first.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the best parameters from the previous step with many estimators.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once more, load the diabetes dataset used in the last section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, import `BaggingRegressor` and `KNeighborsRegressor`. Additionally, also
    import `RandomizedSearchCV`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Then, set up a parameter distribution for the grid search. For a bagging meta-estimator,
    some parameters to vary include `max_samples`, `max_features`, `oob_score`, and
    the number of estimators, `n_estimators`. The number of estimators is set to a
    low number, 100, to optimize the other parameters before trying a large number
    of estimators.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Additionally, there is one list of parameters for the KNN algorithm. It is
    named `base_estimator__n_neighbors`, where `n_neighbors` is the internal name
    within the KNN class. The `base_estimator` name is the name of the base estimator
    within the `BaggingRegressor` class. The `base_estimator__n_neighbors` list has
    the numbers `3` and `5`, which refer to the number of neighbors in the nearest
    neighbors algorithm:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Instantiate the `KNeighboursRegressor` class and pass it as the `base_estimator`
    within `BaggingRegressor`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, instantiate and run a randomized search. Do a few iterations, `n_iter
    = 5`, as this could be time consuming:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Look at the best parameters in the random search run:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Train a `BaggingRegressor` using the best parameters, except for `n_estimators`,
    which you can increase. We increase the number of estimators to 1,000 in this
    case:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, measure the performance on a test set. The algorithm does not perform
    as well as others, but we can possibly use it as part of a stacking aggregator
    later:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: If you look carefully, bagging regression performed slightly better than the
    random forest in the previous section as both mean absolute error and mean absolute
    percentage error are better. Always remember that you do not have to limit your
    ensemble learning to trees—here, you build an ensemble regressor with the KNN
    algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Tuning gradient boosting trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will examine the California housing dataset with gradient boosting trees.
    Our overall approach will be the same as before:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Focus on important parameters in the gradient boosting algorithm:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`max_features`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_depth`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`min_samples_leaf`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`learning_rate`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`loss`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a parameter distribution where the most important parameters are varied.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform a random grid search. If using an ensemble, keep the number of estimators
    low at first.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the best parameters from the previous step with many estimators.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Load the California housing dataset and split the loaded dataset into training
    and testing sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Load the gradient boosting algorithm and random grid search:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a parameter distribution for the gradient boosting trees:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the grid search to find the best parameters. Perform a randomized search
    with 30 iterations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Now look at the report in dataframe form. The functions to view the report
    have been wrapped so that they can be used more times:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'View the dataframe that shows how gradient boosting trees performed with various
    parameter settings:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/9bef6af7-a648-455f-b522-bc4791f310b1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'From this dataframe; `ls` outperforms `huber` significantly as a loss function,
    `3` is the best `min_samples_leaf` (but `4` could perform well), `3` is the best
    `max_depth` (although `1` or `2` could work as well), `0.3` works well as a learning
    rate (so could `0.2` or `0.4` though), and a `max_features` of `1.0` works well,
    but so could some other number (such as half of the features: `0.5`).'
  prefs: []
  type: TYPE_NORMAL
- en: 'With this information, try another randomized search:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'View the new report that is generated:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/5f3155e2-5fdb-4ac0-804d-311617170495.png)'
  prefs: []
  type: TYPE_IMG
- en: 'With this information, you can run one more randomized search with the following
    parameter distributions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Storing the result under `rs_gbt`, perform training one last time with 4,000
    estimators:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Use scikit-learn''s `metrics` module to describe the errors on the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: If you recall, the R-squared for the random forest was slightly lower at 0.8252\.
    This algorithm was slightly better. For both, we performed randomized searches.
    Note that if you perform hyperparameter optimization with trees frequently, you
    can automate the multiple randomized parameter searches.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, we will optimize a gradient boosting classifier instead of a regressor.
    The procedure is very similar.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the best parameters of a gradient boosting classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Classifying using gradient boosting trees is very similar to the regression
    we have been doing. Again, we will do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Find the best parameters of the gradient boosting classifier. These are the
    same as the gradient boosting regressor, with the exception that the loss function
    options are different. The parameters have the same names and are as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`max_features`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_depth`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`min_samples_leaf`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`learning_rate`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`loss`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Run an estimator with the best parameter but more trees in the estimator. In
    the following code, note the change in the loss function called deviance. To do
    the classification, we will use a binary variable. Recall the visualization of
    the target set, `y`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/3acb7f7a-af30-4270-b9cf-b08d20cf0f52.png)'
  prefs: []
  type: TYPE_IMG
- en: 'On the far right, there seems to be an anomaly: a lot of values in the distribution
    are equal to five. Perhaps we would like to separate that set and analyze it separately.
    As part of that process, we might want to be able to predetermine whether a point
    should belong to the anomaly set or not. We will build a classifier to separate
    points where `y` is equal to or greater than five:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, split the set into training and testing. Stratify the binned variable,
    `binned_y`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a binary variable that has the value `1` if the target variable `y`
    is `5` or greater and `0` if it is less than `5`. Note that if the binary variable
    is `1`, it belongs to the anomalous set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, use the shape of `X_train` to split a binary variable into `y_train_binned`
    and `y_test_binned`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Perform a randomized grid search:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'View the best parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Increase the number of estimators and train the final estimator:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'View the performance of the algorithm:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: The algorithm, a binary classifier, is about 94% accurate at determining whether
    the house belongs to the anomalous set. The hyperparameter optimization of the
    gradient boosting classifier was very similar, with the same important parameters
    as gradient boosting regression.
  prefs: []
  type: TYPE_NORMAL
- en: Tuning an AdaBoost regressor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The important parameters to vary in an AdaBoost regressor are `learning_rate`
    and `loss`. As with the previous algorithms, we will perform a randomized parameter
    search to find the best scores that the algorithm can do.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Import the algorithm and randomized grid search. Try a randomized parameter
    distribution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'View the best parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'These suggest another randomized search with parameter distribution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Copy the dictionary that holds the best parameters. Increase the number of
    estimators in the copy to 3,000:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Train the final AdaBoost model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'Measure the model performance on the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: Unfortunately, this model clearly underperforms relative to the other tree models.
    We will set it aside without optimizing it any further because it would take more
    training time and Python development time.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have found the best parameters for a few algorithms. Here is a table summarizing
    the parameters to optimize for each algorithm under cross-validation. It is suggested
    you start optimizing these parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/01baf86e-5bbd-4420-8088-94e40924376c.png)'
  prefs: []
  type: TYPE_IMG
- en: Writing a stacking aggregator with scikit-learn
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will write a stacking aggregator with scikit-learn. A stacking
    aggregator mixes models of potentially very different types. Many of the ensemble
    algorithms we have seen mix models of the same type, usually decision trees.
  prefs: []
  type: TYPE_NORMAL
- en: The fundamental process in the stacking aggregator is that we use the predictions
    of several machine learning algorithms as input for the training of another machine
    learning algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: In more detail, we train two or more machine learning algorithms using a pair
    of `X` and `y` sets (`X_1`, `y_1`). Then we make predictions on a second `X` set
    (`X_stack`), `y_pred_1`, `y_pred_2`, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: These predictions, `y_pred_1` and `y_pred_2`, become inputs to a machine learning
    algorithm with the training output `y_stack`. Finally, the error can be measured
    on a third input set, `X_3`, and a ground truth set, `y_3`.
  prefs: []
  type: TYPE_NORMAL
- en: It will be easier to see in an example.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Load the data from the California housing dataset once again. Observe how we
    create bins once more to stratify a continuous variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Now split the pair, `X` and `y`, into three `X` and `y` pairs, input and output,
    by using `train_test_split` twice. Note how we stratify the continuous variable
    at each stage:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'Using `RandomizedSearchCV`, find the best parameters for the first of the algorithms
    in the stacking aggregator, in this case a bagging algorithm of several nearest
    neighbor models:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the best parameters, train the bagging regressor using many estimators,
    in this case, 3,000:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'Do the same process for the gradient boost algorithm on the `X_1`, `y_1` pair
    of sets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'Train the best parameter set with more estimators:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'Predict the target using `X_stack` using both algorithms:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'View the metrics (error rates) that each algorithm produces. View the metrics
    for the bagging regressor:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'View the metrics for gradient boost:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a dataframe of the predictions from both algorithms. Alternatively,
    you could also create a NumPy array of the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'View the new dataframe of predictions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: '>![](img/e48f9f14-cee9-4ac8-8199-782a1444fc27.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Look at the correlation between the prediction columns. The columns are correlated,
    but not perfectly. The ideal situation is that the algorithms are not perfectly
    correlated and both perform well. In this case, the bagging regressor does not
    perform nearly as well as gradient boost:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/e1501268-e7c9-4955-a014-8489c424be18.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now do a randomized search with a third algorithm. This algorithm takes as
    input the predictions of the first two. We will use an extra trees regressor to
    make predictions on the predictions of the other two algorithms:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'Copy the parameter dictionary and increase the number of estimators within
    that copied dictionary. View the final dictionary, if you want to:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'Train the extra trees regressor on the predictions dataframe using `y_stack` as
    a target:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'To examine the overall performance of the stacking aggregator, you need a function
    that takes an `X` set as input, predicts creating a dataframe using the bagging
    regressor and gradient boost, and finally predicts on those predictions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'Predict using `X_test_prin`, the `X` set that was left out, using the useful
    `predict_from_X_set` function we just created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'Measure the performance of the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: What now? The R-squared metric improved slightly, and we worked very hard for
    that slight improvement. What we could do next is write more robust, production-like
    code for the stacker that makes it easy to place a lot of estimators that are
    not correlated within the stacker.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we could do feature engineering—improving the columns of the data
    using math and/or domain knowledge of the California housing industry. You can
    also try different algorithms for different inputs. Two columns, latitude and
    longitude, are well suited for random forests and other inputs could be well-modeled
    with a linear algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Thirdly, we could explore different algorithms on the dataset. For this dataset
    we focused on complex, high-variance algorithms. We could try simpler high-bias
    algorithms. These alternative algorithms could help the stacking aggregator we
    used at the end.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, in regards to the stacker, you could rotate the `X_stacker` set through
    cross-validation to make the most of the training set.
  prefs: []
  type: TYPE_NORMAL
