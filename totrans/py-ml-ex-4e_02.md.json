["```py\n>>> import numpy as np\n>>> X_train = np.array([\n...     [0, 1, 1],\n...     [0, 0, 1],\n...     [0, 0, 0],\n...     [1, 1, 0]])\n>>> Y_train = ['Y', 'N', 'Y', 'Y']\n>>> X_test = np.array([[1, 1, 0]]) \n```", "```py\n>>> def get_label_indices(labels):\n...     \"\"\"\n...     Group samples based on their labels and return indices\n...     @param labels: list of labels\n...     @return: dict, {class1: [indices], class2: [indices]}\n...     \"\"\"\n...     from collections import defaultdict\n...     label_indices = defaultdict(list)\n...     for index, label in enumerate(labels):\n...         label_indices[label].append(index)\n...     return label_indices \n```", "```py\n>>> label_indices = get_label_indices(Y_train)\n>>> print('label_indices:\\n', label_indices)\n    label_indices:\n    defaultdict(<class 'list'>, {'Y': [0, 2, 3], 'N': [1]}) \n```", "```py\n>>> def get_prior(label_indices):\n...     \"\"\"\n...     Compute prior based on training samples\n...     @param label_indices: grouped sample indices by class\n...     @return: dictionary, with class label as key, corresponding\n...              prior as the value\n...     \"\"\"\n...     prior = {label: len(indices) for label, indices in\n...                                      label_indices.items()}\n...     total_count = sum(prior.values())\n...     for label in prior:\n...         prior[label] /= total_count\n...     return prior \n```", "```py\n>>> prior = get_prior(label_indices)\n>>> print('Prior:', prior)\n Prior: {'Y': 0.75, 'N': 0.25} \n```", "```py\n>>> def get_likelihood(features, label_indices, smoothing=0):\n...     \"\"\"\n...     Compute likelihood based on training samples\n...     @param features: matrix of features\n...     @param label_indices: grouped sample indices by class\n...     @param smoothing: integer, additive smoothing parameter\n...     @return: dictionary, with class as key, corresponding\n...              conditional probability P(feature|class) vector \n...              as value\n...     \"\"\"\n...     likelihood = {}\n...     for label, indices in label_indices.items():\n...         likelihood[label] = features[indices, :].sum(axis=0)\n...                                + smoothing\n...         total_count = len(indices)\n...         likelihood[label] = likelihood[label] /\n...                                 (total_count + 2 * smoothing)\n...     return likelihood \n```", "```py\n>>> smoothing = 1\n>>> likelihood = get_likelihood(X_train, label_indices, smoothing)\n>>> print('Likelihood:\\n', likelihood)\nLikelihood:\n {'Y': array([0.4, 0.6, 0.4]), 'N': array([0.33333333, 0.33333333, 0.66666667])} \n```", "```py\n>>> def get_posterior(X, prior, likelihood):\n...     \"\"\"\n...     Compute posterior of testing samples, based on prior and\n...     likelihood\n...     @param X: testing samples\n...     @param prior: dictionary, with class label as key,\n...                   corresponding prior as the value\n...     @param likelihood: dictionary, with class label as key,\n...                        corresponding conditional probability\n...                            vector as value\n...     @return: dictionary, with class label as key, corresponding\n...              posterior as value\n...     \"\"\"\n...     posteriors = []\n...     for x in X:\n...         # posterior is proportional to prior * likelihood\n...         posterior = prior.copy()\n...         for label, likelihood_label in likelihood.items():\n...             for index, bool_value in enumerate(x):\n...                 posterior[label] *= likelihood_label[index] if\n...                   bool_value else (1 - likelihood_label[index])\n...         # normalize so that all sums up to 1\n...         sum_posterior = sum(posterior.values())\n...         for label in posterior:\n...             if posterior[label] == float('inf'):\n...                 posterior[label] = 1.0\n...             else:\n...                 posterior[label] /= sum_posterior\n...         posteriors.append(posterior.copy())\n...     return posteriors \n```", "```py\n>>> posterior = get_posterior(X_test, prior, likelihood)\n>>> print('Posterior:\\n', posterior)\nPosterior:\n [{'Y': 0.9210360075805433, 'N': 0.07896399241945673}] \n```", "```py\n>>> from sklearn.naive_bayes import BernoulliNB \n```", "```py\n>>> clf = BernoulliNB(alpha=1.0, fit_prior=True) \n```", "```py\n>>> clf.fit(X_train, Y_train) \n```", "```py\n>>> pred_prob = clf.predict_proba(X_test)\n>>> print('[scikit-learn] Predicted probabilities:\\n', pred_prob)\n[scikit-learn] Predicted probabilities:\n [[0.07896399 0.92103601]] \n```", "```py\n>>> pred = clf.predict(X_test)\n>>> print('[scikit-learn] Prediction:', pred)\n[scikit-learn] Prediction: ['Y'] \n```", "```py\n>>> import numpy as np\n>>> import pandas as pd\n>>> data_path = 'ml-1m/ratings.dat'\n>>> df = pd.read_csv(data_path, header=None, sep='::', engine='python')\n>>> df.columns = ['user_id', 'movie_id', 'rating', 'timestamp']\n>>> print(df)\n         user_id  movie_id  rating  timestamp\n0              1      1193       5  978300760\n1              1       661       3  978302109\n2              1       914       3  978301968\n3              1      3408       4  978300275\n4              1      2355       5  978824291\n...          ...       ...     ...        ...\n1000204     6040      1091       1  956716541\n1000205     6040      1094       5  956704887\n1000206     6040       562       5  956704746\n1000207     6040      1096       4  956715648\n1000208     6040      1097       4  956715569\n[1000209 rows x 4 columns] \n```", "```py\n>>> n_users = df['user_id'].nunique()\n>>> n_movies = df['movie_id'].nunique()\n>>> print(f\"Number of users: {n_users}\")\nNumber of users: 6040\n>>> print(f\"Number of movies: {n_movies}\")\nNumber of movies: 3706 \n```", "```py\n>>> def load_user_rating_data(df, n_users, n_movies):\n...    data = np.zeros([n_users, n_movies], dtype=np.intc)\n              movie_id_mapping = {}\n              for user_id, movie_id, rating in zip(df['user_id'], df['movie_id'], df['rating']):\n                    user_id = int(user_id) - 1\n                    if movie_id not in movie_id_mapping:\n                         movie_id_mapping[movie_id] = len(movie_id_mapping)\n                   data[user_id, movie_id_mapping[movie_id]] = rating\n              return data, movie_id_mapping\n>>> data, movie_id_mapping = load_user_rating_data(df, n_users, n_movies) \n```", "```py\n>>> values, counts = np.unique(data, return_counts=True)\n... for value, count in zip(values, counts):\n...     print(f'Number of rating {value}: {count}')\nNumber of rating 0: 21384031\nNumber of rating 1: 56174\nNumber of rating 2: 107557\nNumber of rating 3: 261197\nNumber of rating 4: 348971\nNumber of rating 5: 226310 \n```", "```py\n>>> print(df['movie_id'].value_counts())\n2858    3428\n260     2991\n1196    2990\n1210    2883\n480     2672\n        ...\n3458       1\n2226       1\n1815       1\n398        1\n2909       1\nName: movie_id, Length: 3706, dtype: int64 \n```", "```py\n>>> target_movie_id = 2858\n>>> X_raw = np.delete(data, movie_id_mapping[target_movie_id], axis=1)\n>>> Y_raw = data[:, movie_id_mapping[target_movie_id]]\n>>> X = X_raw[Y_raw > 0]\n>>> Y = Y_raw[Y_raw > 0]\n>>> print('Shape of X:', X.shape)\nShape of X: (3428, 3705)\n>>> print('Shape of Y:', Y.shape)\nShape of Y: (3428,) \n```", "```py\n>>> recommend = 3\n>>> Y[Y <= recommend] = 0\n>>> Y[Y > recommend] = 1\n>>> n_pos = (Y == 1).sum()\n>>> n_neg = (Y == 0).sum()\n>>> print(f'{n_pos} positive samples and {n_neg} negative samples.')\n2853 positive samples and 575 negative samples. \n```", "```py\n>>> from sklearn.model_selection import train_test_split\n>>> X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n...     test_size=0.2, random_state=42) \n```", "```py\n>>> print(len(Y_train), len(Y_test))\n2742 686 \n```", "```py\n>>> from sklearn.naive_bayes import MultinomialNB\n>>> clf = MultinomialNB(alpha=1.0, fit_prior=True)\n>>> clf.fit(X_train, Y_train) \n```", "```py\n>>> prediction_prob = clf.predict_proba(X_test)\n>>> print(prediction_prob[0:10])\n[[7.50487439e-23 1.00000000e+00]\n [1.01806208e-01 8.98193792e-01]\n [3.57740570e-10 1.00000000e+00]\n [1.00000000e+00 2.94095407e-16]\n [1.00000000e+00 2.49760836e-25]\n [7.62630220e-01 2.37369780e-01]\n [3.47479627e-05 9.99965252e-01]\n [2.66075292e-11 1.00000000e+00]\n [5.88493563e-10 9.99999999e-01]\n [9.71326867e-09 9.99999990e-01]] \n```", "```py\n>>> prediction = clf.predict(X_test)\n>>> print(prediction[:10])\n[[1\\. 1\\. 1\\. 0\\. 0\\. 0\\. 1\\. 1\\. 1\\. 1.] \n```", "```py\n>>> accuracy = clf.score(X_test, Y_test)\n>>> print(f'The accuracy is: {accuracy*100:.1f}%')\nThe accuracy is: 71.6% \n```", "```py\n>>> from sklearn.metrics import confusion_matrix\n>>> print(confusion_matrix(Y_test, prediction, labels=[0, 1]))\n[[ 60  47]\n [148 431]] \n```", "```py\n>>> from sklearn.metrics import precision_score, recall_score, f1_score\n>>> precision_score(Y_test, prediction, pos_label=1)\n0.9016736401673641\n>>> recall_score(Y_test, prediction, pos_label=1)\n0.7443868739205527\n>>> f1_score(Y_test, prediction, pos_label=1)\n0.815515610217597 \n```", "```py\n>>> f1_score(Y_test, prediction, pos_label=0)\n0.38095238095238093 \n```", "```py\n>>> from sklearn.metrics import classification_report\n>>> report = classification_report(Y_test, prediction)\n>>> print(report)\n              precision    recall  f1-score   support\n         0.0       0.29      0.56      0.38       107\n         1.0       0.90      0.74      0.82       579\n   micro avg       0.72      0.72      0.72       686\n   macro avg       0.60      0.65      0.60       686\nweighted avg       0.81      0.72      0.75       686 \n```", "```py\n>>> pos_prob = prediction_prob[:, 1]\n>>> thresholds = np.arange(0.0, 1.1, 0.05)\n>>> true_pos, false_pos = [0]*len(thresholds), [0]*len(thresholds)\n>>> for pred, y in zip(pos_prob, Y_test):\n...     for i, threshold in enumerate(thresholds):\n...         if pred >= threshold:\n...            # if truth and prediction are both 1\n...             if y == 1:\n...                 true_pos[i] += 1\n...            # if truth is 0 while prediction is 1\n...             else:\n...                 false_pos[i] += 1\n...         else:\n...             break \n```", "```py\n>>> n_pos_test = (Y_test == 1).sum()\n>>> n_neg_test = (Y_test == 0).sum()\n>>> true_pos_rate = [tp / n_pos_test for tp in true_pos]\n>>> false_pos_rate = [fp / n_neg_test for fp in false_pos] \n```", "```py\n>>> import matplotlib.pyplot as plt\n>>> plt.figure()\n>>> lw = 2\n>>> plt.plot(false_pos_rate, true_pos_rate,\n...          color='darkorange', lw=lw)\n>>> plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n>>> plt.xlim([0.0, 1.0])\n>>> plt.ylim([0.0, 1.05])\n>>> plt.xlabel('False Positive Rate')\n>>> plt.ylabel('True Positive Rate')\n>>> plt.title('Receiver Operating Characteristic')\n>>> plt.legend(loc=\"lower right\")\n>>> plt.show() \n```", "```py\n>>> from sklearn.metrics import roc_auc_score\n>>> roc_auc_score(Y_test, pos_prob)\n0.6857375752586637 \n```", "```py\n>>> from sklearn.model_selection import StratifiedKFold\n>>> k = 5\n>>> k_fold = StratifiedKFold(n_splits=k, random_state=42) \n```", "```py\n>>> smoothing_factor_option = [1, 2, 3, 4, 5, 6]\n>>> fit_prior_option = [True, False]\n>>> auc_record = {} \n```", "```py\n>>> for train_indices, test_indices in k_fold.split(X, Y):\n...     X_train_k, X_test _k= X[train_indices], X[test_indices]\n...     Y_train_k, Y_test_k = Y[train_indices], Y[test_indices]\n...     for alpha in smoothing_factor_option:\n...         if alpha not in auc_record:\n...             auc_record[alpha] = {}\n...         for fit_prior in fit_prior_option:\n...             clf = MultinomialNB(alpha=alpha,\n...                                 fit_prior=fit_prior)\n...             clf.fit(X_train_k, Y_train_k)\n...             prediction_prob = clf.predict_proba(X_test_k)\n...             pos_prob = prediction_prob[:, 1]\n...             auc = roc_auc_score(Y_test_k, pos_prob)\n...             auc_record[alpha][fit_prior] = auc +\n...                        auc_record[alpha].get(fit_prior, 0.0) \n```", "```py\n>>> for smoothing, smoothing_record in auc_record.items():\n...     for fit_prior, auc in smoothing_record.items():\n...         print(f'    {smoothing}        {fit_prior}  \n...               {auc/k:.5f}')\nsmoothing  fit prior  auc\n    1        True    0.65647\n    1        False    0.65708\n    2        True    0.65795\n    2        False    0.65823\n    3        True    0.65740\n    3        False    0.65801\n    4        True    0.65808\n    4        False    0.65795\n    5        True    0.65814\n    5        False    0.65694\n    6        True    0.65663\n    6        False    0.65719 \n```", "```py\n>>> clf = MultinomialNB(alpha=2.0, fit_prior=False)\n>>> clf.fit(X_train, Y_train)\n>>> pos_prob = clf.predict_proba(X_test)[:, 1]\n>>> print('AUC with the best model:', roc_auc_score(Y_test,\n...       pos_prob))\nAUC with the best model:  0.6862056720417091 \n```"]