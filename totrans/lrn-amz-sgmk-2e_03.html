<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer063">
			<h1 id="_idParaDest-32"><a id="_idTextAnchor030"/>Chapter 2: Handling Data Preparation Techniques </h1>
			<p>Data is the starting point of any machine learning project, and it takes lots of work to turn data into a dataset that can be used to train a model. That work typically involves annotating datasets, running bespoke scripts to preprocess them, and saving processed versions for later use. As you can guess, doing all this work manually, or building tools to automate it, is not an exciting prospect for machine learning teams. </p>
			<p>In this chapter, you will learn about AWS services that help you build and process data. We'll first cover <strong class="bold">Amazon SageMaker Ground Truth</strong>, a capability of Amazon SageMaker that helps you quickly build accurate training datasets. Then, we'll introduce <strong class="bold">Amazon SageMaker Data Wrangler</strong>, a new way to transform your data interactively. Next, we'll talk about <strong class="bold">Amazon SageMaker Processing</strong>, another capability that helps you run your data processing workloads, such as feature engineering, data validation, model evaluation, and model interpretation. Finally, we'll quickly discuss other AWS services that may help with data analytics: <strong class="bold">Amazon Elastic Map Reduce</strong>, <strong class="bold">AWS Glue</strong>, and <strong class="bold">Amazon Athena</strong>.</p>
			<p>This chapter consists of the following topics:</p>
			<ul>
				<li>Labeling data with Amazon SageMaker Ground Truth</li>
				<li>Transforming data with Amazon SageMaker Data Wrangler</li>
				<li>Running batch jobs with Amazon SageMaker Processing</li>
			</ul>
			<h1 id="_idParaDest-33"><a id="_idTextAnchor031"/>Technical requirements</h1>
			<p>You will need an AWS account to run the examples included in this chapter. If you haven't got one already, please point your browser at <a href="https://aws.amazon.com/getting-started/">https://aws.amazon.com/getting-started/</a> to create one. You should also familiarize yourself with the AWS Free Tier , which lets you use many AWS services for free within certain usage limits.</p>
			<p>You will need to install and to configure the AWS <strong class="bold">Command Line Interface</strong> (<strong class="bold">CLI</strong>) for your account (<a href="https://aws.amazon.com/cli/">https://aws.amazon.com/cli/</a>).  </p>
			<p>You will need a working Python 3.x environment. Installing the Anaconda distribution (<a href="https://www.anaconda.com/">https://www.anaconda.com/</a>) is not mandatory, but strongly encouraged as it includes many projects that we will need (Jupyter, <strong class="source-inline">pandas</strong>, <strong class="source-inline">numpy</strong>, and more).</p>
			<p>Code examples included in the book are available on GitHub at <a href="https://github.com/PacktPublishing/Learn-Amazon-SageMaker-second-edition">https://github.com/PacktPublishing/Learn-Amazon-SageMaker-second-edition</a>. You will need to install a Git client to access them (<a href="https://git-scm.com/">https://git-scm.com/</a>). </p>
			<h1 id="_idParaDest-34"><a id="_idTextAnchor032"/>Labeling data with Amazon SageMaker Ground Truth</h1>
			<p>Added<a id="_idIndexMarker078"/> to Amazon SageMaker <a id="_idIndexMarker079"/>in late 2018, Amazon SageMaker Ground Truth helps you quickly build accurate training datasets. Machine learning practitioners can distribute labeling work to public and private workforces of human labelers. Labelers can be productive immediately, thanks to built-in workflows and graphical interfaces for common image, video, and text tasks. In addition, Ground Truth can enable automatic labeling, a technique that trains a machine learning model able to label data without additional human intervention.</p>
			<p>In this section, you'll learn how to use Ground Truth to label images and text.</p>
			<h2 id="_idParaDest-35"><a id="_idTextAnchor033"/>Using workforces</h2>
			<p>The<a id="_idIndexMarker080"/> first step in using Ground Truth is to create a workforce, a group of workers in charge of labeling data samples. </p>
			<p>Let's head out to the SageMaker console: in the left-hand vertical menu, we click on <strong class="bold">Ground Truth</strong>, then on <strong class="bold">Labeling workforces</strong>. Three types of workforces are available: <strong class="bold">Amazon Mechanical Turk</strong>, <strong class="bold">Vendor</strong>, and <strong class="bold">Private</strong>. Let's discuss what they are, and when you should use them.</p>
			<h3>Amazon Mechanical Turk</h3>
			<p><strong class="bold">Amazon Mechanical Turk</strong> (<a href="https://www.mturk.com/">https://www.mturk.com/</a>) makes<a id="_idIndexMarker081"/> it easy to <a id="_idIndexMarker082"/>break down large batch jobs into small work units that can be processed by a distributed workforce. </p>
			<p>With Mechanical Turk, you can enroll tens or even hundreds of thousands of workers located across the globe. This is a great option when you need to label extremely large datasets. For example, think about a dataset for autonomous driving, made up of 1,000 hours of video: each frame would need to be processed in order to identify other vehicles, pedestrians, road signs, and more. If you wanted to annotate every single frame, you'd be looking at 1,000 hours x 3,600 seconds x 24 frames per second = <strong class="bold">86.4 million images</strong>! Clearly, you would have to scale out your labeling workforce to get the job done, and Mechanical Turk lets you do that.</p>
			<h3>Vendor workforce</h3>
			<p>As scalable as Mechanical Turk is, sometimes<a id="_idIndexMarker083"/> you need more control on who data is shared with, and on the quality of annotations, particularly if additional domain knowledge is required.</p>
			<p>For this purpose, AWS has vetted a number of data labeling companies, which have integrated Ground Truth in their workflows. You can find the list of companies <a id="_idIndexMarker084"/>on <strong class="bold">AWS Marketplace</strong> (<a href="https://aws.amazon.com/marketplace/">https://aws.amazon.com/marketplace/</a>), under <strong class="bold">Machine Learning</strong> | <strong class="bold">Data Labeling Services</strong> | <strong class="bold">Amazon SageMaker Ground Truth Services</strong>. </p>
			<h3>Private workforce</h3>
			<p>Sometimes, data can't be <a id="_idIndexMarker085"/>processed by third parties. Maybe it's just too sensitive, or maybe it requires expert knowledge that only your company's employees have. In this case, you can create a private workforce made up of well-identified individuals that will access and label your data.</p>
			<h2 id="_idParaDest-36"><a id="_idTextAnchor034"/>Creating a private workforce</h2>
			<p>Creating a private <a id="_idIndexMarker086"/>workforce is the quickest and simplest option. Let's see how it's done:</p>
			<ol>
				<li>Starting from the <strong class="bold">Labeling workforces</strong> entry in the SageMaker console, we select the <strong class="bold">Private</strong> tab, as seen in the following screenshot. Then, we click on <strong class="bold">Create private team</strong>:<div id="_idContainer029" class="IMG---Figure"><img src="Images/B17705_02_001.jpg" alt="Figure 2.1 – Creating a private workforce&#13;&#10;" width="761" height="440"/></div><p class="figure-caption">Figure 2.1 – Creating a private workforce</p></li>
				<li>We give the<a id="_idIndexMarker087"/> team a name, then we have to decide whether we're going to invite workers by email, or whether we're going to import users that belong to an existing <strong class="bold">Amazon Cognito</strong> group. <p>Amazon Cognito (<a href="https://aws.amazon.com/cognito/">https://aws.amazon.com/cognito/</a>) is a<a id="_idIndexMarker088"/> managed service<a id="_idIndexMarker089"/> that lets you build and manage user directories at any scale. Cognito supports both social identity providers (Google, Facebook, and Amazon), and enterprise identity providers (Microsoft Active Directory, SAML).</p><p>This makes a lot of sense in an enterprise context, but let's keep things simple and use email instead. Here, I will use some sample email addresses: please make sure to use your own, otherwise you won't be able to join the team!</p></li>
				<li>Then, we need to enter an organization name, and more importantly a contact email that workers can use for questions and feedback on the labeling job. These conversations are extremely important in order to fine-tune labeling instructions, pinpoint problematic data samples, and more.</li>
				<li>Optionally, we can set up notifications <a id="_idIndexMarker090"/>with <strong class="bold">Amazon Simple Notification Service</strong> (<a href="https://aws.amazon.com/sns/">https://aws.amazon.com/sns/</a>) to let workers know that they have work to do. </li>
				<li>The screen should look <a id="_idIndexMarker091"/>like in the following screenshot. Then, we click on <strong class="bold">Create private team</strong>:<div id="_idContainer030" class="IMG---Figure"><img src="Images/B17705_02_002.jpg" alt="Figure 2.2 – Setting up a private workforce&#13;&#10;" width="751" height="882"/></div><p class="figure-caption">Figure 2.2 – Setting up a private workforce</p></li>
				<li>A few seconds later, the team has been set up. Invitations have been sent to workers, requesting that they join the workforce by logging in to a specific URL. The invitation email looks like that shown in the following screenshot:<div id="_idContainer031" class="IMG---Figure"><img src="Images/B17705_02_003.jpg" alt="Figure 2.3 – Email invitation&#13;&#10;" width="638" height="415"/></div><p class="figure-caption">Figure 2.3 – Email invitation</p></li>
				<li>Clicking on the link opens a login window. Once we've logged in and defined a new password, we're <a id="_idIndexMarker092"/>taken to a new screen showing available jobs, as in the following screenshot. As we haven't defined one yet, it's obviously empty:</li>
			</ol>
			<div>
				<div id="_idContainer032" class="IMG---Figure">
					<img src="Images/B17705_02_004.jpg" alt="Figure 2.4 – Worker console&#13;&#10;" width="637" height="293"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.4 – Worker console</p>
			<p>Let's keep our workers busy and create an image labeling job.</p>
			<h2 id="_idParaDest-37"><a id="_idTextAnchor035"/>Uploading data for labeling</h2>
			<p>As you would<a id="_idIndexMarker093"/> expect, Amazon SageMaker Ground Truth uses <a id="_idIndexMarker094"/>Amazon S3 to store datasets:</p>
			<ol>
				<li value="1">Using the AWS CLI, we create an S3 bucket hosted in the same region we're running SageMaker in. Bucket names are globally unique, so please make sure to pick your own unique name when you create the bucket. Use the following code (feel free to use another AWS Region):<p class="source-code"><strong class="bold">$ aws s3 mb s3://sagemaker-book --region eu-west-1</strong></p></li>
				<li>Then, we <a id="_idIndexMarker095"/>copy the cat images located in the <strong class="source-inline">chapter2</strong> folder <a id="_idIndexMarker096"/>of our GitHub repository as follows:<p class="source-code"><strong class="bold">$ aws s3 cp --recursive cat/ s3://sagemaker-book/chapter2/cat/</strong></p></li>
			</ol>
			<p>Now that we have some data waiting to be labeled, let's create a labeling job. </p>
			<h2 id="_idParaDest-38"><a id="_idTextAnchor036"/>Creating a labeling job</h2>
			<p class="Basic-Paragraph">As you would expect, we<a id="_idIndexMarker097"/> need to define the location of the data, what type of task we want to label it for, and what our instructions are:</p>
			<ol>
				<li value="1">In the left-hand vertical menu of the SageMaker console, we click on <strong class="bold">Ground Truth</strong>, then on <strong class="bold">Labeling jobs</strong>, then on the <strong class="bold">Create labeling job</strong> button.</li>
				<li>First, we give the job a name, say '<strong class="source-inline">my-cat-job</strong>'. Then, we define the location of the data in S3. Ground Truth expects a <strong class="bold">manifest file</strong>: a manifest file is a <strong class="bold">JSON</strong> file that<a id="_idIndexMarker098"/> lets you filter <a id="_idIndexMarker099"/>which objects need to be labeled, and which ones should be left out. Once the job is complete, a new file, called the augmented manifest, will contain labeling information, and we'll be able to use this to feed data to training jobs.</li>
				<li>Then, we define the location and the type of our input data, just like in the following screenshot:<div id="_idContainer033" class="IMG---Figure"><img src="Images/B17705_02_005.jpg" alt="Figure 2.5 – Configuring input data&#13;&#10;" width="745" height="443"/></div><p class="figure-caption">Figure 2.5 – Configuring input data</p></li>
				<li>As is visible <a id="_idIndexMarker100"/>in the next screenshot, we select the IAM role that we created for SageMaker in the first chapter (your name will be different), and we then click on the <strong class="bold">Complete data setup</strong> button to validate this section:<div id="_idContainer034" class="IMG---Figure"><img src="Images/B17705_02_006.jpg" alt="Figure 2.6 – Validating input data&#13;&#10;" width="739" height="195"/></div><p class="figure-caption">Figure 2.6 – Validating input data</p><p>Clicking on <strong class="bold">View more details</strong>, you can learn about what is happening under the hood. SageMaker Ground Truth crawls your data in S3 and creates a JSON file called the <strong class="bold">manifest file</strong>. You can<a id="_idIndexMarker101"/> go and download it from S3 if you're curious. This file points at your objects in S3 (images, text files, and so on). </p></li>
				<li>Optionally, we could decide to work either with the full manifest, a random sample, or a filtered subset based on a <strong class="bold">SQL</strong> query. We could also provide an <strong class="bold">Amazon KMS</strong> key<a id="_idIndexMarker102"/> to encrypt the output of the job. Let's stick to the defaults here.</li>
				<li>The <strong class="bold">Task type</strong> section<a id="_idIndexMarker103"/> asks us what kind of job we'd like to run. Please take a minute to explore the different task categories that are available (text, image, video, point cloud, and custom). As shown in the next screenshot, let's select the <strong class="bold">Image</strong> task category and the <strong class="bold">Semantic segmentation</strong> task, and then click <strong class="bold">Next</strong>:<div id="_idContainer035" class="IMG---Figure"><img src="Images/B17705_02_007.jpg" alt="Figure 2.7 – Selecting a task type&#13;&#10;" width="708" height="720"/></div><p class="figure-caption">Figure 2.7 – Selecting a task type</p></li>
				<li>On the next screen, visible in the following screenshot, we first select our private team of workers:<div id="_idContainer036" class="IMG---Figure"><img src="Images/B17705_02_008.jpg" alt="Figure 2.8 – Selecting a team type&#13;&#10;" width="869" height="357"/></div><p class="figure-caption">Figure 2.8 – Selecting a team type</p></li>
				<li>If we had a lot of<a id="_idIndexMarker104"/> samples (say, tens of thousands or more), we should consider enabling <strong class="bold">automated data labeling</strong>, as this feature would reduce both the duration and the cost of the labeling job. Indeed, as workers would start labeling data samples, SageMaker Ground Truth would train a machine learning model on these samples. It would use them as a dataset for a supervised learning problem. With enough worker-labeled data, this model would pretty quickly be able to match and exceed human accuracy, at which point it would replace workers and label the rest of the dataset. If you'd like to know more <a id="_idIndexMarker105"/>about this feature, please read the documentation at <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sms-automated-labeling.html">https://docs.aws.amazon.com/sagemaker/latest/dg/sms-automated-labeling.html</a>.</li>
				<li>The last step in configuring our training job is to enter instructions for the workers. This is an important step, especially if your job is distributed to third-party workers. The better our instructions, the higher the quality of the annotations. Here, let's explain what the job is about, and enter a "cat" label for workers to apply. In a real-life scenario, you should add detailed instructions, provide sample images for good and bad examples, explain what your expectations are, and so on. The following screenshot shows what our instructions look like:<div id="_idContainer037" class="IMG---Figure"><img src="Images/B17705_02_009.jpg" alt="Figure 2.9 – Setting up instructions&#13;&#10;" width="987" height="866"/></div><p class="figure-caption">Figure 2.9 – Setting up instructions</p></li>
				<li>Once we're done<a id="_idIndexMarker106"/> with instructions, we click on <strong class="bold">Create</strong> to launch the labeling job. After a few minutes, the job is ready to be distributed to workers.</li>
			</ol>
			<h2 id="_idParaDest-39"><a id="_idTextAnchor037"/>Labeling images</h2>
			<p>Logging in to the<a id="_idIndexMarker107"/> worker URL, we can see from the screen shown in the following screenshot that we have work to do:</p>
			<div>
				<div id="_idContainer038" class="IMG---Figure">
					<img src="Images/B17705_02_010.jpg" alt="Figure 2.10 – Worker console&#13;&#10;" width="841" height="361"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.10 – Worker console</p>
			<p>We will use the following steps:</p>
			<ol>
				<li value="1">Clicking on <strong class="bold">Start working</strong> opens a new window, visible in the next picture. It displays <a id="_idIndexMarker108"/>instructions as well as a first image to work on:<div id="_idContainer039" class="IMG---Figure"><img src="Images/B17705_02_011.jpg" alt="Figure 2.11 – Labeling images&#13;&#10;" width="853" height="722"/></div><p class="figure-caption">Figure 2.11 – Labeling images</p></li>
				<li>Using the graphical tools in the toolbar, and especially the auto-segment tool, we can very quickly produce high-quality annotations. Please take a few minutes to practice, and you'll be able to do the same in no time.</li>
				<li>Once we're<a id="_idIndexMarker109"/> done with the three images, the job is complete, and we can visualize the labeled images under <strong class="bold">Labeling jobs</strong> in the SageMaker console. Your screen should look like the following screenshot:</li>
			</ol>
			<div>
				<div id="_idContainer040" class="IMG---Figure">
					<img src="Images/B17705_02_012.jpg" alt="Figure 2.12 – Labeled images&#13;&#10;" width="888" height="401"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.12 – Labeled images</p>
			<p>More importantly, we can find labeling information in the S3 output location.</p>
			<p>In<a id="_idIndexMarker110"/> particular, the <strong class="bold">augmented manifest</strong> (<strong class="source-inline">output/my-cat-job/manifests/output/output.manifest</strong>) contains annotation information<a id="_idIndexMarker111"/> on each data sample, such as the classes present in the image, and a link to the segmentation mask.</p>
			<p>In <a href="B17705_05_Final_JM_ePub.xhtml#_idTextAnchor091"><em class="italic">Chapter 5</em></a><em class="italic">, Training Computer Vision Models</em>, we'll see how we can feed this information directly to the built-in computer vision algorithms implemented in Amazon SageMaker. Of course, we could also parse this information, and convert it for whatever framework we use to train our computer vision model.</p>
			<p>As you can see, SageMaker Ground Truth makes it easy to label image datasets. You just need to upload your data to S3 and create a workforce. Ground Truth will then distribute the work automatically, and store the results in S3.</p>
			<p>We just saw how to label images, but what about text tasks? Well, they're equally easy to set up and run. Let's go through an example.</p>
			<h2 id="_idParaDest-40"><a id="_idTextAnchor038"/>Labeling text</h2>
			<p>This is a quick example of<a id="_idIndexMarker112"/> labeling text for named entity recognition. The dataset is made up of text fragments from one of my blog posts, where we'd like to label all AWS service names. These are available in our GitHub repository.</p>
			<p>We will start labeling text using the following steps:</p>
			<ol>
				<li value="1">First, let's upload text fragments to S3 with the following line of code:<p class="source-code"><strong class="bold">$ aws s3 cp --recursive ner/ s3://sagemaker-book/chapter2/ner/</strong></p></li>
				<li>Just like in the <a id="_idIndexMarker113"/>previous example, we configure a text labeling job, set up input data, and select an IAM role, as shown in the following screenshot:<div id="_idContainer041" class="IMG---Figure"><img src="Images/B17705_02_013.jpg" alt="Figure 2.13 – Creating a text labeling job&#13;&#10;" width="625" height="685"/></div><p class="figure-caption">Figure 2.13 – Creating a text labeling job</p></li>
				<li>Then, we<a id="_idIndexMarker114"/> select <strong class="bold">Text</strong> as the category, and <strong class="bold">Named entity recognition</strong> as the task. </li>
				<li>On the next screen, shown in the following screenshot, we simply select our private team again, add a label, and enter instructions:<div id="_idContainer042" class="IMG---Figure"><img src="Images/B17705_02_014.jpg" alt="Figure 2.14 – Setting up instructions&#13;&#10;" width="894" height="819"/></div><p class="figure-caption">Figure 2.14 – Setting up instructions</p></li>
				<li>Once the<a id="_idIndexMarker115"/> job is ready, we log in to the worker console and start labeling. You can see a labeled example in the following screenshot:<div id="_idContainer043" class="IMG---Figure"><img src="Images/B17705_02_015.jpg" alt="Figure 2.15 – Labeling text&#13;&#10;" width="1105" height="337"/></div><p class="figure-caption">Figure 2.15 – Labeling text</p></li>
				<li>We're done quickly, and we can find the labeling information in our S3 bucket. For each<a id="_idIndexMarker116"/> sample, we see a start offset, an end offset, and a label for each labeled entity.</li>
			</ol>
			<p>Amazon SageMaker<a id="_idIndexMarker117"/> Ground Truth really makes it easy to label datasets at scale. It has many nice features including job chaining and custom workflows, which I encourage you to explore at <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/sms.html">https://docs.aws.amazon.com/sagemaker/latest/dg/sms.html</a>.</p>
			<p>Now that we know how to label datasets, let's see how we can easily transform data interactively with Amazon SageMaker Data Wrangler.</p>
			<h1 id="_idParaDest-41"><a id="_idTextAnchor039"/>Transforming data with Amazon SageMaker Data Wrangler</h1>
			<p>Collecting and <a id="_idIndexMarker118"/>labeling data samples<a id="_idIndexMarker119"/> is only the first step in preparing a dataset. Indeed, it's very likely that you'll have to pre-process your dataset in order to do the following, for example:</p>
			<ul>
				<li>Convert it to the input format expected by the machine learning algorithm you're using.</li>
				<li>Rescale or normalize numerical features.</li>
				<li>Engineer higher-level features, for example, one-hot encoding.</li>
				<li>Clean and tokenize text for natural language processing applications</li>
			</ul>
			<p>In the early stage of a machine learning project, it's not always obvious which transformations are required, or which ones are most efficient. Thus, practioners often need to experiment with lots of different combinations, transforming data in many different ways, training models, and evaluating results.</p>
			<p>In this section, we're going to learn about <strong class="bold">Amazon SageMaker Data Wrangler</strong>, a graphical interface integrated in SageMaker Studio that makes it very easy to transform data, and to export results to a variety of Jupyter notebooks.</p>
			<h2 id="_idParaDest-42"><a id="_idTextAnchor040"/>Loading a dataset in SageMaker Data Wrangler</h2>
			<p>First, we need a <a id="_idIndexMarker120"/>dataset. We'll use the direct<a id="_idIndexMarker121"/> marketing dataset published by S. Moro, P. Cortez, and P. Rita in "A Data-Driven Approach to Predict the Success of Bank Telemarketing", <em class="italic">Decision Support Systems</em>, Elsevier, 62:22-31, June 2014.</p>
			<p>This dataset describes a binary classification problem: will a customer accept a marketing offer, yes or no? It contains a little more than 41,000 customer samples, and labels are stored in the <strong class="bold">y</strong> column.</p>
			<p>We will get started using the following steps:</p>
			<ol>
				<li value="1">Using the AWS command line, let's download the dataset, extract it, and copy it to the default SageMaker bucket for the region we're running in (it should have been created automatically). You can run this on your local machine or in a Jupyter terminal:<p class="callout-heading">Note</p><p class="callout">In this example, I'm running SageMaker in the ap-northeast-2 region (Seoul). Replace accordingly.</p><p class="source-code"><strong class="bold">$ aws s3 cp s3://sagemaker-sample-data-us-west-2.s3-us-west-2.amazonaws.com/autopilot/direct_marketing/bank-additional.zip .</strong></p><p class="source-code"><strong class="bold">$ unzip bank-additional.zip</strong></p><p class="source-code"><strong class="bold">$ aws s3 cp bank-additional/bank-additional-full.csv s3://sagemaker-ap-northeast-2-123456789012/direct-marketing/</strong></p></li>
				<li>In SageMaker Studio, we create a new Data Wrangler flow with <strong class="bold">File</strong> | <strong class="bold">New</strong> | <strong class="bold">Data Wrangler Flow</strong> to create. The following screenshot shows the Data Wrangler image <a id="_idIndexMarker122"/>being loaded:<div id="_idContainer044" class="IMG---Figure"><img src="Images/B17705_02_016.jpg" alt="Figure 2.16 – Loading Data Wrangler&#13;&#10;" width="649" height="119"/></div><p class="figure-caption">Figure 2.16 – Loading Data Wrangler</p></li>
				<li>Once<a id="_idIndexMarker123"/> Data Wrangler is ready, the <strong class="bold">Import</strong> screen opens. We also see the Data Wrangler image in the left-hand pane, as shown in the next screenshot:<div id="_idContainer045" class="IMG---Figure"><img src="Images/B17705_02_017.jpg" alt="Figure 2.17 – Opening Data Wrangler&#13;&#10;" width="950" height="404"/></div><p class="figure-caption">Figure 2.17 – Opening Data Wrangler</p></li>
				<li>We can import data from S3, Athena or Redshift (by clicking on <strong class="bold">Add data source</strong>). Here, we click on S3.</li>
				<li>As shown in the following screenshot, we can easily locate the dataset that we just uploaded. Let's click on it.<div id="_idContainer046" class="IMG---Figure"><img src="Images/B17705_02_018.jpg" alt="Figure 2.18 – Locating a dataset&#13;&#10;" width="626" height="312"/></div><p class="figure-caption">Figure 2.18 – Locating a dataset</p></li>
				<li>This <a id="_idIndexMarker124"/>opens a preview of the<a id="_idIndexMarker125"/> dataset, as shown in the next screenshot:<div id="_idContainer047" class="IMG---Figure"><img src="Images/B17705_02_019.jpg" alt="Figure 2.19 – Previewing a dataset&#13;&#10;" width="829" height="551"/></div><p class="figure-caption">Figure 2.19 – Previewing a dataset</p></li>
				<li>Let's just click on <strong class="bold">Import</strong>, which opens the <strong class="bold">Prepare</strong> view, as shown in the next screenshot:<div id="_idContainer048" class="IMG---Figure"><img src="Images/B17705_02_020.jpg" alt="Figure 2.20 – Previewing a dataset&#13;&#10;" width="733" height="512"/></div><p class="figure-caption">Figure 2.20 – Previewing a dataset</p></li>
				<li>Clicking <a id="_idIndexMarker126"/>on the <strong class="bold">+</strong> icon, we<a id="_idIndexMarker127"/> could add more data sources, joining them or concatenating them to our dataset. We could also edit data types for all columns, should Data Wrangler have detected them incorrectly. Instead, let's select <strong class="bold">Add analysis</strong> to visualize properties of our dataset. This opens the <strong class="bold">Analyze view</strong>, visible in the next screenshot:<div id="_idContainer049" class="IMG---Figure"><img src="Images/B17705_02_021.jpg" alt="Figure 2.21 – Visualizing a dataset&#13;&#10;" width="725" height="717"/></div><p class="figure-caption">Figure 2.21 – Visualizing a dataset</p></li>
				<li>The next <a id="_idIndexMarker128"/>screenshot shows a <a id="_idIndexMarker129"/>scatter plot on duration vs. age. See how easy this is? You can experiment by selecting different columns, click on <strong class="bold">Preview</strong> to see results, and click on <strong class="bold">Save</strong> to create the analysis and save it for further use. <div id="_idContainer050" class="IMG---Figure"><img src="Images/B17705_02_022.jpg" alt="Figure 2.22 – Building a scatter plot&#13;&#10;" width="823" height="848"/></div><p class="figure-caption">Figure 2.22 – Building a scatter plot</p></li>
				<li>On top of<a id="_idIndexMarker130"/> histograms <a id="_idIndexMarker131"/>and scatter plots, we can also build <strong class="bold">Table Summary</strong>, <strong class="bold">Bias Analysis</strong>, and <strong class="bold">Target Leakage</strong> reports. Let's build the latter to find out if certain columns are either leaking into the prediction, or not helpful at all. You can see the report in the next screenshot:<div id="_idContainer051" class="IMG---Figure"><img src="Images/B17705_02_023.jpg" alt="Figure 2.23 – Building a target leakage report&#13;&#10;" width="756" height="838"/></div><p class="figure-caption">Figure 2.23 – Building a target leakage report</p></li>
				<li>This<a id="_idIndexMarker132"/> report tells us that no column <a id="_idIndexMarker133"/>is leaking (all scores are lower than 1). Several columns are also not useful in predicting the target (some scores are 0.5 or lower): we should probably drop these columns during data processing. </li>
			</ol>
			<p>We could also try the <strong class="bold">Quick Model</strong> report, which trains a model using a <strong class="bold">Random Forest</strong> algorithm<a id="_idIndexMarker134"/> implemented with Spark, right in SageMaker Studio. Unfortunately, an error message pops up, complaining about column names. Indeed, some column names include a dot, which is not allowed by Spark. No problem, we can easily fix this during data processing, and build the report later.</p>
			<p>In fact, let's move on to transforming data with Data Wrangler.</p>
			<h2 id="_idParaDest-43"><a id="_idTextAnchor041"/>Transforming a dataset in SageMaker Data Wrangler</h2>
			<p class="Basic-Paragraph">Data <a id="_idIndexMarker135"/>Wrangler includes hundreds of <a id="_idIndexMarker136"/>built-in transforms, and we can also add our own.</p>
			<ol>
				<li value="1">Starting from the <strong class="bold">Prepare</strong> view visible in the next screenshot, we click on the <strong class="bold">+</strong> icon to add transforms.<div id="_idContainer052" class="IMG---Figure"><img src="Images/B17705_02_024.jpg" alt="Figure 2.24 – Adding a transform&#13;&#10;" width="539" height="307"/></div><p class="figure-caption">Figure 2.24 – Adding a transform</p></li>
				<li>This opens the list of transforms, shown in the next screenshot. Take a minute to explore them.</li>
				<li>Let's start <a id="_idIndexMarker137"/>by dropping the <a id="_idIndexMarker138"/>columns flagged as useless in the <strong class="bold">Target Leakage</strong> report: <strong class="source-inline">marital</strong>, <strong class="source-inline">day of week</strong>, <strong class="source-inline">month</strong>, <strong class="source-inline">housing</strong>, <strong class="source-inline">cons.conf.idx</strong>, <strong class="source-inline">nr.employed</strong>, <strong class="source-inline">cons.price.idx</strong>. We click on <strong class="bold">Manage columns</strong>, select the <strong class="bold">Drop column</strong> transform, and pick the <strong class="source-inline">marital</strong> column. Your screen should look like the following screenshot:<div id="_idContainer053" class="IMG---Figure"><img src="Images/B17705_02_025.jpg" alt="Figure 2.25 – Dropping a column&#13;&#10;" width="450" height="221"/></div><p class="figure-caption">Figure 2.25 – Dropping a column</p></li>
				<li>We can preview results and add the transform to our pipeline. We'll repeat the same operations for the other columns we want to drop.</li>
				<li>Now, let's remove these annoying dots in column names, replacing them with underscores. The easiest way to do this is to<a id="_idIndexMarker139"/> use a <strong class="bold">custom transform</strong> in PySpark, as visible in the next screenshot. The dataset is available as a Pandas dataframe named <strong class="source-inline">df</strong>.<div id="_idContainer054" class="IMG---Figure"><img src="Images/B17705_02_026.jpg" alt="Figure 2.26 – Applying a custom transform&#13;&#10;" width="420" height="249"/></div><p class="figure-caption">Figure 2.26 – Applying a custom transform</p></li>
				<li>Jumping <a id="_idIndexMarker140"/>back to the <strong class="bold">Analyze</strong> view, and <a id="_idIndexMarker141"/>clicking on <strong class="bold">Steps</strong>, we can see the list of transforms that we've already applied, as shown in the next screenshot. We could also delete each transform by clicking on the icon to the right of it.<div id="_idContainer055" class="IMG---Figure"><img src="Images/B17705_02_027.jpg" alt="Figure 2.27 – Viewing a pipeline&#13;&#10;" width="648" height="452"/></div><p class="figure-caption">Figure 2.27 – Viewing a pipeline</p></li>
				<li>Clicking on <a id="_idIndexMarker142"/>the <strong class="bold">+</strong> icon, we select <strong class="bold">Add analysis</strong>  then we create a <strong class="bold">Quick Model</strong> on the <strong class="source-inline">y</strong> label, as shown<a id="_idIndexMarker143"/> in the next screenshot. The F1 score for this classification model is 0.881, and the most important features are <strong class="source-inline">duration</strong>, <strong class="source-inline">euribor3m</strong>, and <strong class="source-inline">pdays</strong>. By applying more transforms and building a quick model again, we can iteratively measure the positive impact (or the lack thereof) of our feature engineering steps.<div id="_idContainer056" class="IMG---Figure"><img src="Images/B17705_02_028.jpg" alt="Figure 2.28 – Building a quick model&#13;&#10;" width="738" height="523"/></div><p class="figure-caption">Figure 2.28 – Building a quick model</p></li>
				<li>Coming <a id="_idIndexMarker144"/>back to the <strong class="bold">Prepare</strong> view, let's add a few more transforms. Our data set contains two categorical features: <strong class="source-inline">job</strong> and <strong class="source-inline">education</strong>. We decide to encode them to help algorithms <a id="_idIndexMarker145"/>understand that the different values are different dimensions to the problem. Starting with <strong class="source-inline">job</strong>, we apply the <strong class="bold">Encode categorical</strong> transform. As visible in the following screenshot, we see new columns for each job name. The original <strong class="source-inline">job</strong> column is automatically dropped.<div id="_idContainer057" class="IMG---Figure"><img src="Images/B17705_02_029.jpg" alt="Figure 2.29 – One-hot encoding a column&#13;&#10;" width="1101" height="745"/></div><p class="figure-caption">Figure 2.29 – One-hot encoding a column</p></li>
				<li>The <strong class="source-inline">job_admin.</strong> column name contains a dot! We can remove it with the <strong class="bold">Manage columns|Rename column</strong> transform. Now, let's one-hot encode the <strong class="source-inline">education</strong> column… and remove the dots in column names. We could apply <strong class="bold">Process numeric</strong> transforms to scale and normalize numerical columns, but let's stop <a id="_idIndexMarker146"/>there for now. Feel free to explore and experiment!</li>
				<li>One last thing: Data Wrangler <a id="_idIndexMarker147"/>workflows are stored in <strong class="source-inline">.flow</strong> files, visible in the Jupyter file view. These are JSON files that you can (and should) store in your Git repositories, in order to reuse them later and share them with other team members.</li>
			</ol>
			<p>Now that our pipeline is ready, let's see how we can export it to Python code. All it takes is a single click, and we won't have to write a single line of code.</p>
			<h2 id="_idParaDest-44"><a id="_idTextAnchor042"/>Exporting a SageMaker Data Wrangler pipeline</h2>
			<p class="Basic-Paragraph">Data Wrangler<a id="_idIndexMarker148"/> makes it easy to export a pipeline in four ways:</p>
			<ul>
				<li>Plain Python code that you can readily include in your machine learning project.</li>
				<li>A Jupyter notebook running a SageMaker Processing job, which will apply the pipeline to your dataset and save results in S3. The notebook also includes optional code to train a model.</li>
				<li>A Jupyter notebook storing the processed dataset in SageMaker Feature Store.</li>
				<li>A Jupyter notebook creating a SageMaker Pipelines workflow, with steps to process your dataset and train a model on it.</li>
			</ul>
			<p>OK, let's go for it:</p>
			<ol>
				<li value="1">Starting from the <strong class="bold">Export</strong> view, we click on Steps and select the steps we'd like to export. Here, I selected them all, as shown in the next screenshot:<div id="_idContainer058" class="IMG---Figure"><img src="Images/B17705_02_030.jpg" alt="Figure 2.30 – Selecting steps to export&#13;&#10;" width="820" height="550"/></div><p class="figure-caption">Figure 2.30 – Selecting steps to export</p></li>
				<li>Then, we simply click on <strong class="bold">Export step</strong> and select one of the four options. Here, I go for <strong class="bold">Save to S3</strong> in order to run a SageMaker Processing job.</li>
				<li>This opens a new <a id="_idIndexMarker149"/>notebook. We'll discuss SageMaker Processing in the next section, but let's go ahead and run the job. Once the Job Status &amp; S3 Output Location cell is complete, our dataset is available in S3, as visible in the next screenshot:<div id="_idContainer059" class="IMG---Figure"><img src="Images/B17705_02_031.jpg" alt="Figure 2.31 – Locating the processed dataset in S3&#13;&#10;" width="800" height="160"/></div><p class="figure-caption">Figure 2.31 – Locating the processed dataset in S3</p></li>
				<li>Downloading and opening the CSV file stored at this location, we see that it contains the processed dataset, as shown in the next screenshot. In a typical machine learning workflow, we would then use this data directly to train a model.</li>
			</ol>
			<div>
				<div id="_idContainer060" class="IMG---Figure">
					<img src="Images/B17705_02_032.jpg" alt="Figure 2.32 – Viewing the processed dataset&#13;&#10;" width="1650" height="227"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.32 – Viewing the processed dataset</p>
			<p>As you can see, SageMaker<a id="_idIndexMarker150"/> Data Wrangler makes it very easy (and even fun) to apply transforms to your datasets. Once you're done, you can immediately export them to Python code, without having to write a single line of code.</p>
			<p>In the next section, we're going to learn about Amazon SageMaker Processing, a great way run batch jobs for data processing and other machine learning tasks.</p>
			<h1 id="_idParaDest-45"><a id="_idTextAnchor043"/>Running batch jobs with Amazon SageMaker Processing </h1>
			<p>As discussed in the <a id="_idIndexMarker151"/>previous section, datasets<a id="_idIndexMarker152"/> usually need quite a bit of work to be ready for training. Once training is complete, you may also want to run additional jobs to post-process the predicted data and to evaluate your model on different datasets. </p>
			<p>Once the experimentation phase is complete, it's good practice to start automating all these jobs, so that you can run them on demand with little effort.</p>
			<h2 id="_idParaDest-46"><a id="_idTextAnchor044"/>Discovering the Amazon SageMaker Processing API</h2>
			<p>The Amazon<a id="_idIndexMarker153"/> SageMaker Processing API is part of the SageMaker SDK, which we installed in <a href="B17705_01_Final_JM_ePub.xhtml#_idTextAnchor013"><em class="italic">Chapter 1</em></a><em class="italic">, Introducing Amazon SageMaker</em>.</p>
			<p>SageMaker Processing jobs run inside Docker containers:</p>
			<ul>
				<li>A built-in container <a id="_idIndexMarker154"/>for <strong class="bold">scikit-learn</strong> (<a href="https://scikit-learn.org">https://scikit-learn.org</a>)</li>
				<li>A built-in container<a id="_idIndexMarker155"/> for <strong class="bold">PySpark</strong> (<a href="https://spark.apache.org/docs/latest/api/python/">https://spark.apache.org/docs/latest/api/python/</a>), which supports distributed training</li>
				<li>Your own custom container</li>
			</ul>
			<p>Logs are <a id="_idIndexMarker156"/>available in <strong class="bold">Amazon CloudWatch Logs</strong> in the <strong class="source-inline">/aws/sagemaker/ProcessingJobs</strong> log group.</p>
			<p>Let's first see how we can use scikit-learn and SageMaker Processing to prepare a dataset for training. </p>
			<h2 id="_idParaDest-47"><a id="_idTextAnchor045"/>Processing a dataset with scikit-learn</h2>
			<p>Here's the high-level process:</p>
			<ul>
				<li>Upload your<a id="_idIndexMarker157"/> unprocessed dataset to Amazon S3.</li>
				<li>Write a script <a id="_idIndexMarker158"/>with scikit-learn in order to load the dataset, process it, and save the processed features and labels.</li>
				<li>Run this script with SageMaker Processing on managed infrastructure.</li>
			</ul>
			<h3>Uploading the dataset to Amazon S3</h3>
			<p>We're going to<a id="_idIndexMarker159"/> reuse the direct marketing dataset introduced <a id="_idIndexMarker160"/>in the previous section, and apply our own transforms.</p>
			<ol>
				<li value="1">Creating a new Jupyter notebook, let's first download and extract the dataset:<p class="source-code">%%sh</p><p class="source-code">apt-get -y install unzip</p><p class="source-code">wget -N https://sagemaker-sample-data-us-west-2.s3-us-west-2.amazonaws.com/autopilot/direct_marketing/bank-additional.zip</p><p class="source-code">unzip -o bank-additional.zip</p></li>
				<li>Then, we load it with <strong class="source-inline">pandas</strong>:<p class="source-code">import pandas as pd</p><p class="source-code">data = pd.read_csv('./bank-additional/bank-additional-full.csv')</p><p class="source-code">print(data.shape)</p><p class="source-code"><strong class="bold">(41188, 21)</strong></p></li>
				<li>Now, let's display the first five lines:<p class="source-code">data[:5] </p><p>This prints out<a id="_idIndexMarker161"/> the table visible in the following<a id="_idIndexMarker162"/> figure:</p><div id="_idContainer061" class="IMG---Figure"><img src="Images/B17705_02_033.jpg" alt="Figure 2.33 – Viewing the dataset&#13;&#10;" width="917" height="162"/></div><p class="figure-caption">Figure 2.33 – Viewing the dataset</p><p>Scrolling to the right, we can see a column named <strong class="bold">y</strong>, storing the labels.</p></li>
				<li>Now, let's upload the dataset to Amazon S3. We'll use a default bucket automatically created by SageMaker in the region we're running in. We'll just add a prefix to keep things nice and tidy:<p class="source-code">import sagemaker</p><p class="source-code">prefix = 'sagemaker/DEMO-smprocessing/input'</p><p class="source-code">input_data = sagemaker.Session().upload_data(path='./bank-additional/bank-additional-full.csv', key_prefix=prefix)</p></li>
			</ol>
			<h3>Writing a processing script with scikit-learn</h3>
			<p>As SageMaker Processing takes care of all infrastructure concerns, we can focus on the script itself. SageMaker Processing will also automatically copy the input dataset from S3 into the container, and<a id="_idIndexMarker163"/> the processed datasets from the <a id="_idIndexMarker164"/>container to S3. </p>
			<p>Container paths are provided when we configure the job itself. Here's what we'll use:</p>
			<ul>
				<li>The input dataset: <strong class="source-inline">/opt/ml/processing/input</strong></li>
				<li>The processed training set: <strong class="source-inline">/opt/ml/processing/train</strong></li>
				<li>The processed test set: <strong class="source-inline">/opt/ml/processing/test</strong></li>
			</ul>
			<p>In our Jupyter environment, let's start writing a new Python file named <strong class="source-inline">preprocessing.py</strong>. As you would expect, this script will load the dataset, perform basic feature engineering, and save the processed dataset:</p>
			<ol>
				<li value="1">First, we read our single command-line parameter with the <strong class="source-inline">argparse</strong> library (<a href="https://docs.python.org/3/library/argparse.html">https://docs.python.org/3/library/argparse.html</a>): the ratio for the training and test datasets. The actual value will be passed to the script by the SageMaker Processing SDK:<p class="source-code">import argparse</p><p class="source-code">parser = argparse.ArgumentParser()</p><p class="source-code">parser.add_argument('--train-test-split-ratio', </p><p class="source-code">                    type=float, default=0.3)</p><p class="source-code">args, _ = parser.parse_known_args()</p><p class="source-code">print('Received arguments {}'.format(args))</p><p class="source-code">split_ratio = args.train_test_split_ratio</p></li>
				<li>We load the input dataset using <strong class="source-inline">pandas</strong>. At startup, SageMaker Processing automatically copied it from S3 to a user-defined location inside the container, <strong class="source-inline">/opt/ml/processing/input</strong>:<p class="source-code">import os</p><p class="source-code">import pandas as pd</p><p class="source-code">input_data_path = os.path.join('/opt/ml/processing/input', 'bank-additional-full.csv')</p><p class="source-code">df = pd.read_csv(input_data_path) </p></li>
				<li>Then, we remove any line with missing values, as well as duplicate lines:<p class="source-code">df.dropna(inplace=True)</p><p class="source-code">df.drop_duplicates(inplace=True)</p></li>
				<li>Then, we <a id="_idIndexMarker165"/>count negative and positive samples, and<a id="_idIndexMarker166"/> display the class ratio. This will tell us how unbalanced the dataset is:<p class="source-code">one_class = df[df['y']=='yes']</p><p class="source-code">one_class_count = one_class.shape[0]</p><p class="source-code">zero_class = df[df['y']=='no']</p><p class="source-code">zero_class_count = zero_class.shape[0]</p><p class="source-code">zero_to_one_ratio = zero_class_count/one_class_count</p><p class="source-code">print("Ratio: %.2f" % zero_to_one_ratio)</p></li>
				<li>Looking at the dataset, we can see a column named <strong class="source-inline">pdays</strong>, telling us how long ago a customer has been contacted. Some lines have a 999 value, and that looks pretty suspicious: indeed, this is a placeholder value meaning that a customer has never been contacted. To help the model understand this assumption, let's add a new column stating it explicitly:<p class="source-code">import numpy as np</p><p class="source-code">df['no_previous_contact'] = </p><p class="source-code">   np.where(df['pdays'] == 999, 1, 0)</p></li>
				<li>In the job column, we can see three categories (<strong class="source-inline">student</strong>, <strong class="source-inline">retired</strong>, and <strong class="source-inline">unemployed</strong>) that should probably be grouped to indicate that these customers don't have a full-time job. Let's add another column:<p class="source-code">df['not_working'] = np.where(np.in1d(df['job'], ['student', 'retired', 'unemployed']), 1, 0)</p></li>
				<li>Now, let's<a id="_idIndexMarker167"/> split the dataset into training and<a id="_idIndexMarker168"/> test sets. Scikit-learn has a convenient API for this, and we set the split ratio according to a command-line argument passed to the script:<p class="source-code">from sklearn.model_selection import train_test_split</p><p class="source-code">X_train, X_test, y_train, y_test = train_test_split(</p><p class="source-code">        df.drop('y', axis=1),</p><p class="source-code">        df['y'],</p><p class="source-code">        test_size=split_ratio, random_state=0) </p></li>
				<li>The next step is to scale numerical features and to one-hot encode the categorical features. We'll use <strong class="source-inline">StandardScaler</strong> for the former, and <strong class="source-inline">OneHotEncoder</strong> for the latter:<p class="source-code">from sklearn.compose import make_column_transformer</p><p class="source-code">from sklearn.preprocessing import StandardScaler,OneHotEncoder</p><p class="source-code">preprocess = make_column_transformer(</p><p class="source-code">  (StandardScaler(), ['age', 'duration', 'campaign', 'pdays', 'previous']),</p><p class="source-code">  (OneHotEncoder(sparse=False), ['job', 'marital', 'education', 'default', 'housing', 'loan','contact', 'month', 'day_of_week', 'poutcome'])</p><p class="source-code">)</p></li>
				<li>Then, we process the training and test datasets:<p class="source-code">train_features = preprocess.fit_transform(X_train)</p><p class="source-code">test_features = preprocess.transform(X_test)</p></li>
				<li>Finally, we save the processed datasets, separating the features and labels. They're<a id="_idIndexMarker169"/> saved to user-defined locations in the<a id="_idIndexMarker170"/> container, and SageMaker Processing will automatically copy the files to S3 before terminating the job:<p class="source-code">train_features_output_path = os.path.join('/opt/ml/processing/train', 'train_features.csv')</p><p class="source-code">train_labels_output_path = os.path.join('/opt/ml/processing/train', 'train_labels.csv')</p><p class="source-code">test_features_output_path = os.path.join('/opt/ml/processing/test', 'test_features.csv')</p><p class="source-code">test_labels_output_path = os.path.join('/opt/ml/processing/test', 'test_labels.csv')</p><p class="source-code">pd.DataFrame(train_features).to_csv(train_features_output_path, header=False, index=False)</p><p class="source-code">pd.DataFrame(test_features).to_csv(test_features_output_path, header=False, index=False)</p><p class="source-code">y_train.to_csv(train_labels_output_path, header=False, index=False)</p><p class="source-code">y_test.to_csv(test_labels_output_path, header=False, index=False)</p></li>
			</ol>
			<p>That's it. As you can see, this code is vanilla scikit-learn, so it shouldn't be difficult to adapt your own scripts for SageMaker Processing. Now let's see how we can actually run this.</p>
			<h3>Running a processing script</h3>
			<p>Coming back to <a id="_idIndexMarker171"/>our Jupyter notebook, we use the <strong class="source-inline">SKLearnProcessor</strong> object from the SageMaker SDK to configure the processing job:</p>
			<ol>
				<li value="1">First, we define which version of scikit-learn we want to use, and what our infrastructure requirements are. Here, we go for an <strong class="source-inline">ml.m5.xlarge</strong> instance, an all-round good choice:<p class="source-code">from sagemaker.sklearn.processing import SKLearnProcessor</p><p class="source-code">sklearn_processor = SKLearnProcessor(</p><p class="source-code">    framework_version='0.23-1',</p><p class="source-code">    role=sagemaker.get_execution_role(),</p><p class="source-code">    instance_type='ml.m5.xlarge',</p><p class="source-code">    instance_count=1)</p></li>
				<li>Then, we simply launch the job, passing the name of the script, the dataset input path in S3, the user-defined dataset paths inside the SageMaker Processing environment, and the command-line arguments:<p class="source-code">from sagemaker.processing import ProcessingInput, ProcessingOutput</p><p class="source-code">sklearn_processor.run(</p><p class="source-code">    code='preprocessing.py',</p><p class="source-code">    inputs=[ProcessingInput(</p><p class="source-code">        source=input_data,   # Our data in S3                   </p><p class="source-code">        destination='/opt/ml/processing/input')</p><p class="source-code">    ],               </p><p class="source-code">    outputs=[</p><p class="source-code">        ProcessingOutput(</p><p class="source-code">            source='/opt/ml/processing/train',                             </p><p class="source-code">            output_name='train_data'),                                   </p><p class="source-code">        ProcessingOutput(</p><p class="source-code">            source='/opt/ml/processing/test',</p><p class="source-code">            output_name='test_data'                                                 </p><p class="source-code">            )</p><p class="source-code">    ],</p><p class="source-code">    arguments=['--train-test-split-ratio', '0.2']</p><p class="source-code">)</p><p>As the job starts, SageMaker <a id="_idIndexMarker172"/>automatically provisions a managed <strong class="source-inline">ml.m5.xlarge</strong> instance, pulls the appropriate container to it, and runs our script inside the container. Once the job is complete, the instance is terminated, and we only pay for the amount of time we used it. There is zero infrastructure management, and we'll never leave idle instances running for no reason.</p></li>
				<li>After a few minutes, the job is complete, and we can see the output of the script as follows:<p class="source-code"><strong class="bold">Received arguments Namespace(train_test_split_ratio=0.2)</strong></p><p class="source-code"><strong class="bold">Reading input data from /opt/ml/processing/input/bank-additional-full.csv</strong></p><p class="source-code"><strong class="bold">Positive samples: 4639</strong></p><p class="source-code"><strong class="bold">Negative samples: 36537</strong></p><p class="source-code"><strong class="bold">Ratio: 7.88</strong></p><p class="source-code"><strong class="bold">Splitting data into train and test sets with ratio 0.2</strong></p><p class="source-code"><strong class="bold">Running preprocessing and feature engineering transformations</strong></p><p class="source-code"><strong class="bold">Train data shape after preprocessing: (32940, 58)</strong></p><p class="source-code"><strong class="bold">Test data shape after preprocessing: (8236, 58)</strong></p><p class="source-code"><strong class="bold">Saving training features to /opt/ml/processing/train/train_features.csv</strong></p><p class="source-code"><strong class="bold">Saving test features to /opt/ml/processing/test/test_features.csv</strong></p><p class="source-code"><strong class="bold">Saving training labels to /opt/ml/processing/train/train_labels.csv</strong></p><p class="source-code"><strong class="bold">Saving test labels to /opt/ml/processing/test/test_labels.csv</strong></p><p>The following<a id="_idIndexMarker173"/> screenshot shows the same log in <strong class="bold">CloudWatch</strong>:</p><div id="_idContainer062" class="IMG---Figure"><img src="Images/B17705_02_034.jpg" alt="Figure 2.34 – Viewing the log in CloudWatch Logs&#13;&#10;" width="1106" height="533"/></div><p class="figure-caption">Figure 2.34 – Viewing the log in CloudWatch Logs</p></li>
				<li>Finally, we can describe the job and see the location of the processed datasets:<p class="source-code">preprocessing_job_description = </p><p class="source-code">   sklearn_processor.jobs[-1].describe()</p><p class="source-code">output_config = preprocessing_job_description['ProcessingOutputConfig']</p><p class="source-code">for output in output_config['Outputs']:</p><p class="source-code">    print(output['S3Output']['S3Uri'])</p><p>This results in the following output:</p><p class="source-code"><strong class="bold">s3://sagemaker-eu-west-1-123456789012/sagemaker-scikit-learn-2020-04-22-10-09-43-146/output/train_data</strong></p><p class="source-code"><strong class="bold">s3://sagemaker-eu-west-1-123456789012/sagemaker-scikit-learn-2020-04-22-10-09-43-146/output/test_data</strong></p><p>In a terminal, we<a id="_idIndexMarker174"/> can use the AWS CLI to fetch the processed training set located at the preceding path, and take a look at the first sample and label:</p><p class="source-code"><strong class="bold">$ aws s3 cp s3://sagemaker-eu-west-1-123456789012/sagemaker-scikit-learn-2020-04-22-09-45-05-711/output/train_data/train_features.csv .</strong></p><p class="source-code"><strong class="bold">$ aws s3 cp s3://sagemaker-eu-west-1-123456789012/sagemaker-scikit-learn-2020-04-22-09-45-05-711/output/train_data/train_labels.csv .</strong></p><p class="source-code"><strong class="bold">$ head -1 train_features.csv</strong></p><p class="source-code"><strong class="bold">0.09604515376959515,-0.6572847857673993,-0.20595554104907898,0.19603112301129622,-0.35090125695736246,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0</strong></p><p class="source-code"><strong class="bold">$ head -1 train_labels.csv</strong></p><p class="source-code"><strong class="bold">no</strong></p></li>
			</ol>
			<p>Now that the dataset has been processed with our own code, we could use it to train a machine learning model. In real life, we would also automate these steps instead of running them manually <a id="_idIndexMarker175"/>inside a notebook.</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">One last thing: here, our job<a id="_idIndexMarker176"/> writes output data to S3. SageMaker Processing also supports writing directly to an existing Feature Group in <strong class="bold">SageMaker Feature Store</strong> (which we'll introduce later in the book). API details<a id="_idIndexMarker177"/> are available at <a href="https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.processing.ProcessingOutput">https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.processing.ProcessingOutput</a>.</p>
			<h2 id="_idParaDest-48"><a id="_idTextAnchor046"/>Processing a dataset with your own code</h2>
			<p>In the previous <a id="_idIndexMarker178"/>example, we used a built-in container to run our <a id="_idIndexMarker179"/>scikit-learn code. SageMaker Processing also makes it possible to use your own container. You can find an example at <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/build-your-own-processing-container.html">https://docs.aws.amazon.com/sagemaker/latest/dg/build-your-own-processing-container.html</a>.</p>
			<p>As you can see, SageMaker Processing makes it really easy to run data processing jobs. You can focus on writing and running your script, without having to worry about provisioning and managing infrastructure. </p>
			<h1 id="_idParaDest-49"><a id="_idTextAnchor047"/>Summary</h1>
			<p>In this chapter, you learned how Amazon SageMaker Ground Truth helps you build highly accurate training datasets using image and text labeling workflows. We'll see in <a href="B17705_05_Final_JM_ePub.xhtml#_idTextAnchor091"><em class="italic">Chapter 5</em></a><em class="italic">,</em> <em class="italic">Training Computer Vision Models</em>, how to use image datasets labeled with Ground Truth.</p>
			<p>Then, you learned about Amazon SageMaker Processing, a capability that helps you run your own data processing workloads on managed infrastructure: feature engineering, data validation, model evaluation, and so on. </p>
			<p>Finally, we discussed three other AWS services (Amazon EMR, AWS Glue, and Amazon Athena), and how they could fit into your analytics and machine learning workflows.</p>
			<p>In the next chapter, we'll start training models using the built-in machine learning models of Amazon SageMaker.</p>
		</div>
	</div></body></html>