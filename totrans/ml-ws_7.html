<html><head></head><body>
		<div id="_idContainer113" class="Content">
			<h1 id="_idParaDest-172"><a id="_idTextAnchor178"/>Appendix</h1>
		</div>
		<div id="_idContainer133" class="Content">
			<h1 id="_idParaDest-173"><a id="_idTextAnchor179"/>1. Introduction to Scikit-Learn</h1>
			<h2 id="_idParaDest-174"><a id="_idTextAnchor180"/>Activity 1.01: Selecting a Target Feature and Creating a Target Matrix</h2>
			<p>Solution:</p>
			<ol>
				<li>Load the <strong class="source-inline">titanic</strong> dataset using the <strong class="source-inline">seaborn</strong> library:<p class="source-code">import seaborn as sns</p><p class="source-code">titanic = sns.load_dataset('titanic')</p><p class="source-code">titanic.head(10)</p><p>The first couple of rows should look as follows:</p><div id="_idContainer114" class="IMG---Figure"><img src="image/B15781_01_22.jpg" alt="Figure 1.22: An image showing the first 10 instances of the Titanic dataset&#13;&#10;"/></div><p class="figure-caption">Figure 1.22: An image showing the first 10 instances of the Titanic dataset</p></li>
				<li>Select your preferred target feature for the goal of this activity.<p>The preferred target feature could be either <strong class="source-inline">survived</strong> or <strong class="source-inline">alive</strong>. This is mainly because both of them label whether a person survived the crash. For the following steps, the variable that's been chosen is <strong class="source-inline">survived</strong>. However, choosing <strong class="source-inline">alive</strong> will not affect the final shape of the variables.</p></li>
				<li>Create both the features matrix and the target matrix. Make sure that you store the data from the features matrix in a variable, X, and the data from the target matrix in another variable, Y:<p class="source-code">X = titanic.drop('survived',axis = 1)</p><p class="source-code">Y = titanic['survived']</p></li>
				<li>Print out the shape of <strong class="source-inline">X</strong>, as follows:<p class="source-code">X.shape</p><p>The output is as follows:</p><p class="source-code">(891, 14)</p><p>Do the same for <strong class="source-inline">Y</strong>:</p><p class="source-code">Y.shape</p><p>The output is as follows:</p><p class="source-code">(891,)</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/37BwgSv">https://packt.live/37BwgSv</a>.</p><p class="callout">You can also run this example online at <a href="https://packt.live/2MXFtuP">https://packt.live/2MXFtuP</a>. You must execute the entire Notebook in order to get the desired result.</p></li>
			</ol>
			<p>You have successfully split the dataset into two subsets, which will be used later on to train a model.</p>
			<h2 id="_idParaDest-175"><a id="_idTextAnchor181"/>Activity 1.02: Pre-processing an Entire Dataset</h2>
			<p>Solution:</p>
			<ol>
				<li value="1">Import <strong class="source-inline">seaborn</strong> and the <strong class="source-inline">LabelEncoder</strong> class from scikit-learn. Next, load the <strong class="source-inline">titanic</strong> dataset and create the features matrix, including the following features: <strong class="source-inline">sex</strong>, <strong class="source-inline">age</strong>, <strong class="source-inline">fare</strong>, <strong class="source-inline">class</strong>, <strong class="source-inline">embark_town</strong>, and <strong class="source-inline">alone</strong>:<p class="source-code">import seaborn as sns</p><p class="source-code">from sklearn.preprocessing import LabelEncoder</p><p class="source-code">titanic = sns.load_dataset('titanic')</p><p class="source-code">X = titanic[['sex','age','fare','class',\</p><p class="source-code">             'embark_town','alone']].copy()</p><p class="source-code">X.shape</p><p>The features matrix was created as copies of the dataset in order to avoid getting a warning message every time the matrix was to be updated through the preprocessing process.</p><p>The output is as follows:</p><p class="source-code">(891, 6)</p></li>
				<li>Check for missing values in all the features. As we did previously, use <strong class="source-inline">isnull()</strong> to determine whether a value is missing and use <strong class="source-inline">sum()</strong> to sum up the occurrences of missing values along each feature:<p class="source-code">print("Sex: " + str(X['sex'].isnull().sum()))</p><p class="source-code">print("Age: " + str(X['age'].isnull().sum()))</p><p class="source-code">print("Fare: " + str(X['fare'].isnull().sum()))</p><p class="source-code">print("Class: " + str(X['class'].isnull().sum()))</p><p class="source-code">print("Embark town: " + str(X['embark_town'].isnull().sum()))</p><p class="source-code">print("Alone: " + str(X['alone'].isnull().sum()))</p><p>The output will look as follows:</p><p class="source-code">Sex: 0</p><p class="source-code">Age: 177</p><p class="source-code">Fare: 0</p><p class="source-code">Class: 0</p><p class="source-code">Embark town: 2</p><p class="source-code">Alone: 0</p><p>As you can see from the preceding output, only one feature contains a significant amount of missing values: <strong class="source-inline">age</strong>. As it contains many missing values that account for almost 20% of the total, the values should be replaced. The mean imputation methodology will be applied, as shown in the following code:</p><p class="source-code">mean = X['age'].mean()</p><p class="source-code">mean =round(mean)</p><p class="source-code">X['age'].fillna(mean,inplace = True)</p><p>Next, discover the outliers present in the numeric features. Let's use three standard deviations as the measure to calculate the min and max threshold for numeric features:</p><p class="source-code">features = ["age", "fare"]</p><p class="source-code">for feature in features:</p><p class="source-code">    min_ = X[feature].mean() - (3 * X[feature].std())</p><p class="source-code">    max_ = X[feature].mean() + (3 * X[feature].std())</p><p class="source-code">    X = X[X[feature] &lt;= max_]</p><p class="source-code">    X = X[X[feature] &gt;= min_]</p><p class="source-code">    print(feature,    ":", X.shape)</p><p>The output is as follows:</p><p class="source-code">age: (884, 6)</p><p class="source-code">fare: (864, 6)</p><p>The total count of outliers for the age and fare features is 7 and 20, respectively, reducing the shape of the initial matrix by 27 instances.</p><p>Next, using a <strong class="source-inline">for</strong> loop, discover outliers present in text features. The <strong class="source-inline">value_counts()</strong> function is used to count the occurrence of the classes in each feature:</p><p class="source-code">features = ["sex", "class", "embark_town", "alone"]</p><p class="source-code">for feature in features:</p><p class="source-code">    count_ = X[feature].value_counts()</p><p class="source-code">    print(feature)</p><p class="source-code">    print(count_, "\n")</p><p>The output is as follows:</p><div id="_idContainer115" class="IMG---Figure"><img src="image/B15781_01_23.jpg" alt="Figure 1.23: Count of occurrence of the classes in each feature&#13;&#10;"/></div><p class="figure-caption">Figure 1.23: Count of occurrence of the classes in each feature</p><p>None of the classes for any of the features are considered to be outliers as they all represent over 5% of the entire dataset.</p></li>
				<li>Convert all text features into their numeric representations. Use scikit-learn's <strong class="source-inline">LabelEncoder</strong> class, as shown in the following code:<p class="source-code">enc = LabelEncoder()</p><p class="source-code">X["sex"] = enc.fit_transform(X['sex'].astype('str'))</p><p class="source-code">X["class"] = enc.fit_transform(X['class'].astype('str'))</p><p class="source-code">X["embark_town"] = enc.fit_transform(X['embark_town'].\</p><p class="source-code">                                     astype('str'))</p><p class="source-code">X["alone"] = enc.fit_transform(X['alone'].astype('str'))</p><p>Print out the top five instances of the features matrix to view the result of the conversion:</p><p class="source-code">X.head()</p><p>The output is as follows:</p><div id="_idContainer116" class="IMG---Figure"><img src="image/B15781_01_24.jpg" alt="Figure 1.24: A screenshot displaying the first five instances of the features matrix&#13;&#10;"/></div><p class="figure-caption">Figure 1.24: A screenshot displaying the first five instances of the features matrix</p></li>
				<li>Rescale your data, either by normalizing or standardizing it.<p>As you can see from the following code, all features go through the normalization process, but only those that don't meet the criteria of a normalized variable are changed:</p><p class="source-code">X = (X - X.min()) / (X.max() - X.min())</p><p class="source-code">X.head(10)</p><p>The top 10 rows of the final output are shown in the following screenshot:</p><div id="_idContainer117" class="IMG---Figure"><img src="image/B15781_01_25.jpg" alt="Figure 1.25: Displaying the first 10 instances of the normalized dataset&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 1.25: Displaying the first 10 instances of the normalized dataset</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2MY1wld">https://packt.live/2MY1wld</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3e2lyqt">https://packt.live/3e2lyqt</a>. You must execute the entire Notebook in order to get the desired result.</p>
			<p>You have successfully performed data preprocessing over a dataset, which can now be used to train a ML algorithm.</p>
			<h1 id="_idParaDest-176"><a id="_idTextAnchor182"/>2. Unsupervised Learning – Real-Life Applications</h1>
			<h2 id="_idParaDest-177"><a id="_idTextAnchor183"/>Activity 2.01: Using Data Visualization to Aid the Pre-processing Process</h2>
			<p>Solution:</p>
			<ol>
				<li value="1">Import all the required elements to load the dataset and pre-process it:<p class="source-code">import pandas as pd</p><p class="source-code">import matplotlib.pyplot as plt</p><p class="source-code">import numpy as np</p></li>
				<li>Load the previously downloaded dataset by using pandas' <strong class="source-inline">read_csv()</strong> function. Store the dataset in a pandas DataFrame named <strong class="source-inline">data</strong>:<p class="source-code">data = pd.read_csv("wholesale_customers_data.csv")</p></li>
				<li>Check for missing values in your DataFrame. Using the <strong class="source-inline">isnull()</strong> function plus the <strong class="source-inline">sum()</strong> function, count the missing values of the entire dataset at once:<p class="source-code">data.isnull().sum()</p><p>The output is as follows:</p><p class="source-code">Channel             0</p><p class="source-code">Region              0</p><p class="source-code">Fresh               0</p><p class="source-code">Milk                0</p><p class="source-code">Grocery             0</p><p class="source-code">Frozen              0</p><p class="source-code">Detergents_Paper    0</p><p class="source-code">Delicassen          0</p><p class="source-code">dtype: int64</p><p>As you can see from the preceding screenshot, there are no missing values in the dataset. </p></li>
				<li>Check for outliers in your DataFrame. Mark as outliers all the values that are three standard deviations away from the mean.<p>The following code snippet allows you to look for outliers in the entire set of features at once. However, another valid method would be to check for outliers one feature at a time:</p><p class="source-code">outliers = {}</p><p class="source-code">for i in range(data.shape[1]):</p><p class="source-code">    min_t = data[data.columns[i]].mean() \</p><p class="source-code">            - (3 * data[data.columns[i]].std())</p><p class="source-code">    max_t = data[data.columns[i]].mean() \</p><p class="source-code">            + (3 * data[data.columns[i]].std())</p><p class="source-code">    count = 0</p><p class="source-code">    for j in data[data.columns[i]]:</p><p class="source-code">        if j &lt; min_t or j &gt; max_t:</p><p class="source-code">            count += 1</p><p class="source-code">    outliers[data.columns[i]] = [count,data.shape[0]-count]</p><p class="source-code">print(outliers)</p><p>The count of outliers for each of the features is as follows:</p><p class="source-code">{'Channel': [0, 440], 'Region': [0, 440], 'Fresh': [7, 433], 'Milk': [9, 431], 'Grocery': [7, 433], 'Frozen': [6, 434], 'Detergents_Paper': [10, 430], 'Delicassen': [4, 436]}</p><p>As you can see from the preceding screenshot, some features do have outliers. Considering that there are only a few outliers for each feature, there are two possible ways to handle them.</p><p>First, you could decide to delete the outliers. This decision can be supported by displaying a histogram for the features with outliers:</p><p class="source-code">plt.hist(data["Fresh"])</p><p class="source-code">plt.show()</p><p>The output is as follows:</p><div id="_idContainer118" class="IMG---Figure"><img src="image/B15781_02_14.jpg" alt="Figure 2.14: An example histogram plot for the “Fresh” feature&#13;&#10;"/></div><p class="figure-caption">Figure 2.14: An example histogram plot for the "Fresh" feature</p><p>In the preceding plot, the <em class="italic">x-axis</em> represents the values present in the dataset for the selected feature, while the y-axis refers to the number of occurrences of each value. It is worth mentioning that histograms built for continuous values make ranges out of the values in order to be able to count their occurrences in the dataset.</p><p>For instance, for the feature named <strong class="source-inline">Fresh</strong>, it can be seen through the histogram that most instances are represented by values below 40,000. Hence, deleting the instances above that value will not affect the performance of the model.</p><p>On the other hand, the second approach would be to leave the outliers as they are, considering that they do not represent a large portion of the dataset, which can be supported with data visualization tools using a pie chart. Refer to the code and the output that follows: </p><p class="source-code">plt.figure(figsize=(8,8))</p><p class="source-code">plt.pie(outliers["Detergents_Paper"],autopct="%.2f")</p><p class="source-code">plt.show()</p><p>The output is as follows:</p><p> </p><div id="_idContainer119" class="IMG---Figure"><img src="image/B15781_02_15.jpg" alt="Figure 2.15: A pie chart showing the participation of outliers from the Detergents_papers feature in the dataset&#13;&#10;"/></div><p class="figure-caption">Figure 2.15: A pie chart showing the participation of outliers from the Detergents_papers feature in the dataset</p><p>The preceding diagram shows the participation of the outliers from the <strong class="source-inline">Detergents_papers</strong> feature, which was the feature with the most outliers in the dataset. Only 2.27% of the values are outliers, a value so low that it will not affect the performance of the model either.</p><p>For the solution in this book, it was decided to keep the outliers since they are not likely to affect the performance of the model.</p></li>
				<li>Rescale the data. <p>For this solution, the formula for standardization has been used. Note that the formula can be applied to the entire dataset at once, instead of being applied individually to each feature:</p><p class="source-code">data_standardized = (data - data.mean())/data.std()</p><p class="source-code">data_standardized.head()</p><p>The output is as follows:</p><div id="_idContainer120" class="IMG---Figure"><img src="image/B15781_02_16.jpg" alt="Figure 2.16: Rescaled data&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.16: Rescaled data</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2Y3ooGh">https://packt.live/2Y3ooGh</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2B8vKPI">https://packt.live/2B8vKPI</a>. You must execute the entire Notebook in order to get the desired result.</p>
			<p>You have successfully pre-processed the Wholesale Customers dataset, which will be used in subsequent activities to build a model that will classify these observations into clusters.</p>
			<h2 id="_idParaDest-178"><a id="_idTextAnchor184"/>Activity 2.02: Applying the k-means Algorithm to a Dataset</h2>
			<p>Solution:</p>
			<ol>
				<li value="1">Open the Jupyter Notebook that you used for the previous activity. There, you should have imported all the required libraries and performed the necessary steps to pre-process the dataset. <p>The standardized data should look as follows:</p><div id="_idContainer121" class="IMG---Figure"><img src="image/B15781_02_17.jpg" alt="Figure 2.17: A screenshot displaying the first five instances of the standardized dataset&#13;&#10;"/></div><p class="figure-caption">Figure 2.17: A screenshot displaying the first five instances of the standardized dataset</p></li>
				<li>Calculate the average distance of data points from its centroid in relation to the number of clusters. Based on this distance, select the appropriate number of clusters to train the model on. <p>First, import the algorithm class:</p><p class="source-code">from sklearn.cluster import KMeans</p><p>Next, using the code in the following snippet, calculate the average distance of data points from its centroid based on the number of clusters created:</p><p class="source-code">ideal_k = []</p><p class="source-code">for i in range(1,21):</p><p class="source-code">    est_kmeans = KMeans(n_clusters=i, random_state=0)</p><p class="source-code">    est_kmeans.fit(data_standardized)</p><p class="source-code">    ideal_k.append([i,est_kmeans.inertia_])</p><p class="source-code">ideal_k = np.array(ideal_k)</p><p>Finally, plot the relation to find the breaking point of the line and select the number of clusters:</p><p class="source-code">plt.plot(ideal_k[:,0],ideal_k[:,1])</p><p class="source-code">plt.show()</p><p>The output is as follows:</p><p> </p><div id="_idContainer122" class="IMG---Figure"><img src="image/B15781_02_18.jpg" alt="Figure 2.18: The output of the plot function used&#13;&#10;"/></div><p class="figure-caption">Figure 2.18: The output of the plot function used</p><p>Again, the <em class="italic">x-axis</em> represents the number of clusters, while the <em class="italic">y-axis</em> refers to the calculated average distance of the data points in a cluster from their centroid.</p></li>
				<li>Train the model and assign a cluster to each data point in your dataset. Plot the results. <p>To train the model, use the following code:</p><p class="source-code">est_kmeans = KMeans(n_clusters=6, random_state = 0)</p><p class="source-code">est_kmeans.fit(data_standardized)</p><p class="source-code">pred_kmeans = est_kmeans.predict(data_standardized)</p><p>The number of clusters selected is <strong class="source-inline">6</strong>; however, since there is no exact breaking point, values between 5 and 10 are also acceptable.</p><p>Finally, plot the results of the clustering process. Since the dataset contains eight different features, choose two features to draw at once, as shown in the following code:</p><p class="source-code">plt.subplots(1, 2, sharex='col', \</p><p class="source-code">             sharey='row', figsize=(16,8))</p><p class="source-code">plt.scatter(data.iloc[:,5], data.iloc[:,3], \</p><p class="source-code">            c=pred_kmeans, s=20)</p><p class="source-code">plt.xlim([0, 20000])</p><p class="source-code">plt.ylim([0, 20000])</p><p class="source-code">plt.xlabel('Frozen')</p><p class="source-code">plt.subplot(1, 2, 1)</p><p class="source-code">plt.scatter(data.iloc[:,4], data.iloc[:,3], \</p><p class="source-code">            c=pred_kmeans, s=20)</p><p class="source-code">plt.xlim([0, 20000])</p><p class="source-code">plt.ylim([0,20000])</p><p class="source-code">plt.xlabel('Grocery')</p><p class="source-code">plt.ylabel('Milk')</p><p class="source-code">plt.show()</p><p>The output is as follows:</p><div id="_idContainer123" class="IMG---Figure"><img src="image/B15781_02_19.jpg" alt="Figure 2.19: Two example plots obtained after the clustering process&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.19: Two example plots obtained after the clustering process</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this activity, please refer to <a href="https://packt.live/3fhgO0y">https://packt.live/3fhgO0y</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3eeEOB6">https://packt.live/3eeEOB6</a>. You must execute the entire Notebook in order to get the desired result.</p>
			<p>The <strong class="source-inline">subplots()</strong> function from <strong class="source-inline">matplotlib</strong> has been used to plot two scatter graphs at a time. For each graph, the axes represent the values for a selected feature in relation to the values of another feature. As can be seen from the plots, there is no obvious visual relation due to the fact that we are only able to use two of the eight features present in the dataset. However, the final output of the model creates six different clusters that represent six different profiles of clients.</p>
			<h2 id="_idParaDest-179"><a id="_idTextAnchor185"/>Activity 2.03: Applying the Mean-Shift Algorithm to a Dataset</h2>
			<p>Solution:</p>
			<ol>
				<li value="1">Open the Jupyter Notebook that you used for the previous activity.</li>
				<li>Train the model and assign a cluster to each data point in your dataset. Plot the results. <p>First, import the algorithm class:</p><p class="source-code">from sklearn.cluster import MeanShift</p><p>To train the model, use the following code:</p><p class="source-code">est_meanshift = MeanShift(0.4)</p><p class="source-code">est_meanshift.fit(data_standardized)</p><p class="source-code">pred_meanshift = est_meanshift.predict(data_standardized)</p><p>The model was trained using a bandwidth of <strong class="source-inline">0.4</strong>. However, feel free to test other values to see how the result changes.</p><p>Finally, plot the results of the clustering process. As the dataset contains eight different features, choose two features to draw at once, as shown in the following snippet. Similar to the previous activity, the separation between clusters is not seen visually due to the capability to only draw two out of the eight features:</p><p class="source-code">plt.subplots(1, 2, sharex='col', \</p><p class="source-code">             sharey='row', figsize=(16,8))</p><p class="source-code">plt.scatter(data.iloc[:,5], data.iloc[:,3], \</p><p class="source-code">            c=pred_meanshift, s=20)</p><p class="source-code">plt.xlim([0, 20000])</p><p class="source-code">plt.ylim([0,20000])</p><p class="source-code">plt.xlabel('Frozen')</p><p class="source-code">plt.subplot(1, 2, 1)</p><p class="source-code">plt.scatter(data.iloc[:,4], data.iloc[:,3], \</p><p class="source-code">            c=pred_meanshift, s=20)</p><p class="source-code">plt.xlim([0, 20000])</p><p class="source-code">plt.ylim([0,20000])</p><p class="source-code">plt.xlabel('Grocery')</p><p class="source-code">plt.ylabel('Milk')</p><p class="source-code">plt.show()</p><p>The output is as follows:</p><div id="_idContainer124" class="IMG---Figure"><img src="image/B15781_02_20.jpg" alt="Figure 2.20: Example plots obtained at the end of the process&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.20: Example plots obtained at the end of the process</p>
			<p>For each of the plots, the axes represent the values of a selected feature, against the values of another feature.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this activity, please refer to <a href="https://packt.live/3fviVy1">https://packt.live/3fviVy1</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2Y1aqEF">https://packt.live/2Y1aqEF</a>. You must execute the entire Notebook in order to get the desired result.</p>
			<p>You have successfully applied the mean-shift algorithm over the Wholesale Customers dataset. Later on, you will be able to compare the results of the different algorithms over the same dataset to choose the one that performs the best.</p>
			<h2 id="_idParaDest-180"><a id="_idTextAnchor186"/>Activity 2.04: Applying the DBSCAN Algorithm to the Dataset</h2>
			<p>Solution:</p>
			<ol>
				<li value="1">Open the Jupyter Notebook that you used for the previous activity.</li>
				<li>Train the model and assign a cluster to each data point in your dataset. Plot the results. <p>First, import the algorithm class:</p><p class="source-code">from sklearn.cluster import DBSCAN</p><p>To train the model, use the following code:</p><p class="source-code">est_dbscan = DBSCAN(eps=0.8)</p><p class="source-code">pred_dbscan = est_dbscan.fit_predict(data_standardized)</p><p>The model was trained using an epsilon value of <strong class="source-inline">0.8</strong>. However, feel free to test other values to see how the results change.</p><p>Finally, plot the results of the clustering process. As the dataset contains eight different features, choose two features to draw at once, as shown in the following code:</p><p class="source-code">plt.subplots(1, 2, sharex='col', \</p><p class="source-code">             sharey='row', figsize=(16,8))</p><p class="source-code">plt.scatter(data.iloc[:,5], data.iloc[:,3], \</p><p class="source-code">            c=pred_dbscan, s=20)</p><p class="source-code">plt.xlim([0, 20000])</p><p class="source-code">plt.ylim([0,20000])</p><p class="source-code">plt.xlabel('Frozen')</p><p class="source-code">plt.subplot(1, 2, 1)</p><p class="source-code">plt.scatter(data.iloc[:,4], data.iloc[:,3], \</p><p class="source-code">            c=pred_dbscan, s=20)</p><p class="source-code">plt.xlim([0, 20000])</p><p class="source-code">plt.ylim([0,20000])</p><p class="source-code">plt.xlabel('Grocery')</p><p class="source-code">plt.ylabel('Milk')</p><p class="source-code">plt.show()</p><p>The output is as follows:</p><div id="_idContainer125" class="IMG---Figure"><img src="image/B15781_02_21.jpg" alt="Figure 2.21: Example plots obtained at the end of the clustering process&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.21: Example plots obtained at the end of the clustering process</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this activity, please refer to <a href="https://packt.live/2YCFvh8">https://packt.live/2YCFvh8</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2MZgnvC">https://packt.live/2MZgnvC</a>. You must execute the entire Notebook in order to get the desired result.</p>
			<p>Similar to the previous activity, the separation between clusters is not seen visually due to the capability to only draw two out of the eight features at once.</p>
			<h2 id="_idParaDest-181"><a id="_idTextAnchor187"/>Activity 2.05: Measuring and Comparing the Performance of the Algorithms</h2>
			<p>Solution: </p>
			<ol>
				<li value="1">Open the Jupyter Notebook that you used for the previous activity.</li>
				<li>Calculate both the Silhouette Coefficient score and the Calinski–Harabasz index for all the models that you trained previously. <p>First, import the metrics:</p><p class="source-code">from sklearn.metrics import silhouette_score</p><p class="source-code">from sklearn.metrics import calinski_harabasz_score</p><p>Calculate the Silhouette Coefficient score for all the algorithms, as shown in the following code:</p><p class="source-code">kmeans_score = silhouette_score(data_standardized, \</p><p class="source-code">                                pred_kmeans, \</p><p class="source-code">                                metric='euclidean')</p><p class="source-code">meanshift_score = silhouette_score(data_standardized, \</p><p class="source-code">                                   pred_meanshift, \</p><p class="source-code">                                   metric='euclidean')</p><p class="source-code">dbscan_score = silhouette_score(data_standardized, \</p><p class="source-code">                                pred_dbscan, \</p><p class="source-code">                                metric='euclidean')</p><p class="source-code">print(kmeans_score, meanshift_score, dbscan_score)</p><p>The scores come to be around <strong class="source-inline">0.3515</strong>, <strong class="source-inline">0.0933</strong>, and <strong class="source-inline">0.1685</strong> for the k-means, mean-shift, and DBSCAN algorithms, respectively.</p><p>Finally, calculate the Calinski–Harabasz index for all the algorithms. The following is a snippet of the code for this:</p><p class="source-code">kmeans_score = calinski_harabasz_score(data_standardized, \</p><p class="source-code">                                       pred_kmeans)</p><p class="source-code">meanshift_score = calinski_harabasz_score(data_standardized, \</p><p class="source-code">                                          pred_meanshift)</p><p class="source-code">dbscan_score = calinski_harabasz_score(data_standardized, \</p><p class="source-code">                                       pred_dbscan)</p><p class="source-code">print(kmeans_score, meanshift_score, dbscan_score)</p><p>The scores come to be approximately <strong class="source-inline">145.73</strong>, <strong class="source-inline">112.90</strong>, and <strong class="source-inline">42.45</strong> for the three algorithms in the order given in the preceding code snippet.</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this activity, please refer to <a href="https://packt.live/2Y2xHWR">https://packt.live/2Y2xHWR</a>.</p><p class="callout">You can also run this example online at <a href="https://packt.live/3hszegy">https://packt.live/3hszegy</a>. You must execute the entire Notebook in order to get the desired result.</p></li>
			</ol>
			<p>By quickly looking at the results we obtained for both metrics, it is possible to conclude that the k-means algorithm outperforms the other models, and hence should be the one that's selected to solve the data problem.</p>
			<h1 id="_idParaDest-182"><a id="_idTextAnchor188"/>3. Supervised Learning – Key Steps</h1>
			<h2 id="_idParaDest-183"><a id="_idTextAnchor189"/>Activity 3.01: Data Partitioning on a Handwritten Digit Dataset</h2>
			<p>Solution:</p>
			<ol>
				<li value="1">Import all the required elements to split a dataset, as well as the <strong class="source-inline">load_digits</strong> function from scikit-learn to load the <strong class="source-inline">digits</strong> dataset. Use the following code to do so:<p class="source-code">from sklearn.datasets import load_digits</p><p class="source-code">import pandas as pd</p><p class="source-code">from sklearn.model_selection import train_test_split</p><p class="source-code">from sklearn.model_selection import KFold</p></li>
				<li>Load the <strong class="source-inline">digits</strong> dataset and create Pandas DataFrames containing the features and target matrices:<p class="source-code">digits = load_digits()</p><p class="source-code">X = pd.DataFrame(digits.data)</p><p class="source-code">Y = pd.DataFrame(digits.target)</p><p class="source-code">print(X.shape, Y.shape)</p><p>The shape of your features and target matrices should be as follows, respectively:</p><p class="source-code">(1797, 64) (1797, 1)</p></li>
				<li>Perform the conventional split approach, using a split ratio of 60/20/20%.<p>Using the <strong class="source-inline">train_test_split</strong> function, split the data into an initial train set and a test set:</p><p class="source-code">X_new, X_test, \</p><p class="source-code">Y_new, Y_test = train_test_split(X, Y, test_size=0.2)</p><p class="source-code">print(X_new.shape, Y_new.shape, X_test.shape, Y_test.shape)</p><p>The shape of the sets that you created should be as follows:</p><p class="source-code">(1437, 64) (1437, 1) (360, 64) (360, 1)</p><p>Next, calculate the value of <strong class="source-inline">test_size</strong>, which sets the size of the dev set equal to the size of the test set that was created previously:</p><p class="source-code">dev_size = X_test.shape[0]/X_new.shape[0]</p><p class="source-code">print(dev_size)</p><p>The result of the preceding operation is <strong class="source-inline">0.2505</strong>.</p><p>Finally, split <strong class="source-inline">X_new</strong> and <strong class="source-inline">Y_new</strong> into the final train and dev sets. Use the following code to do so:</p><p class="source-code">X_train, X_dev, \</p><p class="source-code">Y_train, Y_dev = train_test_split(X_new, Y_new, \</p><p class="source-code">                                  test_size = dev_size)</p><p class="source-code">print(X_train.shape, Y_train.shape, X_dev.shape, \</p><p class="source-code">      Y_dev.shape, X_test.shape, Y_test.shape)</p><p>The output from the preceding snippet is as follows:</p><p class="source-code">(1077, 64) (1077, 1) (360, 64) (360, 1) (360, 64) (360, 1)</p></li>
				<li>Using the same DataFrames, perform a 10-fold cross-validation split.<p>First, divide the datasets into initial training and testing sets:</p><p class="source-code">X_new_2, X_test_2, \</p><p class="source-code">Y_new_2, Y_test_2 = train_test_split(X, Y, test_size=0.1)</p><p>Using the <strong class="source-inline">KFold</strong> class, perform a 10-fold split:</p><p class="source-code">kf = KFold(n_splits = 10)</p><p class="source-code">splits = kf.split(X_new_2)</p><p>Remember that cross-validation performs a different configuration of splits, shuffling data each time. Considering this, perform a <strong class="source-inline">for</strong> loop that will go through all the split configurations:</p><p class="source-code">for train_index, dev_index in splits:</p><p class="source-code">    X_train_2, X_dev_2 = X_new_2.iloc[train_index,:], \</p><p class="source-code">                         X_new_2.iloc[dev_index,:]</p><p class="source-code">    Y_train_2, Y_dev_2 = Y_new_2.iloc[train_index,:], \</p><p class="source-code">                         Y_new_2.iloc[dev_index,:]</p><p>The code in charge of training and evaluating the model should be inside the body of the <strong class="source-inline">for</strong> loop in order to train and evaluate the model with each configuration of splits:</p><p class="source-code">print(X_train_2.shape, Y_train_2.shape, X_dev_2.shape, \</p><p class="source-code">      Y_dev_2.shape, X_test_2.shape, Y_test_2.shape)</p><p>By printing the shape of all the subsets, as per the preceding snippet, the output is as follows:</p><p class="source-code">(1456, 64) (1456, 1) (161, 64) (161, 1) (180, 64) (180, 1)</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/37xatv3">https://packt.live/37xatv3</a>.</p><p class="callout">You can also run this example online at <a href="https://packt.live/2Y2nolS">https://packt.live/2Y2nolS</a>. You must execute the entire Notebook in order to get the desired result.</p></li>
			</ol>
			<p>You have successfully split a dataset using both the conventional split approach, as well as the cross-validation one. These sets can now be used to train outstanding models that perform well on unseen data.</p>
			<h2 id="_idParaDest-184"><a id="_idTextAnchor190"/>Activity 3.02: Evaluating the Performance of the Model Trained on a Handwritten Dataset</h2>
			<p>Solution:</p>
			<ol>
				<li value="1">Import all the required elements to load and split a dataset in order to train a model and evaluate the performance of the classification tasks:<p class="source-code">from sklearn.datasets import load_digits</p><p class="source-code">import pandas as pd</p><p class="source-code">from sklearn.model_selection import train_test_split</p><p class="source-code">from sklearn import tree</p><p class="source-code">from sklearn.metrics import confusion_matrix</p><p class="source-code">from sklearn.metrics import accuracy_score</p><p class="source-code">from sklearn.metrics import precision_score</p><p class="source-code">from sklearn.metrics import recall_score</p></li>
				<li>Load the <strong class="source-inline">digits</strong> toy dataset from scikit-learn and create Pandas DataFrames containing the features and target matrices:<p class="source-code">digits = load_digits()</p><p class="source-code">X = pd.DataFrame(digits.data)</p><p class="source-code">Y = pd.DataFrame(digits.target)</p></li>
				<li>Split the data into training and testing sets. Use 20% as the size of the testing set:<p class="source-code">X_train, X_test, \</p><p class="source-code">Y_train, Y_test = train_test_split(X,Y, test_size = 0.2,\</p><p class="source-code">                                   random_state = 0)</p></li>
				<li>Train a decision tree on the train set. Then, use the model to predict the class label on the test set (hint: to train the decision tree, revisit <em class="italic">Exercise 3.04</em>, <em class="italic">Calculating Different Evaluation Metrics on a Classification Task</em>):<p class="source-code">model = tree.DecisionTreeClassifier(random_state = 0)</p><p class="source-code">model = model.fit(X_train, Y_train)</p><p class="source-code">Y_pred = model.predict(X_test)</p></li>
				<li>Use scikit-learn to construct a confusion matrix:<p class="source-code">confusion_matrix(Y_test, Y_pred)</p><p>The output of the confusion matrix is as follows:</p><p> </p><div id="_idContainer126" class="IMG---Figure"><img src="image/B15781_03_14.jpg" alt="Figure 3.14: Output of the confusion matrix&#13;&#10;"/></div><p class="figure-caption">Figure 3.14: Output of the confusion matrix</p></li>
				<li>Calculate the accuracy of the model:<p class="source-code">accuracy = accuracy_score(Y_test, Y_pred)</p><p class="source-code">print("accuracy:", accuracy)</p><p>The accuracy is equal to <strong class="source-inline">84.72</strong>%.</p></li>
				<li>Calculate the precision and recall. Considering that both the precision and recall can only be calculated on binary data, we'll assume that we are only interested in classifying instances as number 6 or any other number:<p class="source-code">Y_test_2 = Y_test[:]</p><p class="source-code">Y_test_2[Y_test_2 != 6] = 1</p><p class="source-code">Y_test_2[Y_test_2 == 6] = 0</p><p class="source-code">Y_pred_2 = Y_pred</p><p class="source-code">Y_pred_2[Y_pred_2 != 6] = 1</p><p class="source-code">Y_pred_2[Y_pred_2 == 6] = 0</p><p class="source-code">precision = precision_score(Y_test_2, Y_pred_2)</p><p class="source-code">print("precision:", precision)</p><p class="source-code">recall = recall_score(Y_test_2, Y_pred_2)</p><p class="source-code">print("recall:", recall)</p><p>The output from the preceding code snippet is as follows:</p><p class="source-code">precision: 0.9841269841269841</p><p class="source-code">recall: 0.9810126582278481</p><p>According to this, the precision and recall scores should be equal to <strong class="source-inline">98.41</strong>% and <strong class="source-inline">98.10</strong>%, respectively.</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2UJMFPC">https://packt.live/2UJMFPC</a>.</p><p class="callout">You can also run this example online at <a href="https://packt.live/2zwqkgX">https://packt.live/2zwqkgX</a>. You must execute the entire Notebook in order to get the desired result.</p></li>
			</ol>
			<p>You have successfully measured the performance of classification tasks.</p>
			<h2 id="_idParaDest-185"><a id="_idTextAnchor191"/>Activity 3.03: Performing Error Analysis on a Model Trained to Recognize Handwritten Digits</h2>
			<p>Solution:</p>
			<ol>
				<li value="1">Import the required elements to load and split a dataset. We will do this to train the model and measure its accuracy:<p class="source-code">from sklearn.<a id="_idTextAnchor192"/>datasets import load_digits</p><p class="source-code">import pandas as pd</p><p class="source-code">from sklearn.model_selection import train_test_split</p><p class="source-code">import numpy as np</p><p class="source-code">from sklearn import tree</p><p class="source-code">from sklearn.metrics import accuracy_score</p></li>
				<li>Load the <strong class="source-inline">digits</strong> toy dataset from scikit-learn and create Pandas DataFrames containing the features and target matrices:<p class="source-code">digits = load_digits()</p><p class="source-code">X = pd.DataFrame(digits.data)</p><p class="source-code">Y = pd.DataFrame(digits.target)</p></li>
				<li>Split the data into training, validation, and testing sets. Use <strong class="source-inline">0.1</strong> as the size of the test set, and an equivalent number to build a validation set of the same shape:<p class="source-code">X_new, X_test, \</p><p class="source-code">Y_new, Y_test = train_test_split(X, Y, test_size = 0.1,\</p><p class="source-code">                                 random_state = 101)</p><p class="source-code">test_size = X_test.shape[0] / X_new.shape[0]</p><p class="source-code">X_train, X_dev, \</p><p class="source-code">Y_train, Y_dev = train_test_split(X_new, Y_new, \</p><p class="source-code">                                  test_size= test_size, \</p><p class="source-code">                                  random_state = 101)</p><p class="source-code">print(X_train.shape, Y_train.shape, X_dev.shape, \</p><p class="source-code">      Y_dev.shape, X_test.shape, Y_test.shape)</p><p>The resulting shapes are as follows:</p><p class="source-code">(1437, 64) (1437, 1) (180, 64) (180, 1) (180, 64) (180, 1)</p></li>
				<li>Create a train/dev set for both the features and the target values that contains <strong class="source-inline">90</strong> instances/labels of the train set and <strong class="source-inline">90</strong> instances/labels of the dev set:<p class="source-code">np.random.seed(101)</p><p class="source-code">indices_train = np.random.randint(0, len(X_train), 90)</p><p class="source-code">indices_dev = np.random.randint(0, len(X_dev), 90)</p><p class="source-code">X_train_dev = pd.concat([X_train.iloc[indices_train,:], \</p><p class="source-code">                         X_dev.iloc[indices_dev,:]])</p><p class="source-code">Y_train_dev = pd.concat([Y_train.iloc[indices_train,:], \</p><p class="source-code">                         Y_dev.iloc[indices_dev,:]])</p><p class="source-code">print(X_train_dev.shape, Y_train_dev.shape)</p><p>The resulting shapes are as follows:</p><p class="source-code">(180, 64) (180, 1)</p></li>
				<li>Train a decision tree on that training set data:<p class="source-code">model = tree.DecisionTreeClassifier(random_state = 101)</p><p class="source-code">model = model.fit(X_train, Y_train)</p></li>
				<li>Calculate the error rate for all sets of data and determine which condition is affecting the performance of the model:<p class="source-code">sets = ["Training", "Train/dev", "Validation", "Testing"]</p><p class="source-code">X_sets = [X_train, X_train_dev, X_dev, X_test]</p><p class="source-code">Y_sets = [Y_train, Y_train_dev, Y_dev, Y_test]</p><p class="source-code">scores = {}</p><p class="source-code">for i in range(0, len(X_sets)):</p><p class="source-code">    pred = model.predict(X_sets[i])</p><p class="source-code">    score = accuracy_score(Y_sets[i], pred)</p><p class="source-code">    scores[sets[i]] = score</p><p class="source-code">print(scores)</p><p>The output is as follows:</p><p class="source-code">{'Training': 1.0, 'Train/dev': 0.9444444444444444, 'Validation': 0.8833333333333333, 'Testing': 0.8833333333333333}</p><p>The error rates can be seen in the following table:</p><div id="_idContainer127" class="IMG---Figure"><img src="image/B15781_03_15.jpg" alt="Figure 3.15: Error rates of the Handwritten Digits model&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 3.15: Error rates of the Handwritten Digits model</p>
			<p>From the preceding results, it can be concluded that the model is equally suffering from variance and data mismatch.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3d0c4uM">https://packt.live/3d0c4uM</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3eeFlTC">https://packt.live/3eeFlTC</a>. You must execute the entire Notebook in order to get the desired result.</p>
			<p>You have now successfully performed an error analysis to determine a course of action to improve the model's performance.</p>
			<h1 id="_idParaDest-186"><a id="_idTextAnchor193"/>4. Supervised Learning Algorithms: Predicting Annual Income</h1>
			<h2 id="_idParaDest-187"><a id="_idTextAnchor194"/>Activity 4.01: Training a Naïve Bayes Model for Our Census Income Dataset</h2>
			<p>Solution:</p>
			<ol>
				<li value="1">In a Jupyter Notebook, import all the required elements to load and split the dataset, as well as to train a Naïve Bayes algorithm:<p class="source-code">import pandas as pd</p><p class="source-code">from sklearn.model_selection import train_test_split</p><p class="source-code">from sklearn.naive_bayes import GaussianNB</p></li>
				<li>Load the pre-processed Census Income dataset. Next, separate the features from the target by creating two variables, <strong class="source-inline">X</strong> and <strong class="source-inline">Y</strong>:<p class="source-code">data = pd.read_csv("census_income_dataset_preprocessed.csv")</p><p class="source-code">X = data.drop("target", axis=1)</p><p class="source-code">Y = data["target"]</p><p>Note that there are several ways to achieve the separation of <strong class="source-inline">X</strong> and <strong class="source-inline">Y</strong>. Use the one that you feel most comfortable with. However, take into account that <strong class="source-inline">X</strong> should contain the features of all instances, while <strong class="source-inline">Y</strong> should contain the class labels of all instances.</p></li>
				<li>Divide the dataset into training, validation, and testing sets, using a split ratio of 10%:<p class="source-code">X_new, X_test, \</p><p class="source-code">Y_new, Y_test = train_test_split(X, Y, test_size=0.1, \</p><p class="source-code">                                 random_state=101)</p><p class="source-code">test_size = X_test.shape[0] / X_new.shape[0]</p><p class="source-code">X_train, X_dev, \</p><p class="source-code">Y_train, Y_dev = train_test_split(X_new, Y_new, \</p><p class="source-code">                                  test_size=test_size, \</p><p class="source-code">                                  random_state=101)</p><p class="source-code">print(X_train.shape, Y_train.shape, X_dev.shape, \</p><p class="source-code">      Y_dev.shape, X_test.shape, Y_test.shape)</p><p>The final shape will look as follows:</p><p class="source-code">(26047, 9) (26047,) (3257, 9) (3257,) (3257, 9) (3257,)</p></li>
				<li>Use the <strong class="source-inline">fit</strong> method to train a Naïve Bayes model on the training sets (<strong class="source-inline">X_train</strong> and <strong class="source-inline">Y_train</strong>):<p class="source-code">model_NB = GaussianNB()</p><p class="source-code">model_NB.fit(X_train,Y_train)</p></li>
				<li>Finally, perform a prediction using the model that you trained previously for a new instance with the following values for each feature – <strong class="source-inline">39</strong>, <strong class="source-inline">6</strong>, <strong class="source-inline">13</strong>, <strong class="source-inline">4</strong>, <strong class="source-inline">0</strong>, <strong class="source-inline">2174</strong>, <strong class="source-inline">0</strong>, <strong class="source-inline">40</strong>, <strong class="source-inline">38</strong>:<p class="source-code">pred_1 = model_NB.predict([[39,6,13,4,0,2174,0,40,38]])</p><p class="source-code">print(pred_1)</p><p>The output from the prediction is as follows:</p><p class="source-code">[0]</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3ht1TCs">https://packt.live/3ht1TCs</a>.</p><p class="callout">You can also run this example online at <a href="https://packt.live/2zwqxkf">https://packt.live/2zwqxkf</a>. You must execute the entire Notebook in order to get the desired result.</p></li>
			</ol>
			<p>This means that the individual has an income less than or equal to 50K, considering that 0 is the label for individuals with a salary less than or equal to 50K.</p>
			<h2 id="_idParaDest-188"><a id="_idTextAnchor195"/>Activity 4.02: Training a Decision Tree Model for Our Census Income Dataset</h2>
			<p>Solution:</p>
			<ol>
				<li value="1">Open the Jupyter Notebook that you used for the previous activity and import the decision tree algorithm from scikit-learn:<p class="source-code">from sklearn.tree import DecisionTreeClassifier</p></li>
				<li>Train the model using the <strong class="source-inline">fit</strong> method on the <strong class="source-inline">DecisionTreeClassifier</strong> class from scikit-learn. To train the model, use the training set data from the previous activity (<strong class="source-inline">X_train</strong> and <strong class="source-inline">Y_train</strong>):<p class="source-code">model_tree = DecisionTreeClassifier(random_state=101)</p><p class="source-code">model_tree.fit(X_train,Y_train)</p></li>
				<li>Finally, perform a prediction using the model that you trained before for a new instance with the following values for each feature – <strong class="source-inline">39</strong>, <strong class="source-inline">6</strong>, <strong class="source-inline">13</strong>, <strong class="source-inline">4</strong>, <strong class="source-inline">0</strong>, <strong class="source-inline">2174</strong>, <strong class="source-inline">0</strong>, <strong class="source-inline">40</strong>, <strong class="source-inline">38</strong>:<p class="source-code">pred_2 = model_tree.predict([[39,6,13,4,0,2174,0,40,38]])</p><p class="source-code">print(pred_2)</p><p>The output from the preceding code snippet is as follows:</p><p class="source-code">[0]</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2zxQIqV">https://packt.live/2zxQIqV</a>.</p><p class="callout">You can also run this example online at <a href="https://packt.live/2AC7iWX">https://packt.live/2AC7iWX</a>. You must execute the entire Notebook in order to get the desired result.</p></li>
			</ol>
			<p>This means that the subject has an income lower than or equal to 50K.</p>
			<h2 id="_idParaDest-189"><a id="_idTextAnchor196"/>Activity 4.03: Training an SVM Model for Our Census Income Dataset</h2>
			<p>Solution:</p>
			<ol>
				<li value="1">Open the Jupyter Notebook that you used for the previous activity and import the SVM algorithm from scikit-learn:<p class="source-code">from sklearn.svm import SVC</p></li>
				<li>Train the model using the <strong class="source-inline">fit</strong> method on the <strong class="source-inline">SVC</strong> class from scikit-learn. To train the model, use the training set data from the previous activity (<strong class="source-inline">X_train</strong> and <strong class="source-inline">Y_train</strong>):<p class="source-code">model_svm = SVC()</p><p class="source-code">model_svm.fit(X_train, Y_train)</p></li>
				<li>Finally, perform a prediction using the model that you trained before for a new instance with the following values for each feature – <strong class="source-inline">39</strong>, <strong class="source-inline">6</strong>, <strong class="source-inline">13</strong>, <strong class="source-inline">4</strong>, <a id="_idTextAnchor197"/><strong class="source-inline">0</strong>, <strong class="source-inline">2174</strong>, <strong class="source-inline">0</strong>, <strong class="source-inline">40</strong>, <strong class="source-inline">38</strong>:<p class="source-code">pred_3 = model_svm.predict([[39,6,13,4,0,2174,0,40,38]])</p><p class="source-code">print(pred_3)</p><p>The output is as follows:</p><p class="source-code">[0]</p><p>The prediction for the individual is equal to zero, which means that the individual has an income below or equal to <strong class="source-inline">50K</strong>.</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2Nb6J9z">https://packt.live/2Nb6J9z</a>.</p><p class="callout">You can also run this example online at <a href="https://packt.live/3hbpCGm">https://packt.live/3hbpCGm</a>. You must execute the entire Notebook in order to get the desired result.</p></li>
			</ol>
			<h1 id="_idParaDest-190"><a id="_idTextAnchor198"/>5. Artificial Neural Networks: Predicting Annual Income</h1>
			<h2 id="_idParaDest-191"><a id="_idTextAnchor199"/>Activity 5.01: Training an MLP for Our Census Income Dataset</h2>
			<p>Solution:</p>
			<ol>
				<li value="1">Import all the elements required to load and split a dataset, to train an MLP, and to measure accuracy:<p class="source-code">import pandas as pd</p><p class="source-code">from sklearn.model_selection import train_test_split</p><p class="source-code">from sklearn.neural_network import MLPClassifier</p><p class="source-code">from sklearn.metrics import accuracy_score</p></li>
				<li>Using the preprocessed Census Income Dataset, separate the features from the target, creating the variables <strong class="source-inline">X</strong> and <strong class="source-inline">Y</strong>:<p class="source-code">data = pd.read_csv("census_income_dataset_preprocessed.csv")</p><p class="source-code">X = data.drop("target", axis=1)</p><p class="source-code">Y = data["target"]</p><p>As explained previously, there are several ways to achieve the separation of <strong class="source-inline">X</strong> and <strong class="source-inline">Y</strong>, and the main thing to consider is that <strong class="source-inline">X</strong> should contain the features for all instances, while <strong class="source-inline">Y</strong> should contain the class label of all instances.</p></li>
				<li>Divide the dataset into training, validation, and testing sets, using a split ratio of 10%:<p class="source-code">X_new, X_test, \</p><p class="source-code">Y_new, Y_test = train_test_split(X, Y, test_size=0.1, \</p><p class="source-code">                                 random_state=101)</p><p class="source-code">test_size = X_test.shape[0] / X_new.shape[0]</p><p class="source-code">X_train, X_dev, \</p><p class="source-code">Y_train, Y_dev = train_test_split(X_new, Y_new, \</p><p class="source-code">                                  test_size=test_size, \</p><p class="source-code">                                  random_state=101)</p><p class="source-code">print(X_train.shape, X_dev.shape, X_test.shape, \</p><p class="source-code">      Y_train.shape, Y_dev.shape, Y_test.shape)</p><p>The shape of the sets created should be as follows:</p><p class="source-code">(26047, 9) (3257, 9) (3257, 9) (26047,) (3257,) (3257,)</p></li>
				<li>Instantiate the <strong class="source-inline">MLPClassifier</strong> class from scikit-learn and train the model with the training data. Leave the hyperparameters to their default values. Again, use a <strong class="source-inline">random_state</strong> equal to <strong class="source-inline">101</strong>:<p class="source-code">model = MLPClassifier(random_state=101)</p><p class="source-code">model = model.fit(X_train, Y_train)</p></li>
				<li>Calculate the accuracy of the model for all three sets (training, validation, and testing):<p class="source-code">sets = ["Training", "Validation", "Testing"]</p><p class="source-code">X_sets = [X_train, X_dev, X_test]</p><p class="source-code">Y_sets = [Y_train, Y_dev, Y_test]</p><p class="source-code">accuracy = {}</p><p class="source-code">for i in range(0,len(X_sets)):</p><p class="source-code">    pred = model.predict(X_sets[i])</p><p class="source-code">    score = accuracy_score(Y_sets[i], pred)</p><p class="source-code">    accuracy[sets[i]] = score</p><p class="source-code">print(accuracy)</p><p>The accuracy score for the three sets should be as follows:</p><p class="source-code">{'Training': 0.8465909090909091, 'Validation': 0.8246314496314496, 'Testing': 0.8415719987718759}</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3hneWFr">https://packt.live/3hneWFr</a>.</p><p class="callout">This section does not currently have an online interactive example, and will need to be run locally.</p></li>
			</ol>
			<p>You have successfully trained an MLP model to solve a real-life data problem.</p>
			<h2 id="_idParaDest-192"><a id="_idTextAnchor200"/>Activity 5.02: Comparing Different Models to Choose the Best Fit for the Census Income Data Problem</h2>
			<p>Solution:</p>
			<ol>
				<li value="1">Open the Jupyter Notebooks that you used to train the models.</li>
				<li>Compare the four models, based only on their accuracy scores.<p>By taking the accuracy scores of the models from the previous chapter, and the accuracy of the model trained in this chapter, it is possible to perform a final comparison to choose the model that best solves the data problem. To do so, the following table displays the accuracy scores for all four models:</p><div id="_idContainer128" class="IMG---Figure"><img src="image/B15781_05_15.jpg" alt="Figure 5.15: Accuracy scores of all four models for the Census Income Dataset&#13;&#10;"/></div><p class="figure-caption">Figure 5.15: Accuracy scores of all four models for the Census Income Dataset</p></li>
				<li>On the basis of the accuracy scores, identify the model that best solves the data problem.<p>To identify the model that best solves the data problem, begin by comparing the accuracy rates over the training sets. From this, it is possible to conclude that the decision tree model is a better fit for the data problem. Nonetheless, the performance over the validation and testing sets is lower than the one achieved using the MLP, which is an indication of the presence of high variance in the decision tree model.</p><p>Hence, a good approach would be to address the high variance of the decision tree model by simplifying the model. This can be achieved by adding a pruning argument that "trims" the leaves of the tree to simplify it and ignore some of the details of the tree in order to generalize the model to the data. Ideally, the model should be able to reach a similar level of accuracy for all three sets, which would make it the best model for the data problem.</p><p>However, if the model is not able to overcome the high variance, and assuming that all the models have been fine-tuned to achieve the maximum performance possible, the MLP should be the model that is selected, considering that it performs best over the testing sets. This is mainly because the performance of the model over the testing set is the one that defines its overall performance over unseen data, which means that the one with higher testing-set performance will be more useful in the long term.</p></li>
			</ol>
			<h1 id="_idParaDest-193"><a id="_idTextAnchor201"/>6. Building Your Own Program</h1>
			<h2 id="_idParaDest-194"><a id="_idTextAnchor202"/>Activity 6.01: Performing the Preparation and Creation Stages for the Bank Marketing Dataset</h2>
			<p>Solution:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To ensure the reproducibility of the results available at <a href="https://packt.live/2RpIhn9">https://packt.live/2RpIhn9</a>, make sure that you use a <strong class="source-inline">random_state</strong> of <strong class="source-inline">0</strong> when splitting the datasets and a <strong class="source-inline">random_state</strong> of <strong class="source-inline">2</strong> when training the models.</p>
			<ol>
				<li value="1">Open a Jupyter Notebook and import all the required elements:<p class="source-code">import pandas as pd</p><p class="source-code">from sklearn.preprocessing import LabelEncoder</p><p class="source-code">from sklearn.model_selection import train_test_split</p><p class="source-code">from sklearn.tree import DecisionTreeClassifier</p><p class="source-code">from sklearn.neural_network import MLPClassifier</p><p class="source-code">from sklearn.metrics import precision_score</p></li>
				<li>Load the dataset into the notebook. Make sure that you load the one that was edited previously, named <strong class="source-inline">bank-full-dataset.csv</strong>, which is also available at <a href="https://packt.live/2wnJyny">https://packt.live/2wnJyny</a>:<p class="source-code">data = pd.read_csv("bank-full-dataset.csv")</p><p class="source-code">data.head(10)</p><p>The output is as follows:</p><div id="_idContainer129" class="IMG---Figure"><img src="image/B15781_06_08.jpg" alt="Figure 6.8: A screenshot showing the first 10 instances of the dataset&#13;&#10;"/></div><p class="figure-caption">Figure 6.8: A screenshot showing the first 10 instances of the dataset</p><p>The missing values are shown as <strong class="source-inline">NaN</strong>, as explained previously.</p></li>
				<li>Select the metric that's the most appropriate for measuring the performance of the model, considering that the purpose of the study is to detect clients who would subscribe to the term deposit.<p>The metric to evaluate the performance of the model is the <strong class="bold">precision</strong> metric, as it compares the correctly classified positive labels against the total number of instances predicted as positive.</p></li>
				<li>Pre-process the dataset.<p>The process of handling missing values is handled as per the concepts we learned about in <em class="italic">Chapter 1</em>, <em class="italic">Introduction to Scikit-Learn</em>, and that have been applied throughout this book. Use the following code to check for missing values:</p><p class="source-code">data.isnull().sum()</p><p>Based on the results, you will observe that only four features contain missing values: <strong class="source-inline">job</strong> (288), <strong class="source-inline">education</strong> (1,857), <strong class="source-inline">contact</strong> (13,020), and <strong class="source-inline">poutcome</strong> (36,959).</p><p>The first two features can be left unhandled, considering that the missing values represent less than 5% of the entire data. On the other hand, 28.8% of the values are missing from the <strong class="source-inline">contact</strong> feature, and taking into account that the feature refers to the mode of contact, which is considered to be irrelevant for determining whether a person will subscribe to a new product, it is safe to remove this feature from the study. Finally, the <strong class="source-inline">poutcome</strong> feature is missing 81.7% of its values, which is why this feature is also removed from the study.</p><p>Using the following code, the preceding two features are dropped:</p><p class="source-code">data = data.drop(["contact", "poutcome"], axis=1)</p><p>As we explained in <em class="italic">Chapter 1</em>, <em class="italic">Introduction to Scikit-Learn</em>, and applied throughout this book, the process of converting categorical features into their numeric form is as follows.</p><p>For all nominal features, use the following code:</p><p class="source-code">enc = LabelEncoder()</p><p class="source-code">features_to_convert=["job","marital","default",\</p><p class="source-code">                     "housing","loan","month","y"]</p><p class="source-code">for i in features_to_convert:</p><p class="source-code">    data[i] = enc.fit_transform(data[i].astype('str'))</p><p>The preceding code, as explained in previous chapters, converts all the qualitative features into their numeric forms.</p><p>Next, to handle the ordinal feature, we must use the following code, as mentioned in <em class="italic">Step 4</em>:</p><p class="source-code">data['education'] = data['education'].fillna('unknown')</p><p class="source-code">encoder = ['unknown','primary','secondary','tertiary']</p><p class="source-code">for i, word in enumerate(encoder):</p><p class="source-code">    data['education'] = data['education'].astype('str').\</p><p class="source-code">                        str.replace(word, str(i))</p><p class="source-code">data['education'] = data['education'].astype('int64')</p><p class="source-code">data.head()</p><p>Here, the first line converts <strong class="source-inline">NaN</strong> values into the word <strong class="source-inline">unknown</strong>, while the second line sets the order of the values in the feature. Next, a <strong class="source-inline">for</strong> loop is used to replace each word with a number that follows an order. For the preceding example, <strong class="source-inline">0</strong> will be used to replace the word <strong class="source-inline">unknown</strong>, then <strong class="source-inline">1</strong> will be used instead of <strong class="source-inline">primary</strong>, and so on. Finally, the whole column is converted into an integer type since the <strong class="source-inline">replace</strong> function writes down the numbers as strings.</p><p>If we display the head of the resulting DataFrame, the output is as follows:</p><div id="_idContainer130" class="IMG---Figure"><img src="image/B15781_06_09.jpg" alt="Figure 6.9: A screenshot showing the first five instances of the dataset after converting the categorical features into numerical ones&#13;&#10;"/></div><p class="figure-caption">Figure 6.9: A screenshot showing the first five instances of the dataset after converting the categorical features into numerical ones</p><p>We learned how to deal with the outliers in <em class="italic">Chapter 1</em>, <em class="italic">Introduction to Scikit-Learn</em>. Use the following code to check for outliers:</p><p class="source-code">outliers = {}</p><p class="source-code">for i in range(data.shape[1]):</p><p class="source-code">    min_t = data[data.columns[i]].mean() \</p><p class="source-code">            - (3 * data[data.columns[i]].std())</p><p class="source-code">    max_t = data[data.columns[i]].mean() \</p><p class="source-code">            + (3 * data[data.columns[i]].std())</p><p class="source-code">    count = 0</p><p class="source-code">    for j in data[data.columns[i]]:</p><p class="source-code">        if j &lt; min_t or j &gt; max_t:</p><p class="source-code">            count += 1</p><p class="source-code">    outliers[data.columns[i]] = [count, data.shape[0]]</p><p class="source-code">print(outliers)</p><p>If we print the resulting dictionary, we get the following output: </p><p class="source-code">{'age': [381, 45211], 'job': [0, 45211], 'marital': [0, 45211], 'education': [0, 45211], 'default': [815, 45211], 'balance': [745, 45211], 'housing': [0, 45211], 'loan': [0, 45211], 'day': [0, 45211], 'month': [0, 45211], 'duration': [963, 45211], 'campaign': [840, 45211], 'pdays': [1723, 45211], 'previous': [582, 45211], 'y': [0, 45211]}</p><p>As we can see, the outliers do not account for more than 5% of the total values in each feature, which is why they can be left unhandled.</p><p>This can be verified by taking the feature with the most outliers (<strong class="source-inline">pdays</strong>) and dividing the number of outliers by the total number of instances (1,723 divided by 45,211). The result from that operation is 0.038, which is equivalent to 3.8%. This means that the feature only has 3.8% of the outlier values.</p></li>
				<li>Separate the features from the class label and split the dataset into three sets (training, validation, and testing).<p>To separate the features from the target value, use the following code:</p><p class="source-code">X = data.drop("y", axis = 1)</p><p class="source-code">Y = data["y"]</p><p>Next, to perform a 60/20/20 split, use the following code:</p><p class="source-code">X_new, X_test, \</p><p class="source-code">Y_new, Y_test = train_test_split(X, Y, test_size=0.2,\</p><p class="source-code">                                 random_state = 0)</p><p class="source-code">test_size = X_test.shape[0] / X_new.shape[0]</p><p class="source-code">X_train, X_dev, \</p><p class="source-code">Y_train, Y_dev = train_test_split(X_new, Y_new, \</p><p class="source-code">                                  test_size=test_size,\</p><p class="source-code">                                  random_state = 0)</p><p class="source-code">print(X_train.shape, Y_train.shape, X_dev.shape, \</p><p class="source-code">    Y_dev.shape, X_test.shape, Y_test.shape)</p><p>If we print the shape of all the subsets, the output is as follows:</p><p class="source-code">(27125, 14) (27125,) (9043, 14) (9043,) (9043, 14) (9043,)</p></li>
				<li>Use the decision tree algorithm on the dataset and train the model: <p class="source-code">model_tree = DecisionTreeClassifier(random_state = 2)</p><p class="source-code">model_tree.fit(X_train, Y_train)</p><p class="callout-heading">Note</p><p class="callout">As a reminder, the output from calling the <strong class="source-inline">fit</strong> method consists of the model currently being trained with all the parameters that it takes in.</p></li>
				<li>Use the multilayer perceptron algorithm on the dataset and train the model. To revisit this, go to <em class="italic">Chapter 5</em>, <em class="italic">Artificial Neural Networks: Predicting Annual Income</em>:<p class="source-code">model_NN = MLPClassifier(random_state = 2)</p><p class="source-code">model_NN.fit(X_train, Y_train)</p></li>
				<li>Evaluate both models by using the metric that was selected previously. <p>Using the following code, it is possible to measure the precision score of the decision tree model:</p><p class="source-code">X_sets = [X_train, X_dev, X_test]</p><p class="source-code">Y_sets = [Y_train, Y_dev, Y_test]</p><p class="source-code">precision = []</p><p class="source-code">for i in range(0, len(X_sets)):</p><p class="source-code">    pred = model_tree.predict(X_sets[i])</p><p class="source-code">    score = precision_score(Y_sets[i], pred)</p><p class="source-code">    precision.append(score)</p><p class="source-code">print(precision)</p><p>If we print the list containing the precision score for each of the sets for the decision tree model, the output is as follows:</p><p class="source-code">[1.0, 0.43909348441926344, 0.4208059981255858]</p><p>The same code can be modified to calculate the score for the multilayer perceptron:</p><p class="source-code">X_sets = [X_train, X_dev, X_test]</p><p class="source-code">Y_sets = [Y_train, Y_dev, Y_test]</p><p class="source-code">precision = []</p><p class="source-code">for i in range(0, len(X_sets)):</p><p class="source-code">    pred = model_NN.predict(X_sets[i])</p><p class="source-code">    score = precision_score(Y_sets[i], pred)</p><p class="source-code">    precision.append(score)</p><p class="source-code">print(precision)</p><p>If we print the list containing the precision score for each of the sets for the multilayer perceptron model, the output is as follows:</p><p class="source-code">[0.35577647236029525, 0.35199283475145543, 0.3470483005366726]</p><p>The precision score for all subsets of data for both models is shown in the following table:</p><div id="_idContainer131" class="IMG---Figure"><img src="image/B15781_06_10.jpg" alt="Figure 6.10: Precision scores for both models&#13;&#10;"/></div><p class="figure-caption">Figure 6.10: Precision scores for both models</p></li>
				<li>Fine-tune some of the hyperparameters to fix the issues that were detected during the evaluation of the model by performing error analysis.<p>Although the precision of the decision tree on the training sets is perfect, on comparing it against the results of the other two sets, it is possible to conclude that the model suffers from high variance. </p><p>On the other hand, the multilayer perceptron has a similar performance on all three sets, but the overall performance is low, which means that the model is more likely to be suffering from high bias.</p><p>Considering this, for the decision tree model, both the minimum number of samples required to be at a leaf node and the maximum depth of the tree are changed in order to simplify the model. On the other hand, for the multilayer perceptron, the number of iterations, the number of hidden layers, the number of units in each layer, and the tolerance for optimization are changed. </p><p>The following code shows the final values that were used for the hyperparameters of the decision tree algorithm, considering that to arrive at them it is required to try different values:</p><p class="source-code">model_tree = DecisionTreeClassifier(random_state = 2, \</p><p class="source-code">                                    min_samples_leaf=100, \</p><p class="source-code">                                    max_depth=100)</p><p class="source-code">model_tree.fit(X_train, Y_train)</p><p>The following snippet displays the final values used for the hyperparameters of the multilayer perceptron algorithm:</p><p class="source-code">model_NN = \</p><p class="source-code">    MLPClassifier(random_state = 2, max_iter=1000,\</p><p class="source-code">                  hidden_layer_sizes = [100,100,50,25,25], \</p><p class="source-code">                  tol=1e-4)</p><p class="source-code">model_NN.fit(X_train, Y_train)</p><p class="callout-heading">Note</p><p class="callout">As a reminder, the output from calling the <strong class="source-inline">fit</strong> method consists of the model currently being trained with all the parameters that it takes in.</p></li>
				<li>Compare the final versions of your models and select the one that you consider best fits the data.<p>Using the same code as in previous steps, it is possible to calculate the precision of the decision tree model over the different sets of data:</p><p class="source-code">X_sets = [X_train, X_dev, X_test]</p><p class="source-code">Y_sets = [Y_train, Y_dev, Y_test]</p><p class="source-code">precision = []</p><p class="source-code">for i in range(0, len(X_sets)):</p><p class="source-code">    pred = model_tree.predict(X_sets[i])</p><p class="source-code">    score = precision_score(Y_sets[i], pred)</p><p class="source-code">    precision.append(score)</p><p class="source-code">print(precision)</p><p>The output list should look as follows:</p><p class="source-code">[0.6073670992046881, 0.5691158156911582, 0.5448113207547169]</p><p>To calculate the precision of the multilayer perceptron, the following code snippet can be used:</p><p class="source-code">X_sets = [X_train, X_dev, X_test]</p><p class="source-code">Y_sets = [Y_train, Y_dev, Y_test]</p><p class="source-code">precision = []</p><p class="source-code">for i in range(0, len(X_sets)):</p><p class="source-code">    pred = model_NN.predict(X_sets[i])</p><p class="source-code">    score = precision_score(Y_sets[i], pred)</p><p class="source-code">    precision.append(score)</p><p class="source-code">print(precision)</p><p>The resulting list should look as follows:</p><p class="source-code">[0.759941089837997, 0.5920398009950248, 0.5509259259259259]</p><p>By calculating the precision score for all three sets for the newly trained models, we obtain the following values:</p></li>
			</ol>
			<div>
				<div id="_idContainer132" class="IMG---Figure">
					<img src="image/B15781_06_11.jpg" alt="Figure 6.11: Precision scores for the newly trained models&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.11: Precision scores for the newly trained models</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2RpIhn9">https://packt.live/2RpIhn9</a>.</p>
			<p class="callout">This section does not currently have an online interactive example, and will need to be run locally.</p>
			<p>An improvement in performance for both models is achieved, and by comparing the values, it is possible to conclude that the multilayer perceptron outperforms the decision tree model. Based on this, the multilayer perceptron is selected as the better model for solving the data problem.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">You are encouraged to continue to fine-tune the parameters to reach an even higher precision score.</p>
			<h2 id="_idParaDest-195"><a id="_idTextAnchor203"/>Activity 6.02: Saving and Loading the Final Model for the Bank Marketing Dataset</h2>
			<p>Solution:</p>
			<ol>
				<li value="1">Open the Jupyter Notebook from <em class="italic">Activity 6.01</em>, <em class="italic">Performing the Preparation and Creation Stages for the Bank Marketing Dataset</em>.</li>
				<li>For learning purposes, take the model that you selected as the best model, remove the <strong class="source-inline">random_state</strong> argument, and run it a couple of times. </li>
				<li>Save the model that you choose as the best performing one into a file named <strong class="source-inline">final_model.pkl</strong>.<p class="callout-heading">Note</p><p class="callout">The model selected in this book is the multilayer perceptron, which uses a <strong class="source-inline">random_state</strong> of <strong class="source-inline">2</strong>, was trained for 1,000 iterations with five hidden layers of size 100, 100, 50, 25 and 25, and a tolerance level of 1e-4.</p><p>The code for this is as follows:</p><p class="source-code">path = os.getcwd() + "/final_model.pkl"</p><p class="source-code">file = open(path, "wb")</p><p class="source-code">pickle.dump(model_NN, file)</p></li>
				<li>Open a new Jupyter Notebook and import the required modules and class:<p class="source-code">from sklearn.neural_network import MLPClassifier</p><p class="source-code">import pickle</p><p class="source-code">import os</p></li>
				<li>Load the saved model:<p class="source-code">path = os.getcwd() + "/final_model.pkl"</p><p class="source-code">file = open(path, "rb")</p><p class="source-code">model = pickle.load(file)</p></li>
				<li>Perform a prediction for an individual by using the following values: <strong class="source-inline">42</strong>, <strong class="source-inline">2</strong>, <strong class="source-inline">0</strong>, <strong class="source-inline">0</strong>, <strong class="source-inline">1</strong>, <strong class="source-inline">2</strong>, <strong class="source-inline">1</strong>, <strong class="source-inline">0</strong>, <strong class="source-inline">5</strong>, <strong class="source-inline">8</strong>, <strong class="source-inline">380</strong>, <strong class="source-inline">1</strong>, <strong class="source-inline">-1</strong>, <strong class="source-inline">0</strong>:<p class="source-code">pred = model.predict([[42,2,0,0,1,2,1,0,5,8,380,1,-1,0]])</p><p class="source-code">print(pred)</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2UIWFss">https://packt.live/2UIWFss</a>.</p><p class="callout">This section does not currently have an online interactive example, and will need to be run locally.</p></li>
			</ol>
			<p>If we printing the <strong class="source-inline">pred</strong> variable, the output is <strong class="source-inline">0</strong>, which is the numeric form of <strong class="source-inline">No</strong>. This means that the individual is more likely to not subscribe to the new product.</p>
			<h2 id="_idParaDest-196"><a id="_idTextAnchor204"/>Activity 6.03: Allowing Interaction with the Bank Marketing Dataset Model</h2>
			<p>Solution:</p>
			<ol>
				<li value="1">In a text editor, create a class object that contains two main functions. One should be an initializer that loads the saved model, while the other should be a <strong class="source-inline">predict</strong> method where the data is fed to the model to retrieve an output:<p class="source-code">import pickle</p><p class="source-code">import os</p><p>As per the preceding snippet, the first step is to import all the required elements to locate the saved model and deserialize it:</p><p class="source-code">Class NN_Model(object):</p><p class="source-code">    def __init__(self):</p><p class="source-code">        path = os.getcwd() + "/model_exercise.pkl"</p><p class="source-code">        file = open(path, "rb")</p><p class="source-code">        self.model = pickle.load(file)</p><p class="source-code">    def predict(self, age, job, marital, education, \</p><p class="source-code">                default, balance, housing, loan, day, \</p><p class="source-code">                month, duration, campaign, pdays, previous):</p><p class="source-code">        X = [[age, job, marital, education, default, \</p><p class="source-code">              balance, housing, loan, day, month, \</p><p class="source-code">              duration, campaign, pdays, previous]]</p><p class="source-code">        return self.model.predict(X)</p><p>Next, as per the preceding code snippet, the class that will connect the saved model with the channel of interaction is programmed. It should have an initializer method to deserialize and load the saved model, and a <strong class="source-inline">predict</strong> method to feed the input data to the model to perform a prediction.</p></li>
				<li>In a Jupyter Notebook, import and initialize the class that you created in the previous step. Next, create the variables that will hold the values for the features of a new observation and use the following values: <strong class="source-inline">42</strong>, <strong class="source-inline">2</strong>, <strong class="source-inline">0</strong>, <strong class="source-inline">0</strong>, <strong class="source-inline">1</strong>, <strong class="source-inline">2</strong>, <strong class="source-inline">1</strong>, <strong class="source-inline">0</strong>, <strong class="source-inline">5</strong>, <strong class="source-inline">8</strong>, <strong class="source-inline">380</strong>, <strong class="source-inline">1</strong>, <strong class="source-inline">-1</strong>, <strong class="source-inline">0</strong>:<p class="source-code">from trainedModel import NN_Model</p><p class="source-code">model = NN_Model()</p><p class="source-code">age = 42</p><p class="source-code">job = 2</p><p class="source-code">marital = 0</p><p class="source-code">education = 0</p><p class="source-code">default = 1</p><p class="source-code">balance = 2</p><p class="source-code">housing = 1</p><p class="source-code">loan = 0</p><p class="source-code">day = 5</p><p class="source-code">month = 8</p><p class="source-code">duration = 380</p><p class="source-code">campaign = 1</p><p class="source-code">pdays = -1</p><p class="source-code">previous = 0</p><p>Perform a prediction by applying the <strong class="source-inline">predict</strong> method:</p><p class="source-code">pred = model.predict(age=age, job=job, marital=marital, \</p><p class="source-code">                     education=education, default=default, \</p><p class="source-code">                     balance=balance, housing=housing, \</p><p class="source-code">                     loan=loan, day=day, month=month, \</p><p class="source-code">                     duration=duration, campaign=campaign, \</p><p class="source-code">                     pdays=pdays, previous=previous)</p><p class="source-code">print(pred)</p><p>By printing the variable, the prediction is equal to <strong class="source-inline">0</strong>; that is, the individual with the given features is not likely to subscribe to the product, as can be seen here:</p><p class="source-code">[0]</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2Y2yBCJ">https://packt.live/2Y2yBCJ</a>.</p><p class="callout">You can also run this example online at <a href="https://packt.live/3d6ku3E">https://packt.live/3d6ku3E</a>. You must execute the entire Notebook in order to get the desired result.</p></li>
			</ol>
			<p>Throughout the activities in this chapter, you have successfully learned how to develop a complete machine learning solution, going from data pre-processing and training the model to selecting the best performing model using error analysis and saving the model to be able to make use of it effectively.</p>
		</div>
	</body></html>