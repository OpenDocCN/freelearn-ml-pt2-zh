["```py\n>>> import matplotlib.pyplot as plt\n>>> from sklearn.datasets import fetch_mldata\n>>> import matplotlib.cm as cm\n\n>>> digits = fetch_mldata('MNIST original', data_home='data/mnist').data\n>>> counter = 1\n>>> for i in range(1, 4):\n>>>     for j in range(1, 6):\n>>>         plt.subplot(3, 5, counter)\n>>>         plt.imshow(digits[(i - 1) * 8000 + j].reshape((28, 28)), cmap=cm.Greys_r)\n>>>         plt.axis('off')\n>>>         counter += 1\n>>> plt.show()\n```", "```py\nfrom sklearn.datasets import fetch_mldata\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import scale\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.metrics import classification_report\n```", "```py\nif __name__ == '__main__':\n    data = fetch_mldata('MNIST original', data_home='data/mnist')\n    X, y = data.data, data.target\n    X = X/255.0*2 â€“ 1\n```", "```py\n    X_train, X_test, y_train, y_test = train_test_split(X, y)\n```", "```py\n    pipeline = Pipeline([\n        ('clf', SVC(kernel='rbf', gamma=0.01, C=100))\n    ])\n    print X_train.shape\n    parameters = {\n        'clf__gamma': (0.01, 0.03, 0.1, 0.3, 1),\n        'clf__C': (0.1, 0.3, 1, 3, 10, 30),\n    }\n    grid_search = GridSearchCV(pipeline, parameters, n_jobs=2, verbose=1, scoring='accuracy')\n    grid_search.fit(X_train[:10000], y_train[:10000])\n    print 'Best score: %0.3f' % grid_search.best_score_\n    print 'Best parameters set:'\n    best_parameters = grid_search.best_estimator_.get_params()\n    for param_name in sorted(parameters.keys()):\n        print '\\t%s: %r' % (param_name, best_parameters[param_name])\n    predictions = grid_search.predict(X_test)\n    print classification_report(y_test, predictions)\n```", "```py\nFitting 3 folds for each of 30 candidates, totalling 90 fits\n[Parallel(n_jobs=2)]: Done   1 jobs       | elapsed:  7.7min\n[Parallel(n_jobs=2)]: Done  50 jobs       | elapsed: 201.2min\n[Parallel(n_jobs=2)]: Done  88 out of  90 | elapsed: 304.8min remaining:  6.9min\n[Parallel(n_jobs=2)]: Done  90 out of  90 | elapsed: 309.2min finished\nBest score: 0.966\nBest parameters set:\n\tclf__C: 3\n\tclf__gamma: 0.01\n             precision    recall  f1-score   support\n\n        0.0       0.98      0.99      0.99      1758\n        1.0       0.98      0.99      0.98      1968\n        2.0       0.95      0.97      0.96      1727\n        3.0       0.97      0.95      0.96      1803\n        4.0       0.97      0.98      0.97      1714\n        5.0       0.96      0.96      0.96      1535\n        6.0       0.98      0.98      0.98      1758\n        7.0       0.97      0.96      0.97      1840\n        8.0       0.95      0.96      0.96      1668\n        9.0       0.96      0.95      0.96      1729\n\navg / total       0.97      0.97      0.97     17500\n```", "```py\nimport os\nimport numpy as np\nfrom sklearn.svm import SVC\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import classification_report\nimport Image\n```", "```py\ndef resize_and_crop(image, size):\n    img_ratio = image.size[0] / float(image.size[1])\n    ratio = size[0] / float(size[1])\n    if ratio > img_ratio:\n        image = image.resize((size[0], size[0] * image.size[1] / image.size[0]), Image.ANTIALIAS)\n        image = image.crop((0, 0, 30, 30))\n    elif ratio < img_ratio:\n        image = image.resize((size[1] * image.size[0] / image.size[1], size[1]), Image.ANTIALIAS)\n        image = image.crop((0, 0, 30, 30))\n    else:\n        image = image.resize((size[0], size[1]), Image.ANTIALIAS)\n    return image\n```", "```py\nX = []\ny = []\n\nfor path, subdirs, files in os.walk('data/English/Img/GoodImg/Bmp/'):\n    for filename in files:\n        f = os.path.join(path, filename)\n        img = Image.open(f).convert('L') # convert to grayscale\n        img_resized = resize_and_crop(img, (30, 30))\n        img_resized = np.asarray(img_resized.getdata(), dtype=np.float64) \\\n            .reshape((img_resized.size[1] * img_resized.size[0], 1))\n        target = filename[3:filename.index('-')]\n        X.append(img_resized)\n        y.append(target)\n\nX = np.array(X)\nX = X.reshape(X.shape[:2])\n\nWe will then train a support vector classifier with a polynomial kernel.classifier = SVC(verbose=0, kernel='poly', degree=3)\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\nclassifier.fit(X_train, y_train)\npredictions = classifier.predict(X_test)\nprint classification_report(y_test, predictions)\n```", "```py\n             precision    recall  f1-score   support\n\n        001       0.24      0.22      0.23        23\n        002       0.24      0.45      0.32        20\n       ...\n        061       0.33      0.15      0.21        13\n        062       0.08      0.25      0.12         8\n\navg / total       0.41      0.34      0.36      1927\n```"]