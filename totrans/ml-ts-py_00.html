<html><head></head><body>
  <div id="_idContainer034">
    <h1 class="chapterNumber">1</h1>
    <h1 id="_idParaDest-13" class="chapterTitle">Introduction to Time-Series with Python</h1>
    <p class="normal">This book is about machine learning for time-series with Python, and you can see this chapter as a 101 class for time-series. In this chapter, we'll introduce time-series, the history of research into time-series, and how to use Python for time-series. </p>
    <p class="normal">We'll start with what a time-series is and its main properties. We'll then look at the history of the study of time-series in different scientific disciplines foundational to the field, such as demography, astronomy, medicine, and economics.</p>
    <p class="normal">Then, we'll go over the capabilities of Python for time-series and why Python is the go-to language for doing machine learning with time-series. Finally, I will describe how to install the most prominent libraries in Python for time-series analysis and machine learning, and we'll cover the basics of Python as relevant to time-series and machine learning.</p>
    <p class="normal">We're going to cover the following topics:</p>
    <ul>
      <li class="bullet">What Is a Time-Series?<ul>
          <li class="bullet-l2">Characteristics of Time-Series</li>
        </ul>
      </li>
      <li class="bullet">Time-Series and Forecasting – Past and Present<ul>
          <li class="bullet-l2">Demography</li>
          <li class="bullet-l2">Genetics</li>
          <li class="bullet-l2">Astronomy</li>
          <li class="bullet-l2">Economics</li>
          <li class="bullet-l2">Meteorology</li>
          <li class="bullet-l2">Medicine</li>
          <li class="bullet-l2">Applied Statistics</li>
        </ul>
      </li>
      <li class="bullet">Python for Time-Series</li>
    </ul>
    <p class="normal">But what is a time-series? Let's start with a definition!</p>
    <h1 id="_idParaDest-14" class="title">What Is a Time-Series?</h1>
    <p class="normal">Since this is a book about time-series data, we should start with a clarification of what we are talking about. In this section, we'll introduce time-series and their characteristics, and we'll go through different kinds of problems and types of analyses relevant to machine learning and statistics.</p>
    <p class="normal">Many disciplines, such as finance, public administration, energy, retail, and healthcare, are dominated by time-series data. Large areas of micro- and macro-economics rely on applied statistics <a id="_idIndexMarker000"/>with an emphasis on time-series analyses and modeling. The following are examples of time-series data:</p>
    <ul>
      <li class="bullet">Daily closing values of a stock index</li>
      <li class="bullet">Number of weekly infections of a disease</li>
      <li class="bullet">Weekly <a id="_idIndexMarker001"/>series of train accidents</li>
      <li class="bullet">Rainfall per day</li>
      <li class="bullet">Sensor data such as temperature measurements per hour</li>
      <li class="bullet">Population growth per year</li>
      <li class="bullet">Quarterly earnings of a company over a number of years</li>
    </ul>
    <p class="normal">This is only to name but a few. Any data that deals with changes over time is a time-series.</p>
    <p class="normal">It might be worth defining briefly what is considered a time-series. </p>
    <div class="packt_tip">
      <p class="Tip--PACKT-">Definition: Time-Series are datasets where observations are arranged in chronological order.</p>
    </div>
    <p class="normal">This is a very broad definition. Alternatively, we could have said that a time-series is a sequence of data points taken sequentially over time, or that a time-series is the result of a stochastic process.</p>
    <p class="normal">Formally, we can define a time-series in two ways. The first one is as a mapping from the time domain <a id="_idIndexMarker002"/>to the domain of real numbers:</p>
    <figure class="mediaobject"><img src="../Images/B17577_01_001.png" alt="" style="height: 1.5em;"/></figure>
    <p class="normal">where <img src="../Images/B17577_01_002.png" alt="" style="height: 0.9em;"/> and <img src="../Images/B17577_01_003.png" alt="" style="height: 0.9em;"/>.</p>
    <p class="normal">Another way to define a time-series is as a stochastic process:</p>
    <figure class="mediaobject"><img src="../Images/B17577_01_004.png" alt="" style="height: 2em;"/></figure>
    <p class="normal">Here, <img src="../Images/B17577_01_005.png" alt="" style="height: 1em;"/> or <img src="../Images/B17577_01_006.png" alt="" style="height: 1em;"/> denotes the value of the random variable X at time point t.</p>
    <p class="normal">If T is a set of real numbers, it's a continuous-time stochastic process. If T is a set of integers, we call it a stochastic process in discrete time. The convention in the latter case is to write <img src="../Images/B17577_01_007.png" alt="" style="height: 1em;"/>.</p>
    <p class="normal">Since time is the primary index of the dataset, by implication, time-series datasets describe how the world changes over time. They often deal with the question of how the past influences the presence or future.</p>
    <p class="normal">The increase of monitoring and data collection brings with it the need for both statistical and machine learning techniques applied to time-series to predict and characterize the behavior of complex systems or components within a system. An important part of working with time-series is the question of how the future can be predicted based on the past. This is called forecasting.</p>
    <p class="normal">Some methods allow adding business cycles as additional features. These additional features are called <strong class="keyword">exogenous</strong> features - they are time-dependent, explanatory variables. We'll go through examples of feature generation in <em class="chapterRef">chapter 3</em>, <em class="italic">Preprocessing Time-Series</em>.</p>
    <h2 id="_idParaDest-15" class="title">Characteristics of Time-Series</h2>
    <p class="normal">Here's an extract of a time-series dataset as an example, exported from Google Trends, on searches for Python, R, and Julia:</p>
    <figure class="mediaobject"><img src="../Images/B17577_01_01.png" alt="/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/(A Document Being Saved By screencaptureui 2)/Screenshot 2021-03-11 at 17.13.02.png"/></figure>
    <p class="packt_figref">Figure 1.1: Extract of a time-series dataset</p>
    <p class="normal">This is a <strong class="keyword">multivariate</strong> time-series, with columns for Python, R, and Julia. The first column is the index, a date <a id="_idIndexMarker003"/>column, and its period is the month. In cases, where we have only a single variable, we speak of a <strong class="keyword">univariate</strong> series. This dataset would <a id="_idIndexMarker004"/>be univariate if we had only one programming language instead of three.</p>
    <p class="normal">Time-Series mostly come as discrete-time, where the time difference between each point is the same. The most important characteristics of time-series are the following:</p>
    <ul>
      <li class="bullet">Long-term <a id="_idIndexMarker005"/>movements of the values (<strong class="keyword">trend</strong>)</li>
      <li class="bullet">Seasonal variations (<strong class="keyword">seasonality</strong>)</li>
      <li class="bullet">Irregular or cyclic components</li>
    </ul>
    <p class="normal">A trend is the general direction in which something is developing or changing, such as a long-term increase or decrease in a sequence. An example of where a trend can be observed would be global warming, the process by which the temperatures on our planet have been rising over the last half-century. </p>
    <p class="normal">Here's a plot of <a id="_idIndexMarker006"/>global surface temperature changes over the last 100 years from the GISS Surface Temperature Analysis dataset released by NASA:</p>
    <figure class="mediaobject"><img src="../Images/B17577_01_02.png" alt="temperatures.png"/></figure>
    <p class="packt_figref">Figure 1.2: GISS surface temperature analysis from 1880 to 2019</p>
    <p class="normal">As you can see in <em class="italic">Figure 1.2</em>, temperature changes have been varying around 0 until the mid-20<sup class="Superscript--PACKT-">th</sup> century; however, since then, there's been a clearly visible trend of an overall rise in the yearly temperature.</p>
    <p class="normal">Seasonality is a variation that occurs at specific regular intervals of less than a year. Seasonality can occur on different time spans, such as daily, weekly, monthly, or yearly. An example of weekly seasonality would be sales of ice cream picking up each weekend. Also, depending on where you live, ice cream might only be sold in spring and summer. This is a yearly variation.</p>
    <p class="normal">Other than seasonal changes and trends, there is variability that's not of a fixed frequency or that rises and falls in a way that's not based on seasonal frequency. Some of these we might be able to explain based on the knowledge we have. </p>
    <p class="normal">As an example of cyclic variability that's irregular, bank holidays can fall on different calendar days each year, and promotional campaigns could depend on business decisions, such as <a id="_idIndexMarker007"/>the introduction of a new product. As an example of cyclic changes that are not seasonal, changes at the scale of milliseconds or that take place over time periods longer than a year would not be called seasonal effects. </p>
    <p class="normal"><strong class="keyword">Stationarity</strong> is the property of a time-series not to change its distribution over time as described by its summary statistics. If a time-series is stationary, it means that it has no trend and no <a id="_idIndexMarker008"/>deterministic seasonal variability, although other cyclical variability is permitted. This is an important feature for the algorithms that we'll discuss in <em class="chapterRef">Chapter 5</em>, <em class="italic">Forecasting with Moving Averages and Autoregressive Models</em>. To apply them, we'll need to transform non-stationary data into stationary data by removing seasonality and trend.</p>
    <p class="normal">We'll discuss these and other concepts in more detail in <em class="chapterRef">Chapter 2</em>, <em class="italic">Time-Series Analysis with Python</em>, and <em class="italic">Chapter 3, Preprocessing Time-Series</em>.</p>
    <p class="normal">The task of identifying, quantifying, and decomposing these and other characteristics is called <strong class="keyword">time-series</strong><strong class="keyword"> analysis</strong>. Exploratory time-series analysis is often the first step before any feature <a id="_idIndexMarker009"/>transformation and machine learning.</p>
    <h1 id="_idParaDest-16" class="title">Time-Series and Forecasting – Past and Present</h1>
    <p class="normal">Time-Series have been studied since antiquity, and since then, time-series analysis and forecasting have come a long way. A variety of disciplines contributed to the development of <a id="_idIndexMarker010"/>techniques applied to time-series, including mathematics, astronomy, demographics, and statistics. Many innovations came initially from mathematics, later <a id="_idIndexMarker011"/>statistics, and finally machine learning. Many innovations in applied statistics had their origins in demography (used in public administration), economics, or other fields.</p>
    <p class="normal">In this section, I'll sketch the development path from simpler methods leading up to the machine learning methods available today. I'll try to chart the development of concepts relevant to time-series from the time of the Industrial Revolution to modernity. We'll deal with the more technical and up-to-date side of things in <em class="chapterRef">Chapter 4</em>, <em class="italic">Introduction to Machine Learning with Time-Series</em>.</p>
    <p class="normal">There's still much more to come for time-series. The development of wearable sensors and the Internet of Things means that big data is available to be analyzed and used for forecasting. The availability of large datasets for benchmarks and competitions has been helping create new methods in recent years as we'll discuss in later chapters.</p>
    <h2 id="_idParaDest-17" class="title">Demography</h2>
    <p class="normal">Much of the early work that went into establishing the theory and practice of time-series analysis came from demography as used in public administration. Many of the people mentioned <a id="_idIndexMarker012"/>in this section either worked as public servants or contributed in a private capacity out of interest in abstract problems.</p>
    <p class="normal">John Graunt, originally a haberdasher by profession, became interested in death records as recorded by London parishes. In 1662, he published public health statistics in his book "<em class="italic">Natural and Political Observations Made upon the Bills of Mortality.</em>" Among statistics about epidemiology, it included the first life table. A <strong class="keyword">life table</strong> (also called a mortality table or actuarial table) is a table that shows, for each age, what the probability is that a person of that age will die <a id="_idIndexMarker013"/>before their next birthday. Graunt made his inferences from bills of mortality, generated by parish clerks who recorded burials in Church of England churchyards in the City of London and areas outside the city.</p>
    <p class="normal">Graunt's book was highly influential, and he is widely regarded as the founder of demography. Graunt was elected as a fellow of the Royal Society; however, he suffered bankruptcy after his house burned down during the Great Fire of London in 1666, and he died of jaundice and liver disease at the age of 53.</p>
    <p class="normal">Among other things, he inspired the work of Swiss mathematician Jakob Bernoulli, "<em class="italic">Ars Conjectandi</em>," written between 1684 and 1689 and published posthumously in 1713, a landmark publication in combinatorics and probability theory that included – among many other things – a first version of the law of large numbers.</p>
    <div class="packt_tip">
      <p class="Tip--PACKT-">The law of large numbers describes what happens when an experiment is repeated a large number of times. Bernoulli proved that in a game of chance with two outcomes (such as a coin toss), a win or a loss, if it's repeated many times, the fraction of times that the game would be won approaches the true, expected probability.</p>
    </div>
    <p class="normal">Another major <a id="_idIndexMarker014"/>milestone in the history of demography, the statistical study of human populations, came in 1689 as an article written by Caspar Neumann, a German professor and clergyman – "<em class="italic">Reflexionen über Leben und Tod bei denen in Breslau Geborenen und Gestorbenen</em>" (translated: Reflections about the Life and Death of People Who Were Born and Died in Breslau). Neumann sent this treatise to Gottfried Leibniz, the eminent philosopher and mathematician, and later made his data available to the Royal Society in London. </p>
    <p class="normal">Many subsequent works were based on the data and statistics in this article. In 1693, in an article on life annuities ("<em class="italic">An Estimate of the Degrees of the Mortality of Mankind</em>") published in the <em class="italic">Philosophical Transactions of the Royal Society</em>, Edmond Halley prepared mortality tables based on Neumann's data. <strong class="keyword">Annuities</strong> are payments made at equal intervals, such as mortgage, insurance, and pension payments. Halley's article guided the development <a id="_idIndexMarker015"/>of actuarial science and informed the British government when it came to selling retirement income insurance at an appropriate price based on the age of the purchaser. We'll encounter Halley again in the astronomy section.</p>
    <p class="normal">Abraham de Moivre was a Frenchman who moved to England at a young age due to the religious persecution of the Huguenots in France. Today, he is best known for his work on the normal distribution and probability theory. In 1724, he published a book called "<em class="italic">Annuities upon Lives</em>," the cover of which you can see below, about mortality statistics and the foundation of the theory of annuities.</p>
    <figure class="mediaobject"><img src="../Images/B17577_01_03.png" alt="../../Desktop/Screenshot%202021-04-15%20at%2022.55.21.pn"/></figure>
    <p class="packt_figref">Figure 1.3: Annuities upon Lives</p>
    <p class="normal">De Moivre is also remembered for an approximation to the binomial distribution and for his work on the Poisson distribution (later named after Siméon Denis Poisson).</p>
    <p class="normal">With some statistics foundations in place, we are now getting into projections into the future, and this is where time-series forecasts come in. In 1751, Benjamin Franklin examined population growth and its limits in his essay "<em class="italic">Observations Concerning the Increase of Mankind, Peopling of Countries, etc.</em>," projecting exponential growth in the British colonies. He projected a doubling of the population in the British Crown Colonies every 25 years, with the potential, he argued, to spread <a id="_idIndexMarker016"/>liberal political tradition and increase the power of England. His projection proved correct, and the exponential growth held up until the 1850s when the population of the United States surpassed England's. </p>
    <p class="normal">Influenced by Franklin was the English cleric Thomas Robert Malthus, who feared that population growth would outstrip growth in food production. In his scenario, while population growth is exponential, the growth of food supply and other resources is linear, which would eventually lead to a collapse of society and massive population death. Writing at the end of the 18th century, he described ever-increasing famine and poverty (referred to after him as the "<em class="italic">Malthusian catastrophe</em>"). </p>
    <p class="normal">Many other statistical and mathematical concepts were worked out based on demographics data. Adolphe Quetelet, an astronomer, mathematician, and sociologist from Ghent, in today's Belgium, introduced statistical methods to social sciences to describe relationships underlying crime rates, marriage rates, and suicide rates. He called for a "social physics" that would find the laws underlying social phenomena, thus revealing the work of God. Among other things, he developed the body mass index, originally called the Quetelet index. In his 1835 book, called "<em class="italic">Treatise on Man</em>" in the English translation, he describes the concept of the average man based on normal distribution. One of Quetelet's students, Pierre Verhulst, developed the logistic function as a model of population growth.</p>
    <p class="normal">Siméon Denis Poisson published "<em class="italic">Recherches sur la probabilité des jugements en matière criminelle et en matière civile</em>" (translated: Studies on the Probability of Judgments in Criminal and Civil Matters) in 1837, where he elaborated on probability theory for discrete <a id="_idIndexMarker017"/>occurrences that take place within a given interval. The Poisson distribution was named after him.</p>
    <p class="normal">Wilhelm Lexis, a pioneer of the analysis of demographic time-series, published a paper called "<em class="italic">On the Theory of the Stability of Statistical Series</em>" (1879), which introduced the quantity now called the Lexis ratio. The ratio distinguishes between stable series, where underlying probability distributions giving rise to the observed rates remain constant, and non-stable series. These stable time-series would not be influenced by forces other than random noise. In today's terminology, a stable time-series would be referred to as a white noise process or a zero-order moving average. </p>
    <p class="normal">In order to distinguish between stable and non-stable time-series, Lexis created a test statistic equal to the ratio between the dispersion of the observed rates and the dispersion that would be expected if the underlying probabilities for each of the observed rates were all equal across all of the observations. If this ratio, Q, was more than 1.41, he argued, this means the time-series is non-stable or – in his words – influenced by physical forces. Lexis later became a member of the Insurance Advisory Council for Germany's Federal Insurance Supervisory Office.</p>
    <h2 id="_idParaDest-18" class="title">Genetics</h2>
    <p class="normal">Francis Galton, a Victorian-era English scientist, was born into an illustrious family of bankers and gun manufacturers <a id="_idIndexMarker018"/>that included several members of the Royal Society. Galton was a highly prolific writer and researcher. Today, he is mostly remembered for coining the word eugenics, the study of changes to the racial quality of future generations with a focus on desirable human qualities. Eugenics is associated with racism and white supremacy. </p>
    <p class="normal">Galton was interested in many scientific disciplines, such as psychology, statistics, psychophysics, photography, and others, and for his contributions, he was knighted in 1909. Among other things, he contributed to anthropometry, the systematic measurement and <a id="_idIndexMarker019"/>description of human bodies. For this work, he rediscovered the concept of correlation (first developed by French physicist Auguste Bravais in 1846) and described correlations between forearm length and height, head width and head breadth, and head length and height (1888). </p>
    <p class="normal">One of his protégés (and biographers) was Karl Pearson, born in Islington, London, into a Quaker family to a father who was Queen's Counsel (a lawyer). After studying mathematics at King's College, Cambridge, physics and philosophy at the University of Heidelberg, and physiology at the University of Berlin, he returned to London to study law. In London, he was introduced to Galton, and the two stayed in contact. </p>
    <p class="normal">After Galton's death, Pearson was the first to hold the Chair in Eugenics endowed by Galton in his will. Pearson's main interest was in applying biometrics in the context of inheritance. He is credited with the invention of the standard deviation, a measure of the variability of the normal distribution, which replaced Carl Friedrich Gauss' concept of the mean error. He also developed contributions to statistics, including the chi-squared test, the p-value for statistical significance, correlation as it's used today, principal component analysis, and the histogram.</p>
    <p class="normal">Pearson was succeeded as the Galton Professor of Eugenics (later renamed the Galton Chair of Genetics) by Ronald Fisher. Fisher made many innovations in evolutionary theory about mimicry, parental investment, and the Fisher principle behind the 1:1 sex ratio. In statistics, he described the linear discriminant analysis, Fisher information, the F-distribution, and the Student's t-distribution. </p>
    <p class="normal">His contributions to statistics laid the groundwork for statistical testing in time-series analysis and some of the classical models. Fisher was made a Knight Bachelor by Queen Elizabeth II in 1952. However, his connection to racist views – for example, he endorsed the German Nazi party's policy of extermination with the goal of improving the genetic stock – has led to a recent reappraisal of his work. </p>
    <p class="normal">As a consequence, the Ronald Fisher Centre at <strong class="keyword">University College London</strong> (<strong class="keyword">UCL</strong>) was renamed to the Centre for Computational Biology, and UCL released a public apology for its role in propagating eugenics. </p>
    <h2 id="_idParaDest-19" class="title">Astronomy</h2>
    <p class="normal">Observations of comets and asteroids, and the and the movements of the sun and the planets have been recorded for a long time, and people have been studying these records to understand the regularities and relationships of these movements and our place in the universe. Edmond Halley, English astronomer and geophysicist, who we mentioned in the section on demography, applied <a id="_idIndexMarker020"/>Isaac Newton's laws of motion (from 1687) to comet sightings throughout history. A comet visible to the naked eye from Earth, it has been seen around the world and inscribed by astronomers and philosophers for at least about 2,000 years, appearing in Ancient Greek writings and Babylonian tables. </p>
    <p class="normal">For instance, its appearance in 12 BCE, close to the assigned date of the birth of Jesus Christ, has led to suggestions that it might be behind the biblical story of the Star of Bethlehem. In 1066, the comet was seen in England and thought to be a divine message, a bad omen foretelling Harold II's fate when he died the same year at the Battle of Hastings fighting against Norman invaders led by William the Conqueror. </p>
    <p class="normal">Halley connected many of these sightings and concluded that it was the same comet each time and calculated a periodicity of 75-76 years. Today it is named after him in his honor, <strong class="keyword">Halley's Comet</strong>. This was published in the "<em class="italic">Synopsis of the Astronomy of Comets</em> (1705)". Halley's Comet will re-appear in 2061.</p>
    <p class="normal">This figure shows the orbit of Halley's Comet (source: Wikimedia Commons):</p>
    <figure class="mediaobject"><img src="../Images/B17577_01_04.png" alt="ile:Halley's Comet animation.gif - Wikimedia Commons"/></figure>
    <p class="packt_figref">Figure 1.4: Halley's Comet orbit</p>
    <p class="normal">German polymath Carl Friedrich Gauss devised a method for determining the orbit of the dwarf planet Ceres in 1801. Ceres orbits in the asteroid belt between Mars and Jupiter. Gauss did this <a id="_idIndexMarker021"/>based on observations of a Catholic priest and astronomer, Giuseppe Piazzi, who traced an object between January and February of the same year, before losing sight of it.</p>
    <p class="normal">Later, line fitting was applied to the movements of celestial bodies, most prominently, the <strong class="keyword">least squares method</strong>. It was first described by Adrien-Marie Legendre in 1805 ("<em class="italic">méthode des moindres carrés</em>"), but today it is co-credited to Gauss. Gauss published about the method later, in 1809; however, he expanded significantly beyond Legendre's work, among other things inventing the distribution named after him, the Gaussian distribution (also called the normal or Bell distribution).</p>
    <div class="packt_tip">
      <p class="Tip--PACKT-">The <strong class="keyword">least squares</strong> method is the underpinning of linear regression methods, where the parameters <a id="_idIndexMarker022"/>in sets of equations are estimated. It's a statistical procedure to find the best fit for a set of data points by minimizing the sum of the squared residuals from the plotted curve.</p>
    </div>
    <p class="normal">Only a year later, Pierre-Simon Laplace proved the <strong class="keyword">central limit theorem</strong>, which roughly states that the sum of <a id="_idIndexMarker023"/>independent variables, even if they are not from the normal distribution, tends toward a normal distribution. This gave an important justification for the method of least <a id="_idIndexMarker024"/>squares and the normal distribution in the case of large datasets. The normal distribution has been highly influential in the field of statistics ever since, and measures such as the mean and the standard deviation are used to describe it. </p>
    <p class="normal">Laplace was highly interested in planetary motion, but he also came up with a dynamic systems theory of tidal movements and probability theory. A fun fact to know about Laplace is that he was Napoleon Bonapart's examiner in 1784 when the latter attended the École Militaire in Paris. </p>
    <p class="normal">One of Laplace's most famous contributions is the rule of succession, which describes the probability that an event will occur given past events. The sunrise example that he came up with for illustration of the rule of succession is the probability of the sun rising tomorrow given the number of days it has risen in the past:</p>
    <figure class="mediaobject"><img src="../Images/B17577_01_008.png" alt="" style="height: 2.5em;"/></figure>
    <p class="normal">Laplace's assumption for the sunrise problem was that we have no knowledge of the matter other than the number of days of observations used in the formula. He actually cautioned that the application in this context is a misapplication of the rule given that we know much more about the movements of the sun and Earth.</p>
    <p class="normal">Motivated by astronomic calculations, Augustin-Louis Cauchy invented the gradient descent optimization algorithm in 1847 (in the journal of the French Academy of Sciences, <em class="italic">Comptes rendus de l'Académie des Sciences</em>), where repeated steps in the opposite direction of the gradient led to finding a local minimum.</p>
    <p class="normal">Many other optimization and curve-fitting innovations followed. First published in 1944 by Kenneth Levenberg and rediscovered in 1963 by Donald Marquardt, the Levenberg–Marquardt algorithm (also called the damped least-squares method) can be used for curve fitting in problems, where the dependent variables are a non-linear combination of the model parameters (non-linear problems). It combines the Gauss-Newton algorithm, a variation of the Newton algorithm published by Gauss in 1809, and the method of gradient descent invented about a hundred years earlier.</p>
    <h2 id="_idParaDest-20" class="title">Economics</h2>
    <p class="normal">William Playfair was born in Scotland in 1759, the fourth son of a reverend's family. He took an apprenticeship <a id="_idIndexMarker025"/>with Andrew Meikle, the inventor of the threshing machine, and went on to become the personal assistant to James Watt at the Boulton and Watt steam engine manufactory.</p>
    <p class="normal">His life was so eventful that several novels could be written about it. In 1789, he took part in the storming of the Bastille in Paris. After that he was involved as an agent of William Duer, a speculator, and the Scioto Company, in what could have been an embezzlement scheme, selling worthless deeds for land in Ohio to Frenchmen willing to emigrate. Back in London, he opened a bank that went bankrupt. Later, he was imprisoned for a few years in a debtor's prison, Fleet Prison, for being indebted. Then he went on to become a British secret agent, counterfeiting the French currency from 1789 to 1796, the assignat, to undermine the French government. The assignat soon became worthless, and inflation undermined the French government. He also patented several inventions for metalworking machinery and ships.</p>
    <p class="normal">One of Playfair's principal achievements, however, was his popularization of several kinds of visualizations, such as the pie chart, the bar chart, and the time-series chart. He is sometimes credited with the invention of the bar chart, although Nicole Oresme showed a bar chart in a publication several hundred years earlier. </p>
    <p class="normal">Here are two plots, the bar chart and the time-series plot, both from his "<em class="italic">Commercial and Political Atlas</em>" in 1786 (image source: Wikipedia):</p>
    <figure class="mediaobject"><img src="../Images/B17577_01_05.png" alt="https://upload.wikimedia.org/wikipedia/commons/e/e0/1786_Playfair_-_Exports_and_Imports_of_Scotland_to_and_from_different_parts_for_one_Year_from_Christmas_1780_to_Christmas_1781.jpg"/></figure>
    <p class="packt_figref">Figure 1.5: Playfair's visualizations from Commercial and Political Atlas</p>
    <p class="normal">On the left, you can <a id="_idIndexMarker026"/>see the bar chart Playfair used for a quantitative comparison of import and export data in Scotland. On the right is the time-series chart, to show the British trade balance over time.</p>
    <h2 id="_idParaDest-21" class="title">Meteorology</h2>
    <p class="normal">The Greek philosopher Aristotle was the first to write about weather and its measurement; however, it took much longer for the first weather predictions to be made. Vice Admiral Robert FitzRoy founded the United Kingdom's national weather service, the Meteorological Office, in 1854. FitzRoy had already reserved his place in history as the captain of the HMS Beagle, the ship that carried a recently <a id="_idIndexMarker027"/>graduated naturalist by the name of Charles Darwin around the world, playing a pivotal role in the formation of theories on evolution and natural selection.</p>
    <p class="normal">Supported by the telegraph and the barograph, a form of barometer, the Met Office collected weather data from many different locations in London. In 1859, the steam clipper Royal Charter, while returning to Liverpool from Melbourne, Australia, shipwrecked on rocks off the Welsh coast in a storm, leading to the loss of about 450 lives. This disaster led to the development of a storm warning system that was later extended to general weather predictions. It was FitzRoy, in fact, who coined the word <em class="italic">forecast</em>, although at the time, many contemporaries referred to them as "quack weather prognostications". It is unclear whether his forecasts followed any system. He was much ridiculed by the scientific establishments for his work. He was prominently criticized by Sir Francis Galton, who had published a book called "<em class="italic">Meteorographica</em>" and later published the first <a id="_idIndexMarker028"/>weather maps. FitzRoy took his own life by cutting his throat in 1865. The storm warnings were temporarily discontinued, only to be resumed a few years later to continue to this day.</p>
    <p class="normal">The first weather models that used atmosphere and oceans were attempted in the 1920s by Lewis Fry Richardson based on work by Norwegian Vilhelm Bjerknes, lecturer at the University of Stockholm on differential equations of fluid dynamics and thermodynamics. These models were impractical before the advent of computers, however—Richardson worked for about six weeks on a weather forecast of a limited area. His forecast turned out to be inaccurate because of numerical instability, even though his methodology was essentially correct. He abandoned his work when it became clear that his work could be of value to chemical weapons designers.</p>
    <p class="normal">The first <a id="_idIndexMarker029"/>computerized weather models were programmed on the <strong class="keyword">Electronic Numerical Integrator and Computer</strong> (<strong class="keyword">ENIAC</strong>). The ENIAC, designed by John Mauchly and J. Presper Eckert, could run arbitrary sequences of operations; however, it didn't read the programs from tapes but from plugboard switches. The giant 15x9-meter machine is exhibited today at the Smithsonian Institute in Washington, D.C. Consisting of 17,500 vacuum tubes, it first produced calculations for the construction of a hydrogen bomb and was then exploited to extend forecasting past one or two days using new methods of numerical weather prediction. The computer was programmed by Klara von Neumann. </p>
    <p class="normal">Here's a photo of the ENIAC (source: Wikimedia Commons):</p>
    <p class="packt_figref"><img src="../Images/B17577_01_06.png" alt="https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Eniac.jpg/1024px-Eniac.jpg"/></p>
    <p class="packt_figref">Figure 1.6: Electronic Numerical Integrator and Computer (ENIAC)</p>
    <p class="normal">You can see Betty Snyder, one of the earliest programmers of the ENIAC, standing in front of the ENIAC.</p>
    <p class="normal">Later, Joseph Smagorinsky and Douglas Lilly developed a mathematical model for turbulence <a id="_idIndexMarker030"/>used in computational fluid dynamics. This model, the Smagorinsky-Lilly model, which is still in use today, used data about the wind, cloud cover, precipitation, atmospheric pressure, and radiation emanating from the earth and sun as input. Smagorinsky continued to lead research on global warming, investigating the climate's sensitivity to increasing carbon dioxide levels.</p>
    <p class="normal">The introduction of mobile sensor arrays and computerized models has greatly increased the accuracy of predictions. Valuable temperature and wind data is collected by sensors deployed by meteorology offices or other sources, most importantly by commercial aircraft as they fly. Today, within a seven-day window, a forecast is accurate about 80% of the time. The grounding of commercial flights during the COVID pandemic, where there were about 75% fewer flights for some periods, has led to less accurate forecasts recently.</p>
    <h2 id="_idParaDest-22" class="title">Medicine</h2>
    <p class="normal">In 1901, Willem Einthoven applied the string galvanometer used in the telegraph receiver to physiology. Working in Leiden, in the Netherlands, he improved upon previous designs, producing the first practical electrocardiogram (ECG). The ECG is important for <a id="_idIndexMarker031"/>monitoring and screening the function of the heart and can detect cardiac rhythm disturbances, inadequate coronary artery blood flow, and electrolyte disturbances. For the importance of this innovation, Einthoven was awarded the 1924 Nobel prize in Physiology or Medicine.</p>
    <p class="normal">Hans Berger recorded the first human electroencephalography (EEG) recording in 1924. EEG measures the <a id="_idIndexMarker032"/>electrical activity of the brain with electrodes placed on the scalp. An EEG recording shows the brain's spontaneous electrical activity over a period of time. </p>
    <p class="normal">Here's a graph of an EEG signal (from the EEG Eye State dataset uploaded by Oliver Roesler from DHBW, Germany):</p>
    <figure class="mediaobject"><img src="../Images/B17577_01_07.png" alt="eeg_signal.png"/></figure>
    <p class="packt_figref">Figure 1.7: EEG signal</p>
    <p class="normal">In EEG, the electrical activity of the brain is recorded through electrodes placed on the scalp. Its signal <a id="_idIndexMarker033"/>typically shows strong oscillations (also referred to as brain waves) at a variety of frequency ranges, most prominently these:</p>
    <ul>
      <li class="bullet">Alpha (8-12 Hertz) would occur in a relaxed state, especially when closing the eyes</li>
      <li class="bullet">Beta (16-31 Hertz) signals more active thinking</li>
      <li class="bullet">Gamma (more than 32 Hertz) indicates cross-modal sensory processing</li>
    </ul>
    <p class="normal">The medical uses <a id="_idIndexMarker034"/>of EEG are broad – among other things, EEG can be used to diagnose epilepsy, sleep disorders, tumors, stroke, depth of anesthesia, coma, and brain death.</p>
    <h2 id="_idParaDest-23" class="title">Applied Statistics</h2>
    <p class="normal">Applied statistics and mathematics also provided inspiration and a foundation for work with time-series. Reverend Thomas Bayes (pronounced /be<img src="../Images/B17577_01_009.png" alt="" style="height: 0.22em;"/>z/) proves a theorem that describes the probability <a id="_idIndexMarker035"/>of an event based on prior knowledge. Bayes' theorem is considered the foundation of Bayesian inference, a statistical inference approach. </p>
    <p class="normal">We'll come back to this in <em class="chapterRef">Chapter 9</em>, <em class="italic">Probabilistic Models for Time-Series</em>. Bayes' manuscripts were read to the Royal Society by his friend Richard Price within two years of his death (in 1761) in a heavily edited form.</p>
    <p class="normal">The Fourier transform, which is important for filtering, converts a signal from its time domain to a representation in the frequency domain. The trigonometric decomposition of functions was discovered by Joseph Fourier in 1807, but a fast algorithm was first invented by Gauss around 1805 (although published only after his death and in Latin), and then rediscovered 160 years later by J. W. Cooley and John Tukey. </p>
    <p class="normal">Classical time-series modeling approaches were introduced by George Box and Gwilym Jenkins in 1970 in their book "<em class="italic">Time-Series Analysis Forecasting and Control</em>." Most importantly, they formalized the ARIMA and ARMAX models and described how to apply them to time-series forecasting. We'll talk about these types of models in <em class="chapterRef">Chapter 5</em>, <em class="italic">Forecasting with Moving Averages and Autoregressive Models</em>.</p>
    <h1 id="_idParaDest-24" class="title">Python for Time-Series</h1>
    <p class="normal">For time-series, there are two main languages, R and Python, and it's worth briefly comparing the two <a id="_idIndexMarker036"/>and describing what makes Python special. Python is one of the top programming languages by popularity. According to the TIOBE from February 2021, it is only surpassed in popularity by C and Java.</p>
    <table id="table001" class="No-Table-Style _idGenTablePara-1">
      <colgroup>
        <col/>
        <col/>
        <col/>
      </colgroup>
      <tbody>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="normal"><strong class="keyword">Rank</strong></p>
          </td>
          <td class="No-Table-Style">
            <p class="normal"><strong class="keyword">Language</strong></p>
          </td>
          <td class="No-Table-Style">
            <p class="normal"><strong class="keyword">Ratings</strong></p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="normal">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="normal">C</p>
          </td>
          <td class="No-Table-Style">
            <p class="normal">16.34%</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="normal">2</p>
          </td>
          <td class="No-Table-Style">
            <p class="normal">Java</p>
          </td>
          <td class="No-Table-Style">
            <p class="normal">11.29%</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="normal">3</p>
          </td>
          <td class="No-Table-Style">
            <p class="normal">Python</p>
          </td>
          <td class="No-Table-Style">
            <p class="normal">10.86%</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="normal">4</p>
          </td>
          <td class="No-Table-Style">
            <p class="normal">C++</p>
          </td>
          <td class="No-Table-Style">
            <p class="normal">6.88%</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="normal">...</p>
          </td>
          <td class="No-Table-Style">
            <p class="normal">...</p>
          </td>
          <td class="No-Table-Style">
            <p class="normal">...</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="normal">11</p>
          </td>
          <td class="No-Table-Style">
            <p class="normal">R</p>
          </td>
          <td class="No-Table-Style">
            <p class="normal">1.56%</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="normal">...</p>
          </td>
          <td class="No-Table-Style">
            <p class="normal">...</p>
          </td>
          <td class="No-Table-Style">
            <p class="normal">...</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="normal">29</p>
          </td>
          <td class="No-Table-Style">
            <p class="normal">Julia</p>
          </td>
          <td class="No-Table-Style">
            <p class="normal">0.52%</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="packt_figref">Figure 1.8: TIOBE language usage statistics</p>
    <p class="normal">I've included R and Julia, two other languages used for data science, in order to support the point that Python is the most popular data science language. When comparing search volumes for Python, R, and Julia, the three foremost languages for data science, we can see that <a id="_idIndexMarker037"/>Python is much more popular than R, with Julia being the distant third. In fact, Python is ranked similar to languages such as C, Java, and C++. R is at a similar level to Assembly language and Groovy, and Julia is at the level of specialist languages such as Prolog.</p>
    <p class="normal">R's community consists of statisticians and mathematicians, and R's strengths lie in statistics and plotting (ggplot). The weakness of R is its tooling and the virtual absence of consistent code style conventions.</p>
    <p class="normal">On the other side, Python has been catching up in statistics and scientific computing with libraries such as NumPy, SciPy, and pandas, and it has overtaken R in both usage and usability for data science.</p>
    <p class="normal">Python stands out in terms of machine learning libraries. The following libraries are written entirely or mainly in Python:</p>
    <ul>
      <li class="bullet">Scikit-learn is written in Python and Cython (a Python dialect similar to the C programming language). It provides implementations of a very large set of algorithms for training and evaluating machine learning models.</li>
      <li class="bullet">Statsmodels <a id="_idIndexMarker038"/>provides statistical tests, and models such as the generalized linear model (GLM), ARMA, and many more.</li>
      <li class="bullet">Keras is an abstraction for training neural networks in Python that interact with TensorFlow and other libraries.</li>
    </ul>
    <p class="normal">Some of the most popular machine learning frameworks – ones that see lots of use for development and have a large range of scalable algorithms, such as TensorFlow, PyTorch, and XGBoost – are also mainly written in Python or provide first-class interfaces for Python.</p>
    <p class="normal">Furthermore, being a general-purpose language, Python is ideal if you want to go beyond just data analysis. With Python, you can implement the full data flow necessary for building an end-to-end machine learning system that you can deploy and integrate with the backend platforms of your company.</p>
    <p class="normal">The following time-series plot shows the popularity of Python and R according to Google Trends. Julia is omitted <a id="_idIndexMarker039"/>because it hardly registered at the bottom of the graph. </p>
    <p class="normal">Recently, COVID has dented the popularity of Python, but other programming languages have gone down in terms of search volumes as well.</p>
    <figure class="mediaobject"><img src="../Images/B17577_01_08.png" alt="python_timeline.png"/></figure>
    <p class="packt_figref">Figure 1.9: Python versus R usage over time</p>
    <p class="normal">Python has been clearly winning out over R for the last few years, although it has to be admitted that the comparison is not completely fair since Python finds much broader application than R. However, Python is also one of the best-supported languages for data science in general and time-series in particular. As of February 2021, if we search GitHub for time-series, we find about five times the number of repositories (including repositories with Jupyter notebooks). For Julia, I found about 104 repositories. Please see the following table for the exact numbers:</p>
    <table id="table002" class="No-Table-Style _idGenTablePara-1">
      <colgroup>
        <col/>
        <col/>
      </colgroup>
      <tbody>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="normal"><strong class="keyword">Language</strong></p>
          </td>
          <td class="No-Table-Style">
            <p class="normal"><strong class="keyword">Repositories for time-series</strong></p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="normal">Jupyter Notebook</p>
          </td>
          <td class="No-Table-Style">
            <p class="normal">11,297</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="normal">Python</p>
          </td>
          <td class="No-Table-Style">
            <p class="normal">4,891</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="normal">R</p>
          </td>
          <td class="No-Table-Style">
            <p class="normal">3,656</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="normal">Julia</p>
          </td>
          <td class="No-Table-Style">
            <p class="normal">104</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="packt_figref">Figure 1.10: TIOBE language usage statistics</p>
    <p class="normal">In order to just give a flavor of Python machine learning projects specializing in time-series, here's a short list <a id="_idIndexMarker040"/>of prominent libraries on GitHub:</p>
    <ul>
      <li class="bullet">prophet</li>
      <li class="bullet">sktime</li>
      <li class="bullet">gluon-ts</li>
      <li class="bullet">tslearn</li>
      <li class="bullet">pyts</li>
      <li class="bullet">seglearn</li>
      <li class="bullet">darts</li>
      <li class="bullet">cesium</li>
      <li class="bullet">pmdarima</li>
    </ul>
    <p class="normal">These screenshots (taken from gitcompare.com) summarize some of the statistics around these libraries, such as the number of stars (how many times someone liked the library), forks (how many times someone copied the library in order to study it or make changes), age (how long has the repository existed), and others:</p>
    <figure class="mediaobject"><img src="../Images/B17577_01_09.png" alt="/Users/ben/Dropbox/vimwiki/_html/assets/time-series-libraries1.png"/></figure>
    <figure class="mediaobject"><img src="../Images/B17577_01_10.png" alt="/Users/ben/Dropbox/vimwiki/_html/assets/time-series-libraries2.png"/></figure>
    <p class="packt_figref">Figure 1.11: Library statistics for prominent Python libraries</p>
    <p class="normal">We'll go through many of these time-series libraries in this book. We'll deal with a few Python data science libraries in the following sections, but if you want a full introduction <a id="_idIndexMarker041"/>to any of these libraries, you should go through a book specific to data science in Python, or even NumPy and pandas.</p>
    <h2 id="_idParaDest-25" class="title">Installing libraries</h2>
    <p class="normal">The two main tools for maintaining and installing the Python libraries you'll need for this book are conda and pip.</p>
    <p class="normal">Please note that the commands within the next two subsections should be executed from the system <a id="_idIndexMarker042"/>terminal or – in the case of conda – using the Anaconda navigator. For Windows and Mac users, there are graphical user interfaces available, where libraries can be searched and installed, instead of relying on the terminal. </p>
    <p class="normal"><strong class="keyword">conda</strong> works with Python, R, and other languages for the management of dependencies, and for environment <a id="_idIndexMarker043"/>encapsulation. conda helps with the installation of system libraries as well by maintaining lists of libraries associated with Python libraries. </p>
    <p class="normal">The best way to <a id="_idIndexMarker044"/>get started with conda is to install anaconda by following the instructions from this link: <a href="https://docs.continuum.io/anaconda/install/"><span class="url">https://docs.continuum.io/anaconda/install/</span></a>.</p>
    <p class="normal">There's also a graphical interface to conda that comes with a slick design, as this screenshot shows:</p>
    <figure class="mediaobject"><img src="../Images/B17577_01_11.png" alt="anaconda%20navigator.png"/></figure>
    <p class="packt_figref">Figure 1.12: Anaconda navigator</p>
    <p class="normal">The Anaconda navigator can be installed on macOS and Microsoft Windows. </p>
    <p class="normal">Alternatively, you <a id="_idIndexMarker045"/>can rely completely on the terminal. For example, here's how to install the NumPy library from your terminal:</p>
    <pre class="programlisting con"><code class="hljs-con">conda install numpy
</code></pre>
    <p class="normal">As a side note – if you want to work with the R programming language, you can use conda, too:</p>
    <pre class="programlisting con"><code class="hljs-con">conda install r-caret
</code></pre>
    <p class="normal">See the conda documentation for an in-depth introduction and tutorials. Conda also installs versions of Python <a id="_idIndexMarker046"/>and pip, so you can use either pip or conda to install Python libraries, while having your environment managed with conda.</p>
    <p class="normal">Terminal commands can be executed either from your system terminal or from within the Jupyter environment, the notebook or JupyterLab, by prefixing an exclamation mark.</p>
    <p class="normal">For example, a command from within the terminal:</p>
    <pre class="programlisting con"><code class="hljs-con">pip install xgboost
</code></pre>
    <p class="normal">Can be written within the Jupyter environment as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">!pip install xgboost
</code></pre>
    <p class="normal">The exclamation mark from within Jupyter tells the interpreter that this is a shell command. In recent versions of Jupyter, the exclamation mark is not necessary anymore with the pip command.</p>
    <p class="normal">Let's take a quick look at how a simple session of starting Python and installing a library could appear on the terminal:</p>
    <figure class="mediaobject"><img src="../Images/B17577_01_12.png" alt="terminal.png"/></figure>
    <p class="packt_figref">Figure 1.13: Terminal window</p>
    <p class="normal">pip is a package manager <a id="_idIndexMarker047"/>for Python libraries. Here are some useful commands <a id="_idIndexMarker048"/>from your terminal:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">#</span><span class="bash"> install NumPy:</span> 
pip install numpy
<span class="hljs-con-meta">#</span><span class="bash"> install a particular version:</span>
pip install numpy==1.20.0
<span class="hljs-con-meta">#</span><span class="bash"> upgrade a library:</span>
pip install -U numpy
<span class="hljs-con-meta">#</span><span class="bash"> install all libraries listed in a requirements file:</span>
pip install -r production/requirements.txt
<span class="hljs-con-meta">#</span><span class="bash"> </span>write a list of all installed libraries and their versions to a file:
pip freeze &gt; production/requirements.txt
</code></pre>
    <p class="normal">You can install different versions of Python and pip and different versions of libraries. These can be <a id="_idIndexMarker049"/>maintained as environments that you can switch between. Virtualenv is a tool to maintain environments:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">#</span><span class="bash"> create a new environment myenv:</span>
virtualenv myenv
<span class="hljs-con-meta">#</span><span class="bash"> activate the myenv environment:</span>
source myenv/bin/activate
<span class="hljs-con-meta">#</span><span class="bash"> install dependencies or run python, for example:</span>
python
<span class="hljs-con-meta">#</span><span class="bash"> leave the environment again:</span>
deactivate
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">activate</code> command will change your <code class="Code-In-Text--PACKT-">$PATH</code> variable to point to the <code class="Code-In-Text--PACKT-">virtualenv bin/</code> directory, which contains versions of Python and pip executables, among other things. This means you have all of those available to use as options. You should usually see the prompt reflect this change. </p>
    <p class="normal">Please note that for the activation of the environment, you can use a complete or relative path. In Windows, the activation command is slightly different – you'd run a shell script:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">#</span><span class="bash"> activate the myenv environment:</span>
myenv\Scripts\activate.bat
</code></pre>
    <h2 id="_idParaDest-26" class="title">Jupyter Notebook and JupyterLab</h2>
    <p class="normal">Jupyter stands for Julia, Python, R. It's a platform to run scripts in these and other supported languages, such <a id="_idIndexMarker050"/>as Scala and C, in an interactive environment. </p>
    <p class="normal">You can start up a notebook server on your computer from the terminal like this: </p>
    <pre class="programlisting con"><code class="hljs-con">jupyter notebook
</code></pre>
    <p class="normal">You should see your browser opening a new tab with the Jupyter notebook. The beginning of my notebook <a id="_idIndexMarker051"/>for loading the data science language time-series looks like this:</p>
    <figure class="mediaobject"><img src="../Images/B17577_01_13.png" alt="/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/(A Document Being Saved By screencaptureui 3)/Screenshot 2021-03-11 at 17.29.18.png"/></figure>
    <p class="packt_figref">Figure 1.14: Jupyter notebook</p>
    <p class="normal">Alternatively, we can also use JupyterLab, the next-generation notebook server that brings significant <a id="_idIndexMarker052"/>improvements in usability. </p>
    <p class="normal">You can start up a JupyterLab notebook server from the terminal like this: </p>
    <pre class="programlisting con"><code class="hljs-con">jupyter lab
</code></pre>
    <p class="normal">JupyerLab looks a bit different from the default Jupyter server, as you can see in the screenshot <a id="_idIndexMarker053"/>below (from the JupyterLab GitHub repo):</p>
    <figure class="mediaobject"><img src="../Images/B17577_01_14.png" alt="i_glow_up"/></figure>
    <p class="packt_figref">Figure 1.15: JupyterLab</p>
    <p class="normal">Either one of these <a id="_idIndexMarker054"/>two, the Jupyter notebook or JupyterLab, will give you an <strong class="keyword">integrated development environment</strong> (<strong class="keyword">IDE</strong>) to work on the code that we'll be introducing in this book.</p>
    <p class="normal">Finally, it's very handy to know how to get help from within Jupyter. This is where the question mark comes in. The question mark, ?, is used to provide in-notebook help like so:</p>
    <figure class="mediaobject"><img src="../Images/B17577_01_15.png" alt="/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_jyFfFP/Screenshot 2021-06-26 at 22.06.11.png"/></figure>
    <p class="packt_figref">Figure 1.16: In-notebook help</p>
    <p class="normal">You can also use single or double question marks at the end of a function if you want to access the signature or the complete source code listing of the function. This functionality can save a lot of time – instead of searching Google for the code or the definition of classes or functions, you can get to the information in milliseconds.</p>
    <h2 id="_idParaDest-27" class="title">NumPy</h2>
    <p class="normal">NumPy is a foundational library for scientific computing in Python because so many libraries depend on it. Libraries such as PyTorch and TensorFlow provide an interface with NumPy so that <a id="_idIndexMarker055"/>data import/export is a breeze. pandas is basically a high-level interface around NumPy arrays. </p>
    <p class="normal">SciPy also builds on top of NumPy. SciPy stands for <em class="italic">scientific Python</em> and contains functionality ranging from <a id="_idIndexMarker056"/>mathematical constants to integration, optimization, interpolation, signal processing, and more.</p>
    <p class="normal">NumPy allows you to work with matrices in different dimensions and perform computations on them. You might work mainly with pandas or other libraries and never come much in <a id="_idIndexMarker057"/>contact with NumPy; however, for a deeper understanding and for high performance, it's definitely important to know NumPy. </p>
    <p class="normal">A few basic commands in NumPy are below. This is supposed to be executed in the Python interpreter. We'll create one-dimensional and two-dimensional arrays:</p>
    <pre class="programlisting con"><code class="hljs-con">import numpy as np
# 1 dimensional array:
x1 = np.array([1, 2, 3])
&gt;&gt;&gt; <span class="python">array([0, </span><span class="python">1, 2])</span>
x2 = np.arange(3)
<span class="python">&gt;&gt;&gt; array([0, 1, 2])</span>
x1 == x2 
&gt;&gt;&gt; True
# 2 dimensional array: 
y = np.array([(1, 2, 3),(4, 5, 6)])
</code></pre>
    <p class="normal">NumPy has very handy functions for documentation; for example, to retrieve the documentation for the <code class="Code-In-Text--PACKT-">optimize.fmin</code> function, use this (I've omitted a few lines for conciseness):</p>
    <pre class="programlisting con"><code class="hljs-con">&gt;&gt; np.info(optimize.fmin)
fmin(func, x0, args=(), xtol=0.0001, ftol=0.0001, maxiter=None, maxfun=None,full_output=0, disp=1, retall=0, callback=None)
Minimize a function using the downhill simplex algorithm.
Parameters
----------
func : callable func(x,*args)
    The objective function to be minimized.
x0 : ndarray
    Initial guess.
args : tuple
    Extra arguments passed to func, i.e. ``f(x,*args)``.
callback : callable
    Called after each iteration, as callback(xk), where xk is the
    current parameter vector.
Returns
-------
xopt : ndarray
    Parameter that minimizes function.
fopt : float
    Value of function at minimum: ``fopt = func(xopt)``.
iter : int
    Number of iterations performed.
…
Notes
-----
Uses a Nelder-Mead simplex algorithm to find the minimum of function of
one or more variables.
</code></pre>
    <h2 id="_idParaDest-28" class="title">pandas</h2>
    <p class="normal">pandas is a library that allows <a id="_idIndexMarker058"/>accessing matrices or arrays as tables, by indexes such as column names – this is called a <strong class="keyword">DataFrame</strong>. A single column or single row can be accessed as a series, another <a id="_idIndexMarker059"/>datatype in pandas. These series are NumPy arrays.</p>
    <p class="normal">The pandas library includes functions and classes for importing and exporting data from/to CSV, Excel, and many other formats; for selecting and slicing data; and for merge, join, groupby, and aggregation functions reminiscent of Structured Query Language (SQL). You can <a id="_idIndexMarker060"/>also plot directly from pandas, because pandas is integrated with matplotlib, but it also <a id="_idIndexMarker061"/>works with other plotting libraries such as bokeh:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-comment"># read a csv file:</span>
df = pd.read_csv(<span class="hljs-string">'value.csv'</span>)
<span class="hljs-comment"># find how many rows in a dataframe:</span>
<span class="hljs-built_in">len</span>(df)
<span class="hljs-comment"># return the head or tail of a dataframe:</span>
df.head()
df.tail()
<span class="hljs-comment"># print the full dataframe:</span>
<span class="hljs-keyword">with</span> pd.option_context(
  <span class="hljs-string">'display.max_rows'</span>, <span class="hljs-literal">None</span>,
  <span class="hljs-string">'display.max_columns'</span>, <span class="hljs-literal">None</span>
):
  print(df)
<span class="hljs-comment"># create a dataframe:</span>
df2 = pd.DataFrame({<span class="hljs-string">"A"</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], <span class="hljs-string">"B"</span>: [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]})
<span class="hljs-comment"># plot two columns against each other:</span>
df2.plot(x=<span class="hljs-string">'A'</span>, y=<span class="hljs-string">'B'</span>, kind=<span class="hljs-string">'scatter'</span>)
<span class="hljs-comment"># save the dataframe to a csv:</span>
df2.to_csv(<span class="hljs-string">'new_file.csv'</span>, index=<span class="hljs-literal">False</span>)
<span class="hljs-comment"># output to NumPy matrix:</span>
df2.to_numpy()
</code></pre>
    <p class="normal">The output of <a id="_idIndexMarker062"/>the last command should look like this:</p>
    <pre class="programlisting con"><code class="hljs-con">array([[1, 3],
       [2, 4]])
</code></pre>
    <h2 id="_idParaDest-29" class="title">Best practice in Python</h2>
    <p class="normal">In this section, I want to talk about good coding. Whole books have been written about this, and this one section cannot do justice to this matter; however, I aim to at least give some essentials <a id="_idIndexMarker063"/>and pointers. For coding beyond the beginner's level and within a corporate environment, or any organization for that matter, good practice takes on importance. </p>
    <p class="normal">It's not easy and takes experience to write generalizable code that lends itself to maintenance and enhancements. Only code that expresses ideas in a way that is readable to other people will be useful for a team. One of the most important principles is DRY (don't repeat yourself), where repetition is reduced and each functionality finds its unique representation within the system.</p>
    <p class="normal">This is not a full list, but some other principles include the following:</p>
    <ul>
      <li class="bullet">Documentation</li>
      <li class="bullet">Dependency management</li>
      <li class="bullet">Code validation</li>
      <li class="bullet">Error handling</li>
      <li class="bullet">Testing (in particular, unit testing)</li>
    </ul>
    <p class="normal">Some of these have entire books written about them, and it's outside our scope here to go into detail. Each of these is crucially important once you gear up to production so your code can be relied on.</p>
    <p class="normal">It still happens to me that I feel like an idiot whenever I return to one of my projects, be it in my job or private life, and realize I didn't write enough documentation. When that happens, I have to expend energy rebuilding the correct mental representation of my code. If done properly, writing documentation can help you in your flow. Other people reading your code, and your future self in a few months, will be glad you wrote documentation, especially for functions, classes, and modules (docstrings).</p>
    <p class="normal">Encapsulation of dependencies means that your code is isolated, portable, and reproducible. Two main tools have emerged during the last few years for the management of <a id="_idIndexMarker064"/>dependencies and environments in Python, conda and pip, which we've mentioned in the previous section.</p>
    <p class="normal">A mishmash of styles and conventions render any project a mess that's not only hard to read but hard to maintain. One of the most important coding styles for Python is Python Enhancement Proposal 8, or PEP 8 for <a id="_idIndexMarker065"/>short. You can find the style guide for PEP 8 at <a href="http://bit.ly/3evsgIW"><span class="url">http://bit.ly/3evsgIW</span></a>. </p>
    <p class="normal">A few tools have been developed to check Python code for adherence to PEP 8 (and a few additional conventions). These tools can help you make your code more legible and maintainable while saving time and mental energy; for example, Flake8, Black, mypy, or Pylint. Flake8 and Pylint not only check for coding style but also for common coding mistakes and potential bugs. If you want to run a Flake8 test on a Python script, you can type this, for example:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="bash">flake8 --shore-source --show-pep8 myscript.py</span>
</code></pre>
    <p class="normal">Black can nag you about formatting or automatically fix formats in a file, module, or even a whole project. pydocstyle checks for the existence of documentation and the compliance of the documentation with documentation style guidelines.</p>
    <p class="normal">Further, more in-depth development and coding styles have been created by developers from several high-level projects and can be very instructive. The guide for the scikit-learn project <a id="_idIndexMarker066"/>can be found at <a href="http://bitly.com/3etFrtz"><span class="url">http://bitly.com/3etFrtz</span></a>. For pandas, you can compare the styles at <a href="http://bit.ly/2OlpCKZ"><span class="url">http://bit.ly/2OlpCKZ</span></a>.</p>
    <p class="normal">Unit testing is a method by which you set up tests for modules, classes, and other units of code. One of the most popular libraries for unit testing in Python is pytest. You can find out more <a id="_idIndexMarker067"/>about pytest in the pytest documentation: <a href="https://docs.pytest.org/en/stable/"><span class="url">https://docs.pytest.org/en/stable/</span></a></p>
    <h1 id="_idParaDest-30" class="title">Summary</h1>
    <p class="normal">In this chapter, we've introduced time-series, the history of research into time-series, and Python for time-series. </p>
    <p class="normal">We started with a definition of time-series and its main properties. We then looked at the history of the study of time-series in different scientific disciplines, such as demography and genetics, astronomy, economics, meteorology, medicine, and applied statistics.</p>
    <p class="normal">Then, we went over the capabilities of Python for time-series and why Python is the go-to language for doing machine learning with time-series. Finally, I described how to install and use Python for time-series analysis and machine learning, and we covered some of the basics of Python as relevant to time-series and machine learning.</p>
    <p class="normal">In the next chapter, we'll look at time-series analysis with Python.</p>
  </div>
</body></html>