<html><head></head><body>
		<br/>
		<p class="style0">7. Model Evaluation</p>
		<div style="page-break-before: always;"/>
	

		<br/>
		<h4 class="style0">Activity 7.01: Final Test Project</h4>
		<br/>
		<p class="style0">Import the relevant libraries:</p>
		<br/>
		<p class="style0">import pandas as pd</p>
		<br/>
		<p class="style0">import numpy as np</p>
		<br/>
		<p class="style0">import json</p>
		<br/>
		<p class="style0">%matplotlib inline</p>
		<br/>
		<p class="style0">import matplotlib.pyplot as plt</p>
		<br/>
		<p class="style0">from sklearn.preprocessing import OneHotEncoder</p>
		<br/>
		<p class="style0">from sklearn.model_selection import RandomizedSearchCV, train_test_split</p>
		<br/>
		<p class="style0">from sklearn.ensemble import GradientBoostingClassifier</p>
		<br/>
		<p class="style0">from sklearn.metrics import (accuracy_score, precision_score, \</p>
		<br/>
		<p class="style0">recall_score, confusion_matrix, precision_recall_curve)</p>
		<br/>
		<p class="style0">Read the breast-cancer-data.csv dataset:</p>
		<br/>
		<p class="style0">data = pd.read_csv('../Datasets/breast-cancer-data.csv')</p>
		<br/>
		<p class="style0">data.info()</p>
		<br/>
		<p class="style0">Let's separate the input data (X) and the target (y):</p>
		<br/>
		<p class="style0">X = data.drop(columns=['diagnosis'])</p>
		<br/>
		<p class="style0">y = data['diagnosis'].map({'malignant': 1, 'benign': 0}.get).values</p>
		<br/>
		<p class="style0">Split the dataset into training and test sets:</p>
		<br/>
		<p class="style0">X_train, X_test, \</p>
		<br/>
		<p class="style0">y_train, y_test = train_test_split(X, y, \</p>
		<br/>
		<p class="style0">                                   test_size=0.2, random_state=11)</p>
		<br/>
		<p class="style0">print(X_train.shape)</p>
		<br/>
		<p class="style0">print(y_train.shape)</p>
		<br/>
		<p class="style0">print(X_test.shape)</p>
		<br/>
		<p class="style0">print(y_test.shape)</p>
		<br/>
		<p class="style0">You should get the following output:</p>
		<br/>
		<p class="style0">(455, 30)</p>
		<br/>
		<p class="style0">(455,)</p>
		<br/>
		<p class="style0">(114, 30)</p>
		<br/>
		<p class="style0">(114,)</p>
		<br/>
		<p class="style0">Choose a base model and define the range of hyperparameter values corresponding to the model to be searched for hyperparameter tuning. Let's use a gradient-boosted classifier as our model. We then define ranges of values for all hyperparameters we want to tune in the form of a dictionary:</p>
		<br/>
		<p class="style0">meta_gbc = GradientBoostingClassifier()</p>
		<br/>
		<p class="style0">param_dist = {'n_estimators': list(range(10, 210, 10)), \</p>
		<br/>
		<p class="style0">              'criterion': ['mae', 'mse'],\</p>
		<br/>
		<p class="style0">              'max_features': ['sqrt', 'log2', 0.25, 0.3, \</p>
		<br/>
		<p class="style0">                               0.5, 0.8, None], \</p>
		<br/>
		<p class="style0">              'max_depth': list(range(1, 10)), \</p>
		<br/>
		<p class="style0">              'min_samples_leaf': list(range(1, 10))}</p>
		<br/>
		<p class="style0">Define the parameters with which to initialize the RandomizedSearchCV object and use K-fold cross-validation to identify the best model hyperparameters. Define the parameters required for random search, including cv as 5, indicating that the hyperparameters should be chosen by evaluating the performance using 5-fold cross-validation. Then, initialize the RandomizedSearchCV object and use the .fit() method to initiate optimization:</p>
		<br/>
		<p class="style0">rand_search_params = {'param_distributions': param_dist, \</p>
		<br/>
		<p class="style0">                      'scoring': 'accuracy', 'n_iter': 100, \</p>
		<br/>
		<p class="style0">                      'cv': 5, 'return_train_score': True, \</p>
		<br/>
		<p class="style0">                      'n_jobs': -1, 'random_state': 11 }</p>
		<br/>
		<p class="style0">random_search = RandomizedSearchCV(meta_gbc, **rand_search_params)</p>
		<br/>
		<p class="style0">random_search.fit(X_train, y_train)</p>
		<br/>
		<p class="style0">You should get the following output:</p>
		<br style="line-height: 1,4"/>
		<div>
			<img src="../Images/image-B4U09VDI.jpg" alt="Figure 7.36: The RandomizedSearchCSV object&#13;&#10;" height="100%"/>
		</div>
		<br/>
		<p class="style0" style="text-align: center">Figure 7.36: The RandomizedSearchCSV object</p>
		<br/>
		<p class="style0">Once the tuning is complete, find the position (iteration number) at which the highest mean test score was obtained. Find the corresponding hyperparameters and save them to a dictionary:</p>
		<br/>
		<p class="style0">idx = np.argmax(random_search.cv_results_['mean_test_score'])</p>
		<br/>
		<p class="style0">final_params = random_search.cv_results_['params'][idx]</p>
		<br/>
		<p class="style0">final_params</p>
		<br/>
		<p class="style0">You should get the following output:</p>
		<br style="line-height: 1,4"/>
		<div>
			<img src="../Images/image-Q75G5A0N.jpg" alt="Figure 7.37: Hyperparameters&#13;&#10;" height="100%"/>
		</div>
		<br/>
		<p class="style0" style="text-align: center">Figure 7.37: Hyperparameters</p>
		<br/>
		<p class="style0">Split the training dataset further into training and validation sets and train a new model using the final hyperparameters on the training dataset. Use scikit-learn's train_test_split() method to split X and y into train and validation components, with the validation set comprising 15% of the dataset:</p>
		<br/>
		<p class="style0">train_X, val_X, \</p>
		<br/>
		<p class="style0">train_y, val_y = train_test_split(X_train, y_train, \</p>
		<br/>
		<p class="style0">                                  test_size=0.15, random_state=11)</p>
		<br/>
		<p class="style0">train_X.shape, train_y.shape, val_X.shape, val_y.shape</p>
		<br/>
		<p class="style0">You should get the following output:</p>
		<br/>
		<p class="style0">((386, 30), (386,), (69, 30), (69,))</p>
		<br/>
		<p class="style0">Train the gradient-boosted classification model using the final hyperparameters and make predictions in relation to the training and validation sets. Also, calculate the probability regarding the validation set:</p>
		<br/>
		<p class="style0">gbc = GradientBoostingClassifier(**final_params)</p>
		<br/>
		<p class="style0">gbc.fit(train_X, train_y)</p>
		<br/>
		<p class="style0">preds_train = gbc.predict(train_X)</p>
		<br/>
		<p class="style0">preds_val = gbc.predict(val_X)</p>
		<br/>
		<p class="style0">pred_probs_val = np.array([each[1] \</p>
		<br/>
		<p class="style0">                 for each in gbc.predict_proba(val_X)])</p>
		<br/>
		<p class="style0">Calculate accuracy, precision, and recall for predictions in relation to the validation set, and print the confusion matrix:</p>
		<br/>
		<p class="style0">print('train accuracy_score = {}'\</p>
		<br/>
		<p class="style0">.format(accuracy_score(y_true=train_y, y_pred=preds_train)))</p>
		<br/>
		<p class="style0">print('validation accuracy_score = {}'\</p>
		<br/>
		<p class="style0">.format(accuracy_score(y_true=val_y, y_pred=preds_val)))</p>
		<br/>
		<p class="style0">print('confusion_matrix: \n{}'\</p>
		<br/>
		<p class="style0">.format(confusion_matrix(y_true=val_y, y_pred=preds_val)))</p>
		<br/>
		<p class="style0">print('precision_score = {}'\</p>
		<br/>
		<p class="style0">.format(precision_score(y_true=val_y, y_pred=preds_val)))</p>
		<br/>
		<p class="style0">print('recall_score = {}'\</p>
		<br/>
		<p class="style0">.format(recall_score(y_true=val_y, y_pred=preds_val)))</p>
		<br/>
		<p class="style0">You should get the following output:</p>
		<br style="line-height: 1,4"/>
		<div>
			<img src="../Images/image-RRBUP7VU.jpg" alt="Figure 7.38: Evaluation scores and the confusion matrix&#13;&#10;" height="100%"/>
		</div>
		<br/>
		<p class="style0" style="text-align: center">Figure 7.38: Evaluation scores and the confusion matrix</p>
		<br/>
		<p class="style0">Experiment with varying thresholds to find the optimal point having a high recall.</p>
		<br/>
		<p class="style0">Plot the precision-recall curve:</p>
		<br/>
		<p class="style0">plt.figure(figsize=(10,7))</p>
		<br/>
		<p class="style0">precision, recall, \</p>
		<br/>
		<p class="style0">thresholds = precision_recall_curve(val_y, \</p>
		<br/>
		<p class="style0">                                    pred_probs_val)</p>
		<br/>
		<p class="style0">plt.plot(recall, precision)</p>
		<br/>
		<p class="style0">plt.xlabel('Recall')</p>
		<br/>
		<p class="style0">plt.ylabel('Precision')</p>
		<br/>
		<p class="style0">plt.show()</p>
		<br/>
		<p class="style0">The output will be as follows:</p>
		<br style="line-height: 1,4"/>
		<div>
			<img src="../Images/image-PQXLFL93.jpg" alt="Figure 7.39: Precision recall curve&#13;&#10;" height="100%"/>
		</div>
		<br/>
		<p class="style0" style="text-align: center">Figure 7.39: Precision recall curve</p>
		<br/>
		<p class="style0">"""</p>
		<br/>
		<p class="style0">Plot the variation in precision and recall with increasing threshold values.</p>
		<br/>
		<p class="style0">"""</p>
		<br/>
		<p class="style0">PR_variation_df = pd.DataFrame({'precision': precision, \</p>
		<br/>
		<p class="style0">                                'recall': recall}, \</p>
		<br/>
		<p class="style0">                                index=list(thresholds)+[1])</p>
		<br/>
		<p class="style0">PR_variation_df.plot(figsize=(10,7))</p>
		<br/>
		<p class="style0">plt.xlabel('Threshold')</p>
		<br/>
		<p class="style0">plt.ylabel('P/R values')</p>
		<br/>
		<p class="style0">plt.show()</p>
		<br/>
		<p class="style0">You should get the following output:</p>
		<br style="line-height: 1,4"/>
		<div>
			<img src="../Images/image-5EQYQMWH.jpg" alt="Figure 7.40: Variation in precision and recall with increasing threshold values&#13;&#10;" height="100%"/>
		</div>
		<br/>
		<p class="style0" style="text-align: center">Figure 7.40: Variation in precision and recall with increasing threshold values</p>
		<br/>
		<p class="style0">Finalize a threshold that will be used for predictions in relation to the test dataset. Let's finalize a value, say, 0.05. This value is entirely dependent on what you feel would be optimal based on your exploration in the previous step:</p>
		<br/>
		<p class="style0">final_threshold = 0.05</p>
		<br/>
		<p class="style0">Predict the final values in relation to the test dataset and save them to a file. Use the final threshold value determined in Step 10 to find the classes for each value in the training set. Then, write the final predictions to the final_predictions.csv file:</p>
		<br/>
		<p class="style0">pred_probs_test = np.array([each[1] \</p>
		<br/>
		<p class="style0">                  for each in gbc.predict_proba(X_test)])</p>
		<br/>
		<p class="style0">preds_test = (pred_probs_test &gt; final_threshold).astype(int)</p>
		<br/>
		<p class="style0">preds_test</p>
		<br/>
		<p class="style0">The output will be as follows:</p>
		<br style="line-height: 1,4"/>
		<div>
			<img src="../Images/image-M3PSVYTK.jpg" alt="Figure 7.41: Prediction for final values for the test dataset&#13;&#10;" height="100%"/>
		</div>
		<br/>
		<br/>
		<p class="style0" style="text-align: center">Figure 7.41: Prediction for final values for the test dataset</p>
		<br/>
		<p class="style0">Alternatively, you can also get the output in CSV format:</p>
		<br/>
		<p class="style0">with open('final_predictions.csv', 'w') as f:</p>
		<br/>
		<p class="style0">    f.writelines([str(val)+'\n' for val in preds_test])</p>
		<br/>
		<p class="style0">The output will be a CSV file as follows:</p>
		<br style="line-height: 1,4"/>
		<div>
			<img src="../Images/image-B4Q64TC3.jpg" alt="Figure 7.42: Output for the final values&#13;&#10;" height="100%"/>
		</div>
		<br/>
		<p class="style0" style="text-align: center">Figure 7.42: Output for the final values</p>
		<br/>
		<h4 class="style2">Note</h4>
		<br/>
		<p class="style2">To access the source code for this specific section, please refer to https://packt.live/2Ynw6Lt.</p>
		<br/>
		<p class="style2">You can also run this example online at https://packt.live/3erAajt. You must execute the entire Notebook in order to get the desired result.</p>
		<div style="page-break-before: always;"/>
	</body></html>