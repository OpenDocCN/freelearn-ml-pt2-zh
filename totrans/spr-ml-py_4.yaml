- en: Advanced Topics in Supervised Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we''re going to focus on some advanced topics. We''ll cover
    two topics: recommender systems and neural networks. We''ll start with collaborative
    filtering, and then we''ll look at integrating content-based similarities into
    collaborative filtering systems. We''ll get into neural networks and transfer
    learning. Finally, we''ll introduce the math and concept behind each of these,
    before getting into Python code.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Recommended systems and an introduction to collaborative filtering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matrix factorization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Content-based filtering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural networks and deep learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using transfer learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, you will need to install the following software, if you haven''t
    already done so:'
  prefs: []
  type: TYPE_NORMAL
- en: Jupyter Notebook
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anaconda
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code files for this chapter can be found at [https:/​/​github.​com/​PacktPublishing/
  prefs: []
  type: TYPE_NORMAL
- en: Supervised-Machine-Learning-with-Python](https://github.com/PacktPublishing/Supervised-Machine-Learning-with-Python).
  prefs: []
  type: TYPE_NORMAL
- en: Recommended systems and an introduction to collaborative filtering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we'll cover collaborative filtering and recommender systems.
    We'll start out by explaining what may constitute a recommender system, how users
    willingly share loads of data about themselves, without knowing it, and then we'll
    cover collaborative filtering.
  prefs: []
  type: TYPE_NORMAL
- en: Whether you realize it or not, you interact with numerous recommender systems
    on a daily basis. If you've ever purchased from Amazon, or browsed on Facebook,
    or watched a show on Netflix, you've been served some form of personalized content.
    This is how e-commerce platforms maximize conversion rates and keep you coming
    back for more.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the marks of a really good recommender system is that it knows what
    you want whether you already know it or not. A good one will make you really wonder:
    how did they know that? So, it turns out that humans are extraordinarily predictable
    in their behavior, even without having to share information about themselves,
    and we call that voting with our feet, meaning that a user may profess to enjoy
    one genre of movie, say comedy, but disproportionately consume another, say romance.
    So, the goal of a recommender system is simply to get you to bite; However, the
    secondary goal generally differs based on the platform itself. It could be to
    maximize revenue for the seller, create satisfaction for the customer, or any
    number of other metrics. But what really makes these so interesting is that they''re
    directly consumable by human beings, whereas so many other **machine learning**
    (**ML**) models exist to replace an automated process.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example, explaining voting with your feet:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c749c0af-0f08-44c1-b582-95fa2b95603b.png)'
  prefs: []
  type: TYPE_IMG
- en: This user says he likes football, hot wings, and water skiing. And yet his ratings
    history shows that he's thumbed up one wing restaurant, thumbed down another,
    and then thumbed up a movie cinema. So, what this means is that there's something
    about the second wing restaurant that he didn't like. Maybe it was the ambiance,
    or maybe it was a wing sauce. Whatever it was, his interest in hot wings—his professed
    interest in hot wings—is more nuanced than he originally led us to believe. And,
    likewise, he's expressed an interest in movies, even though he's not disclosed
    it. So, the point here is that people say more with their actions than they do
    with their words, and they're more honest with their actions than they are with
    their words. We can exploit that with recommender systems to learn these nuanced
    patterns between items and people's interests.
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative filtering is a common family of recommender systems. It's based
    on a concept known as **homophily**, which is basically *birds of a feather flock
    together*. So, that is, if you like something, people who also like that item
    probably share some other common interests with you; now we have a good pool of
    interest to start recommending things to one another.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a typical collaborative filtering system, this is the format our data is
    going to resemble:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/614624c4-1538-437a-afc7-0bb5068263f1.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding screenshot, users are shown along the *y* axis—which are rows—and
    items are shown along the *x* axis—which are columns. You might have explicit
    ratings, which are usually continuous along this continuum, or implicit, which
    are commonly binary. What we're showing here is explicit. The question we seek
    to answer is what's the predicted rating for a user? But to get there, we have
    to somehow compute the similarities between the items. This is a form of collaborative
    filtering called item-to-item collaborative filtering, and we can only compute
    similarities between the items that have been mutually rated by a user. This usually
    works best for explicitly rated systems; it's based on a paper that was published
    by Amazon several years ago.
  prefs: []
  type: TYPE_NORMAL
- en: 'Computing similarities between items is straightforward. We can compute pairwise
    similarities using one of several common metrics, including the **Pearson correlation**
    or cosine similarity. For example, we''re going to use cosine similarity as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0a4dde7f-f4c5-4c07-bd5b-7ea6512187f0.png)'
  prefs: []
  type: TYPE_IMG
- en: It's computed in a very similar fashion to what we looked at with clustering
    in [Chapter 3](028b1786-df10-4e2b-96be-541675edd2cd.xhtml),*Working with Non-Parametric
    Models*, the **Euclidean distance**. However, this is computing similarity rather
    than spatial distance. So, it's the exact inverse of the concept, but computed
    in a similar fashion.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since our data is so sparse, we''re going to start out by putting it into a
    sparse CSR matrix using SciPy, and rather than having to store 32 elements, now
    we only have to store 14:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This is a dense matrix based on what we would actually see. So, you can imagine
    how handy this becomes when we have thousands of users and millions of items—as
    Amazon does, for instance.
  prefs: []
  type: TYPE_NORMAL
- en: We're simply going to compute the pairwise cosine similarities of the transpose
    of the matrix. We have a lot of zeros in here. It's not that a lot of these are
    orthogonal, which, mathematically, is what a cosine similarity would represent
    with a zero; it's that we're experiencing something called the item cold start,
    where there are several items that have never been mutually rated together. And,
    therefore, we cannot effectively compute the similarity on the basis of ratings
    alone.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we will see how to generate predictions for a given user giving their history
    in the computed items similarities. In the following example, we are using the
    same user and we''re just predicting for `user_3`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: So, computing predictions is easy enough in this algorithm. You just compute
    the dot product of that user's ratings vector and the similarities matrix. Then, `argsort`
    it to descending order, in a very similar fashion to how we did with nearest neighbors,
    but the inverse in terms of descending versus ascending. So, there are things
    to note here. First, the predicted rating exceeds the scale of the ground truth
    rating of `6.12`. We only rated up to five, but we can't guarantee bounded ratings.
    So, we could either call those ratings or use some other strategy, but the other
    two ratings are actually the ones that the user has rated before. If you look
    back to the ratings matrix, both of these were rated as one star by the user.
    So, we can see that this is not a great recommender model with its low rank and
    low number of users.
  prefs: []
  type: TYPE_NORMAL
- en: Recommender systems are technically supervised learning, but they differ in
    the traditional sense of the *x*, *y* pairing since our ground truth is technically
    our data itself. So, in our example, we could look at the ratings for item four and
    one, and say how far we were off from the ground truth.
  prefs: []
  type: TYPE_NORMAL
- en: Item-to-item collaborative filtering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s look at the code. This is item-to-item collaborative filtering. Let''s
    start with the `base.py` file that is present in `packtml/recommendation`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This `base` class is called `RecommenderMixin`. It''s simply an interface.
    There are two methods: one is already written for all subclasses, and that''s
    `recommend_for_all_users`; the other is `recommended_for_user`. So, we need to
    override it based on the subclass. The subclass we''re going to look at is item-to-item
    collaborative filtering.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following `itemitem.py` file, we see two parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We have `R` and `k`. `R`, which is our ratings matrix, it is different from
    other base estimators in that we don''t have the corresponding `y` value. `R`
    is our ground truth as well as the training array. `k` is a parameter that we
    can use to limit the top number of items that are similar. It helps reduce our
    space that we''re comparing within and makes computations easier. So, for the constructor,
    the fit procedure is simply computing the similarity array via the `compute_sim`
    function. We take the `R` array, transpose it so items are along the row axis,
    and then we compute the cosine similarity between the rows, which are now the
    items. We have an *n x n* matrix, the first *n* stands for the November matrix
    and the second *n* is the dimensionality of the number of items. Basically, we''re
    going to say anything that''s not in `top_k`, we''ll set to zero similarity. One
    of the strategies here is that it allows us to augment our similarity matrix in
    a way that, otherwise, we couldn''t. And that''s what we''re doing: argsorting
    into the descending order. We want the most similar first, argsorting along the
    columns. We take the similarity matrix and store that in `self.similarity`. And
    we''re going to use that when we compute predictions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, `recommend_for_user` is the function that we have to override in the super
    abstract interface. We can take several arguments. So, we have the user vector,
    which is an index, and *n*,which is the number of recommendations we want to produce.
    Now we get `user_vector` out of `R`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The recommendations—the raw recommendations—are the inner products between the
    user vector and the similarity matrix, which produces an *nD* or *1D* array in
    NumPy.
  prefs: []
  type: TYPE_NORMAL
- en: 'We get `item_indices` with the help of an `arange` method in NumPy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We're going to order this based on the descending `argsort` of the recommendations.
    Now we can limit them to the top `n` if we want to.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to produce recommendations for everything, you can just pass `None`
    as `n`. We''re going to return `items`, `indices`, and `recommendations`, which
    are the predicted ratings for each of those corresponding items, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We go to the `example_item_item_recommender.py` file. We''ll load up the interestingly
    `titled` dataset called `get_completely_fabricated_ratings_data`, which is available
    in the `data.py` file. Here, we''ve several users, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Let's say that user 0 is a classic 30-year-old millennial who loves the nostalgia
    of the 90s. So, they highly rate `The Princess Bride`, `Ghost Busters`, and `Ghost
    Busters 2`. User 1 is a 40-year-old who only likes action movies. So, they rated
    `Die Hard` and `Pulp Fiction`. User 2 is a 12-year-old whose parents are fairly
    strict, so we can assume that user 2 has not watched `Pulp Fiction` or anything
    like that. But user 2 has watched `Ghost Busters`, `Ghost Busters 2`, and `The
    Goonies`. And user 2 rated them all pretty highly. User 3 has seen it all. And
    user 4 has just opened a Netflix account and hasn't had the chance to watch too
    much. So, user 4 is probably going to be the one we're interested in producing
    recommendations for.
  prefs: []
  type: TYPE_NORMAL
- en: All this is a NumPy array. We're returning a dense array. You can return this
    as a sparse array.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `example_item_item_recommender.py` file that is present in `examples/recommendation`,
    we''re going to get the `R` ratings matrix and `titles` from `get_completely_fabricated_ratings_data`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We create a `recommender` item with `k=3`. We only retain the three most similar
    corresponding items for each of the items. And then we produce the recommendations
    for user 0.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see what the top three rated movies are for user 0 if we run the `example_item_item_recommender.py`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4b81ee6d-5478-4e70-86f7-dde29b7d95dd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'User 0''s top three rated movies are: `Ghost Busters`, `The Goonies`, and `Pulp
    Fiction`. This means user 0 has rated `Ghost Busters` and `The Goonies` highly
    but has not rated `Pulp Fiction`.'
  prefs: []
  type: TYPE_NORMAL
- en: We can also see that the mean average precision is roughly 2/3\. The mean average
    precision is a metric that we're going to use for recommender systems. It actually
    comes out of the information retrieval domain. It's not like, say, mean absolute
    error or mean squared error. What we're doing is stating what proportion of the
    ones we recommend existed in the ground truth set. In this case, it means which
    ones the user rated highly to begin with, which shows that the ones we produced
    were pretty good.
  prefs: []
  type: TYPE_NORMAL
- en: Matrix factorization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we're going to look into recommender systems and introduce
    matrix factorization techniques. In typical collaborative filtering problems,
    we have users along one axis and items or offers along the other axis. We want
    to solve for the predicted rating for a user for any given item, but to get there
    we have to somehow compute the affinity between the users or the item. In the
    previous section, we looked at item-to-item collaborative filtering, where we
    explicitly computed the similarity matrix using the cosine similarity metric,
    but now we want to explore a method that's not going to explicitly compare items
    to items or users to users.
  prefs: []
  type: TYPE_NORMAL
- en: 'Matrix factorization is a form of collaborative filtering that focuses on the
    intangibles of products. At a conceptual level, every product or restaurant, for
    example, has intangibles that cause you to like, dislike, or remain indifferent
    toward them. For example, for a restaurant, maybe the atmosphere or the vibe you
    get outweighs the menu. Or, consider the following statement: the food''s terrible
    but the happy hour is great. In this case, we''re interested in learning the hidden
    or latent variables that underlie and manifest themselves throughout patterns
    in the data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Matrix factorization is going to allow us to discover these latent variables
    by decomposing our single ratings matrix into two low-rank matrices that, 2 when
    multiplied, approximate the original ratings matrix. Intuitively, we''re learning
    about these hidden factors or latent variables and learning how our users and
    items score against them. As shown in the following diagram, one of the low-rank
    matrices maps the users'' affinities for the discovered factors and the other
    maps that item''s rankings on the factors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4934bcc4-61ec-4baf-9f3a-3d5399ace61b.png)'
  prefs: []
  type: TYPE_IMG
- en: A drawback in matrix factorization is the lack of clarity or intuition behind
    what can make up a factor. It's similar to a **principal component **analysis (**PCA**)
    type technique, where a factor can be conceptualized as a topic. A careful, insightful
    analyst who has lots of subject matter expertise could feasibly extract meaning
    from topics, but it's very difficult to do so and, as a result, it's not typically
    pursued given its difficulty. For example, maybe **Factor 1** in the preceding
    diagram is a divey atmosphere. So, the wing shop is rated in varying degrees of
    divey-ness. As you can see on the right-hand side of the preceding diagram, there's
    a strong affinity between **Wing Store A** and the first factor, which is **Dive
    bar**. You can also assume that **The Sports Bar** might rate pretty highly on
    that scale. Then, perhaps **Factor 2** is a place that has some health-conscious
    options. So, the strength of that connection is the level at which a person or
    an offering ranks against the latent factor. You can see this on both the left-and
    the right-hand sides of the preceding diagram.
  prefs: []
  type: TYPE_NORMAL
- en: 'Essentially, we have a ratings matrix, *Q*. In different literature, it''s
    referred to as either *Q* or *R*. We''re going to call it *Q* here. We want to
    discover two lower rank matrices, *X* and *Y*, such that the product of the two
    approximate the ratings matrix. That is, *Q* or *Q* prime is approximately equal
    to *X.Y^T*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9d2b83e8-9d17-4d53-9871-343eaf4841a3.png)'
  prefs: []
  type: TYPE_IMG
- en: Our objective function is at the bottom and is basically a regularized mean
    squared error. So, we're looking at the mean squared error, or the reconstruction
    error, between *X* and *Y* and *Q* prime, and then we have the regularization
    term over on the other side, with lambda.
  prefs: []
  type: TYPE_NORMAL
- en: For the math folks, factorizing a matrix is nothing new. But doing so in the
    context of finding such low-rank matrices in a non-convex optimization problem
    might be a bit of a challenge. So, the approach we're going to see is called **Alternating
    Least Squares** (**ALS**).
  prefs: []
  type: TYPE_NORMAL
- en: 'The ALS algorithm is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Initialize two random matrices, *X* and *Y*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set empty values of *Q* and *O*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Beginning with *X*, solve the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7d8bb3e8-3235-4620-928a-0563034418ed.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now solve for *Y* with the new *X*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4aa21afa-3c85-45b0-81d8-c752d7bc6bdb.png)'
  prefs: []
  type: TYPE_IMG
- en: Iterate, alternating between *X* and *Y* until convergence
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Essentially, we're going to alternate between solving each respective matrix
    with respect to the other, and we'll eventually reach a point of convergence.
    So, we start out by initializing both *X* and *Y* to random values. Then, starting
    with *X*, we solve for *X* prime. Now that we have a more refined version of *X*
    prime, we can use that to solve for *Y* prime. Each matrix creates a better solution
    for the other at each iteration. And we can alternate like this for as many iterations
    as we like, or until we hit a point of diminishing returns, where we would say
    that we've converged.
  prefs: []
  type: TYPE_NORMAL
- en: 'A quick note on the notation here: the *I* that you can see next to lambda
    is simply an *F x F* identity matrix, where *F* is the number of latent factors
    that we want to discover. We multiply that by the regularization parameter lambda.
    So, along the diagonal axis we have lambda, and then the rest is simply zeros.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a hackneyed 30-line approximation of ALS in Python. We start out with
    defining `Q` or the ratings matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This is the rating that we've seen in the earlier example, and in the previous
    section. Now we're going to get a Boolean mask, `nan_mask`. First, we're going
    to set all the missing values to zero for the ensuing computations. Next, we're
    going to initialize `I` as our identity matrix and multiply it by lambda. We only
    have to do that one time, which is nice. Lambda is just 0.01 for now, but that's
    a hyperparameter that can be tuned using cross-validation. So, the higher lambda
    is, the more we'll regularize. Then, we initialize `X` and `Y` with `random_state`.
    `X` is going to be equal to *M x F*, that is, the number of users by the number
    of factors. `Y` is going to be equal to the number of factors by the number of
    items: *F x N*.
  prefs: []
  type: TYPE_NORMAL
- en: In iterating, we solve for `X`, and then we solve for `Y` given the new `X`.
    Then, we compute our training loss, which is again the masked version of the mean
    squared error, where we mask out the missing values from the original ground truth
    array, which is our ratings array. And then we continue to iterate until we reach
    convergence.
  prefs: []
  type: TYPE_NORMAL
- en: At the bottom of the preceding code, you can see the output of the approximation
    between `X` and `Y`. It is an approximation. If you look at the definition of
    `Q`, 3 and then the output at the bottom, it looks pretty similar. So, the way
    that we would create predictions at the end is that we exploit the error in the
    whole system, and return the highest predicted items for a user filtering the
    previously rated ones. So, user 4, (the very last user), would get a recommendation
    for the steakhouse that is *2.0*, and this is the highest non-previously rated
    item for that user. This is actually just a result of the multiplication error
    or the approximation error.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following graph, you can see how the training loss diminishes over each
    iteration:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7195d7ee-a2ae-4df0-a5e9-142bc00d8fb4.png)'
  prefs: []
  type: TYPE_IMG
- en: Matrix factorization in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we wanted to decompose our ratings matrix into two
    low-rank matrices in order to discover the intangible latent factors that drive
    consumers' decisions. One matrix maps the users' affinities for the discovered
    factors and the other maps the items' rankings on those factors.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let''s look at how this can be implemented in Python. We''ve two files,
    `als.py` and `example_als_recommender`. Let''s see our `als.py` file. In the last
    section, we saw the item-to-item collaborative filter; ALS is very similar. It''s
    going to implement `RecommenderMixin`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We have several parameters for ALS. The first one, and the only non-optional
    one, is `R`, our ratings matrix. In some of the math we've seen, we've referred
    to this interchangeably as `R` and `Q`. Again, that's kind of a quirk of the literature.
    Depending on what papers you're reading, it's one or the other. And the second
    parameter we're going to take is `factors`.The `factors` parameter is the number
    of latent variables we want to discover. I have used float, but you can use an
    integer. The floating point is just going to be bound between zero and one. `n_iter`
    is the number of iterations. ALS, in this module, does not support early convergence
    or early stopping. That's something that you could absolutely write. But if you
    have too many iterations, what happens is you're probably going to overfit your
    data. Lambda is our regularization parameter, and then you can just pass `random_state` as
    a way for reproducibility.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the first step, as always, we''re going to check our array to make sure
    that we have only floating points:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: We are going to allow missing data here, because missing data is natural in
    recommender systems. And we can almost guarantee there's always going to be missing
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, we''re making sure that our factor is an integer. And
    if it''s `float`, we figure out the number of `factors` we''re going to discover:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'So, `W` here is equal to `nan_mask`, which we looked at in the previous section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This is going to be, essentially, a weighting array that says whether or not
    the value was missing to begin with. And so, we use this to mask our ground truth
    out of the ratings matrix when we compute our mean squared error during our iterations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we initialize `Y`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We are not initializing `X` because we know that that's going to be the first
    one we solve for in our iterations. So, as we have seen in the previous section,
    we also initialize `I` as the identity matrix—that is, *F x F*—and multiply it
    by our regularization parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we''re going to iterate, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Begin by solving for `X`, and then solve for `Y`. At each iteration, we're going
    to just calculate the training error, which is the mean squared error. We append
    it to the list that we store as a `self` parameter in the following code.
  prefs: []
  type: TYPE_NORMAL
- en: 'The training phase is actually extraordinarily easy for ALS. Now, in the previous,
    section we didn''t see how to concretely generate predictions. We saw the math
    behind it, but we haven''t implemented it. If you call predict on ALS, as shown
    in the following code, it''s simply going to compute the product of the user factors
    and the item factors to return the `R` prime—basically the approximation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: You can pass in `R`, which would ostensibly be the test data. This is the data
    to include new users who weren't included in the fit originally, or it could mean
    that the users have updated their data. But we can recompute the user factors
    if we want to. So, if the users have moved on in time and our fit is about a week
    old, then we can recompute the user factors with respect to the existing item
    factors. Then, at the end, we're just returning the product of `X` and `Y`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we''ll call the `recommend_for_user` function. So, given your test matrix
    and the user index, we want to know what the top `n` items are to recommend for
    a user and we do largely the same thing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We''re going to create this prediction, but extract out the predicted user
    vector. So, we''re using the `self.predict` method, as shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: If we are interested in filtering out the ones we previously saw, we just mask
    those out and return the descending argsorted indices of items that we're interested
    in. This is very similar to what we've seen before when we were looking at spatial
    clustering, but here, all we're doing is computing the approximation of `X` and
    `Y` and argsorting the columns.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at an example in the `example_als_recommender.py` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: You may recall from the preceding code the recommended data. This is the completely
    fabricated data that we went on about in the previous sections. We're going to
    take this same data and we're going to fit ALS on it. We want to know user 0's
    predictions, so, before we run it, we need some information. Let's say user 0
    rated `Ghost Busters` pretty highly, and rated `The Goonies` pretty highly as
    well. This guy knows their stuff! So, this guy is a classic 90s/late 80s millennial.
  prefs: []
  type: TYPE_NORMAL
- en: 'You''ll notice, in the following screenshot, that we have activated my `packt-sml` conda
    environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bfc0e9e8-ca51-4a3a-be29-063f86051706.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The output of the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8e71358d-9e6c-4a09-9a07-701681ebf40f.png)'
  prefs: []
  type: TYPE_IMG
- en: You need to do the same. So, when we run this, we'll get the preceding graph,
    which is showing how the training error diminishes over the iterations, as we
    expect it would. As a result, we would recommend that user 0 watch `Weekend at
    Bernie's` as the top-rated suggestion. And that seems to make sense given `The
    Goonies` and `Ghost Busters`. But then `Pulp Fiction` is a bit violent, and so
    we also recommended `Clockwork Orange`, which also seems to jive with that. So,
    the mean average precision is, essentially, looking at the recommendations and
    then comparing them to the ground truth and saying how many of those were actually
    previously rated highly.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations of ALS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've been using explicit ratings. For example, on Amazon, ratings are between
    one and five stars. The problem here is that explicit rating systems typically
    have trouble getting users to rate the items, because it's easier to consume that
    content than it is to evaluate it from the user side. So, implicit ratings are
    the inverse of explicit ratings and they can be collected by a system, usually,
    without the user's awareness. A lot of times that's more favorable, because it
    doesn't require the user to interact with the system in a secondary sense to explicitly
    rate items, and we can get more data, which means less sparse data. So, implicit
    ratings might include the number of listens to a song. There's really well-known
    ratings dataset collected by the Last FM team that uses implicit ratings, and
    it's commonly used for benchmarking recommender systems. There is an implicit
    variation of ALS, but we only covered the explicit version. But if you check on
    Google for implicit ALS, there's all sorts of literature around it. We encourage
    you to go look it up.
  prefs: []
  type: TYPE_NORMAL
- en: The next challenge of recommenders is sparsity versus density. As we've seen,
    ratings matrices can be pretty sparse. For some systems, such as Amazon, there
    may only be ratings for less than approximately one percent of all items per user,
    and a lot of times even less than that. So, dense matrices are not usually the
    best solution, and oftentimes they're not even feasible. So, we either have to
    use sparse matrices or get really clever with how we distribute the data, so we
    don't totally blow up our memory.
  prefs: []
  type: TYPE_NORMAL
- en: Recommenders typically take a very long time to train. Like many other machine
    learning models, we run into that same kind of thing, but recommenders are a bit
    different in the sense that they have to be updated in much greater frequency,
    in many cases, multiple times per day, depending on the system itself. So, new
    items arriving in a catalog or new users beginning to consume media means that
    the recommender has to be refreshed. But we can't do this online or in real time,
    or we risk taking the system down. So, generally, recommenders are retrained on
    a periodic basis in an offline fashion. And the models are scored in an online
    or more real-time fashion.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we looked at the Python implementation of ALS in the `packtml`
    library and an example. Finally, we discussed some of the real-world challenges
    we face in recommender systems.
  prefs: []
  type: TYPE_NORMAL
- en: Content-based filtering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we're going to wrap up our discussion around recommender systems
    by introducing an entirely separate approach to computing similarities and look
    at how we can use it to augment our collaborative filtering systems.
  prefs: []
  type: TYPE_NORMAL
- en: Content-based recommenders operate similarly to the original item-to-item collaborative
    system that we saw earlier, but they don't use ratings data to compute the similarities.
    Instead, they compute the similarities directly by using provided attributes of
    the items in the catalog. Predictions can then be computed in the same fashion
    as item-to-item collaborative filtering by calculating the product of the ratings
    matrix and similarity matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example of how we might use content vectors to directly compute
    the item similarity matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We're using the same ratings matrix as we have over the last few sections, and
    we've created 11 different attributes about the various restaurants. Generally,
    the content vectors of these dummy-encoded features indicate whether an item belongs
    to a given category. So, you can see the similarity is computed in exactly the
    same fashion. So, we just compute the cosine similarity between the rows. And
    then we even generate predictions in the same way. We compute the product of the
    similarities and the ratings.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations of content-based systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are several notable limitations to content-based systems that make them
    less than ideal in most scenarios. The first of these is the manual nature of
    the feature engineering, which can be extraordinarily tough given that the difficulty
    of collecting the data about the items can be really time-consuming, and many
    times, the data we're presented about an item is limited to a text description.
    So, we're not given this nice encoded matrix and that means we have to extract
    the attributes from descriptions, which can be challenging and extremely time-intensive.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we end up with the largely dummy-encoded set of content vectors, meaning
    it's heavily zero inflated. So, naturally, our similarity computations are going
    to be fairly low with respect to what we might get out of a comparable collaborative
    approaches computation. And, finally, as our feature matrix grows in rank, the
    similarity between the two given items will be orthogonal or zero, so the likelihood
    of that approaches 1\. For more information, you can refer to [https://math.stackexchange.com/questions/995623/why-are-randomly-drawn-vectors-nearly-perpendicular-in-high-dimensions](https://math.stackexchange.com/questions/995623/why-are-randomly-drawn-vectors-nearly-perpendicular-in-high-dimensions).
    It's a loose proof showing that the higher the rank, the more likely it is that
    you approach that orthogonality, which we don't want. All these limitations make
    a good case for why content-based systems are less favorable than collaboratively
    based systems.
  prefs: []
  type: TYPE_NORMAL
- en: But there're also some cases where they can be really useful. One of these is
    called the **cold-start problem**, which we discussed earlier in this section,
    and we encounter in every collaborative filtering application. This is when a
    new item is added and it cannot be compared to an existing item on the basis of
    ratings due to its own lack of ratings. So, the challenge here, apart from being
    unable to compute that similarity, is that if you impute it with a 0 or some other
    random value, you may never present that to a consumer. You implicitly diminish
    the chance that you would ever recommend that item.
  prefs: []
  type: TYPE_NORMAL
- en: In item-to-item collaborative filtering, it also occurs in situations where
    there are two items that have not been mutually rated by the same user, since
    we can't compute the similarity. So, that's an additional case and, in this one,
    it's going to result in a similarity of 0 in our matrix because we impute all
    the missing values with 0, even though we, theoretically, have ratings on which
    to gauge the affinity. In these scenarios, it's useful to have a fallback plan.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we''re fitting an item-to-item collaborative filtering recommender:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: From preceding code, we see several sections from the `packtml` package on our
    ratings data, which we've been using for the last few sections. We're going to
    use the content similarity computations to impute the data that suffers from the
    cold-start problem. When we examine the similarity matrix, you can see that there
    are no more 0s. So, there is a corner case where you might get a 0, and that's
    if you had a missing mutual similarity or a cold-start problem, and then perfect
    orthogonality in the actual content vectors. But we don't see that. So, ostensibly,
    this gets us closer to a more robust model. But you're still restricted to the
    limitations that we have seen before, namely, collecting the content attributes
    and computing those potentially orthogonal vectors.
  prefs: []
  type: TYPE_NORMAL
- en: So, at this point, you're familiar with the concept and you realize content-based
    similarities alone are not very feasible. But they can actually augment your collaborative
    filtering method if you have the right situation and setup. There's been a lot
    of research around using neural networks to automatically hybridize content-based
    and collaborative systems. A lot of them are using neural networks to create features
    from text descriptions a touch informal in an automatic sense, and then creating
    a separate network to factorize the matrices. So, there's a lot of hope in the
    future that content and collaborative systems can exist in parity.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are two papers that are pursuing this approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Hybrid Collaborative Filtering with Neural Networks*, Florian Strub, Jeremie
    Mary, and Romaric Gaudel, 2016'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Hybrid Recommender System Using Semi-supervised Clustering Based on Gaussian
    Mixture Model*, Cyberworlds (CW), 2016 International Conference, pp. 155-158,
    2016'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural networks and deep learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is a huge topic in machine learning, so we can't cover everything in this
    chapter. If you've never seen a neural network before, they look like a giant
    spider web. The vertices of these spider webs are called neurons, or units, and
    they are based on an old-school linear classifier known as a perceptron. The idea
    is that your vector comes in, computes a dot product with a corresponding weight
    vector of parameters, and then gets a bias value added to it. Then, we transform
    it via an activation function. A perceptron, in general, can be canonically the
    same as logistic regression if you're using a sigmoid transformation.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you string a whole bunch of these together, what you get is the massive
    web of perceptrons feeding perceptrons: this is called a multi layer perceptron,
    but it''s also known as a neural network. As each of these perceptrons feeds the
    next layer, the neurons end up learning a series of nonlinear transformations
    in the input space, ultimately producing a prediction in the final layer.'
  prefs: []
  type: TYPE_NORMAL
- en: The history of these models is actually really fascinating. They were first
    proposed in the early 1950s, but their potential was not really unlocked for quite
    a long time, since they're so computationally intensive. Nowadays, though, we
    hear a bout deep learning everywhere, and it's really just referring to the broader
    family of neural networks, including some of their unsupervised and generative
    variants.
  prefs: []
  type: TYPE_NORMAL
- en: So, how does a neural network actually learn? Well, we're going to iteratively
    feed the data through layers of the networks in epochs. Feeding the layer forward
    is as simple as computing a matrix product between one layer and the next, adding
    the bias vector along the column axis, and then transforming the output via the
    activation function. There are a lot of different activation functions you can
    use, but some of the most common ones are the sigmoid; the hyperbolic tangent,
    which is similar to the sigmoid but bounds between negative one and one rather
    than zero and one; and **rectified linear units** (**ReLUs**), which really are
    just flooring functions between the value and zero. It makes sure that nothing
    negative comes out of the units. So, after each epoch or iteration, outside the
    output layer we're going to compute the error of the network, and pass the message
    back up through the layers and they can adjust their weights accordingly. This
    process is called backpropagation. We usually use gradient descent for this.
  prefs: []
  type: TYPE_NORMAL
- en: For our two-layer example, which is really just a single layer in the middle
    with an output layer at the end, we only have to compute two matrix products for
    each epoch. It's been found that how you initialize your weights makes a huge
    difference in the capacity for the network to learn. There are several approaches
    to the strategies for this, but the easiest way is to just initialize them to
    very small values. We typically pick random values between negative and positive
    0.1\. You can go smaller; you can get more clever. We will initialize our biases
    as 1 vectors. Again, there are other clever ways to do this. We're just going
    to use 1, and the weight matrices themselves map one layer to the next. So, going
    from layer 1 to layer 2, we go from three units to four. You can see that dimensionality
    in the number of units. Our corresponding weight matrix is going to be *3 x 4*
    and, likewise, for the second one it's going to be *4 x 2*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we''re just expressing our network as a system of linear equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e1a9a508-461c-4283-8b21-ad4998d3eba1.png)'
  prefs: []
  type: TYPE_IMG
- en: The first layer is passed to the second layer in that nested parentheses on
    the inside, and then to the last layer on the outer parentheses. And what we end
    up with is this real matrix in *m x 2*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a forward pass in a snippet of highly oversimplified Python code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: We're defining our activation function. `f` is a logistic or sigmoid transformation.
    `lam`, or `lambda`, is going to be our learning rate, which we learned about when
    we talked about gradient descent. And you'll remember this from logistic regression,
    where we can control the rate of how we descend that gradient. After initializing
    `X` and `y`, which we're just using as random values, we create hidden `H1` and
    `H2` layers, and `b1` and `b2` biases. In this example, we created the layers
    using the NumPy `rand` function. But this is where you'd want to get clever and
    bound them between negative `0.1` and `0.1` on the positive scale. Then, the result
    of our hidden layer one, `H1_res`, is computed by applying our `f` activation
    function to the `AX + b` linear equation. So, we just compute the inner product
    between `X` and `H1`, and then add the bias vector along the column vectors.
  prefs: []
  type: TYPE_NORMAL
- en: The output is computed by applying the second hidden layer to the output of
    the first in the same fashion. So, we're chaining these linear systems into one
    another, and applying this nonlinear transformation to that output.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, now that we have our first epoch complete, we need to adjust the weights
    of the network to get an error-minimizing state because, right now, the chances
    are our network produced a terrible error. And so, here begins the fun of backpropagation,
    and if you thought we had a lot of calculus earlier in this book, you''re in for
    a treat here. We''re going to compute four derivatives: two for each layer. We
    use them to adjust the weight in the layer immediately above, much like we did
    in logistic regression. Then, the next time we do a forward pass, the weights
    have been adjusted and we''ll, in theory, have less error in the network than
    we did previously.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we''re implementing backpropagation from scratch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'We''re going to compute four derivatives: the derivative and loss function
    with respect to each of the weights layers—that''s two—and the bias layers—that''s
    another two. The first delta is really easy to compute: it''s simply the predicted
    probabilities, which is this matrix minus the truth indices of `y`. Next, we''re
    going to compute the first layer''s output with the delta we just computed, which
    is going to be a derivative with respect to the last layer, which is the output
    layer. And, after that, we can sum along the columns of our results to get the
    derivative of our second layer biases.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the same process to compute our derivatives for the next `H1` and
    `b1` layer. Once we have those gradients computed, we can update the weights and
    biases in the same fashion as we did in logistic regression, which is by multiplying
    each derivative by the negative learning rate, and adding that to the weights
    matrices and `H1` and `b1`, and `H2` and `b2` bias vectors, respectively. And
    now we''ve updated our weights and biases along the axis of greatest change in
    our function: the loss function.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, if you backpropagate correctly, you''re going to get error terms that converge
    similarly to the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b327eaec-85b2-43ee-9655-f34f1aef814b.png)'
  prefs: []
  type: TYPE_IMG
- en: Tips and tricks for training a neural network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here are some tricks that can make your life easier when you're actually training
    a neural network from scratch. You can stop your training a bit early to avoid
    overfitting. In the preceding graph, you can see there's a long tail where the
    error does not decrease anymore and we're still training. It's at a point around
    epoch 25 or 30\. We could have stopped early.
  prefs: []
  type: TYPE_NORMAL
- en: Regularization and dropout are ways that can prevent your network from overfitting.
    Now, for extremely large data, you can do partial fits per epoch, meaning that
    you can fit many batches through your network for each forward pass so that you
    don't have to hold everything in memory. It also makes backpropagation a little
    easier, and different activation functions are going to give you different results.
    So, always try them out. And, finally, always use cross-validation, as we've talked
    about before, to select your model hyperparameters, so that you don't inadvertently
    create model leakage with the validation set, or even with overfitting your training
    set.
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We're going to iteratively feed the data through layers in the network in epochs.
    After each iteration, we're going to compute the error of the network and the
    output, and pass the signal back up through the layers so they can adjust their
    weights accordingly. So, that's all for the theory and recaps.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have two files we''re going to look at. We have the source code and an example: `base.py`
    and `mlp.py`, which stands for multilayer perceptron. Let''s start with `base.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: We have two functions. One function, `tanh`, is a hyperbolic tangent function
    we're going to use as our activation function. And this is just a wrapper for
    `np.tanh`. Then, we have a `NeuralMixin` class, which is kind of an abstract interface
    we're going to use for exporting the weights and biases of each of our networks.
  prefs: []
  type: TYPE_NORMAL
- en: In `mlp.py`, we're going to depend on the typical `check_X_y` from scikit-learn,
    `check_classification_targets`. Because we're only performing either binary or
    multiclass classification, we're going to use softmax, and then `check_random_state`.
    So, we can use a replicable `random_state` inside of our neural network.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a function outside of the class itself—`calculate_loss`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Essentially, this is going to be our objective function inside of our neural
    network that we can compute, and backpropagate that loss up through the network.
    Softmax is going to be the generalization, that is, our logistic function applied
    to multiple classes. So, that's what we get out of this. From the `K` matrix,
    where `K` is the dimension of the number of classes, we have a three-class problem;
    we can compute probabilities for the membership of each of those classes. And
    that's what softmax does.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now our neural net classifier is going to take a number of different parameters,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: As usual, we have our `X` and `y`, and then we have `hidden`, which is going
    to be a tuple or some other iterable that has positional elements indicating the
    number of units in each layer. So, if we wanted to have two layers, we might have
    `X`, `25`, where each layer would have `25` units. There is no exact science to
    determining how many units you want and it kind of depends on your objective.
    If you want to compress the dimensionality, you might make the number of units
    smaller than the input dimensionality. If you want to discover all sorts of nuanced
    features, then you might expand the number of units. The number of iterations
    is actually the number of epochs we're going to perform. The learning rate is
    the lambda that we've seen in logistic regression. Regularization is our `l2`
    penalty that's going to help us prevent overfitting. And `random_state`, again,
    is the seed that we'll use to control `random_state` so this is replicable.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the constructor, all we''re doing is self-assigning different attributes
    to the algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Then, we initialize the weights and biases. We're tracking the last dimension
    of the last matrix, or hidden weight matrix. So, we will start the input with
    `none`. We're going to use the column dimensionality as the input dimensionality
    of the next layer. So, we mentioned in the example that we went from three to
    four. Our dimensionality of the first hidden matrix or hidden layer may be *3
    x 4*. We're tracking the last column dimensionality because that becomes the row
    dimensionality of the next layer. We return to `X`, `y`, `weights`, `biases`,
    and this will be used by subclasses later, as well, which is why it's a class
    function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we start progressing through forward passes of our network. First, we compute
    the forward step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: A forward step is pretty easy. We have `X`, our weights, and our biases. We're
    going to ZIP our weights and biases together so we can track them together. And
    we're just going to compute that product of `X.dot(w)`, `w` being weight, and
    add biases. This is again that `AX` linear system plus `b`. Then, we apply this
    nonlinear transformation, `tanh`. But if you wanted to use sigmoid, you could
    do that. The last layer is slightly different. We're not running `tanh` on the
    last layer, we're actually running softmax. This is a classification problem,
    so we apply softmax to the output of `X` as opposed to `tanh`. And that's the
    output layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the constructor, we''ve computed the first forward step and our first epoch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Now we want to calculate the loss; the loss is just that log loss that we saw
    previously. We're going to track loss per epoch here in `train_loss`. If you want
    to speed this up, you might only calculate the loss, say, every five iterations.
    In the following backpropagation example, we will get a clever idea regarding
    how we implement these gradients in a fashion that's a bit more extensible than
    the two-layer example from the last one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, in the backpropagation function, we compute delta again, which is the
    probabilities of each of the classes minus the truth indices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: That's our first delta. And now, iteratively, what we're going to do is compute
    the derivative as that layer's result times the current delta. We start out with
    the current delta of these probabilities that we just subtracted from. So, now
    that we've got our gradient, we can compute the derivative of our biases by summing
    over the columns in the derivative. Now we have the derivative of the biases,
    and we're going to compute the next delta for the next time we iterate through
    this. The way we use regularization is by multiplying the regularization by `next_weights`.
    So, `next_weights` is the weight's matrix that we will compute the gradient against.
    We regularize it and add that to the derivative, and then we are going to adjust
    the weights. So, we can add `learning_rate` times the delta, or the gradient,
    and we do the same for our biases. We've changed `next_weights` and `next_biases` inside
    of weights and biases. This is a `void` function. It doesn't return anything because
    it all happened in place.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, weights and biases have been iteratively updated. And the next time we
    progress through the iteration – the next epoch—we should see a lower error. As
    such, we''ll continue this through the number of iterations, progress through
    all of our epochs, and save our weights and biases. Then, we will produce a prediction
    and compute those probabilities by doing a forward pass with the softmax at the
    very end. Take the `argmax` of the column: that''s the class that has the highest
    probability. And that''s what we return in a squashed vector.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `example_mlp_classifier` file, we use a similar dataset to what we use
    in decision tree classification, which are these `multivariate_normal` bubbles
    that are kind of clusters, in our two-dimensional space. We''ll do `train_test_split`
    as usual:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: And now we're going to train two neural networks. The first one is only going
    to use four iterations and have a single hidden layer of 10 units. The second
    one is a little more complex. We're going to do 150 iterations with two hidden
    layers of `25` units each.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, we run the `example_mlp_classifier.py` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ddf90324-3d58-4c30-8efb-ca9745dcad6e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We got a pretty good test accuracy with a single hidden layer of 10 units:
    94.4 percent. But you can see that we almost get 100 percent if we have two hidden
    layers at 25 each. We also have the training iterations for the first one.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see in the following graph how the loss kind of jitters around a bit:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/64669de4-b82b-4bfd-a530-913e36491b02.png)'
  prefs: []
  type: TYPE_IMG
- en: But over time, that loss decreases. It's not guaranteed to be a perfect drop
    and it might jump up or drop down a bit, but we can see that, over time, our loss
    hits a point where it's very small. This function that we've learned here in the
    more complex one is a really interesting nonlinear decision boundary. It has a
    little bit of trouble classifying these border points, but this is how we can
    use a neural network to learn a function that's much more complex than something
    that a logistic regression can learn.
  prefs: []
  type: TYPE_NORMAL
- en: Using transfer learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we're going to take it one step further and explore the question
    of whether a neural network could learn from other neural networks and what they've
    already learned. We'll start by covering the concept of transfer learning, and
    then we'll get into some Python code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Transfer learning is essentially the Frankenstein''s monster of machine learning.
    The idea arose from this question: how can I take what some other network has
    already learned and go from there? We''re basically going to do a brain splice
    between several different networks. This can be extremely valuable in cases where
    a network is trained on data that you don''t have access to or the training process
    is the one that would have taken hours or days, as is commonly the case in text
    or image processing domains.'
  prefs: []
  type: TYPE_NORMAL
- en: We don't want to retrain our model because it would take forever, but we want
    to take what we've already learned about the other two classes and start learning
    something else about the other class. Rather than retrain the whole thing, we
    can just use transfer learning to pick up where we left off. So, now that you
    have the idea and the concept behind it, let's look at how that's going to be
    applied to the existing multilayer perceptron framework that we're now familiar
    with.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `transfer.py` file, starting with `TransferLearningClassifier`, there''s
    one more argument than there was in `MLPClassifier`: and that''s the pretrained
    network. That can either be `NeuralNetClassifier` or `TransferLearningClassifier`. But
    we''re just going to take `NeuralNetClassifier` for this example. Similar to the
    MLP constructor, we''re going to spend the first few lines saving everything as
    self attributes, and then we''re going to make sure that whatever you''ve passed
    in as the pretrained network is going to be some form of `NeuralMixin`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Because we have to have access to the weights and the biases from the previous
    classes, we get the pretrained weights and the pretrained biases. We only want
    to initialize the new weights and biases that we can kind of stack on to the end.
    So, if we have a network of four layers before, those are just going to be ancillary.
    We're not going to train those—we're just going to freeze them. Then, we want
    to stack a few layers on the end that we can train and teach new features—new
    characteristics about the new classes we may want to predict. We're going to do
    the initialized weights and biases only for the new weights and biases.
  prefs: []
  type: TYPE_NORMAL
- en: Epochs look slightly different; they look a lot like MLPs, but there's a little
    bit of difference.
  prefs: []
  type: TYPE_NORMAL
- en: So, for each epoch, we're going to perform one pretrained forward step. Basically,
    all we're going to do here is that for each of those layers in the pretrained
    weights and biases, we're going to compute *AX + b* with our `tanh` function on
    it. Notice that even on the output layer, rather than compute a softmax, we're
    going to compute `tanh`, because we're not interested in getting those class probabilities
    anymore. Now we just want to pipe it into the next layer. So, we're going to use
    whatever that activation function is. It could be `sigmoid` or `relu`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we want to take a forward step on the existing or the new weights and bias
    layers that we do want to train:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: We're going to calculate `loss`, and then we're going to backpropagate only
    on the new layers. So, we're not training the old weights and biases at all, but
    we are doing that to the new ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'The predictions are slightly different:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Rather than just compute that single forward step, we're going to compute the
    pretrained forward step, again, because we don't want that softmax in the end
    of the other network. Then, we will compute the normal forward step with the output
    of the pretrained forward step, which will stack the softmax onto the end.
  prefs: []
  type: TYPE_NORMAL
- en: For the predictions, again, we're taking `argmax` of the columns. That is, getting
    the highest probability class from the predict probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at an example file. This is going to look a lot like what we set
    up in our previous MLP example, except we have two datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The first one is going to have those two blobs: the `multivariate_normal` blobs
    that we''ve been using and the majority class. The third here is going to stack
    this third class in between the two. Our transfer learning task is going to be
    learning this new class based on what it''s already learned from the binary classification
    example.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s fit the first neural network that we''ll use, which is our pretrained
    network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: This is going to be very similar to what we saw in the first example, where
    we have a two-layer network with `25` units in each layer. We're going to fit
    `75` epochs with a pretty low learning rate and we'll see how it does on learning
    the binary classification task.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s say we''re predicting some type of disease, and there''s type one
    something and type two something. I''m not going to use diabetes because there''s
    only two types. But let''s say, a third type comes out. Maybe it''s a type of
    Zika virus, and we want to predict whether this new class is present in a patient
    who comes in. We don''t want to retrain everything, because it''s going to take
    forever, perhaps. So, we''re going to just stack this new layer on the end that
    says learn these new features about this third class. And then we''ll produce
    a new output layer for three classes rather than two. We''re only going to do
    `25` new epochs, just based on what we''ve already learned from the previous binary
    classification task. We want to see if we can learn this new class without retraining
    everything. And that''s all we''re going to do here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: And then we're going to plot both out so you can see the decision boundary from
    both the binary and this three-class classification problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s run an example of transfer learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e8008426-04ac-43df-aef3-d7cc146fa30d.png)'
  prefs: []
  type: TYPE_IMG
- en: Our test accuracy is down to `95.2` percent.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see in the following graph that we are able to learn a complex decision
    boundary in the binary classification task:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c7aee88f-511e-437d-af4c-8807b5852299.png)'
  prefs: []
  type: TYPE_IMG
- en: And then we took that and we said let's do transfer learning with a new class,
    and we were still able to learn it really well. So, now we've learned the second
    decision boundary that we built on top of our initial decision boundary and it
    looks really good. So, we get 95.2 percent accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Transfer learning is a flexible concept that'll allow you to stack networks
    together to accomplish far more complex tasks than you thought possible. We covered
    recommender systems and collaborative filtering in particular, and then we looked
    at matrix factorization techniques and how to supplement your recommenders with
    content-based similarities. Lastly, we worked with neural networks and transfer
    learning.
  prefs: []
  type: TYPE_NORMAL
