["```py\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.datasets import make_blobs\nblobs, classes = make_blobs(500, centers=3)\n```", "```py\nimport matplotlib.pyplot as plt\n%matplotlib inline  #Within an ipython notebook\n```", "```py\nf, ax = plt.subplots(figsize=(7.5, 7.5))\nrgb = np.array(['r', 'g', 'b'])\nax.scatter(blobs[:, 0], blobs[:, 1], color=rgb[classes])\nax.set_title(\"Blobs\")\n```", "```py\nfrom sklearn.cluster import KMeans\nkmean = KMeans(n_clusters=3)\n\nkmean.fit(blobs)\nKMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n    n_clusters=3, n_init=10, n_jobs=1, precompute_distances='auto',\n    random_state=None, tol=0.0001, verbose=0)\nkmean.cluster_centers_ \narray([[ 3.48939154, -0.92786786],\n [-2.05114953,  1.58697731],\n [ 1.58182736, -6.80678064]])\nf, ax = plt.subplots(figsize=(7.5, 7.5))\nax.scatter(blobs[:, 0], blobs[:, 1], color=rgb[classes])\nax.scatter(kmean.cluster_centers_[:, 0],kmean.cluster_centers_[:, 1], marker='*', s=250,color='black', label='Centers')\nax.set_title(\"Blobs\")\nax.legend(loc='best')\n```", "```py\nkmean.labels_[:5]\narray([2, 0, 1, 1, 0])\n```", "```py\nclasses[:5]\narray([2, 0, 1, 1, 0])\n```", "```py\nkmean.transform(blobs)[:5]\narray([[ 6.75214231, 9.29599311, 0.71314755], [ 3.50482136, 6.7010513 , 9.68538042], [ 6.07460324, 1.91279125, 7.74069472], [ 6.29191797, 0.90698131, 8.68432547], [ 2.84654338, 6.07653639, 3.64221613]])\n```", "```py\nfrom sklearn.datasets import make_blobs\nimport numpy as np\nblobs, classes = make_blobs(500, centers=3)\n\nfrom sklearn.cluster import KMeans\nkmean = KMeans(n_clusters=3)\nkmean.fit(blobs)\nKMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n n_clusters=3, n_init=10, n_jobs=1, precompute_distances='auto',\n random_state=None, tol=0.0001, verbose=0)\n```", "```py\nfrom sklearn import metrics\nsilhouette_samples = metrics.silhouette_samples(blobs, kmean.labels_)\nnp.column_stack((classes[:5], silhouette_samples[:5]))\narray([[ 0\\.        ,  0.69568017],\n       [ 0\\.        ,  0.76789931],\n       [ 0\\.        ,  0.62470466],\n       [ 0\\.        ,  0.6266658 ],\n       [ 2\\.        ,  0.63975981]])\n```", "```py\nsilhouette_samples.mean()\n0.5633513643546264\n```", "```py\nmetrics.silhouette_score(blobs, kmean.labels_)\n0.5633513643546264\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nblobs, classes = make_blobs(500, centers=10)\nsilhouette_avgs = []\nfor k in range(2, 60):\n kmean = KMeans(n_clusters=k).fit(blobs)\n silhouette_avgs.append(metrics.silhouette_score(blobs, kmean.labels_))\n\nf, ax = plt.subplots(figsize=(7, 5))\nax.plot(silhouette_avgs)\n```", "```py\nfrom sklearn import datasets\nfrom sklearn import cluster\n\nblobs, ground_truth = datasets.make_blobs(1000, centers=3,cluster_std=1.75)\n```", "```py\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nf, ax = plt.subplots(figsize=(7, 5))\ncolors = ['r', 'g', 'b']\nfor i in range(3):\n p = blobs[ground_truth == i]\n ax.scatter(p[:,0], p[:,1], c=colors[i],\n label=\"Cluster {}\".format(i))\nax.set_title(\"Cluster With Ground Truth\")\nax.legend()\n```", "```py\nkmeans = cluster.KMeans(n_clusters=3)\nkmeans.fit(blobs)\nKMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n n_clusters=3, n_init=10, n_jobs=1, precompute_distances='auto',\n random_state=None, tol=0.0001, verbose=0)\nkmeans.cluster_centers_\narray([[ 3.61594791, -6.6125572 ],\n       [-0.76071938, -2.73916602],\n       [-3.64641767, -6.23305142]])\n```", "```py\nf, ax = plt.subplots(figsize=(7, 5))\ncolors = ['r', 'g', 'b']\nfor i in range(3): \n p = blobs[ground_truth == i]\n ax.scatter(p[:,0], p[:,1], c=colors[i], label=\"Cluster {}\".format(i))\n```", "```py\nfor i in range(3):\n print (kmeans.labels_ == ground_truth)[ground_truth == i].astype(int).mean()\n0.946107784431\n0.135135135135\n0.0750750750751\n```", "```py\nnew_ground_truth = ground_truth.copy()\nnew_ground_truth[ground_truth == 1] = 2\nnew_ground_truth[ground_truth == 2] = 1\n0.946107784431\n0.852852852853\n0.891891891892\n```", "```py\nfrom sklearn import metrics\nmetrics.normalized_mutual_info_score(ground_truth, kmeans.labels_)\n0.66467613668253844\n```", "```py\nmetrics.normalized_mutual_info_score(ground_truth, ground_truth)\n1.0\n```", "```py\nmetrics.mutual_info_score(ground_truth, kmeans.labels_)\n0.72971342940406325\n```", "```py\nkmeans.inertia_\n4849.9842988128385\n```", "```py\nimport numpy as np\nfrom sklearn.datasets import make_blobs\nblobs, labels = make_blobs(int(1e6), 3)\n\nfrom sklearn.cluster import KMeans, MiniBatchKMeans\nkmeans = KMeans(n_clusters=3)\nminibatch = MiniBatchKMeans(n_clusters=3)\n```", "```py\n%time kmeans.fit(blobs) #IPython Magic\nWall time: 7.88 s \nKMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n    n_clusters=3, n_init=10, n_jobs=1, precompute_distances='auto',\n    random_state=None, tol=0.0001, verbose=0)\n%time minibatch.fit(blobs)\nWall time: 2.66 s \nMiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n        init_size=None, max_iter=100, max_no_improvement=10, n_clusters=3,\n        n_init=3, random_state=None, reassignment_ratio=0.01, tol=0.0,\n        verbose=0)\n```", "```py\nkmeans.cluster_centers_\narray([[-3.74304286, -0.4289715 , -8.69684375],\n       [-5.73689621, -6.39166391,  6.18598804],\n       [ 0.63866644, -9.93289824,  3.24425045]])\nminibatch.cluster_centers_\narray([[-3.72580548, -0.46135647, -8.63339789],\n       [-5.67140979, -6.33603949,  6.21512625],\n       [ 0.64819477, -9.87197712,  3.26697532]])\n```", "```py\nfrom sklearn.metrics import pairwise\npairwise.pairwise_distances(kmeans.cluster_centers_[0].reshape(1, -1), minibatch.cluster_centers_[0].reshape(1, -1))\narray([[ 0.07328909]])\n```", "```py\nnp.diag(pairwise.pairwise_distances(kmeans.cluster_centers_, minibatch.cluster_centers_))\narray([ 0.07328909,  0.09072807,  0.06571599])\n```", "```py\nminibatch = MiniBatchKMeans(batch_size=len(blobs))\n%time minibatch.fit(blobs)\nWall time: 1min \nMiniBatchKMeans(batch_size=1000000, compute_labels=True, init='k-means++',\n        init_size=None, max_iter=100, max_no_improvement=10, n_clusters=8,\n        n_init=3, random_state=None, reassignment_ratio=0.01, tol=0.0,\n        verbose=0)\n```", "```py\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom scipy import ndimage\nimg = ndimage.imread(\"headshot.jpg\")\nplt.figure(figsize = (10,7))\nplt.imshow(img)\n```", "```py\nimg.shape\n(379L, 337L, 3L)\n```", "```py\nx, y, z = img.shape\nlong_img = img.reshape(x*y, z)\nlong_img.shape\n(127723L, 3L)\n```", "```py\nfrom sklearn import cluster\nk_means = cluster.KMeans(n_clusters=5)\nk_means.fit(long_img)\ncenters = k_means.cluster_centers_\ncenters\narray([[ 169.01964615,  123.08399844,   99.6097561 ],\n       [  45.79271071,   94.56844879,  120.00911162],\n       [ 218.74043562,  202.152748  ,  184.14355039],\n       [  67.51082485,  151.50671141,  201.9408963 ],\n       [ 169.69235986,  189.63274724,  143.75511521]])\n```", "```py\nlabels = k_means.labels_\nlabels\narray([4, 4, 4, ..., 3, 3, 3])\n```", "```py\nplt.figure(figsize = (10,7))\nplt.imshow(centers[labels].reshape(x, y, z))\n```", "```py\nimport numpy as np\n\nfrom sklearn.metrics import pairwise\nfrom sklearn.datasets import make_blobs\npoints, labels = make_blobs()\n```", "```py\ndistances = pairwise.pairwise_distances(points)\n```", "```py\nnp.diag(distances) [:5] \ndistances[0][:5]\narray([ 0\\. , 4.24926332, 8.8630893 , 5.01378992, 10.05620093])\n```", "```py\nranks = np.argsort(distances[0])\nranks[:5]\narray([ 0, 63, 6, 21, 17], dtype=int64)\n```", "```py\npoints[ranks][:5]\n array([[-0.15728042, -5.76309092],\n [-0.20720885, -5.52734277],\n [-0.08686778, -6.42054076],\n [ 0.33493582, -6.29824601],\n [-0.89842683, -5.78335127]])\nsp_points = points[ranks][:5]\n```", "```py\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.figure(figsize=(10,7))\nplt.scatter(points[:,0], points[:,1], label = 'All Points')\nplt.scatter(sp_points[:,0],sp_points[:,1],color='red', label='Closest Points')\nplt.scatter(points[0,0],points[0,1],color='green', label = 'Chosen Point')\n\nplt.legend()\n```", "```py\ndef euclid_distances(x, y):\n return np.power(np.power(x - y, 2).sum(), .5)\neuclid_distances(points[0], points[1])\n4.249263322917467  \n```", "```py\n pairwise.pairwise_distances([[0, 0], [5, 5]], metric='cityblock')[0]\narray([  0.,  10.])\n```", "```py\nX = np.random.binomial(1, .5, size=(2, 4)).astype(np.bool)\nX\narray([[False, False, False, False],\n [False, True, True, True]], dtype=bool)\npairwise.pairwise_distances(X, metric='hamming')\narray([[ 0\\. , 0.75],\n [ 0.75, 0\\. ]])\n```", "```py\nimport numpy as np\n\nN = 1000\nin_m = 72\nin_w = 66\ns_m = 2\ns_w = s_m\nm = np.random.normal(in_m, s_m, N)\nw = np.random.normal(in_w, s_w, N)\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nf, ax = plt.subplots(figsize=(7, 5))\nax.set_title(\"Histogram of Heights\")\nax.hist(m, alpha=.5, label=\"Men\");\nax.hist(w, alpha=.5, label=\"Women\");\nax.legend()\n```", "```py\n random_sample = np.random.choice([True, False], size=m.size)\n m_test = m[random_sample]\n m_train = m[~random_sample]\n w_test = w[random_sample]\n w_train = w[~random_sample]\n```", "```py\nfrom scipy import stats\nm_pdf = stats.norm(m_train.mean(), m_train.std())\nw_pdf = stats.norm(w_train.mean(), w_train.std())\n```", "```py\nm_pdf.pdf(m[0])\n0.19762291119664221\nw_pdf.pdf(m[0])\n0.00085042279862613103\n```", "```py\nguesses_m = np.ones_like(m_test)\nguesses_m[m_pdf.pdf(m_test) &lt; w_pdf.pdf(m_test)] = 0\n```", "```py\nguesses_m.mean()\n0.94176706827309242\n```", "```py\nguesses_w = np.ones_like(w_test)\nguesses_w[m_pdf.pdf(w_test) > w_pdf.pdf(w_test)] = 0\nguesses_w.mean()\n 0.93775100401606426\n```", "```py\ns_m = 1\ns_w = 4\nm = np.random.normal(in_m, s_m, N)\nw = np.random.normal(in_w, s_w, N)\n```", "```py\nm_test = m[random_sample]\nm_train = m[~random_sample]\nw_test = w[random_sample]\nw_train = w[~random_sample]\nf, ax = plt.subplots(figsize=(7, 5))\nax.set_title(\"Histogram of Heights\")\nax.hist(m_train, alpha=.5, label=\"Men\");\nax.hist(w_train, alpha=.5, label=\"Women\");\nax.legend()\n```", "```py\nm_pdf = stats.norm(m_train.mean(), m_train.std())\nw_pdf = stats.norm(w_train.mean(), w_train.std())\n\nx = np.linspace(50,80,300)\nplt.figure(figsize=(8,5))\nplt.title('PDF of Heights')\nplt.plot(x, m_pdf.pdf(x), 'k', linewidth=2, color='blue', label='Men')\nplt.plot(x, w_pdf.pdf(x), 'k', linewidth=2, color='green',label='Women')\n```", "```py\nclass_A = np.random.normal(0, 1, size=(100, 2))\nclass_B = np.random.normal(4, 1.5, size=(100, 2))\nf, ax = plt.subplots(figsize=(8, 5))\nplt.title('Random 2D Normal Draws')\nax.scatter(class_A[:,0], class_A[:,1], label='A', c='r')\nax.scatter(class_B[:,0], class_B[:,1], label='B')\n```", "```py\nfrom sklearn.mixture import GaussianMixture\ngmm = GaussianMixture(n_components=2)\nX = np.row_stack((class_A, class_B))\ny = np.hstack((np.ones(100), np.zeros(100)))\n```", "```py\ntrain = np.random.choice([True, False], 200)\ngmm.fit(X[train])\nGaussianMixture(covariance_type='full', init_params='kmeans', max_iter=100,\n means_init=None, n_components=2, n_init=1, precisions_init=None,\n random_state=None, reg_covar=1e-06, tol=0.001, verbose=0,\n verbose_interval=10, warm_start=False, weights_init=None)\n```", "```py\ngmm.fit(X[train])\ngmm.predict(X[train])[:5]\narray([0, 0, 0, 0, 0], dtype=int64)\n```", "```py\nfrom sklearn.datasets import make_blobs\nX, labels = make_blobs(100, centers=1)\nimport numpy as np\n```", "```py\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=1)\nkmeans.fit(X)\nKMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n n_clusters=1, n_init=10, n_jobs=1, precompute_distances='auto',\n random_state=None, tol=0.0001, verbose=0)\n```", "```py\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nf, ax = plt.subplots(figsize=(8, 5))\nax.set_title(\"Blob\")\nax.scatter(X[:, 0], X[:, 1], label='Points')\nax.scatter(kmeans.cluster_centers_[:, 0],kmeans.cluster_centers_[:, 1], label='Centroid',color='r')\nax.legend()\n```", "```py\ndistances = kmeans.transform(X)\n\n# argsort returns an array of indexes which will sort the array in ascending order\n# so we reverse it via [::-1] and take the top five with [:5]\n\nsorted_idx = np.argsort(distances.ravel())[::-1][:5]\n```", "```py\nf, ax = plt.subplots(figsize=(7, 5))\nax.set_title(\"Single Cluster\")\nax.scatter(X[:, 0], X[:, 1], label='Points')\nax.scatter(kmeans.cluster_centers_[:, 0],kmeans.cluster_centers_[:, 1],label='Centroid', color='r')\nax.scatter(X[sorted_idx][:, 0], X[sorted_idx][:, 1],label='Extreme Value', edgecolors='g',facecolors='none', s=100)\nax.legend(loc='best')\n```", "```py\nnew_X = np.delete(X, sorted_idx, axis=0) \n```", "```py\nnew_kmeans = KMeans(n_clusters=1)\nnew_kmeans.fit(new_X)\n```", "```py\nf, ax = plt.subplots(figsize=(7, 5))\nax.set_title(\"Extreme Values Removed\")\nax.scatter(new_X[:, 0], new_X[:, 1], label='Pruned Points')\nax.scatter(kmeans.cluster_centers_[:, 0],kmeans.cluster_centers_[:, 1], label='Old Centroid',color='r',s=80, alpha=.5)\nax.scatter(new_kmeans.cluster_centers_[:, 0],new_kmeans.cluster_centers_[:, 1], label='New Centroid',color='m', s=80, alpha=.5)\n ax.legend(loc='best')\n```", "```py\nfrom scipy import stats\nemp_dist = stats.multivariate_normal(kmeans.cluster_centers_.ravel())\nlowest_prob_idx = np.argsort(emp_dist.pdf(X))[:5]\nnp.all(X[sorted_idx] == X[lowest_prob_idx]) \n\nTrue\n```", "```py\nimport numpy as np\nfrom sklearn import datasets\niris = datasets.load_iris()\niris.feature_names\n```", "```py\n X = iris.data[:,:2]\n y = iris.data[:,2]\n\n from sklearn.linear_model import LinearRegression\n lr = LinearRegression()\n lr.fit(X, y)\n print \"The MSE is: {:.2}\".format(np.power(y - lr.predict(X),2).mean())\n\nThe MSE is: 0.41\n```", "```py\nfrom sklearn.neighbors import KNeighborsRegressor\nknnr = KNeighborsRegressor(n_neighbors=10)\nknnr.fit(X, y)\nprint \"The MSE is: {:.2}\".format(np.power(y - knnr.predict(X),2).mean()) \n\nThe MSE is: 0.17\n```", "```py\nf, ax = plt.subplots(nrows=2, figsize=(7, 10))\nax[0].set_title(\"Predictions\")\nax[0].scatter(X[:, 0], X[:, 1], s=lr.predict(X)*80, label='LR Predictions', color='c', edgecolors='black')\nax[1].scatter(X[:, 0], X[:, 1], s=knnr.predict(X)*80, label='k-NN Predictions', color='m', edgecolors='black')\nax[0].legend()\nax[1].legend()\n```", "```py\nsetosa_idx = np.where(iris.target_names=='setosa')\nsetosa_mask = iris.target == setosa_idx[0]\ny[setosa_mask][:5]\narray([ 1.4,  1.4,  1.3,  1.5,  1.4])\nknnr.predict(X)[setosa_mask][:5]\narray([ 1.46,  1.47,  1.51,  1.42,  1.48])\nlr.predict(X)[setosa_mask][:5]\narray([ 1.83762646,  2.1510849 ,  1.52707371,  1.48291658,  1.52562087])\n```", "```py\n example_point = X[0]\n```", "```py\nfrom sklearn.metrics import pairwise\ndistances_to_example = pairwise.pairwise_distances(X)[0]\nten_closest_points = X[np.argsort(distances_to_example)][:10]\nten_closest_y = y[np.argsort(distances_to_example)][:10]\nten_closest_y.mean() \n\n1.46\n```"]