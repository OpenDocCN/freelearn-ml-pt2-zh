- en: Chapter 2. Managing and Understanding Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A key early component of any machine learning project involves managing and
    understanding data. Although this may not be as gratifying as building and deploying
    models—the stages in which you begin to see the fruits of your labor—it is unwise
    to ignore this important preparatory work.
  prefs: []
  type: TYPE_NORMAL
- en: Any learning algorithm is only as good as its input data, and in many cases,
    the input data is complex, messy, and spread across multiple sources and formats.
    Because of this complexity, often the largest portion of effort invested in machine
    learning projects is spent on data preparation and exploration.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter approaches these topics in three ways. The first section discusses
    the basic data structures R uses to store data. You will become very familiar
    with these structures as you create and manipulate datasets. The second section
    is practical, as it covers several functions that are useful to get data in and
    out of R. In the third section, methods for understanding data are illustrated
    while exploring a real-world dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will understand:'
  prefs: []
  type: TYPE_NORMAL
- en: How to use R's basic data structures to store and extract data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simple functions to get data into R from common source formats
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Typical methods to understand and visualize complex data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since the way R thinks about data will define the way you work with data, it
    is helpful to know R's data structures before jumping directly into data preparation.
    However, if you are already familiar with R programming, feel free to skip ahead
    to the section on data preprocessing.
  prefs: []
  type: TYPE_NORMAL
- en: R data structures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are numerous types of data structures across programming languages, each
    with strengths and weaknesses suited to particular tasks. Since R is a programming
    language used widely for statistical data analysis, the data structures it utilizes
    were designed with this type of work in mind.
  prefs: []
  type: TYPE_NORMAL
- en: The R data structures used most frequently in machine learning are vectors,
    factors, lists, arrays and matrices, and data frames. Each is tailored to a specific
    data management task, which makes it important to understand how they will interact
    in your R project. In the sections that follow, we will review their similarities
    and differences.
  prefs: []
  type: TYPE_NORMAL
- en: Vectors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The fundamental R data structure is the **vector**, which stores an ordered
    set of values called **elements**. A vector can contain any number of elements,
    but all of the elements must be of the same **type** of values. For instance,
    a vector cannot contain both numbers and text. To determine the type of vector
    `v`, use the `typeof(v)` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'Several vector types are commonly used in machine learning: `integer` (numbers
    without decimals), `double` (numbers with decimals), `character` (text data),
    and `logical` (`TRUE` or `FALSE` values). There are also two special values: `NULL`,
    which is used to indicate the absence of any value, and `NA`, which indicates
    a missing value.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Some R functions will report both `integer` and `double` vectors as `numeric`,
    while others will distinguish between the two. As a result, although all `double`
    vectors are `numeric`, not all `numeric` vectors are `double` type.
  prefs: []
  type: TYPE_NORMAL
- en: It is tedious to enter large amounts of data manually, but small vectors can
    be created by using the `c()` combine function. The vector can also be given a
    name using the `<-` arrow operator, which is R's way of assigning values, much
    like the `=` assignment operator is used in many other programming languages.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, let''s construct several vectors to store the diagnostic data
    of three medical patients. We''ll create a `character` vector named `subject_name`
    to store the three patient names, a `double` vector named `temperature` to store
    each patient''s body temperature, and a logical vector named `flu_status` to store
    each patient''s diagnosis (`TRUE` if he or she has influenza, `FALSE` otherwise).
    Let''s have a look at the following code to create these three vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Because R vectors are inherently ordered, the records can be accessed by counting
    the item''s number in the set, beginning at one, and surrounding this number with
    square brackets (that is, `[` and `]`) after the name of the vector. For instance,
    to obtain the body temperature for patient Jane Doe (the second element in the
    `temperature` vector) simply type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'R offers a variety of convenient methods to extract data from vectors. A range
    of values can be obtained using the (`:`) colon operator. For instance, to obtain
    the body temperature of Jane Doe and Steve Graves, type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Items can be excluded by specifying a negative item number. To exclude Jane
    Doe''s `temperature` data, type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, it is also sometimes useful to specify a logical vector indicating
    whether each item should be included. For example, to include the first two `temperature`
    readings but exclude the third, type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: As you will see shortly, the vector provides the foundation for many other R
    data structures. Therefore, the knowledge of the various vector operations is
    crucial to work with data in R.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Downloading the example code**'
  prefs: []
  type: TYPE_NORMAL
- en: You can download the example code files for all Packt books you have purchased
    from your account at [http://www.packtpub.com](http://www.packtpub.com). If you
    purchased this book elsewhere, you can visit [http://www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files e-mailed directly to you.
  prefs: []
  type: TYPE_NORMAL
- en: New to the second edition of this book, the example code is also available via
    GitHub at [https://github.com/dataspelunking/MLwR/](https://github.com/dataspelunking/MLwR/).
    Check here for the most up-to-date R code, as well as issue tracking and a public
    wiki. Please join the community!
  prefs: []
  type: TYPE_NORMAL
- en: Factors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you recall from [Chapter 1](ch01.html "Chapter 1. Introducing Machine Learning"),
    *Introducing Machine Learning*, features that represent a characteristic with
    categories of values are known as **nominal**. Although it is possible to use
    a character vector to store nominal data, R provides a data structure specifically
    for this purpose. A **factor** is a special case of vector that is solely used
    to represent categorical or ordinal variables. In the medical dataset we are building,
    we might use a factor to represent gender, because it uses two categories: `MALE`
    and `FEMALE`.'
  prefs: []
  type: TYPE_NORMAL
- en: Why not use character vectors? An advantage of factors is that the category
    labels are stored only once. For instance, rather than storing `MALE`, `MALE`,
    `FEMALE`, the computer can store `1`, `1`, `2`, which reduces the size of memory
    needed to store the same information. Additionally, many machine learning algorithms
    treat nominal and numeric data differently. Coding as factors is often needed
    to inform an R function to treat categorical data appropriately.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A factor should not be used for character vectors that are not truly categorical.
    If a vector stores mostly unique values like names or identification strings,
    keep it as a character vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a factor from a character vector, simply apply the `factor()` function.
    For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that when the gender data for John Doe and Jane Doe were displayed,
    R printed additional information about the `gender` factor. The `levels` variable
    comprise the set of possible categories `factor` could take, in this case: `MALE`
    or `FEMALE`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When we create factors, we can add additional levels that may not appear in
    the data. Suppose we add another factor for the blood type, as shown in the following
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Notice that when we defined the `blood` factor for the three patients, we specified
    an additional vector of four possible blood types using the `levels` parameter.
    As a result, even though our data included only types `O`, `AB`, and `A`, all
    the four types are stored with the `blood` factor as indicated by the output.
    Storing the additional level allows for the possibility of adding data with the
    other blood types in the future. It also ensures that if we were to create a table
    of blood types, we would know that the `B` type exists, despite it not being recorded
    in our data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The factor data structure also allows us to include information about the order
    of a nominal variable''s categories, which provides a convenient way to store
    ordinal data. For example, suppose we have data on the severity of a patient''s
    `symptoms` coded in an increasing level of severity from mild, to moderate, to
    severe. We indicate the presence of ordinal data by providing the factor''s `levels`
    in the desired order, listed in ascending order from lowest to highest, and setting
    the `ordered` parameter to `TRUE`, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting `symptoms` factor now includes information about the order we
    requested. Unlike our prior factors, the levels value of this factor are separated
    by `<` symbols, to indicate the presence of a sequential order from mild to severe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'A helpful feature of the ordered factors is that logical tests work as you
    expect. For instance, we can test whether each patient''s symptoms are greater
    than moderate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Machine learning algorithms capable of modeling ordinal data will expect the
    ordered factors, so be sure to code your data accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: Lists
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A **list** is a data structure, much like a vector, in that it is used for storing
    an ordered set of elements. However, where a vector requires all its elements
    to be the same type, a list allows different types of elements to be collected.
    Due to this flexibility, lists are often used to store various types of input
    and output data and sets of configuration parameters for machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate lists, consider the medical patient dataset we have been constructing
    with the data for three patients stored in six vectors. If we want to display
    all the data on John Doe (subject 1), we would need to enter five R commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This seems like a lot of work to display one patient's medical data. The list
    structure allows us to group all of the patient's data into one object that we
    can use repeatedly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to creating a vector with `c()`, a list is created using the `list()`
    function, as shown in the following example. One notable difference is that when
    a list is constructed, each component in the sequence is almost always given a
    name. The names are not technically required, but allow the list''s values to
    be accessed later on by name rather than by numbered position. To create a list
    with named components for all of the first patient''s data, type the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'This patient''s data is now collected in the `subject1` list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the values are labeled with the names we specified in the preceding
    command. However, a list can still be accessed using methods similar to a vector.
    To access the `temperature` value, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The result of using vector-style operators on a list object is another list
    object, which is a subset of the original list. For example, the preceding code
    returned a list with a single `temperature` component. To return a single list
    item in its native data type, use double brackets (`[[` and `]]`) when attempting
    to select the list component. For example, the following returns a numeric vector
    of length one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'For clarity, it is often easier to access list components directly, by appending
    a `$` and the value''s name to the name of the list component, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Like the double bracket notation, this returns the list component in its native
    data type (in this case, a numeric vector of length one).
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Accessing the value by name also ensures that the correct item is retrieved,
    even if the order of the list's elements is changed later on.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is possible to obtain several items in a list by specifying a vector of
    names. The following returns a subset of the `subject1` list, which contains only
    the `temperature` and `flu_status` components:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Entire datasets could be constructed using lists and lists of lists. For example,
    you might consider creating a `subject2` and `subject3` list, and combining these
    into a single list object named `pt_data`. However, constructing a dataset in
    this way is common enough that R provides a specialized data structure specifically
    for this task.
  prefs: []
  type: TYPE_NORMAL
- en: Data frames
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By far, the most important R data structure utilized in machine learning is
    the **data frame**, a structure analogous to a spreadsheet or database, since
    it has both rows and columns of data. In R terms, a data frame can be understood
    as a list of vectors or factors, each having exactly the same number of values.
    Because the data frame is literally a list of vector type objects, it combines
    aspects of both vectors and lists.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a data frame for our patient dataset. Using the patient data
    vectors we created previously, the `data.frame()` function combines them into
    a data frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'You might notice something new in the preceding code. We included an additional
    parameter: `stringsAsFactors = FALSE`. If we do not specify this option, R will
    automatically convert every character vector to a factor.'
  prefs: []
  type: TYPE_NORMAL
- en: This feature is occasionally useful, but also sometimes unwarranted. Here, for
    example, the `subject_name` field is definitely not categorical data, as names
    are not categories of values. Therefore, setting the `stringsAsFactors` option
    to `FALSE` allows us to convert character vectors to factors only where it makes
    sense for the project.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we display the `pt_data` data frame, we see that the structure is quite
    different from the data structures we worked with previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Compared to the one-dimensional vectors, factors, and lists, a data frame has
    two dimensions and is displayed in matrix format. This particular data frame has
    one column for each vector of patient data and one row for each patient. In machine
    learning terms, the data frame's columns are the features or attributes and the
    rows are the examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'To extract entire columns (vectors) of data, we can take advantage of the fact
    that a data frame is simply a list of vectors. Similar to lists, the most direct
    way to extract a single element is by referring to it by name. For example, to
    obtain the `subject_name` vector, type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Also similar to lists, a vector of names can be used to extract several columns
    from a data frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: When we access the data frame in this way, the result is a data frame containing
    all the rows of data for all the requested columns. Alternatively, the `pt_data[2:3]`
    command will also extract the `temperature` and `flu_status` columns. However,
    requesting the columns by name results in a clear and easy-to-maintain R code
    that will not break if the data frame is restructured in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'To extract values in the data frame, methods like those for accessing values
    in vectors are used. However, there is an important exception. Because the data
    frame is two-dimensional, both the desired rows and columns to be extracted must
    be specified. Rows are specified first, followed by a comma and then the columns
    in a format like this: `[rows, columns]`. As with vectors, rows and columns are
    counted beginning at one.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, to extract the value in the first row and second column of the
    patient data frame (the `temperature` value for John Doe), use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'If you like more than a single row or column of data, specify vectors for the
    rows and columns desired. The following command will pull data from the first
    and third rows and the second and fourth columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'To extract all the rows or columns, simply leave the row or column portion
    blank. For example, to extract all the rows of the first column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'To extract all the columns of the first row, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'To extract everything, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Other methods to access values in lists and vectors can also be used to retrieve
    data frame rows and columns. For example, columns can be accessed by name rather
    than position, and negative signs can be used to exclude rows or columns of data.
    Therefore, the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Is equivalent to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: To become more familiar with data frames, try practicing similar operations
    with the patient dataset, or even better, use data from one of your own projects.
    These types of operations are crucial for much of the work we will do in the upcoming
    chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Matrixes and arrays
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In addition to data frames, R provides other structures that store values in
    a tabular form. A **matrix** is a data structure that represents a two-dimensional
    table with rows and columns of data. Like vectors, R matrixes can contain any
    one type of data, although they are most often used for mathematical operations
    and, therefore, typically store only numeric data.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a matrix, simply supply a vector of data to the `matrix()` function
    along with a parameter specifying the number of rows (`nrow`) or number of columns
    (`ncol`). For example, to create a 2 x 2 matrix storing the numbers one through
    four, we can use the `nrow` parameter to request the data to be divided into two
    rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'This is equivalent to the matrix produced using `ncol = 2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: You will notice that R loaded the first column of the matrix first before loading
    the second column. This is called **column-major order**, and is R's default method
    for loading matrices.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To override this default setting and load a matrix by rows, set the parameter
    `byrow = TRUE` when creating the matrix.
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate this further, let's see what happens if we add more values to
    the matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'With six values, requesting two rows creates a matrix with three columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Requesting two columns creates a matrix with three rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'As with data frames, values in matrixes can be extracted using `[row, column]`
    notation. For instance, `m[1, 1]` will return the value `1` and `m[3, 2]` will
    extract `6` from the `m` matrix. Additionally, entire rows or columns can be requested:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Closely related to the matrix structure is the **array**, which is a multidimensional
    table of data. Where a matrix has rows and columns of values, an array has rows,
    columns, and any number of additional layers of values. Although we will be occasionally
    using matrixes in the upcoming chapters, the use of arrays is outside the scope
    of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Managing data with R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the challenges faced while working with massive datasets involves gathering,
    preparing, and otherwise managing data from a variety of sources. Although we
    will cover data preparation, data cleaning, and data management in depth by working
    on real-world machine learning tasks in the later chapters, this section will
    highlight the basic functionality to get data into and out of R.
  prefs: []
  type: TYPE_NORMAL
- en: Saving, loading, and removing R data structures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you have spent a lot of time getting a data frame into the desired form,
    you shouldn't need to recreate your work each time you restart your R session.
    To save a data structure to a file that can be reloaded later or transferred to
    another system, use the `save()` function. The `save()` function writes one or
    more R data structures to the location specified by the `file` parameter. R data
    files have an `.RData` extension.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose you have three objects named `x`, `y`, and `z` that you would like
    to save in a permanent file. Regardless of whether they are vectors, factors,
    lists, or data frames, we could save them to a file named `mydata.RData` using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The `load()` command can recreate any data structures that have been saved
    to an `.RData` file. To load the `mydata.RData` file we saved in the preceding
    code, simply type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: This will recreate the `x`, `y`, and `z` data structures.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Be careful of what you are loading! All data structures stored in the file you
    are importing with the `load()` command will be added to your workspace, even
    if they overwrite something else you are working on.
  prefs: []
  type: TYPE_NORMAL
- en: If you need to wrap up your R session in a hurry, the `save.image()` command
    will write your entire session to a file simply called `.RData`. By default, R
    will look for this file the next time you start R, and your session will be recreated
    just as you had left it.
  prefs: []
  type: TYPE_NORMAL
- en: 'After working on an R session for sometime, you may have accumulated a number
    of data structures. The `ls()` listing function returns a vector of all the data
    structures currently in the memory. For example, if you''ve been following along
    with the code in this chapter, the `ls()` function returns the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'R will automatically remove these from its memory upon quitting the session,
    but for large data structures, you may want to free up the memory sooner. The
    `rm()` remove function can be used for this purpose. For example, to eliminate
    the `m` and `subject1` objects, simply type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The `rm()` function can also be supplied with a character vector of the object
    names to be removed. This works with the `ls()` function to clear the entire R
    session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Be very careful while executing the preceding command, as you will not be prompted
    before your objects are removed!
  prefs: []
  type: TYPE_NORMAL
- en: Importing and saving data from CSV files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is very common for public datasets to be stored in text files. Text files
    can be read on virtually any computer or operating system, which makes the format
    nearly universal. They can also be exported and imported to and from programs
    such as Microsoft Excel, providing a quick and easy way to work with spreadsheet
    data.
  prefs: []
  type: TYPE_NORMAL
- en: A **tabular** (as in "table") data file is structured in the matrix form, such
    that each line of text reflects one example, and each example has the same number
    of features. The feature values on each line are separated by a predefined symbol,
    known as a **delimiter**. Often, the first line of a tabular data file lists the
    names of the columns of data. This is called a **header** line.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perhaps the most common tabular text file format is the **CSV** (**Comma-Separated
    Values**) file, which as the name suggests, uses the comma as a delimiter. The
    CSV files can be imported to and exported from many common applications. A CSV
    file representing the medical dataset constructed previously could be stored as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Given a patient data file named `pt_data.csv` located in the R working directory,
    the `read.csv()` function can be used as follows to load the file into R:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: This will read the CSV file into a data frame titled `pt_data`. Just as we did
    previously while constructing a data frame, we need to use the `stringsAsFactors
    = FALSE` parameter to prevent R from converting all text variables into factors.
    This step is better left to you, not R, to perform.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If your dataset resides outside the R working directory, the full path to the
    CSV file (for example, `/path/to/mydata.csv`) can be used when calling the `read.csv()`
    function.
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, R assumes that the CSV file includes a header line listing the
    names of the features in the dataset. If a CSV file does not have a header, specify
    the option `header = FALSE`, as shown in the following command, and R will assign
    default feature names in the `V1` and `V2` forms and so on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: The `read.csv()` function is a special case of the `read.table()` function,
    which can read tabular data in many different forms, including other delimited
    formats such as **Tab-Separated Values** (**TSV**). For more detailed information
    on the `read.table()` family of functions, refer to the R help page using the
    `?read.table` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'To save a data frame to a CSV file, use the `write.csv()` function. If your
    data frame is named `pt_data`, simply enter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: This will write a CSV file with the name `pt_data.csv` to the R working folder.
    The `row.names` parameter overrides R's default setting, which is to output row
    names in the CSV file. Unless row names have been added to a data frame, this
    output is unnecessary and will simply inflate the size of the resulting file.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring and understanding data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After collecting data and loading it into R's data structures, the next step
    in the machine learning process involves examining the data in detail. It is during
    this step that you will begin to explore the data's features and examples, and
    realize the peculiarities that make your data unique. The better you understand
    your data, the better you will be able to match a machine learning model to your
    learning problem.
  prefs: []
  type: TYPE_NORMAL
- en: The best way to learn the process of data exploration is with an example. In
    this section, we will explore the `usedcars.csv` dataset, which contains actual
    data about used cars recently advertised for sale on a popular U.S. website.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `usedcars.csv` dataset is available for download on the Packt Publishing
    support page for this book. If you are following along with the examples, be sure
    that this file has been downloaded and saved to your R working directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the dataset is stored in the CSV form, we can use the `read.csv()` function
    to load the data into an R data frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Given the `usedcars` data frame, we will now assume the role of a data scientist
    who has the task of understanding the used car data. Although data exploration
    is a fluid process, the steps can be imagined as a sort of investigation in which
    questions about the data are answered. The exact questions may vary across projects,
    but the types of questions are always similar. You should be able to adapt the
    basic steps of this investigation to any dataset you like, whether large or small.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the structure of data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the first questions to ask in an investigation of a new dataset should
    be about how the dataset is organized. If you are fortunate, your source will
    provide a **data dictionary**, which is a document that describes the dataset's
    features. In our case, the used car data does not come with this documentation,
    so we'll need to create one on our own.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `str()` function provides a method to display the structure of R data structures
    such as data frames, vectors, or lists. It can be used to create the basic outline
    for our data dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Using such a simple command, we learn a wealth of information about the dataset.
    The statement `150 obs` informs us that the data includes 150 **observations**,
    which is just another way of saying that the dataset contains 150 records or examples.
    The number of observations is often simply abbreviated as *n*. Since we know that
    the data describes used cars, we can now presume that we have examples of *n =
    150* automobiles for sale.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `6 variables` statement refers to the six features that were recorded in
    the data. These features are listed by name on separate lines. Looking at the
    line for the feature called `color`, we can note some additional details:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: After the variable's name, the `chr` label tells us that the feature is `character`
    type. In this dataset, three of the variables are character while three are noted
    as `int`, which indicates `integer` type. Although the `usedcars` dataset includes
    only `character` and `integer` variables, you are also likely to encounter `num`
    or `numeric` type while using noninteger data. Any factors would be listed as
    `factor` type. Following each variable's type, R presents a sequence of the first
    few feature values. The values `"Yellow" "Gray" "Silver" "Gray"` are the first
    four values of the `color` feature.
  prefs: []
  type: TYPE_NORMAL
- en: Applying a bit of the subject-area knowledge to the feature names and values
    allows us to make some assumptions about what the variables represent. The `year`
    variable could refer to the year the vehicle was manufactured or it could specify
    the year the advertisement was posted. We will have to investigate this feature
    more in detail later, since the four example values (`2011 2011 2011 2011`) could
    be used to argue for either possibility. The `model`, `price`, `mileage`, `color`,
    and `transmission` variables most likely refer to the characteristics of the car
    for sale.
  prefs: []
  type: TYPE_NORMAL
- en: Although our data seems to have been given meaningful variable names, this is
    not always the case. Sometimes datasets have features with nonsensical names or
    codes like `V1`. In these cases it may be necessary to do additional sleuthing
    to determine what a feature actually represents. Still, even with helpful feature
    names, it is always prudent to be skeptical about the labels you have been provided
    with. Let's investigate further.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring numeric variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To investigate the numeric variables in the used car data, we will employ a
    common set of measurements to describe values known as **summary statistics**.
    The `summary()` function displays several common summary statistics. Let''s take
    a look at a single feature, `year`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Even if you aren't already familiar with summary statistics, you may be able
    to guess some of them from the heading before the `summary()` output. Ignoring
    the meaning of the values for now, the fact that we see numbers such as `2000`,
    `2008`, and `2009` could lead us to believe that the `year` variable indicates
    the year of manufacture rather than the year the advertisement was posted, since
    we know the vehicles were recently listed for sale.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also use the `summary()` function to obtain summary statistics for several
    `numeric` variables at the same time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The six summary statistics that the `summary()` function provides are simple,
    yet powerful tools to investigate data. They can be divided into two types: measures
    of center and measures of spread.'
  prefs: []
  type: TYPE_NORMAL
- en: Measuring the central tendency – mean and median
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Measures of **central tendency** are a class of statistics used to identify
    a value that falls in the middle of a set of data. You most likely are already
    familiar with one common measure of center: the average. In common use, when something
    is deemed average, it falls somewhere between the extreme ends of the scale. An
    average student might have marks falling in the middle of his or her classmates;
    an average weight is neither unusually light nor heavy. An average item is typical
    and not too unlike the others in the group. You might think of it as an exemplar
    by which all the others are judged.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In statistics, the average is also known as the **mean**, which is a measurement
    defined as the sum of all values divided by the number of values. For example,
    to calculate the mean income in a group of three people with incomes of $36,000,
    $44,000, and $56,000, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'R also provides a `mean()` function, which calculates the mean for a vector
    of numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: The mean income of this group of people is about $45,333\. Conceptually, this
    can be imagined as the income each person would have, if the total amount of income
    were divided equally across every person.
  prefs: []
  type: TYPE_NORMAL
- en: Recall that the preceding `summary()` output listed mean values for the `price`
    and `mileage` variables. The means suggest that the typical used car in this dataset
    was listed at a price of $12,962 and had an odometer reading of 44,261\. What
    does this tell us about our data? Since the average price is relatively low, we
    might expect that the dataset contains economy class cars. Of course, the data
    can also include late-model luxury cars with high mileage, but the relatively
    low mean mileage statistic doesn't provide evidence to support this hypothesis.
    On the other hand, it doesn't provide evidence to ignore the possibility either.
    We'll need to keep this in mind as we examine the data further.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although the mean is by far the most commonly cited statistic to measure the
    center of a dataset, it is not always the most appropriate one. Another commonly
    used measure of central tendency is the **median**, which is the value that occurs
    halfway through an ordered list of values. As with the mean, R provides a `median()`
    function, which we can apply to our salary data, as shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Because the middle value is `44000`, the median income is $44,000.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If a dataset has an even number of values, there is no middle value. In this
    case, the median is commonly calculated as the average of the two values at the
    center of the ordered list. For example, the median of the values 1, 2, 3, and
    4 is 2.5.
  prefs: []
  type: TYPE_NORMAL
- en: At the first glance, it seems like the median and mean are very similar measures.
    Certainly, the mean value of $45,333 and the median value of $44,000 are not very
    different. Why have two measures of central tendency? The reason is due to the
    fact that the mean and median are affected differently by the values falling at
    the far ends of the range. In particular, the mean is highly sensitive to **outliers**,
    or values that are atypically high or low in relation to the majority of data.
    Because the mean is sensitive to outliers, it is more likely to be shifted higher
    or lower by a small number of extreme values.
  prefs: []
  type: TYPE_NORMAL
- en: Recall again the reported median values in the `summary()` output for the used
    car dataset. Although the mean and median price are fairly similar (differing
    by approximately five percent), there is a much larger difference between the
    mean and median for mileage. For mileage, the mean of 44,261 is approximately
    20 percent more than the median of 36,385\. Since the mean is more sensitive to
    extreme values than the median, the fact that the mean is much higher than the
    median might lead us to suspect that there are some used cars in the dataset with
    extremely high mileage values. To investigate this further, we'll need to add
    additional summary statistics to our analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring spread – quartiles and the five-number summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Measuring the mean and median provides one way to quickly summarize the values,
    but these measures of center tell us little about whether or not there is diversity
    in the measurements. To measure the diversity, we need to employ another type
    of summary statistics that is concerned with the **spread** of data, or how tightly
    or loosely the values are spaced. Knowing about the spread provides a sense of
    the data's highs and lows and whether most values are like or unlike the mean
    and median.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **five-number summary** is a set of five statistics that roughly depict
    the spread of a feature''s values. All five of the statistics are included in
    the output of the `summary()` function. Written in order, they are:'
  prefs: []
  type: TYPE_NORMAL
- en: Minimum (`Min.`)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: First quartile, or Q1 (`1st Qu.`)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Median, or Q2 (`Median`)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Third quartile, or Q3 (`3rd Qu.`)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Maximum (`Max.`)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As you would expect, minimum and maximum are the most extreme feature values,
    indicating the smallest and largest values, respectively. R provides the `min()`
    and `max()` functions to calculate these values on a vector of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The span between the minimum and maximum value is known as the **range**. In
    R, the `range()` function returns both the minimum and maximum value. Combining
    `range()` with the `diff()` difference function allows you to examine the range
    of data with a single line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: The first and third quartiles—Q1 and Q3—refer to the value below or above which
    one quarter of the values are found. Along with the (Q2) median, the **quartiles**
    divide a dataset into four portions, each with the same number of values.
  prefs: []
  type: TYPE_NORMAL
- en: Quartiles are a special case of a type of statistics called **quantiles**, which
    are numbers that divide data into equally sized quantities. In addition to quartiles,
    commonly used quantiles include **tertiles** (three parts), **quintiles** (five
    parts), **deciles** (10 parts), and **percentiles** (100 parts).
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Percentiles are often used to describe the ranking of a value; for instance,
    a student whose test score was ranked at the 99^(th) percentile performed better
    than, or equal to, 99 percent of the other test takers.
  prefs: []
  type: TYPE_NORMAL
- en: 'The middle 50 percent of data between the first and third quartiles is of particular
    interest because it in itself is a simple measure of spread. The difference between
    Q1 and Q3 is known as the **Interquartile Range** (**IQR**), and it can be calculated
    with the `IQR()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: We could have also calculated this value by hand from the `summary()` output
    for the `usedcars$price` variable by computing *14904 – 10995 = 3909*. The small
    difference between our calculation and the `IQR()` output is due to the fact that
    R automatically rounds the `summary()` output.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `quantile()` function provides a robust tool to identify quantiles for
    a set of values. By default, the `quantile()` function returns the five-number
    summary. Applying the function to the used car data results in the same statistics
    as done earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While computing quantiles, there are many methods to handle ties among values
    and datasets with no middle value. The `quantile()` function allows you to specify
    among nine different algorithms by specifying the `type` parameter. If your project
    requires a precisely defined quantile, it is important to read the function documentation
    using the `?quantile` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we specify an additional `probs` parameter using a vector denoting cut points,
    we can obtain arbitrary quantiles, such as the 1^(st) and 99^(th) percentiles:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'The `seq()` function is used to generate vectors of evenly-spaced values. This
    makes it easy to obtain other slices of data, such as the quintiles (five groups),
    as shown in the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Equipped with an understanding of the five-number summary, we can re-examine
    the used car `summary()` output. On the `price` variable, the minimum was $3,800
    and the maximum was $21,992\. Interestingly, the difference between the minimum
    and Q1 is about $7,000, as is the difference between Q3 and the maximum; yet,
    the difference from Q1 to the median to Q3 is roughly $2,000\. This suggests that
    the lower and upper 25 percent of values are more widely dispersed than the middle
    50 percent of values, which seem to be more tightly grouped around the center.
    We see a similar trend with the `mileage` variable, which is not unsurprising.
    As you will learn later in this chapter, this pattern of spread is common enough
    that it has been called a "normal" distribution of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The spread of the `mileage` variable also exhibits another interesting property:
    the difference between Q3 and the maximum value is far greater than that between
    the minimum value and Q1\. In other words, the larger values are far more spread
    out than the smaller values.'
  prefs: []
  type: TYPE_NORMAL
- en: This finding explains why the mean value is much greater than the median. Because
    the mean is sensitive to extreme values, it is pulled higher, while the median
    stays relatively in the same place. This is an important property, which becomes
    more apparent when the data is presented visually.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing numeric variables – boxplots
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Visualizing numeric variables can be helpful in diagnosing data problems. A
    common visualization of the five-number summary is **boxplot**, also known as
    a **box-and-whiskers** plot. The boxplot displays the center and spread of a numeric
    variable in a format that allows you to quickly obtain a sense of the range and
    skew of a variable or compare it to other variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at a boxplot for the used car price and mileage data. To
    obtain a boxplot for a variable, we will use the `boxplot()` function. We will
    also specify a pair of extra parameters, `main` and `ylab`, to add a title to
    the figure and label the *y* axis (the vertical axis), respectively. The commands
    to create the `price` and `mileage` boxplots are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'R will produce figures as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Visualizing numeric variables – boxplots](img/B03905_02_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The box-and-whiskers plot depicts the five-number summary values using the horizontal
    lines and dots. The horizontal lines forming the box in the middle of each figure
    represent Q1, Q2 (the median), and Q3 while reading the plot from the bottom to
    the top. The median is denoted by the dark line, which lines up with $13,592 on
    the vertical axis for `price` and 36,385 mi. on the vertical axis for `mileage`.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In simple boxplots such as those in the preceding diagram, the width of the
    box-and-whiskers plot is arbitrary and does not illustrate any characteristic
    of the data. For more sophisticated analyses, it is possible to use the shape
    and size of the boxes to facilitate comparisons of the data across several groups.
    To learn more about such features, begin by examining the `notch` and `varwidth`
    options in the R `boxplot()` documentation by typing the `?boxplot` command.
  prefs: []
  type: TYPE_NORMAL
- en: The minimum and maximum values can be illustrated using the whiskers that extend
    below and above the box; however, a widely used convention only allows the whiskers
    to extend to a minimum or maximum of 1.5 times the IQR below Q1 or above Q3\.
    Any values that fall beyond this threshold are considered outliers and are denoted
    as circles or dots. For example, recall that the IQR for the `price` variable
    was 3,909 with a Q1 of 10,995 and a Q3 of 14,904\. An outlier is therefore any
    value that is less than *10995 - 1.5 * 3909= 5131.5* or greater than *14904 +
    1.5 * 3909 = 20767.5*.
  prefs: []
  type: TYPE_NORMAL
- en: The plot shows two such outliers on both the high and low ends. On the `mileage`
    boxplot, there are no outliers on the low end and thus, the bottom whisker extends
    to the minimum value, 4,867\. On the high end, we see several outliers beyond
    the 100,000 mile mark. These outliers are responsible for our earlier finding,
    which noted that the mean value was much greater than the median.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing numeric variables – histograms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A **histogram** is another way to graphically depict the spread of a numeric
    variable. It is similar to a boxplot in a way that it divides the variable's values
    into a predefined number of portions or **bins** that act as containers for values.
    Their similarities end there, however. On one hand, a boxplot requires that each
    of the four portions of data must contain the same number of values, and widens
    or narrows the bins as needed. On the other hand, a histogram uses any number
    of bins of an identical width, but allows the bins to contain different number
    of values.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create a histogram for the used car price and mileage data using the
    `hist()` function. As we did with the boxplot, we will specify a title for the
    figure using the `main` parameter, and label the *x* axis with the `xlab` parameter.
    The commands to create the histograms are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Visualizing numeric variables – histograms](img/B03905_02_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The histogram is composed of a series of bars with heights indicating the count,
    or **frequency** of values falling within each of the equal width bins partitioning
    the values. The vertical lines that separate the bars, as labeled on the horizontal
    axis, indicate the start and end points of the range of values for the bin.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You may have noticed that the preceding histograms have a different number of
    bins. This is because the `hist()` function attempts to identify a reasonable
    number of bins for the variable's range. If you'd like to override this default,
    use the `breaks` parameter. Supplying an integer like `breaks = 10` would create
    exactly 10 bins of equal width; supplying a vector like `c(5000, 10000, 15000,
    20000)` would create bins that break at the specified values.
  prefs: []
  type: TYPE_NORMAL
- en: On the `price` histogram, each of the 10 bars spans an interval of $2,000, beginning
    at $2,000 and ending at $22,000\. The tallest bar at the center of the figure
    covers the $12,000 to $14,000 range and has a frequency of 50\. Since we know
    that our data includes 150 cars, we know that one-third of all the cars are priced
    from $12,000 to $14,000\. Nearly 90 cars—more than half—are priced from $12,000
    to $16,000.
  prefs: []
  type: TYPE_NORMAL
- en: The `mileage` histogram includes eight bars indicating bins of 20,000 miles
    each, beginning at 0 and ending at 160,000 miles. Unlike the price histogram,
    the tallest bar is not at the center of the data, but on the left-hand side of
    the diagram. The 70 cars contained in this bin have odometer readings from 20,000
    to 40,000 miles.
  prefs: []
  type: TYPE_NORMAL
- en: 'You might also notice that the shape of the two histograms is somewhat different.
    It seems that the used car prices tend to be evenly divided on both sides of the
    middle, while the car mileages stretch further to the right. This characteristic
    is known as **skew**, or more specifically right skew, because the values on the
    high end (right side) are far more spread out than the values on the low end (left
    side). As shown in the following diagram, histograms of skewed data look stretched
    on one of the sides:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Visualizing numeric variables – histograms](img/B03905_02_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The ability to quickly diagnose such patterns in our data is one of the strengths
    of the histogram as a data exploration tool. This will become even more important
    as we start examining other patterns of spread in numeric data.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding numeric data – uniform and normal distributions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Histograms, boxplots, and statistics describing the center and spread provide
    ways to examine the distribution of a variable's values. A variable's **distribution**
    describes how likely a value is to fall within various ranges.
  prefs: []
  type: TYPE_NORMAL
- en: 'If all the values are equally likely to occur—say, for instance, in a dataset
    recording the values rolled on a fair six-sided die—the distribution is said to
    be **uniform**. A uniform distribution is easy to detect with a histogram, because
    the bars are approximately the same height. When visualized with a histogram,
    it may look something like the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding numeric data – uniform and normal distributions](img/B03905_02_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: It's important to note that not all random events are uniform. For instance,
    rolling a weighted six-sided trick die would result in some numbers coming up
    more often than others. While each roll of the die results in a randomly selected
    number, they are not equally likely.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take, for instance, the used car data. This is clearly not uniform, since some
    values are seemingly far more likely to occur than others. In fact, on the price
    histogram, it seems that values grow less likely to occur as they are further
    away from both sides of the center bar, resulting in a bell-shaped distribution
    of data. This characteristic is so common in real-world data that it is the hallmark
    of the so-called **normal distribution**. The stereotypical bell-shaped curve
    of normal distribution is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding numeric data – uniform and normal distributions](img/B03905_02_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Although there are numerous types of non-normal distributions, many real-world
    phenomena generate data that can be described by the normal distribution. Therefore,
    the normal distribution's properties have been studied in great detail.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring spread – variance and standard deviation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Distributions allow us to characterize a large number of values using a smaller
    number of parameters. The normal distribution, which describes many types of real-world
    data, can be defined with just two: center and spread. The center of normal distribution
    is defined by its mean value, which we have used earlier. The spread is measured
    by a statistic called the **standard deviation**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to calculate the standard deviation, we must first obtain the **variance**,
    which is defined as the average of the squared differences between each value
    and the mean value. In mathematical notation, the variance of a set of *n* values
    of *x* is defined by the following formula. The Greek letter *mu* (similar in
    appearance to an *m* or *u*) denotes the mean of the values, and the variance
    itself is denoted by the Greek letter *sigma* squared (similar to a *b* turned
    sideways):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Measuring spread – variance and standard deviation](img/B03905_02_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The standard deviation is the square root of the variance, and is denoted by
    *sigma*, as shown in the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Measuring spread – variance and standard deviation](img/B03905_02_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The `var()` and `sd()` functions can be used to obtain the variance and standard
    deviation in R. For example, computing the variance and standard deviation on
    our `price` and `mileage` variables, we find:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: While interpreting the variance, larger numbers indicate that the data are spread
    more widely around the mean. The standard deviation indicates, on average, how
    much each value differs from the mean.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you compute these statistics by hand using the formulas in the preceding
    diagrams, you will obtain a slightly different result than the built-in R functions.
    This is because the preceding formulae use the population variance (which divides
    by *n*), while R uses the sample variance (which divides by *n - 1*). Except for
    very small datasets, the distinction is minor.
  prefs: []
  type: TYPE_NORMAL
- en: 'The standard deviation can be used to quickly estimate how extreme a given
    value is under the assumption that it came from a normal distribution. The **68-95-99.7
    rule** states that 68 percent of the values in a normal distribution fall within
    one standard deviation of the mean, while 95 percent and 99.7 percent of the values
    fall within two and three standard deviations, respectively. This is illustrated
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Measuring spread – variance and standard deviation](img/B03905_02_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Applying this information to the used car data, we know that since the mean
    and standard deviation of `price` were $12,962 and $3,122, respectively, assuming
    that the prices are normally distributed, approximately 68 percent of cars in
    our data were advertised at prices between *$12,962 - $3,122 = $9,840* and *$12,962
    + $3,122 = $16,804*.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although, strictly speaking, the 68-95-99.7 rule only applies to normal distributions,
    the basic principle applies to any data; values more than three standard deviations
    away from the mean are exceedingly rare events.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring categorical variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you recall, the used car dataset had three categorical variables: `model`,
    `color`, and `transmission`. Because we used the `stringsAsFactors = FALSE` parameter
    while loading the data, R has left them as the `character` (`chr`) type vectors
    rather than automatically converting them into `factor` type. Additionally, we
    might consider treating the year variable as categorical; although it has been
    loaded as a `numeric` (`int`) type vector, each year is a category that could
    apply to multiple cars.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In contrast to `numeric` data, categorical data is typically examined using
    tables rather than summary statistics. A table that presents a single categorical
    variable is known as a **one-way table**. The `table()` function can be used to
    generate one-way tables for our used car data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: The `table()` output lists the categories of the nominal variable and a count
    of the number of values falling into this category. Since we know that there are
    150 used cars in the dataset, we can determine that roughly one-third of all the
    cars were manufactured in the year `2010`, given that *49/150 = 0.327*.
  prefs: []
  type: TYPE_NORMAL
- en: 'R can also perform the calculation of table proportions directly, by using
    the `prop.table()` command on a table produced by the `table()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The results of `prop.table()` can be combined with other R functions to transform
    the output. Suppose that we would like to display the results in percentages with
    a single decimal place. We can do this by multiplying the proportions by 100,
    then using the `round()` function while specifying `digits = 1`, as shown in the
    following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Although this includes the same information as the default `prop.table()` output,
    this is easier to read. The results show that black is the most common color,
    since nearly a quarter (23.3 percent) of all the advertised cars are `Black`.
    `Silver` is a close second with 21.3 percent and `Red` is third with 16.7 percent.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring the central tendency – the mode
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In statistics terms, the **mode** of a feature is the value occurring most often.
    Like the mean and median, the mode is another measure of central tendency. It
    is often used for categorical data, since the mean and median are not defined
    for nominal variables.
  prefs: []
  type: TYPE_NORMAL
- en: For example, in the used car data, the mode of the `year` variable is 2010,
    while the modes for the `model` and `color` variables are `SE` and `Black`, respectively.
    A variable may have more than one mode; a variable with a single mode is **unimodal**,
    while a variable with two modes is **bimodal**. Data having multiple modes is
    more generally called **multimodal**.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although you might suspect that you could use the `mode()` function, R uses
    this to obtain the type of variable (as in `numeric`, `list`, and so on) rather
    than the statistical mode. Instead, to find the statistical mode, simply look
    at the table output of the category with the greatest number of values.
  prefs: []
  type: TYPE_NORMAL
- en: The mode or modes are used in a qualitative sense to gain an understanding of
    important values. Yet, it would be dangerous to place too much emphasis on the
    mode, since the most common value is not necessarily a majority. For instance,
    although `Black` was the most common value for the `color` variable, black cars
    were only about a quarter of all advertised cars.
  prefs: []
  type: TYPE_NORMAL
- en: It is best to think about modes in relation to the other categories. Is there
    one category that dominates all the others or are there several? From here, we
    may ask what the most common values tell us about the variable being measured.
    If black and silver are commonly used car colors, we might assume that the data
    are for luxury cars, which tend to be sold in more conservative colors. These
    colors could also indicate economy cars, which are sold with fewer color options.
    We will keep this question in mind as we continue to examine this data.
  prefs: []
  type: TYPE_NORMAL
- en: Thinking about modes as common values allows us to apply the concept of statistical
    mode to the numeric data. Strictly speaking, it would be unlikely to have a mode
    for a continuous variable, since no two values are likely to repeat. Yet, if we
    think about modes as the highest bars on a histogram, we can discuss the modes
    of variables such as `price` and `mileage`. It can be helpful to consider mode
    while exploring the numeric data, particularly to examine whether or not the data
    is multimodal.
  prefs: []
  type: TYPE_NORMAL
- en: '![Measuring the central tendency – the mode](img/B03905_02_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Exploring relationships between variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So far, we have examined variables one at a time, calculating only **univariate**
    statistics. During our investigation, we raised questions that we were unable
    to answer at that time:'
  prefs: []
  type: TYPE_NORMAL
- en: Does the `price` data imply that we are examining only economy-class cars or
    are there also luxury cars with high mileage?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do relationships between the `model` and `color` data provide insight into the
    types of cars we are examining?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These type of questions can be addressed by looking at **bivariate** relationships,
    which consider the relationship between two variables. Relationships of more than
    two variables are called **multivariate** relationships. Let's begin with the
    bivariate case.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing relationships – scatterplots
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A **scatterplot** is a diagram that visualizes a bivariate relationship. It
    is a two-dimensional figure in which dots are drawn on a coordinate plane using
    the values of one feature to provide the horizontal *x* coordinates and the values
    of another feature to provide the vertical *y* coordinates. Patterns in the placement
    of dots reveal the underlying associations between the two features.
  prefs: []
  type: TYPE_NORMAL
- en: To answer our question about the relationship between `price` and `mileage`,
    we will examine a scatterplot. We'll use the `plot()` function along with the
    `main`, `xlab` and `ylab` parameters used previously to label the diagram.
  prefs: []
  type: TYPE_NORMAL
- en: To use `plot()`, we need to specify `x` and `y` vectors containing the values
    used to position the dots on the figure. Although the conclusions would be the
    same regardless of the variable used to supply the *x* and *y* coordinates, convention
    dictates that the *y* variable is the one that is presumed to depend on the other
    (and is therefore known as the dependent variable). Since a seller cannot modify
    the odometer reading, mileage is unlikely to be dependent on the car's price.
    Instead, our hypothesis is that the price depends on the odometer mileage. Therefore,
    we will use `price` as the *y*, or dependent, variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'The full command to create our scatterplot is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following scatterplot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Visualizing relationships – scatterplots](img/B03905_02_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Using the scatterplot, we notice a clear relationship between the price of a
    used car and the odometer reading. To read the plot, examine how values of the
    *y* axis variable change as the values on the *x* axis increase. In this case,
    car prices tend to be lower as the mileage increases. If you have ever sold or
    shopped for a used car, this is not a profound insight.
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps a more interesting finding is the fact that there are very few cars
    that have both high price and high mileage, aside from a lone outlier at about
    125,000 miles and $14,000\. The absence of more points like this provides evidence
    to support a conclusion that our data is unlikely to include any high mileage
    luxury cars. All of the most expensive cars in the data, particularly those above
    $17,500, seem to have extraordinarily low mileage, implying that we could be looking
    at a brand new type of car retailing for about $20,000.
  prefs: []
  type: TYPE_NORMAL
- en: The relationship we've found between car prices and mileage is known as a negative
    association, because it forms a pattern of dots in a line sloping downward. A
    positive association would appear to form a line sloping upward. A flat line,
    or a seemingly random scattering of dots, is evidence that the two variables are
    not associated at all. The strength of a linear association between two variables
    is measured by a statistic known as **correlation**. Correlations are discussed
    in detail in [Chapter 6](ch06.html "Chapter 6. Forecasting Numeric Data – Regression
    Methods"), *Forecasting Numeric Data – Regression Methods*, which covers the methods
    for modeling linear relationships.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Keep in mind that not all associations form straight lines. Sometimes the dots
    form a *U* shape, or a *V* shape; sometimes the pattern seems to be weaker or
    stronger for increasing values of the `x` or `y` variable. Such patterns imply
    that the relationship between the two variables is not linear.
  prefs: []
  type: TYPE_NORMAL
- en: Examining relationships – two-way cross-tabulations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To examine a relationship between two nominal variables, a **two-way cross-tabulation**
    is used (also known as a **crosstab** or **contingency table**). A cross-tabulation
    is similar to a scatterplot in that it allows you to examine how the values of
    one variable vary by the values of another. The format is a table in which the
    rows are the levels of one variable, while the columns are the levels of another.
    Counts in each of the table's cells indicate the number of values falling into
    the particular row and column combination.
  prefs: []
  type: TYPE_NORMAL
- en: 'To answer our earlier question about whether there is a relationship between
    car `model` and `color`, we will examine a crosstab. There are several functions
    to produce two-way tables in R, including `table()`, which we used for one-way
    tables. The `CrossTable()` option in the `gmodels` package by Gregory R. Warnes
    is perhaps the most user-friendly function, as it presents the row, column, and
    margin percentages in a single table, saving us the trouble of combining this
    data ourselves. To install the `gmodels` package, type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: After the package installs, type `library(gmodels)` to load the package. You
    will need to do this during each R session in which you plan on using the `CrossTable()`
    function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before proceeding with our analysis, let''s simplify our project by reducing
    the number of levels in the `color` variable. This variable has nine levels, but
    we don''t really need this much detail. What we are really interested in is whether
    or not the car''s color is conservative. Toward this end, we''ll divide the nine
    colors into two groups: the first group will include the conservative colors `Black`,
    `Gray`, `Silver`, and `White`; and the second group will include `Blue`, `Gold`,
    `Green`, `Red`, and `Yellow`. We will create a binary indicator variable (often
    called a **dummy variable**), indicating whether or not the car''s color is conservative
    by our definition. Its value will be `1` if true, `0` otherwise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'You may have noticed a new command here: the `%in%` operator returns `TRUE`
    or `FALSE` for each value in the vector on the left-hand side of the operator
    depending on whether the value is found in the vector on the right-hand side.
    In simple terms, you can translate this line as "Is the used car color in the
    set of `Black`, `Gray`, `Silver`, and `White`?"'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examining the `table()` output for our newly created variable, we see that
    about two-thirds of the cars have conservative colors, while one-third do not
    have conservative colors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s look at a cross-tabulation to see how the proportion of conservatively
    colored cars varies by the model. Since we''re assuming that the model of the
    car dictates the choice of color, we''ll treat the conservative color indicator
    as the dependent (`y`) variable. The `CrossTable()` command is therefore:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command results in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Examining relationships – two-way cross-tabulations](img/B03905_02_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'There is a wealth of data in the `CrossTable()` output. The legend at the top
    (labeled `Cell Contents`) indicates how to interpret each value. The rows in the
    table indicate the three models of used cars: `SE`, `SEL`, and `SES` (plus an
    additional row for the total across all models). The columns indicate whether
    or not the car''s color is conservative (plus a column totaling across both types
    of color). The first value in each cell indicates the number of cars with that
    combination of model and color. The proportions indicate that the cell''s proportion
    is relative to the chi-square statistic, row''s total, column''s total, and table''s
    total.'
  prefs: []
  type: TYPE_NORMAL
- en: What we are most interested in is the row proportion for conservative cars for
    each model. The row proportions tell us that 0.654 (65 percent) of `SE` cars are
    colored conservatively in comparison to 0.696 (70 percent) of `SEL` cars and 0.653
    (65 percent) of `SES`. These differences are relatively small, suggesting that
    there are no substantial differences in the types of colors chosen by the model
    of the car.
  prefs: []
  type: TYPE_NORMAL
- en: The chi-square values refer to the cell's contribution in the **Pearson's Chi-squared
    test for independence** between two variables. This test measures how likely it
    is that the difference in the cell counts in the table is due to chance alone.
    If the probability is very low, it provides strong evidence that the two variables
    are associated.
  prefs: []
  type: TYPE_NORMAL
- en: You can obtain the chi-squared test results by adding an additional parameter
    specifying `chisq = TRUE` while calling the `CrossTable()` function. In this case,
    the probability is about 93 percent, suggesting that it is very likely that the
    variations in cell count are due to chance alone and not due to a true association
    between the model and the color.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about the basics of managing data in R. We started
    by taking an in-depth look at the structures used for storing various types of
    data. The foundational R data structure is the vector, which is extended and combined
    into more complex data types such as lists and data frames. The data frame is
    an R data structure that corresponds to the notion of a dataset, having both features
    and examples. R provides functions for reading and writing data frames to spreadsheet-like
    tabular data files.
  prefs: []
  type: TYPE_NORMAL
- en: We then explored a real-world dataset containing data on used car prices. We
    examined numeric variables using common summary statistics of center and spread,
    and visualized relationships between prices and odometer readings with a scatterplot.
    We examined nominal variables using tables. In examining the used car data, we
    followed an exploratory process that can be used to understand any dataset. These
    skills will be required for the other projects throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have spent some time understanding the basics of data management
    with R, you are ready to begin using machine learning to solve real-world problems.
    In the next chapter, we will tackle our first classification task using nearest
    neighbor methods.
  prefs: []
  type: TYPE_NORMAL
