<html><head></head><body>
		<div>
			<div id="_idContainer100" class="Content">
			</div>
		</div>
		<div id="_idContainer101" class="Content">
			<h1 id="_idParaDest-153"><a id="_idTextAnchor158"/>6. Building Your Own Program</h1>
		</div>
		<div id="_idContainer109" class="Content">
			<p class="callout-heading">Overview</p>
			<p class="callout">In this chapter, we will present all the steps required to solve a problem using machine learning. We will take a look at the key stages involved in building a comprehensive program. We will save a model in order to get the same results every time it is run and call a saved model to use it for predictions on unseen data. By the end of this chapter, you will be able to create an interactive version of your program so that anyone can use it effectively.</p>
			<h1 id="_idParaDest-154"><a id="_idTextAnchor159"/>Introduction</h1>
			<p>In the previous chapters, we covered the main concepts of machine learning, beginning with the distinction between the two main learning approaches (supervised and unsupervised learning), and then moved on to the specifics of some of the most popular algorithms in the data science community. </p>
			<p>This chapter will talk about the importance of building complete machine learning programs, rather than just training models. This will involve taking the models to the next level, where they can be accessed and used easily.</p>
			<p>We will do this by learning how to save a trained model. This will allow the best performing model to be loaded in order to make predictions over unseen data. We will also learn the importance of making a saved model available through platforms where users can easily interact with it.</p>
			<p>This is especially important when working in a team, either for a company or for research purposes, as it allows all members of the team to use the model without needing a full understanding of it.</p>
			<h1 id="_idParaDest-155"><a id="_idTextAnchor160"/>Program Definition</h1>
			<p>The following section will cover the key stages required to construct a comprehensive machine learning program that allows easy access to the trained model so that we can perform predictions for all future data. These stages will be applied to the construction of a program that allows a bank to determine the promotional strategy for a financial product in its marketing campaign. </p>
			<h2 id="_idParaDest-156"><a id="_idTextAnchor161"/>Building a Program – Key Stages</h2>
			<p>At this point, you should be able to pre-process a dataset, build different models using training data, and compare those models in order to choose the one that best fits the data at hand. These are some of the processes that are handled during the first two stages of building a program, which ultimately allows the creation of the model. Nonetheless, a program should also consider the process of saving the final model, as well as the ability to perform quick predictions without the need for coding. </p>
			<p>The processes that we just discussed are divided into three main stages and will be explained in the following sections. These stages represent the foremost requirements of any machine learning project.</p>
			<h3 id="_idParaDest-157"><a id="_idTextAnchor162"/>Preparation</h3>
			<p>Preparation consists of all the procedures that we have developed thus far, with the objective of outlining the project in alignment with the available information and the desired outcome. The following is a brief description of the three processes in this stage (these have been discussed in detail in previous chapters):</p>
			<ol>
				<li><strong class="bold">Data Exploration</strong>: Once the objective of the study has been established, data exploration is undertaken in order to understand the data that is available and to obtain valuable insights. These insights will be used later to make decisions regarding pre-processing and dividing the data and selecting models, among other uses. The information that's most commonly obtained during data exploration includes the size of the dataset (number of instances and features), the irrelevant features, and whether missing values or evident outliers are present.</li>
				<li><strong class="bold">Data Pre-processing</strong>: As we have already discussed, data pre-processing primarily refers to the process of handling missing values, outliers, and noisy data; converting qualitative features into their numeric forms; and normalizing or standardizing these values. This process can be done manually in any data editor, such as Excel, or by using libraries to code the procedure. </li>
				<li><strong class="bold">Data Splitting</strong>: The final process, data splitting, involves splitting the entire dataset into two or three sets (depending on the approach) that will be used for training, validating, and testing the overall performance of the model. Separating the features and the class label is also handled during this stage.</li>
			</ol>
			<h3 id="_idParaDest-158"><a id="_idTextAnchor163"/>Creation</h3>
			<p>This stage involves all of the steps that are required to create a model that fits the data that is available. This can be done by selecting different algorithms, training and tuning them, comparing the performance of each, and, finally, selecting the one that generalizes best to the data (meaning that it achieves better overall performance). The processes in this stage will be discussed briefly, as follows:</p>
			<ol>
				<li value="1"><strong class="bold">Algorithm Selection</strong>: Irrespective of whether you decide to choose one or multiple algorithms, it is crucial to select an algorithm on the basis of the available data and to take the advantages of each algorithm into consideration. This is important since many data scientists make the mistake of choosing neural networks for any data problem when, in reality, simpler problems can be tackled using simpler models that run more quickly and perform better with smaller datasets. </li>
				<li><strong class="bold">Training Process</strong>: This process involves training the model using the training dataset. This means that the algorithm uses the features data (<strong class="source-inline">X</strong>) and the label classes (<strong class="source-inline">Y</strong>) to determine relationship patterns that will help generalize to unseen data and make predictions when the class label is not available.</li>
				<li><strong class="bold">Model Evaluation</strong>: This process is handled by measuring the performance of the algorithm through the metric that's been selected for the study. As we mentioned previously, it is important to choose the metric that best represents the purpose of the study, considering that the same model can do very well in terms of one metric and poorly in terms of another. <p>While evaluating the model on the validation set, hyperparameters are fine-tuned to achieve the best possible performance. Once the hyperparameters have been tuned, the evaluation is performed on the testing set to measure the overall performance of the model on unseen data.</p></li>
				<li><strong class="bold">Model Comparison and Selection</strong>: When multiple models are created based on different algorithms, a model comparison is performed to select the one that outperforms the others. This comparison should be done by using the same metric for all the models.</li>
			</ol>
			<h3 id="_idParaDest-159"><a id="_idTextAnchor164"/>Interaction</h3>
			<p>The final stage in building a comprehensive machine learning program consists of allowing the final user to easily interact with the model. This includes the process of saving the model into a file, calling the file that holds the saved model, and developing a channel through which users can interact with the model:</p>
			<ol>
				<li value="1"><strong class="bold">Storing the Final Model</strong>: This process is introduced during the development of a machine learning program as it is crucial to enable the unaltered use of the model for future predictions. The process of saving the model is highly important, considering that most algorithms are randomly initialized each time they are run, which makes the results different for each run. The process of saving the model will be explained further later in this chapter.</li>
				<li><strong class="bold">Loading the Model</strong>: Once the model has been saved in a file, it can be accessed by loading the file into any code. The model is then stored in a variable that can be used to apply the <strong class="source-inline">predict</strong> method on unseen data. This process will also be explained later in this chapter.</li>
				<li><strong class="bold">Channel of Interaction</strong>: Finally, it is crucial to develop an interactive and easy way to perform predictions using the saved model, especially because, on many occasions, models are created by the technology team for other teams to use. This means that an ideal program should allow non-experts to use the model for predicting by simply typing in the input data. This idea will also be expanded upon later in this chapter.</li>
			</ol>
			<p>The following diagram illustrates the preceding stages: </p>
			<div>
				<div id="_idContainer102" class="IMG---Figure">
					<img src="image/B15781_06_01.jpg" alt="Figure 6.1: Stages for building a machine learning program&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.1: Stages for building a machine learning program</p>
			<p>The rest of this chapter will focus on the final stage of building a model (the interaction), considering that all the previous steps were discussed in previous chapters.</p>
			<h2 id="_idParaDest-160"><a id="_idTextAnchor165"/>Understanding the Dataset</h2>
			<p>To learn how to implement the processes in the <em class="italic">Interaction</em> section, we will build a program that's capable of predicting whether a person will be interested in investing in a term deposit, which will help the bank target its promotion efforts. A term deposit is money that is deposited into a banking institution that cannot be withdrawn for a specific period of time.</p>
			<p>The dataset that was used to build this program is available in the UC Irvine Machine Learning Repository under the name <strong class="bold">Bank Marketing Dataset</strong>. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">To download this dataset, visit the following link: <a href="http://archive.ics.uci.edu/ml/datasets/Bank+Marketing">http://archive.ics.uci.edu/ml/datasets/Bank+Marketing</a>.</p>
			<p class="callout">The dataset is also available in this book's GitHub repository: <a href="https://packt.live/2wnJyny">https://packt.live/2wnJyny</a>.</p>
			<p class="callout">Citation: [Moro et al., 2014] S. Moro, P. Cortez and P. Rita<em class="italic">. A Data-Driven Approach to Predict the Success of Bank Telemarketing. </em>Decision Support Systems, Elsevier, 62:22-31, June 2014.</p>
			<p>Once you have accessed the link of the UC Irvine Machine Learning repository, follow these steps to download the dataset:</p>
			<ol>
				<li value="1">First, click on the <strong class="source-inline">Data Folder</strong> link. </li>
				<li>Click the <strong class="source-inline">bank</strong> hyperlink to trigger the download </li>
				<li>Open the <strong class="source-inline">.zip</strong> folder and extract the <strong class="source-inline">bank-full.csv</strong> file.<p>In this section, we will perform a quick exploration of the dataset in a Jupyter Notebook. However, in <em class="italic">Activity 6.01</em>, <em class="italic">Performing the Preparation and Creation Stages for the Bank Marketing Dataset</em>, you will be encouraged to perform a good exploration and pre-process the dataset to arrive at a better mode.</p></li>
				<li>Import the required libraries:<p class="source-code">import pandas as pd</p><p class="source-code">import numpy as np</p></li>
				<li>As we have learned thus far, the dataset can be loaded into a Jupyter Notebook using Pandas:<p class="source-code">data = pd.read_csv("bank-full.csv")</p><p class="source-code">data.head()</p><p>The preceding code reads all the features for one instance in a single column, since the <strong class="source-inline">read_csv</strong> function uses commas as the default delimiter for columns, while the dataset uses semicolons as the delimiter, as can be seen by displaying the head of the resulting DataFrame.</p><p class="callout-heading">Note</p><p class="callout">The delimiter refers to the character that's used to split a string into columns. For instance, a comma-delimited file is one that separates text into columns on the appearances of commas.</p><p>The DataFrame will look as follows:</p><div id="_idContainer103" class="IMG---Figure"><img src="image/B15781_06_02.jpg" alt="Figure 6.2: Screenshot of the data in the .csv file before splitting the data into columns&#13;&#10;"/></div><p class="figure-caption">Figure 6.2: Screenshot of the data in the .csv file before splitting the data into columns</p><p>This can be fixed by adding the <strong class="source-inline">delimiter</strong> parameter to the <strong class="source-inline">read_csv</strong> function and defining the semicolon as the delimiter, as shown in the following code snippet:</p><p class="source-code">data = pd.read_csv("bank-full.csv", delimiter = ";")</p><p class="source-code">data.head()</p><p>After this step, the data should look as follows:</p><div id="_idContainer104" class="IMG---Figure"><img src="image/B15781_06_03.jpg" alt="Figure 6.3: Screenshot of the data in the .csv file after splitting it into columns&#13;&#10;"/></div><p class="figure-caption">Figure 6.3: Screenshot of the data in the .csv file after splitting it into columns</p><p>As shown in the preceding screenshot, the file contains unknown values that should be handled as missing values.</p></li>
				<li>To aid the process of dealing with missing values, all unknown values will be replaced by <strong class="source-inline">NaN</strong> using Pandas' <strong class="source-inline">replace</strong> function, as well as NumPy, as follows:<p class="source-code">data = data.replace("unknown", np.NaN)</p><p class="source-code">data.head()</p><p>By printing the head of the <strong class="source-inline">data</strong> variable, the output of the preceding code snippet is as follows:</p><div id="_idContainer105" class="IMG---Figure"><img src="image/B15781_06_04.jpg" alt="Figure 6.4: Screenshot of the data in the .csv file after replacing unknown values&#13;&#10;"/></div><p class="figure-caption">Figure 6.4: Screenshot of the data in the .csv file after replacing unknown values</p><p>This will allow us to easily handle missing values during the pre-processing of the dataset.</p></li>
				<li>Finally, the edited dataset is saved in a new <strong class="source-inline">.csv</strong> file so that it can be used for the activities throughout this chapter. You can do this by using the <strong class="source-inline">to_csv</strong> function, as follows:<p class="source-code">data.to_csv("bank-full-dataset.csv")</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2AAX2ym">https://packt.live/2AAX2ym</a>.</p><p class="callout">You can also run this example online at <a href="https://packt.live/3ftYXnf">https://packt.live/3ftYXnf</a>. You must execute the entire Notebook in order to get the desired result.</p></li>
			</ol>
			<p>The file should contain a total of 45,211 instances, each with 16 features and one class label, which can be verified by printing the shape of the variable holding the dataset. The class label is binary, of the <strong class="source-inline">yes</strong> or <strong class="source-inline">no</strong> type, and indicates whether the client subscribes to a term deposit with the bank.</p>
			<p>Each instance represents a client of the bank, while the features capture demographic information, as well as data regarding the nature of the contact with the client during the current (and previous) promotional campaign.</p>
			<p>The following table displays brief descriptions of all 16 features. This will help you determine the relevance of each feature to the study, and will provide an idea of some of the steps required to pre-process the data:</p>
			<div>
				<div id="_idContainer106" class="IMG---Figure">
					<img src="image/B15781_06_05.jpg" alt="Figure 6.5: A table describing the features of the dataset&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.5: A table describing the features of the dataset</p>
			<p class="callout-heading">Note</p>
			<p class="callout">You can find the preceding descriptions and more in this book's GitHub repository, in the folder named <strong class="source-inline">Chapter06</strong>. The file for the preceding example is named <strong class="source-inline">bank-names.txt</strong> and can be found in the <strong class="source-inline">.zip</strong> folder called <strong class="source-inline">bank.zip</strong>.</p>
			<p>Using the information we obtained while exploring the dataset, it is possible to proceed with pre-processing the data and training the model, which will be the purpose of the following activity.</p>
			<h2 id="_idParaDest-161"><a id="_idTextAnchor166"/>Activity 6.01: Performing the Preparation and Creation Stages for the Bank Marketing Dataset</h2>
			<p>The objective of this activity is to perform the processes in the <em class="italic">preparation</em> and <em class="italic">creation</em> stages to build a comprehensive machine learning problem.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">For the exercises and activities within this chapter, you will need to have Python 3.7, NumPy, Jupyter, Pandas, and scikit-learn installed on your system.</p>
			<p>Let's consider the following scenario: you work at the principal bank in your town, and the marketing team has decided that they want to know in advance if a client is likely to subscribe to a term deposit so that they can focus their efforts on targeting those clients. </p>
			<p>For this, you have been provided with a dataset containing the details of current and previous marketing activities carried out by the team (the Bank Marketing Dataset that you have downloaded and explored). You have been asked to pre-process the dataset and compare two models so that you can select the best one. </p>
			<p>Follow these steps to achieve this:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">For a reminder of how to pre-process your dataset, revisit <em class="italic">Chapter 1</em>, <em class="italic">Introduction to Scikit-Learn</em>. On the other hand, for a reminder of how to train a supervised model, evaluate performance, and perform error analysis, revisit <em class="italic">Chapter 3</em>, <em class="italic">Supervised Learning – Key Steps</em>, and <em class="italic">Chapter 4</em>, <em class="italic">Supervised Learning Algorithms: Predicting Annual Income</em>.</p>
			<ol>
				<li value="1">Open a Jupyter Notebook to implement this activity and import all the required elements.</li>
				<li>Load the dataset into the notebook. Make sure that you load the one that was edited previously, named <strong class="source-inline">bank-full-dataset.csv</strong>, which is also available at <a href="https://packt.live/2wnJyny">https://packt.live/2wnJyny</a>.</li>
				<li>Select the metric that is the most appropriate for measuring the performance of the model, considering that the purpose of the study is to detect clients who are likely to subscribe to the term deposit.</li>
				<li>Pre-process the dataset.<p>Note that one of the qualitative features is ordinal, which is why it must be converted into a numeric form that follows the respective order. Use the following code snippet to do so:</p><p class="source-code">data["education"] = data["education"].fillna["unknown"]</p><p class="source-code">encoder = ["unknown", "primary", "secondary", "tertiary"]</p><p class="source-code">for i, word in enumerate(encoder):</p><p class="source-code">    data["education"] = data["education"].\</p><p class="source-code">                        str.replace(word,str(i))</p><p class="source-code">    data["education"] = data["education"].astype("int64")</p></li>
				<li>Separate the features from the class label and split the dataset into three sets (training, validation, and testing).</li>
				<li>Use the decision tree algorithm on the dataset and train the model.</li>
				<li>Use the multilayer perceptron algorithm on the dataset and train the model.<p class="callout-heading">Note</p><p class="callout">You can also try this with the other classification algorithms we discussed in this book. However, these two have been chosen so that you are also able to compare the difference in training times.</p></li>
				<li>Evaluate both models by using the metric that you selected previously. </li>
				<li>Fine-tune some of the hyperparameters to fix the issues you detected while evaluating the model by performing error analysis.</li>
				<li>Compare the final versions of your models and select the one that you believe best fits the data.</li>
			</ol>
			<p>Expected output:</p>
			<div>
				<div id="_idContainer107" class="IMG---Figure">
					<img src="image/B15781_06_06.jpg" alt="Figure 6.6: Expected output&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.6: Expected output</p>
			<p class="callout-heading">Note</p>
			<p class="callout">You can find the solution for this activity on page 244.</p>
			<h1 id="_idParaDest-162"><a id="_idTextAnchor167"/>Saving and Loading a Trained Model</h1>
			<p>Although the process of manipulating a dataset and training the right model is crucial for developing a machine learning project, the work does not end there. Knowing how to save a trained model is key as this will allow you to save the hyperparameters, as well as the values for the weights and biases of your final model, so that it remains unchanged when it is run again. </p>
			<p>Moreover, after the model has been saved to a file, it is also important to know how to load the saved model in order to use it to make predictions on new data. By saving and loading a model, we allow for the model to be reused at any moment and through many different means. </p>
			<h2 id="_idParaDest-163"><a id="_idTextAnchor168"/>Saving a Model</h2>
			<p>The process of saving a model is also called <strong class="bold">serialization</strong>, and it has become increasingly important due to the popularity of neural networks that use many parameters (weights and biases) that are randomly initialized every time the model is trained, as well as due to the introduction of bigger and more complex datasets that make the training process last for days, weeks, and sometimes months.</p>
			<p>Considering this, the process of saving a model helps to optimize the use of machine learning solutions by standardizing the results to the saved version of the model. It also saves time as it allows you to directly apply the saved model to new data, without the need for retraining.</p>
			<p>There are two main ways to save a trained model, one of which will be explained in this section. The <strong class="source-inline">pickle</strong> module is the standard way to serialize objects in Python, and it works by implementing a powerful algorithm that serializes the model and then saves it as a <strong class="source-inline">.pkl</strong> file.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The other module that's available for saving a trained model is <strong class="source-inline">joblib</strong>, which is part of the SciPy ecosystem. </p>
			<p>However, take into account that models are only saved when they are meant to be used in future projects or for future predictions. When a machine learning project is developed to understand the current data, there is no need to save it as the analysis will be performed after the model has been trained. </p>
			<h2 id="_idParaDest-164"><a id="_idTextAnchor169"/>Exercise 6.01: Saving a Trained Model </h2>
			<p>For the following exercise, we will use the Fertility Dataset that we downloaded in <em class="italic">Chapter 5</em>, <em class="italic">Artificial Neural Networks: Predicting Annual Income</em>. A neural network will be trained over the training data, and then saved. Follow these steps to complete this exercise:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The dataset is also available in this book's GitHub repository: <a href="https://packt.live/2zBW84e">https://packt.live/2zBW84e</a>.</p>
			<ol>
				<li value="1">Open a Jupyter Notebook to implement this exercise and import all the required elements to load a dataset, train a multilayer perceptron, and save a trained model:<p class="source-code">import pandas as pd</p><p class="source-code">from sklearn.neural_network import MLPClassifier</p><p class="source-code">import pickle</p><p class="source-code">import os</p><p>The <strong class="source-inline">pickle</strong> module, as explained previously, will be used to save the trained model. The <strong class="source-inline">os</strong> module is used to locate the current working directory of the Jupyter Notebook in order to save the model in the same path.</p></li>
				<li>Load the Fertility dataset and split the data into a features matrix, <strong class="source-inline">X</strong>, and a target matrix, <strong class="source-inline">Y</strong>. Use the <strong class="source-inline">header = None</strong> argument, since the dataset does not have a header row:<p class="source-code">data = pd.read_csv("fertility_Diagnosis.csv", header=None)</p><p class="source-code">X = data.iloc[:,:9]</p><p class="source-code">Y = data.iloc[:,9]</p></li>
				<li>Train a multilayer perceptron classifier over the data. Set the number of iterations to <strong class="source-inline">1200</strong> to avoid getting a warning message indicating that the default number of iterations is insufficient to achieve convergence:<p class="source-code">model = MLPClassifier(max_iter = 1200)</p><p class="source-code">model.fit(X,Y)</p><p class="callout-heading">Note</p><p class="callout">As a reminder, the output from calling the <strong class="source-inline">fit</strong> method consists of the model currently being trained with all the parameters that it takes in.</p></li>
				<li>Serialize the model and save it in a file named <strong class="source-inline">model_exercise.pkl</strong>. Use the following code to do so:<p class="source-code">path = os.getcwd() + "/model_exercise.pkl"</p><p class="source-code">file = open(path, "wb")</p><p class="source-code">pickle.dump(model, file)</p><p>In the preceding snippet, the <strong class="source-inline">path</strong> variable contains the path to the file that will hold the serialized model, where the first element locates the current working directory and the second element defines the name of the file to be saved. The <strong class="source-inline">file</strong> variable is used to create a file that will be saved in the desired path and has the file mode set to <strong class="source-inline">wb</strong>, which stands for <strong class="bold">write</strong> and <strong class="bold">binary</strong> (this is the way the serialized model must be written). Finally, the <strong class="source-inline">dump</strong> method is applied over the <strong class="source-inline">pickle</strong> module. It takes the model that was created previously, serializes it, and then saves it.</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3e18vWw">https://packt.live/3e18vWw</a>.</p><p class="callout">You can also run this example online at <a href="https://packt.live/2B7NJpC">https://packt.live/2B7NJpC</a>. You must execute the entire Notebook in order to get the desired result.</p></li>
			</ol>
			<p>You have successfully saved a trained model. In the next section, we will be looking at loading a saved model.</p>
			<h2 id="_idParaDest-165"><a id="_idTextAnchor170"/>Loading a Model</h2>
			<p>The process of loading a model is also known as <strong class="bold">deserialization</strong>, and it consists of taking the previously saved file, deserializing it, and then loading it into code or Terminal so that you can use the model on new data. The <strong class="source-inline">pickle</strong> module is also used to load the model. </p>
			<p>It is worth mentioning that the model does not need to be loaded in the same code file where it was trained and saved; on the contrary, it is meant to be loaded in any other file. This is mainly because the <strong class="source-inline">load</strong> method of the <strong class="source-inline">pickle</strong> library will return the model in a variable that will be used to apply the <strong class="source-inline">predict</strong> method. </p>
			<p>When loading a model, it is important to not only import the <strong class="source-inline">pickle</strong> and <strong class="source-inline">os</strong> modules like we did before, but also the class of the algorithm that is used to train the model. For instance, to load a neural network model, it is necessary to import the <strong class="source-inline">MLPClassifier</strong> class, from the <strong class="source-inline">neural_network</strong> module of scikit-learn.</p>
			<h2 id="_idParaDest-166"><a id="_idTextAnchor171"/>Exercise 6.02: Loading a Saved Model </h2>
			<p>In this exercise, using a different Jupyter Notebook, we will load the previously trained model (<em class="italic">Exercise 6.01</em>, <em class="italic">Saving a Trained Model</em>) and perform a prediction. Follow these steps to complete this exercise:</p>
			<ol>
				<li value="1">Open a Jupyter Notebook to implement this exercise.</li>
				<li>Import the <strong class="source-inline">pickle</strong> and <strong class="source-inline">os</strong> modules. Also, import the <strong class="source-inline">MLPCLassifier</strong> class:<p class="source-code">import pickle</p><p class="source-code">import os</p><p class="source-code">from sklearn.neural_network import MLPClassifier</p><p>The <strong class="source-inline">pickle</strong> module, as explained previously, will be used to load the trained model. The <strong class="source-inline">os</strong> module is used to locate the current working directory of the Jupyter Notebook in order to find the file containing the saved model.</p></li>
				<li>Use <strong class="source-inline">pickle</strong> to load the saved model, as follows:<p class="source-code">path = os.getcwd() + "/model_exercise.pkl"</p><p class="source-code">file = open(path, "rb")</p><p class="source-code">model = pickle.load(file)</p><p>Here, the <strong class="source-inline">path</strong> variable is used to store the path to the file containing the saved model. Next, the <strong class="source-inline">file</strong> variable is used to open the file using the <strong class="source-inline">rb</strong> file mode, which stands for <strong class="bold">read</strong> and <strong class="bold">binary</strong>. Finally, the <strong class="source-inline">load</strong> method is applied on the <strong class="source-inline">pickle</strong> module to deserialize and load the model into the <strong class="source-inline">model</strong> variable.</p></li>
				<li>Use the loaded model to make a prediction for an individual, with the following values as the values for the features: <strong class="source-inline">-0.33, 0.67, 1, 1, 0, 0, 0.8, -1, 0.5</strong>.<p>Store the output obtained by applying the <strong class="source-inline">predict</strong> method to the <strong class="source-inline">model</strong> variable, in a variable named <strong class="source-inline">pred</strong>: </p><p class="source-code">pred = model.predict([[-0.33,0.67,1,1,0,0,0.8,-1,0.5]])</p><p class="source-code">print(pred)</p><p>By printing the <strong class="source-inline">pred</strong> variable, we get the value of the prediction to be equal to <strong class="source-inline">O</strong>, which means that the individual has an altered diagnosis, as shown here:</p><p class="source-code">['O']</p></li>
			</ol>
			<p>You have successfully loaded a saved model.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2MXyGS7">https://packt.live/2MXyGS7</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3dYgVxL">https://packt.live/3dYgVxL</a>. You must execute the entire Notebook in order to get the desired result.</p>
			<h2 id="_idParaDest-167"><a id="_idTextAnchor172"/>Activity 6.02: Saving and Loading the Final Model for the Bank Marketing Dataset</h2>
			<p>Consider the following scenario: you have to save the model you created using the Bank Marketing Dataset so that it can be used in the future without the need to retrain the model and without the risk of getting different results each time. For this purpose, you need to save and load the model that you created in <em class="italic">Activity 6.01</em>, <em class="italic">Performing the Preparation and Creation Stages for the Bank Marketing Dataset</em>.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The following activity will be divided into two parts. </p>
			<p class="callout">The first part carries out the process of saving the model and will be performed using the same Jupyter Notebook from <em class="italic">Activity 6.01</em>, <em class="italic">Performing the Preparation and Creation Stages for the Bank Marketing Dataset</em>. The second part consists of loading the saved model, which will be done using a different Jupyter Notebook.</p>
			<p>Follow these steps to complete this activity:</p>
			<ol>
				<li value="1">Open the Jupyter Notebook from <em class="italic">Activity 6.01</em>, <em class="italic">Performing the Preparation and Creation Stages for the Bank Marketing Dataset</em>.</li>
				<li>For learning purposes, take the model that you selected as the best model, remove the <strong class="source-inline">random_state</strong> argument, and run it a couple of times. <p>Make sure that you run the calculation of the precision metric every time you run the model in order to see the difference in performance that's achieved with every run. Feel free to stop when you think you have landed at a model with good performance out of all the results you get from previous runs.</p><p class="callout-heading">Note</p><p class="callout">The results obtained in this book use a <strong class="source-inline">random_state</strong> of <strong class="source-inline">2</strong>.</p></li>
				<li> Save the model that you choose as the best performing one in a file named <strong class="source-inline">final_model.pkl</strong>. <p class="callout-heading">Note</p><p class="callout">Make sure that you use the <strong class="source-inline">os</strong> module to save the model in the same path as the current Jupyter Notebook.</p></li>
				<li>Open a new Jupyter Notebook and import the required modules and class. </li>
				<li>Load the model.</li>
				<li>Perform a prediction for an individual by using the following values: <strong class="source-inline">42</strong>, <strong class="source-inline">2</strong>, <strong class="source-inline">0</strong>, <strong class="source-inline">0</strong>, <strong class="source-inline">1</strong>, <strong class="source-inline">2</strong>, <strong class="source-inline">1</strong>, <strong class="source-inline">0</strong>, <strong class="source-inline">5</strong>, <strong class="source-inline">8</strong>, <strong class="source-inline">380</strong>, <strong class="source-inline">1</strong>, <strong class="source-inline">-1</strong>, <strong class="source-inline">0</strong>.<p>Expected output:</p><p class="source-code">[0] </p><p class="callout-heading">Note</p><p class="callout">The solution for this activity can be found on page 253.</p></li>
			</ol>
			<h1 id="_idParaDest-168"><a id="_idTextAnchor173"/>Interacting with a Trained Model</h1>
			<p>Once the model has been created and saved, it is time for the last step of building a comprehensive machine learning program: allowing easy interaction with the model. This step not only allows the model to be reused, but also introduces efficiency to the implementation of machine learning solutions by allowing you to perform classifications using just input data.</p>
			<p>There are several ways to interact with a model, and the decision that's made between choosing one or the other depends on the nature of the user (the individuals that will be making use of the model on a regular basis). Machine learning projects can be accessed in different ways, some of which require the use of an API, an online or offline program (application), or a website. </p>
			<p>Moreover, once the channel is defined based on the preference or expertise of the users, it is important to code the connection between the final user and the model, which could be either a function or a class that deserializes the model and loads it, then performs the classification, and ultimately returns an output that is displayed again to the user. </p>
			<p>The following diagram displays the relationship built between the channel and the model, where the icon to the left represents the model, the one in the middle is the function or class (the intermediary) performing the connection, and the icon to the right is the channel. Here, as we explained previously, the channel feeds the input data to the intermediary, which then feeds the information into the model to perform a classification. The output from the classification is sent back to the intermediary, which passes it along the channel in order to be displayed:</p>
			<div>
				<div id="_idContainer108" class="IMG---Figure">
					<img src="image/B15781_06_07.jpg" alt="Figure 6.7: Illustration of the interaction between the user and the model&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.7: Illustration of the interaction between the user and the model</p>
			<h2 id="_idParaDest-169"><a id="_idTextAnchor174"/>Exercise 6.03: Creating a Class and a Channel to Interact with a Trained Model </h2>
			<p>In this exercise, we will create a class in a text editor that takes the input data and feeds it to the model that was trained in <em class="italic">Exercise 6.01</em>, <em class="italic">Saving a Trained Model</em>, with the <strong class="source-inline">Fertility Diagnosis</strong> dataset. Additionally, we will create a form in a Jupyter Notebook, where users can input the data and obtain a prediction.</p>
			<p>To create a class in a text editor, follow these steps:</p>
			<ol>
				<li value="1">Open a text editor of preference, such as PyCharm.</li>
				<li>Import <strong class="source-inline">pickle</strong> and <strong class="source-inline">os</strong>:<p class="source-code">import pickle</p><p class="source-code">import os</p></li>
				<li>Create a class object and name it <strong class="source-inline">NN_Model</strong>:<p class="source-code">Class NN_Model(object):</p></li>
				<li>Inside of the class, create an initializer method that loads the file containing the saved model (<strong class="source-inline">model_exercise.pkl</strong>) into the code:<p class="source-code">def __init__(self):</p><p class="source-code">    path = os.getcwd() + "/model_exercise.pkl"</p><p class="source-code">    file = open(path, "rb")</p><p class="source-code">    self.model = pickle.load(file)</p><p class="callout-heading">Note</p><p class="callout">Remember to indent the method inside of the class object.</p><p>As a general rule, all the methods inside a class object must have the <strong class="source-inline">self</strong> argument. On the other hand, when defining the variable of the model using the <strong class="source-inline">self</strong> statement, it is possible to make use of the variable in any other method of the same class.</p></li>
				<li>Inside the class named <strong class="source-inline">NN_Model</strong>, create a <strong class="source-inline">predict</strong> method. It should take in the feature values and input them as arguments to the <strong class="source-inline">predict</strong> method of the model so that it can feed them into the model and make a prediction:<p class="source-code">def predict(self, season, age, childish, trauma, \</p><p class="source-code">            surgical, fevers, alcohol, smoking, sitting):</p><p class="source-code">    X = [[season, age, childish, trauma, surgical, \</p><p class="source-code">          fevers, alcohol, smoking, sitting]]</p><p class="source-code">    return self.model.predict(X)</p><p class="callout-heading">Note</p><p class="callout">Remember to indent the method inside of the class object.</p></li>
				<li>Save the code as a Python file (<strong class="source-inline">.py</strong>) and name it <strong class="source-inline">exerciseClass.py</strong>. The name of this file will be used to load the class into the Jupyter Notebook for the following steps.<p>Now, let's code the frontend solution of the program, which includes creating a form where users can input data and obtain a prediction.</p><p class="callout-heading">Note</p><p class="callout">For learning purposes, the form will be created in a Jupyter Notebook. However, it is often the case that the frontend is in the form of a website, an app, or something similar.</p></li>
				<li>Open a Jupyter Notebook.</li>
				<li>To import the model class that was saved as a Python file in <em class="italic">Step 6</em>, use the following code snippet:<p class="source-code">from exerciseClass import NN_Model</p></li>
				<li>Initialize the <strong class="source-inline">NN_Model</strong> class and store it in a variable called <strong class="source-inline">model</strong>:<p class="source-code">model = NN_Model()</p><p>By making a call to the class that was saved in the Python file, the initializer method is automatically triggered, which loads the saved model into the variable.</p></li>
				<li>Create a set of variables where the user can input the value for each feature, which will then be fed to the model. Use the following values:<p class="callout-heading">Note</p><p class="callout">The <strong class="source-inline">#</strong> symbol <a id="_idTextAnchor175"/>in the code snippet below denotes a code comment. Comments are added into code to help explain specific bits of logic. </p><p class="source-code">a = 1      # season in which the analysis was performed</p><p class="source-code">b = 0.56   # age at the time of the analysis</p><p class="source-code">c = 1      # childish disease</p><p class="source-code">d = 1      # accident or serious trauma</p><p class="source-code">e = 1      # surgical intervention</p><p class="source-code">f = 0      # high fevers in the last year</p><p class="source-code">g = 1      # frequency of alcohol consumption</p><p class="source-code">h = -1     # smoking habit</p><p class="source-code">i = 0.63   # number of hours spent sitting per day</p></li>
				<li>Perform a prediction by using the <strong class="source-inline">predict</strong> method over the <strong class="source-inline">model</strong> variable. Input the feature values as arguments, taking into account that you must name them in the same way that you did when creating the <strong class="source-inline">predict</strong> function in the text editor:<p class="source-code">pred = model.predict(season=a, age=b, childish=c, \</p><p class="source-code">                     trauma=d, surgical=e, fevers=f, \</p><p class="source-code">                     alcohol=g, smoking=h, sitting=i)</p><p class="source-code">print(pred)</p></li>
				<li>By printing the prediction, we get the following output:<p class="source-code">['N']</p><p>This means that the individual has a normal diagnosis.</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2MZPjg0">https://packt.live/2MZPjg0</a>.</p><p class="callout">You can also run this example online at <a href="https://packt.live/3e4tQOC">https://packt.live/3e4tQOC</a>. You must execute the entire Notebook in order to get the desired result.</p></li>
			</ol>
			<p>You have successfully created a function and a channel to interact with your model.</p>
			<h2 id="_idParaDest-170"><a id="_idTextAnchor176"/>Activity 6.03: Allowing Interaction with the Bank Marketing Dataset Model</h2>
			<p>Consider the following scenario: after seeing the results that you presented in the previous activity, your boss has asked you to build a very simple way for him to test the model with data that he will receive over the course of the next month. If all the tests work well, he will be asking you to launch the program in a more effective way. Hence, you have decided to share a Jupyter Notebook with your boss, where he can just input the information and get a prediction. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">The following activity will be developed in two parts. The first part will involve building the class that connects the channel and the model, which will be developed using a text editor. The second part will be the creation of the channel, which will be done in a Jupyter Notebook.</p>
			<p>Follow these steps to complete this activity:</p>
			<ol>
				<li value="1">In a text editor, create a class object that contains two main methods. One should be an initializer that loads the saved model, while the other should be a <strong class="source-inline">predict</strong> method, wherein the data is fed to the model to retrieve an output.</li>
				<li>In a Jupyter Notebook, import and initialize the class that you created in the previous step. Next, create the variables that will hold the values for all the features of a new observation. Use the following values: <strong class="source-inline">42</strong>, <strong class="source-inline">2</strong>, <strong class="source-inline">0</strong>, <strong class="source-inline">0</strong>, <strong class="source-inline">1</strong>, <strong class="source-inline">2</strong>, <strong class="source-inline">1</strong>, <strong class="source-inline">0</strong>, <strong class="source-inline">5</strong>, <strong class="source-inline">8</strong>, <strong class="source-inline">380</strong>, <strong class="source-inline">1</strong>, <strong class="source-inline">-1</strong>, <strong class="source-inline">0</strong>.</li>
				<li>Perform a prediction by applying the <strong class="source-inline">predict</strong> method.</li>
			</ol>
			<p>Expected output: You will get <strong class="source-inline">0</strong> as the output when you complete this activity.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The solution for this activity can be found on page 254.</p>
			<h1 id="_idParaDest-171"><a id="_idTextAnchor177"/>Summary</h1>
			<p>This chapter wraps up all of the concepts and techniques that are required to successfully train a machine learning model based on training data. In this chapter, we introduced the idea of building a comprehensive machine learning program that not only accounts for the stages involved in the preparation of the dataset and creation of the ideal model, but also the stage related to making the model accessible for future use, which is accomplished by carrying out three main processes: saving the model, loading the model, and creating a channel that allows users to easily interact with the model and obtain an outcome. </p>
			<p>For saving and loading a model, the <strong class="source-inline">pickle</strong> module was introduced. This module is capable of serializing the model to save it in a file, while also being capable of deserializing it to make use of the model in the future.</p>
			<p>Furthermore, to make the model accessible to users, the ideal channel (for example, an API, an application, a website, or a form) needs to be selected according to the type of user that will interact with the model. Then, an intermediary needs to be programmed that can connect the channel with the model. This intermediary is usually in the form of a function or a class.</p>
			<p>The main objective of this book was to introduce scikit-learn's library as a way to develop machine learning solutions in a simple manner. After discussing the importance of and the different techniques involved in data exploration and pre-processing, this book divided its knowledge into the two main areas of machine learning, that is, supervised and unsupervised learning. The most common algorithms were discussed. </p>
			<p>Finally, we explained the importance of measuring the performance of models by performing error analysis in order to improve the overall performance of the model on unseen data, and, ultimately, choosing the model that best represents the data. This final model should be saved so that you can use it in the future for visualizations or to perform predictions.</p>
		</div>
		<div>
			<div id="_idContainer110" class="Basic-Text-Frame">
			</div>
		</div>
		<div>
			<div id="_idContainer111" class="Basic-Text-Frame">
			</div>
		</div>
		<div>
			<div id="_idContainer112" class="Content">
			</div>
		</div>
	</body></html>