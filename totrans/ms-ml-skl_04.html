<html><head></head><body><div class="chapter" title="Chapter&#xA0;4.&#xA0;From Linear Regression to Logistic Regression"><div class="titlepage"><div><div><h1 class="title"><a id="ch04"/>Chapter 4. From Linear Regression to Logistic Regression</h1></div></div></div><p>In <a class="link" href="ch02.html" title="Chapter 2. Linear Regression">Chapter 2</a>, <span class="emphasis"><em>Linear Regression</em></span>, we discussed simple linear regression, multiple linear regression, and polynomial regression. These models are special cases of the generalized linear model, a flexible framework that requires fewer assumptions than ordinary linear regression. In this chapter, we will discuss some of these assumptions as they relate to another special case <a class="indexterm" id="id210"/>of the generalized linear model called <span class="strong"><strong>logistic regression</strong></span>.</p><p>Unlike the models we discussed previously, logistic regression is used for classification tasks. Recall that the goal in classification tasks is to find a function that maps an observation to its associated class or label. A learning algorithm must use pairs of feature vectors and their corresponding labels to induce the values of the mapping function's parameters that produce the best classifier, as measured by a particular performance metric. In binary classification, the classifier must assign instances to one of the two classes. Examples of binary classification include predicting whether or not a patient has a particular disease, whether or not an audio sample contains human speech, or whether or not the Duke men's basketball team will lose in the first round of the NCAA tournament. In multiclass classification, the classifier must assign one of several labels to each instance. In multilabel classification, the classifier must assign a subset of the labels to each instance. In this chapter, we will work through several classification problems using logistic regression, discuss performance measures for the classification task, and apply some of the feature extraction techniques you learned in the previous chapter.</p><div class="section" title="Binary classification with logistic regression"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec34"/>Binary classification with logistic regression</h1></div></div></div><p>Ordinary linear regression assumes that the response variable is normally distributed. The <span class="strong"><strong>normal </strong></span>
<a class="indexterm" id="id211"/>
<span class="strong"><strong>distribution</strong></span>, also known as the <span class="strong"><strong>Gaussian distribution</strong></span> or <span class="strong"><strong>bell curve</strong></span>, is a <a class="indexterm" id="id212"/>function that describes the probability <a class="indexterm" id="id213"/>that an observation will have a value between any two real numbers. Normally distributed data is symmetrical. That is, half of the values are <a class="indexterm" id="id214"/>greater than the mean and the other half of the values are less than the mean. The mean, median, and mode of normally distributed data are also equal. Many natural phenomena approximately follow normal distributions. For instance, the height of people is normally distributed; most people are of average height, a few are tall, and a few are short.</p><p>In some problems the response variable is not normally distributed. For instance, a coin toss can result in two outcomes: heads or tails. The <span class="strong"><strong>Bernoulli distribution</strong></span> describes the probability distribution of a <a class="indexterm" id="id215"/>random variable that can take the positive case with probability <span class="emphasis"><em>P</em></span> or the negative case with probability <span class="emphasis"><em>1-P</em></span>. If the response variable represents a probability, it must be constrained to the range {0,1}. Linear <a class="indexterm" id="id216"/>regression assumes that a constant change in the value of an explanatory variable results in a constant change in the value of the response variable, an assumption that does not hold if the value of the response variable represents a probability. Generalized linear models remove this assumption by relating a linear combination of the explanatory variables to the response variable using a link function. In fact, we already used a link function in <a class="link" href="ch02.html" title="Chapter 2. Linear Regression">Chapter 2</a>, <span class="emphasis"><em>Linear Regression</em></span>; ordinary linear regression is a special case of the generalized linear model that relates a linear combination of the explanatory variables to a normally distributed <a class="indexterm" id="id217"/>response variable using the <span class="strong"><strong>identity link function</strong></span>. We can use a different link function to relate a linear combination of the explanatory variables to the response variable that is not normally distributed.</p><p>In logistic regression, the response variable describes the probability that the outcome is the positive case. If the response variable is equal to or exceeds a discrimination threshold, the positive class is predicted; otherwise, the negative class is predicted. The response variable is modeled as a function of a linear combination of the explanatory variables using the <span class="strong"><strong>logistic </strong></span>
<a class="indexterm" id="id218"/>
<span class="strong"><strong>function</strong></span>. Given by the following equation, the logistic function always returns a value between zero and one:</p><div class="mediaobject"><img alt="Binary classification with logistic regression" src="graphics/8365OS_04_01.jpg"/></div><p>The following is a plot of the value of the logistic function for the range {-6,6}:</p><div class="mediaobject"><img alt="Binary classification with logistic regression" src="graphics/8365OS_04_02.jpg"/></div><p>For logistic regression, <span class="inlinemediaobject"><img alt="Binary classification with logistic regression" src="graphics/8365OS_04_16.jpg"/></span> is equal to a linear combination of explanatory variables, as follows:</p><div class="mediaobject"><img alt="Binary classification with logistic regression" src="graphics/8365OS_04_03.jpg"/></div><p>The <span class="strong"><strong>logit function</strong></span> <a class="indexterm" id="id219"/>is the inverse of the logistic function. It links <span class="inlinemediaobject"><img alt="Binary classification with logistic regression" src="graphics/8365OS_04_17.jpg"/></span> back <a class="indexterm" id="id220"/>to a linear combination of <a class="indexterm" id="id221"/>the explanatory variables:</p><div class="mediaobject"><img alt="Binary classification with logistic regression" src="graphics/8365OS_04_04.jpg"/></div><p>Now that we have defined the model for logistic regression, let's apply it to a binary classification task.</p></div></div>
<div class="section" title="Spam filtering"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec35"/>Spam filtering</h1></div></div></div><p>Our first problem is <a class="indexterm" id="id222"/>a modern version of the canonical binary classification problem: spam classification. In our version, however, we will classify spam and ham SMS messages rather than e-mail. We will extract TF-IDF features from the messages using techniques you learned in <a class="link" href="ch03.html" title="Chapter 3. Feature Extraction and Preprocessing">Chapter 3</a>, <span class="emphasis"><em>Feature Extraction and Preprocessing</em></span>, and classify the messages using logistic regression.</p><p>We will use the <a class="indexterm" id="id223"/>SMS Spam Classification Data Set from the UCI Machine Learning Repository. The dataset can be downloaded from <a class="ulink" href="http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection">http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection</a>. First, let's explore the data set and calculate some basic summary statistics using pandas:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; df = pd.read_csv('data/SMSSpamCollection', delimiter='\t', header=None)
&gt;&gt;&gt; print df.head()

      0                                                  1
0   ham  Go until jurong point, crazy.. Available only ...
1   ham                      Ok lar... Joking wif u oni...
2  spam  Free entry in 2 a wkly comp to win FA Cup fina...
3   ham  U dun say so early hor... U c already then say...
4   ham  Nah I don't think he goes to usf, he lives aro...
[5 rows x 2 columns]

&gt;&gt;&gt; print 'Number of spam messages:', df[df[0] == 'spam'][0].count()
&gt;&gt;&gt; print 'Number of ham messages:', df[df[0] == 'ham'][0].count()

Number of spam messages: 747
Number of ham messages: 4825</pre></div><p>A binary label and a text message comprise each row. The data set contains 5,574 instances; 4,827 messages are ham and the remaining 747 messages are spam. The ham messages are labeled with zero, and the spam messages are labeled with one. While the noteworthy, or case, outcome is often assigned the label one and the non-case outcome is often assigned zero, these assignments are arbitrary. Inspecting the data may reveal other attributes that should be captured in the model. The following selection of messages characterizes both of the classes:</p><div class="informalexample"><pre class="programlisting">Spam: Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's
Spam: WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.
Ham: Sorry my roommates took forever, it ok if I come by now?
Ham: Finished class where are you.</pre></div><p>Let's make some predictions using scikit-learn's <code class="literal">LogisticRegression</code> class:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; from sklearn.feature_extraction.text import TfidfVectorizer
&gt;&gt;&gt; from sklearn.linear_model.logistic import LogisticRegression
&gt;&gt;&gt; from sklearn.cross_validation import train_test_split, cross_val_score</pre></div><p>First, we load the <code class="literal">.csv</code> file using pandas and split the data set into training and test sets. By default, <code class="literal">train_test_split()</code> assigns 75 percent of the samples to the training set and allocates the <a class="indexterm" id="id224"/>remaining 25 percent of the samples to the test set:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; df = pd.read_csv('data/SMSSpamCollection', delimiter='\t', header=None)
&gt;&gt;&gt; X_train_raw, X_test_raw, y_train, y_test = train_test_split(df[1], df[0])</pre></div><p>Next, we create a <code class="literal">TfidfVectorizer</code>. Recall from <a class="link" href="ch03.html" title="Chapter 3. Feature Extraction and Preprocessing">Chapter 3</a>, <span class="emphasis"><em>Feature Extraction and Preprocessing</em></span>, that <code class="literal">TfidfVectorizer</code> combines <code class="literal">CountVectorizer</code> and <code class="literal">TfidfTransformer</code>. We fit it with the training messages, and transform both the training and test messages:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; vectorizer = TfidfVectorizer()
&gt;&gt;&gt; X_train = vectorizer.fit_transform(X_train_raw)
&gt;&gt;&gt; X_test = vectorizer.transform(X_test_raw)</pre></div><p>Finally, we create an instance of <code class="literal">LogisticRegression</code> and train our model. Like <code class="literal">LinearRegression</code>, <code class="literal">LogisticRegression</code> implements the <code class="literal">fit()</code> and <code class="literal">predict()</code> methods. As a sanity check, we printed a few predictions for manual inspection:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; classifier = LogisticRegression()
&gt;&gt;&gt; classifier.fit(X_train, y_train)
&gt;&gt;&gt; predictions = classifier.predict(X_test)
&gt;&gt;&gt; for i, prediction in enumerate(predictions[:5]):
&gt;&gt;&gt;     print 'Prediction: %s. Message: %s' % (prediction, X_test_raw[i])</pre></div><p>The following is the output of the script:</p><div class="informalexample"><pre class="programlisting">Prediction: ham. Message: If you don't respond imma assume you're still asleep and imma start calling n shit
Prediction: spam. Message: HOT LIVE FANTASIES call now 08707500020 Just 20p per min NTT Ltd, PO Box 1327 Croydon CR9 5WB 0870 is a national rate call
Prediction: ham. Message: Yup... I havent been there before... You want to go for the yoga? I can call up to book 
Prediction: ham. Message: Hi, can i please get a  &amp;lt;#&amp;gt;  dollar loan from you. I.ll pay you back by mid february. Pls.
Prediction: ham. Message: Where do you need to go to get it?</pre></div><p>How well does our classifier perform? The performance metrics we used for linear regression are inappropriate for this task. We are only interested in whether the predicted class was correct, not how <a class="indexterm" id="id225"/>far it was from the decision boundary. In the next section, we will discuss some performance metrics that can be used to evaluate binary classifiers.</p></div>
<div class="section" title="Binary classification performance metrics"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec36"/>Binary classification performance metrics</h1></div></div></div><p>A variety <a class="indexterm" id="id226"/>of metrics exist to evaluate the performance <a class="indexterm" id="id227"/>of binary classifiers against trusted labels. The most common metrics are <span class="strong"><strong>accuracy</strong></span>, <span class="strong"><strong>precision</strong></span>, <span class="strong"><strong>recall</strong></span>, <span class="strong"><strong>F1 measure</strong></span>, and <span class="strong"><strong>ROC AUC score</strong></span>. All <a class="indexterm" id="id228"/>of these measures depend on the concepts of <span class="strong"><strong>true positives</strong></span>, <span class="strong"><strong>true </strong></span>
<a class="indexterm" id="id229"/>
<span class="strong"><strong>negatives</strong></span>, <span class="strong"><strong>false positives</strong></span>, and <span class="strong"><strong>false negatives</strong></span>. <span class="emphasis"><em>Positive</em></span> and <span class="emphasis"><em>negative</em></span> <a class="indexterm" id="id230"/>refer to the classes. <span class="emphasis"><em>True</em></span> and <span class="emphasis"><em>false</em></span> denote whether the <a class="indexterm" id="id231"/>predicted class is the same as the true class.</p><p>For our SMS <a class="indexterm" id="id232"/>spam classifier, a true positive prediction is when the classifier correctly predicts that a message is spam. A true negative prediction is when the classifier correctly predicts that a message is ham. A prediction that a ham message is spam is a false positive prediction, and a spam message incorrectly classified as <a class="indexterm" id="id233"/>ham is a false negative prediction. A <span class="strong"><strong>confusion matrix</strong></span>, or <a class="indexterm" id="id234"/>
<span class="strong"><strong>contingency table</strong></span>, can be used to visualize true and false positives and negatives. The rows of the matrix are the true classes of the instances, and the columns are the predicted classes of the instances:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.metrics import confusion_matrix
&gt;&gt;&gt; import matplotlib.pyplot as plt

&gt;&gt;&gt; y_test = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]
&gt;&gt;&gt; y_pred = [0, 1, 0, 0, 0, 0, 0, 1, 1, 1]
&gt;&gt;&gt; confusion_matrix = confusion_matrix(y_test, y_pred)
&gt;&gt;&gt; print(confusion_matrix)
&gt;&gt;&gt; plt.matshow(confusion_matrix)
&gt;&gt;&gt; plt.title('Confusion matrix')
&gt;&gt;&gt; plt.colorbar()
&gt;&gt;&gt; plt.ylabel('True label')
&gt;&gt;&gt; plt.xlabel('Predicted label')
&gt;&gt;&gt; plt.show()

 [[4 1]
 [2 3]]</pre></div><p>The confusion matrix indicates that there were four true negative predictions, three true positive predictions, two false negative predictions, and one false positive prediction. Confusion matrices become more useful in multi-class problems, in which it can be difficult to <a class="indexterm" id="id235"/>determine the most frequent <a class="indexterm" id="id236"/>types of errors.</p><div class="mediaobject"><img alt="Binary classification performance metrics" src="graphics/8365OS_04_05.jpg"/></div><div class="section" title="Accuracy"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec19"/>Accuracy</h2></div></div></div><p>Accuracy <a class="indexterm" id="id237"/>measures a fraction of the classifier's predictions that are <a class="indexterm" id="id238"/>correct. scikit-learn provides a function to calculate the accuracy of a set of predictions given the correct labels:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; from sklearn.metrics import accuracy_score
&gt;&gt;&gt; y_pred, y_true = [0, 1, 1, 0], [1, 1, 1, 1]
&gt;&gt;&gt; print 'Accuracy:', accuracy_score(y_true, y_pred)

Accuracy: 0.5</pre></div><p>
<code class="literal">LogisticRegression.score()</code> predicts and scores labels for a test set using accuracy. Let's evaluate our classifier's accuracy:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; from sklearn.feature_extraction.text import TfidfVectorizer
&gt;&gt;&gt; from sklearn.linear_model.logistic import LogisticRegression
&gt;&gt;&gt; from sklearn.cross_validation import train_test_split, cross_val_score
&gt;&gt;&gt; df = pd.read_csv('data/sms.csv')
&gt;&gt;&gt; X_train_raw, X_test_raw, y_train, y_test = train_test_split(df['message'], df['label'])
&gt;&gt;&gt; vectorizer = TfidfVectorizer()
&gt;&gt;&gt; X_train = vectorizer.fit_transform(X_train_raw)
&gt;&gt;&gt; X_test = vectorizer.transform(X_test_raw)
&gt;&gt;&gt; classifier = LogisticRegression()
&gt;&gt;&gt; classifier.fit(X_train, y_train)
&gt;&gt;&gt; scores = cross_val_score(classifier, X_train, y_train, cv=5)
&gt;&gt;&gt; print np.mean(scores), scores

Accuracy 0.956217208018 [ 0.96057348  0.95334928  0.96411483  0.95454545  0.94850299]</pre></div><p>Note that your accuracy may differ as the training and test sets are assigned randomly. While accuracy <a class="indexterm" id="id239"/>measures the overall correctness of the classifier, it does not distinguish between false positive errors and false negative errors. Some applications may be more sensitive to false negatives than false positives, or vice versa. Furthermore, accuracy is not an informative metric if the proportions of the classes are skewed in the <a class="indexterm" id="id240"/>population. For example, a classifier that predicts whether or not credit card transactions are fraudulent may be more sensitive to false negatives than to false positives. To promote customer satisfaction, the credit card company may prefer to risk verifying legitimate transactions than risk ignoring a fraudulent transaction. Because most transactions are legitimate, accuracy is not an appropriate metric for this problem. A classifier that always predicts that transactions are legitimate could have a high accuracy score, but would not be useful. For these reasons, classifiers are often evaluated using two additional measures called precision and recall.</p></div><div class="section" title="Precision and recall"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec20"/>Precision and recall</h2></div></div></div><p>Recall from <a class="link" href="ch01.html" title="Chapter 1. The Fundamentals of Machine Learning">Chapter 1</a>, <span class="emphasis"><em>The Fundamentals of Machine Learning</em></span>, that precision is the <a class="indexterm" id="id241"/>fraction of positive predictions that are <a class="indexterm" id="id242"/>correct. For instance, in our SMS spam classifier, precision is the <a class="indexterm" id="id243"/>fraction of messages classified as spam that are actually spam. Precision is given by the following ratio:</p><div class="mediaobject"><img alt="Precision and recall" src="graphics/8365OS_04_06.jpg"/></div><p>Sometimes called sensitivity in medical domains, recall is the fraction of the truly positive instances that the classifier recognizes. A recall score of one indicates that the classifier did not make any <a class="indexterm" id="id244"/>false negative predictions. For our SMS spam classifier, recall is the fraction of spam messages that were truly classified as spam. Recall is calculated with the following ratio:</p><div class="mediaobject"><img alt="Precision and recall" src="graphics/8365OS_04_07.jpg"/></div><p>Individually, precision and recall are seldom informative; they are both incomplete views of a classifier's performance. Both precision and recall can fail to distinguish classifiers that perform well from certain types of classifiers that perform poorly. A trivial classifier could easily achieve a <a class="indexterm" id="id245"/>perfect recall score by predicting positive for <a class="indexterm" id="id246"/>every instance. For example, assume that a test set contains ten positive examples and ten negative examples. A classifier that predicts positive for every example will achieve a recall of one, as follows:</p><div class="mediaobject"><img alt="Precision and recall" src="graphics/8365OS_04_08.jpg"/></div><p>A classifier that predicts negative for every example, or that makes only false positive and true negative predictions, will achieve a recall score of zero. Similarly, a classifier that predicts that only a single instance is positive and happens to be correct will achieve perfect precision.</p><p>scikit-learn provides a function to calculate the precision and recall for a classifier from a set of predictions and the corresponding set of trusted labels. Let's calculate our SMS classifier's precision and recall:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; from sklearn.feature_extraction.text import TfidfVectorizer
&gt;&gt;&gt; from sklearn.linear_model.logistic import LogisticRegression
&gt;&gt;&gt; from sklearn.cross_validation import train_test_split, cross_val_score
&gt;&gt;&gt; df = pd.read_csv('data/sms.csv')
&gt;&gt;&gt; X_train_raw, X_test_raw, y_train, y_test = train_test_split(df['message'], df['label'])
&gt;&gt;&gt; vectorizer = TfidfVectorizer()
&gt;&gt;&gt; X_train = vectorizer.fit_transform(X_train_raw)
&gt;&gt;&gt; X_test = vectorizer.transform(X_test_raw)
&gt;&gt;&gt; classifier = LogisticRegression()
&gt;&gt;&gt; classifier.fit(X_train, y_train)
&gt;&gt;&gt; precisions = cross_val_score(classifier, X_train, y_train, cv=5, scoring='precision')
&gt;&gt;&gt; print 'Precision', np.mean(precisions), precisions
&gt;&gt;&gt; recalls = cross_val_score(classifier, X_train, y_train, cv=5, scoring='recall')
&gt;&gt;&gt; print 'Recalls', np.mean(recalls), recalls

Precision 0.992137651822 [ 0.98717949  0.98666667  1.          0.98684211  1.        ]
Recall 0.677114261885 [ 0.7         0.67272727  0.6         0.68807339  0.72477064]</pre></div><p>Our classifier's precision is 0.992; almost all of the messages that it predicted as spam were actually spam. Its <a class="indexterm" id="id247"/>recall is lower, indicating that it incorrectly <a class="indexterm" id="id248"/>classified approximately 22 percent of the spam messages as ham. Your precision and recall may vary since the training and test data are randomly partitioned.</p></div></div>
<div class="section" title="Calculating the F1 measure"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec37"/>Calculating the F1 measure</h1></div></div></div><p>The F1 measure <a class="indexterm" id="id249"/>is the harmonic mean, or weighted average, of the precision and recall scores. Also called the f-measure or the f-score, the F1 score is calculated using the following formula:</p><div class="mediaobject"><img alt="Calculating the F1 measure" src="graphics/8365OS_04_09.jpg"/></div><p>The F1 measure penalizes classifiers with imbalanced precision and recall scores, like the trivial classifier that always predicts the positive class. A model with perfect precision and recall scores will achieve an F1 score of one. A model with a perfect precision score and a recall score of zero will achieve an F1 score of zero. As for precision and recall, scikit-learn provides a function to calculate the F1 score for a set of predictions. Let's compute our classifier's F1 score. The following snippet continues the previous code sample:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; f1s = cross_val_score(classifier, X_train, y_train, cv=5, scoring='f1')
&gt;&gt;&gt; print 'F1', np.mean(f1s), f1s

F1 0.80261302628 [ 0.82539683  0.8         0.77348066  0.83157895  0.7826087 ]</pre></div><p>The arithmetic mean of our classifier's precision and recall scores is 0.803. As the difference between the classifier's precision and recall is small, the F1 measure's penalty is small. Models are <a class="indexterm" id="id250"/>sometimes evaluated using the F0.5 and F2 scores, which favor precision over recall and recall over precision, respectively.</p></div>
<div class="section" title="ROC AUC"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec38"/>ROC AUC</h1></div></div></div><p>A <span class="strong"><strong>Receiver Operating Characteristic</strong></span>, or <span class="strong"><strong>ROC curve</strong></span>, visualizes a classifier's performance. Unlike accuracy, the ROC curve is insensitive to data sets with unbalanced class proportions; unlike precision and recall, the ROC curve illustrates the classifier's performance for all values of the <a class="indexterm" id="id251"/>discrimination threshold. ROC curves plot the classifier's recall against its <span class="strong"><strong>fall-out</strong></span>. Fall-out, or the false positive rate, is the number of false positives divided by the <a class="indexterm" id="id252"/>total number of negatives. It is calculated using <a class="indexterm" id="id253"/>the following formula:</p><div class="mediaobject"><img alt="ROC AUC" src="graphics/8365OS_04_10.jpg"/></div><p>
<span class="strong"><strong>AUC</strong></span> is the area under the <a class="indexterm" id="id254"/>ROC curve; it reduces the ROC curve to a single value, which represents the expected performance of the classifier. The dashed line in the following figure is for a classifier that predicts classes randomly; it has an AUC of 0.5. The solid curve is for a classifier that outperforms random guessing:</p><div class="mediaobject"><img alt="ROC AUC" src="graphics/8365OS_04_11.jpg"/></div><p>Let's plot the <a class="indexterm" id="id255"/>ROC curve for our SMS spam classifier:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import matplotlib.pyplot as plt
&gt;&gt;&gt; from sklearn.feature_extraction.text import TfidfVectorizer
&gt;&gt;&gt; from sklearn.linear_model.logistic import LogisticRegression
&gt;&gt;&gt; from sklearn.cross_validation import train_test_split, cross_val_score
&gt;&gt;&gt; from sklearn.metrics import roc_curve, auc
&gt;&gt;&gt; df = pd.read_csv('data/sms.csv')
&gt;&gt;&gt; X_train_raw, X_test_raw, y_train, y_test = train_test_split(df['message'], df['label'])
&gt;&gt;&gt; vectorizer = TfidfVectorizer()
&gt;&gt;&gt; X_train = vectorizer.fit_transform(X_train_raw)
&gt;&gt;&gt; X_test = vectorizer.transform(X_test_raw)
&gt;&gt;&gt; classifier = LogisticRegression()
&gt;&gt;&gt; classifier.fit(X_train, y_train)
&gt;&gt;&gt; predictions = classifier.predict_proba(X_test)
&gt;&gt;&gt; false_positive_rate, recall, thresholds = roc_curve(y_test, predictions[:, 1])
&gt;&gt;&gt; roc_auc = auc(false_positive_rate, recall)
&gt;&gt;&gt; plt.title('Receiver Operating Characteristic')
&gt;&gt;&gt; plt.plot(false_positive_rate, recall, 'b', label='AUC = %0.2f' % roc_auc)
&gt;&gt;&gt; plt.legend(loc='lower right')
&gt;&gt;&gt; plt.plot([0, 1], [0, 1], 'r--')
&gt;&gt;&gt; plt.xlim([0.0, 1.0])
&gt;&gt;&gt; plt.ylim([0.0, 1.0])
&gt;&gt;&gt; plt.ylabel('Recall')
&gt;&gt;&gt; plt.xlabel('Fall-out')
&gt;&gt;&gt; plt.show()</pre></div><p>From the ROC AUC plot, it <a class="indexterm" id="id256"/>is apparent that our classifier outperforms random guessing; most of the plot area lies under its curve:</p><div class="mediaobject"><img alt="ROC AUC" src="graphics/8365OS_04_12.jpg"/></div></div>
<div class="section" title="Tuning models with grid search"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec39"/>Tuning models with grid search</h1></div></div></div><p>Hyperparameters <a class="indexterm" id="id257"/>are parameters of the model that are not learned. For example, hyperparameters of our logistic regression SMS classifier include <a class="indexterm" id="id258"/>the value of the regularization term and thresholds used to remove words that appear too frequently or infrequently. In scikit-learn, hyperparameters are set through the model's constructor. In the previous examples, we did not set any arguments for <code class="literal">LogisticRegression()</code>; we used the default values for all of the hyperparameters. These default values are often a good start, but they may not produce the optimal model. <span class="strong"><strong>Grid search</strong></span> is a common method to select the hyperparameter values that produce the best model. Grid search takes a set of possible values for each hyperparameter that should be tuned, and evaluates a model trained on each element of the Cartesian product of the sets. That is, grid search is an exhaustive search that trains and evaluates a model for each possible combination of the hyperparameter values supplied by the developer. A disadvantage of grid search is that it is <a class="indexterm" id="id259"/>computationally costly for even small sets of hyperparameter values. Fortunately, it is an <span class="strong"><strong>embarrassingly parallel</strong></span> problem; many models can <a class="indexterm" id="id260"/>easily be trained and evaluated concurrently since <a class="indexterm" id="id261"/>no synchronization is required between the processes. Let's use scikit-learn's <code class="literal">GridSearchCV()</code> function to find better hyperparameter values:</p><div class="informalexample"><pre class="programlisting">import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model.logistic import LogisticRegression
from sklearn.grid_search import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.cross_validation import train_test_split
from sklearn.metrics import precision_score, recall_score, accuracy_score

pipeline = Pipeline([
    ('vect', TfidfVectorizer(stop_words='english')),
    ('clf', LogisticRegression())
])
parameters = {
    'vect__max_df': (0.25, 0.5, 0.75),
    'vect__stop_words': ('english', None),
    'vect__max_features': (2500, 5000, 10000, None),
    'vect__ngram_range': ((1, 1), (1, 2)),
    'vect__use_idf': (True, False),
    'vect__norm': ('l1', 'l2'),
    'clf__penalty': ('l1', 'l2'),
    'clf__C': (0.01, 0.1, 1, 10),
}</pre></div><p>
<code class="literal">GridSearchCV()</code> takes an estimator, a parameter space, and performance measure. The argument <code class="literal">n_jobs</code> specifies the maximum number of concurrent jobs; set <code class="literal">n_jobs</code> to <code class="literal">-1</code> to use all CPU cores. Note that <code class="literal">fit()</code> must be called in a Python <code class="literal">main</code> block in order to fork additional processes; this example must be executed as a script, and not in an interactive interpreter:</p><div class="informalexample"><pre class="programlisting">if __name__ == "__main__":
    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='accuracy', cv=3)
    df = pd.read_csv('data/sms.csv')
    X, y, = df['message'], df['label']
    X_train, X_test, y_train, y_test = train_test_split(X, y)
    grid_search.fit(X_train, y_train)
    print 'Best score: %0.3f' % grid_search.best_score_
    print 'Best parameters set:'
    best_parameters = grid_search.best_estimator_.get_params()
    for param_name in sorted(parameters.keys()):
        print '\t%s: %r' % (param_name, best_parameters[param_name])
    predictions = grid_search.predict(X_test)
    print 'Accuracy:', accuracy_score(y_test, predictions)
    print 'Precision:', precision_score(y_test, predictions)
    print 'Recall:', recall_score(y_test, predictions)</pre></div><p>The following <a class="indexterm" id="id262"/>is the output of the script:</p><div class="informalexample"><pre class="programlisting">Fitting 3 folds for each of 1536 candidates, totalling 4608 fits
[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.2s
[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:    4.0s
[Parallel(n_jobs=-1)]: Done 200 jobs       | elapsed:   16.9s
[Parallel(n_jobs=-1)]: Done 450 jobs       | elapsed:   36.7s
[Parallel(n_jobs=-1)]: Done 800 jobs       | elapsed:  1.1min
[Parallel(n_jobs=-1)]: Done 1250 jobs       | elapsed:  1.7min
[Parallel(n_jobs=-1)]: Done 1800 jobs       | elapsed:  2.5min
[Parallel(n_jobs=-1)]: Done 2450 jobs       | elapsed:  3.4min
[Parallel(n_jobs=-1)]: Done 3200 jobs       | elapsed:  4.4min
[Parallel(n_jobs=-1)]: Done 4050 jobs       | elapsed:  7.7min
[Parallel(n_jobs=-1)]: Done 4608 out of 4608 | elapsed:  8.5min finished
Best score: 0.983
Best parameters set:
  clf__C: 10
  clf__penalty: 'l2'
  vect__max_df: 0.5
  vect__max_features: None
  vect__ngram_range: (1, 2)
  vect__norm: 'l2'
  vect__stop_words: None
  vect__use_idf: True
Accuracy: 0.989956958393
Precision: 0.988095238095
Recall: 0.932584269663</pre></div><p>Optimizing the values of <a class="indexterm" id="id263"/>the hyperparameters has improved our <a class="indexterm" id="id264"/>model's recall score on the <code class="literal">test</code> set.</p></div>
<div class="section" title="Multi-class classification"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec40"/>Multi-class classification</h1></div></div></div><p>In the previous sections you learned to use logistic regression for binary classification. In many classification <a class="indexterm" id="id265"/>problems, however, there are more than two classes that are of interest. We might wish to predict the genres of songs from samples of audio, or classify images of galaxies by their types. The goal of <span class="strong"><strong>multi-class classification</strong></span> is to assign an instance to one of the set of classes. scikit-learn uses a strategy called <span class="strong"><strong>one-vs.-all</strong></span>, or <span class="strong"><strong>one-vs.-the-rest</strong></span>, to support multi-class classification. One-vs.-all<span class="strong"><strong> </strong></span>
<a class="indexterm" id="id266"/>classification uses one binary classifier for each of the possible classes. The <a class="indexterm" id="id267"/>class that is predicted with the greatest confidence is assigned to the instance. <code class="literal">LogisticRegression</code> supports multi-class classification using the one-versus-all strategy out of the box. Let's use <code class="literal">LogisticRegression</code> for a multi-class classification problem.</p><p>Assume that you would like to watch a movie, but you have a strong aversion to watching bad movies. To inform your decision, you could read reviews of the movies you are considering, but unfortunately you also have a strong aversion to reading movie reviews. Let's use scikit-learn to find the movies with good reviews.</p><p>In this example, we will classify the sentiments of phrases taken from movie reviews in the Rotten Tomatoes data set. Each phrase can be classified as one of the following sentiments: negative, somewhat negative, neutral, somewhat positive, or positive. While the classes appear to be ordered, the explanatory variables that we will use do not always corroborate this order due to sarcasm, negation, and other linguistic phenomena. Instead, we will approach this problem as a multi-class classification task.</p><p>The data can be downloaded from <a class="ulink" href="http://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data">http://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data</a>. First, let's explore the data set using pandas. Note that the import and data-loading statements in the following snippet are required for the subsequent snippets:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; df = pd.read_csv('movie-reviews/train.tsv', header=0, delimiter='\t')
&gt;&gt;&gt; print df.count()

PhraseId      156060
SentenceId    156060
Phrase        156060
Sentiment     156060
dtype: int64</pre></div><p>The columns of the data set are tab delimited. The data set contains 1,56,060 instances.</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; print df.head()

   PhraseId  SentenceId                                             Phrase  \
0         1           1  A series of escapades demonstrating the adage ...
1         2           1  A series of escapades demonstrating the adage ...
2         3           1                                           A series
3         4           1                                                  A
4         5           1                                             series

   Sentiment
0          1
1          2
2          2
3          2
4          2

[5 rows x 4 columns]</pre></div><p>The <code class="literal">Sentiment</code> column contains the response variables. The <code class="literal">0</code> label corresponds to the sentiment <code class="literal">negative</code>, <code class="literal">1</code> corresponds to <code class="literal">somewhat negative</code>, and so on. The <code class="literal">Phrase</code> column contains the <a class="indexterm" id="id268"/>raw text. Each sentence from the movie reviews has been parsed into smaller phrases. We will not require the <code class="literal">PhraseId</code> and <code class="literal">SentenceId</code> columns in this example. Let's print some of the phrases and examine them:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; print df['Phrase'].head(10)

0    A series of escapades demonstrating the adage ...
1    A series of escapades demonstrating the adage ...
2                                             A series
3                                                    A
4                                               series
5    of escapades demonstrating the adage that what...
6                                                   of
7    escapades demonstrating the adage that what is...
8                                            escapades
9    demonstrating the adage that what is good for ...
Name: Phrase, dtype: object</pre></div><p>Now let's examine the target classes:</p><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; print df['Sentiment'].describe()

count    156060.000000
mean          2.063578
std           0.893832
min           0.000000
25%           2.000000
50%           2.000000
75%           3.000000
max           4.000000
Name: Sentiment, dtype: float64

&gt;&gt;&gt; print df['Sentiment'].value_counts()

2    79582
3    32927
1    27273
4     9206
0     7072
dtype: int64

&gt;&gt;&gt; print df['Sentiment'].value_counts()/df['Sentiment'].count()

2    0.509945
3    0.210989
1    0.174760
4    0.058990
0    0.045316
dtype: float64</pre></div><p>The most common class, <code class="literal">Neutral</code>, includes more than 50 percent of the instances. Accuracy will not be an informative performance measure for this problem, as a degenerate classifier that predicts only <code class="literal">Neutral</code> can obtain an accuracy near 0.5. Approximately <a class="indexterm" id="id269"/>one quarter of the reviews are positive or somewhat positive, and approximately one fifth of the reviews are negative or somewhat negative. Let's train a classifier with scikit-learn:</p><div class="informalexample"><pre class="programlisting">import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model.logistic import LogisticRegression
from sklearn.cross_validation import train_test_split
from sklearn.metrics.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.pipeline import Pipeline
from sklearn.grid_search import GridSearchCV

def main():
    pipeline = Pipeline([
        ('vect', TfidfVectorizer(stop_words='english')),
        ('clf', LogisticRegression())
    ])
    parameters = {
        'vect__max_df': (0.25, 0.5),
        'vect__ngram_range': ((1, 1), (1, 2)),
        'vect__use_idf': (True, False),
        'clf__C': (0.1, 1, 10),
    }
    df = pd.read_csv('data/train.tsv', header=0, delimiter='\t')
    X, y = df['Phrase'], df['Sentiment'].as_matrix()
    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)
    grid_search = GridSearchCV(pipeline, parameters, n_jobs=3, verbose=1, scoring='accuracy')
    grid_search.fit(X_train, y_train)
    print 'Best score: %0.3f' % grid_search.best_score_
    print 'Best parameters set:'
    best_parameters = grid_search.best_estimator_.get_params()
    for param_name in sorted(parameters.keys()):
        print '\t%s: %r' % (param_name, best_parameters[param_name])

if __name__ == '__main__':
    main()</pre></div><p>The following is <a class="indexterm" id="id270"/>the output of the script:</p><div class="informalexample"><pre class="programlisting">Fitting 3 folds for each of 24 candidates, totalling 72 fits
[Parallel(n_jobs=3)]: Done   1 jobs       | elapsed:    3.3s
[Parallel(n_jobs=3)]: Done  50 jobs       | elapsed:  1.1min
[Parallel(n_jobs=3)]: Done  68 out of  72 | elapsed:  1.9min remaining:    6.8s
[Parallel(n_jobs=3)]: Done  72 out of  72 | elapsed:  2.1min finished
Best score: 0.620
Best parameters set:
  clf__C: 10
  vect__max_df: 0.25
  vect__ngram_range: (1, 2)
  vect__use_idf: False</pre></div><div class="section" title="Multi-class classification performance metrics"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec21"/>Multi-class classification performance metrics</h2></div></div></div><p>As with <a class="indexterm" id="id271"/>binary classification, confusion <a class="indexterm" id="id272"/>matrices are useful for visualizing the types of errors made by the classifier. Precision, recall, and F1 score can be computed for each of the classes, and accuracy for all of the predictions can also be calculated. Let's evaluate our classifier's predictions. The following snippet continues the previous example:</p><div class="informalexample"><pre class="programlisting">    predictions = grid_search.predict(X_test)
    print 'Accuracy:', accuracy_score(y_test, predictions)
    print 'Confusion Matrix:', confusion_matrix(y_test, predictions)
    print 'Classification Report:', classification_report(y_test, predictions)</pre></div><p>The following will be appended to the output:</p><div class="informalexample"><pre class="programlisting">Accuracy: 0.636370626682
Confusion Matrix: [[ 1129  1679   634    64     9]
 [  917  6121  6084   505    35]
 [  229  3091 32688  3614   166]
 [   34   408  6734  8068  1299]
 [    5    35   494  2338  1650]]
Classification Report:              precision    recall  f1-score   support

          0       0.49      0.32      0.39      3515
          1       0.54      0.45      0.49     13662
          2       0.70      0.82      0.76     39788
          3       0.55      0.49      0.52     16543
          4       0.52      0.36      0.43      4522

avg / total       0.62      0.64      0.62     78030</pre></div><p>First, we make predictions using the best parameter set found by using grid searching. While our classifier is an improvement over the baseline classifier, it frequently mistakes <code class="literal">Somewhat Positive</code> and <code class="literal">Somewhat Negative</code> for <code class="literal">Neutral</code>.</p></div></div>
<div class="section" title="Multi-label classification and problem transformation"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec41"/>Multi-label classification and problem transformation</h1></div></div></div><p>In the previous <a class="indexterm" id="id273"/>sections, we discussed <a class="indexterm" id="id274"/>binary classification, in which each instance must be assigned to one of the two classes, and multi-class classification, in which each instance must be assigned to one of the set of classes. The final type of classification problem that we will discuss is multi-label classification, in which each instance can be assigned a subset of the set of classes. Examples of multi-label classification include assigning tags to messages posted on a forum, and classifying the objects present in an image. There are two groups of approaches for multi-label classification.</p><p>
<span class="strong"><strong>Problem transformation</strong></span> methods are techniques that cast the original multi-label problem as a set of single-label classification problems. The first problem transformation method <a class="indexterm" id="id275"/>that we will review converts each set of labels encountered in the training data to a single label. For example, consider a multi-label classification problem in which news articles must be assigned to one or <a class="indexterm" id="id276"/>more categories from a set. The following training data contains seven articles that can pertain to one or more of the five categories.</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom"> </th><th colspan="5" style="text-align: center" valign="bottom">
<p>Categories</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Instance</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Local</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>US</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Business</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Science and Technology</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Sports</strong></span>
</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>1</p>
</td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td></tr><tr><td style="text-align: left" valign="top">
<p>2</p>
</td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td></tr><tr><td style="text-align: left" valign="top">
<p>3</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td></tr><tr><td style="text-align: left" valign="top">
<p>4</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>5</p>
</td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td></tr><tr><td style="text-align: left" valign="top">
<p>6</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td></tr><tr><td style="text-align: left" valign="top">
<p>7</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td></tr></tbody></table></div><p>Transforming the problem into a single-label classification task using the power set of labels seen in the training data results in the following training data. Previously, the first instance was classified as <code class="literal">Local</code> and <code class="literal">US</code>. Now it has a single label, <code class="literal">Local </code>
<span class="inlinemediaobject"><img alt="Multi-label classification and problem transformation" src="graphics/8365OS_04_18.jpg"/></span>
<code class="literal"> US</code>.</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom"> </th><th colspan="7" style="text-align: center" valign="bottom">
<p>Category</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Instance</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Local</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Local </strong></span>
<span class="inlinemediaobject"><img alt="Multi-label classification and problem transformation" src="graphics/8365OS_04_18.jpg"/></span>
<span class="strong"><strong> US</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Business</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Local </strong></span>
<span class="inlinemediaobject"><img alt="Multi-label classification and problem transformation" src="graphics/8365OS_04_18.jpg"/></span>
<span class="strong"><strong> Business</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>US </strong></span>
<span class="inlinemediaobject"><img alt="Multi-label classification and problem transformation" src="graphics/8365OS_04_18.jpg"/></span>
<span class="strong"><strong> Science and Technology</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Business </strong></span>
<span class="inlinemediaobject"><img alt="Multi-label classification and problem transformation" src="graphics/8365OS_04_18.jpg"/></span>
<span class="strong"><strong> Science and Technology</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Sports</strong></span>
</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>1</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td></tr><tr><td style="text-align: left" valign="top">
<p>2</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td></tr><tr><td style="text-align: left" valign="top">
<p>3</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td></tr><tr><td style="text-align: left" valign="top">
<p>4</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>5</p>
</td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td></tr><tr><td style="text-align: left" valign="top">
<p>6</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td></tr><tr><td style="text-align: left" valign="top">
<p>7</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td></tr></tbody></table></div><p>The multi-label classification problem that had five classes is now a multi-class classification problem with seven classes. While the power set problem transformation is intuitive, increasing the number of classes is frequently impractical; this transformation can produce many new <a class="indexterm" id="id277"/>labels that correspond to only a few training instances. Furthermore, the classifier can only predict <a class="indexterm" id="id278"/>combinations of labels that were seen in the training data.</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom"> </th><th colspan="2" style="text-align: center" valign="bottom">
<p>Category</p>
</th><th style="text-align: left" valign="bottom"> </th><th colspan="2" style="text-align: center" valign="bottom">
<p>Category</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Instance</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Local</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>¬Local</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Instance</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Business</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>¬Business</strong></span>
</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>1</p>
</td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>1</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>2</p>
</td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>2</p>
</td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td></tr><tr><td style="text-align: left" valign="top">
<p>3</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top">
<p>3</p>
</td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td></tr><tr><td style="text-align: left" valign="top">
<p>4</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top">
<p>4</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>5</p>
</td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>5</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>6</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top">
<p>6</p>
</td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td></tr><tr><td style="text-align: left" valign="top">
<p>7</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top">
<p>7</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td></tr><tr><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td></tr><tr><td style="text-align: left" valign="top"> </td><td colspan="2" style="text-align: center" valign="top">
<p>
<span class="strong"><strong>Category</strong></span>
</p>
</td><td style="text-align: left" valign="top"> </td><td colspan="2" style="text-align: center" valign="top">
<p>
<span class="strong"><strong>Category</strong></span>
</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Instance</p>
</td><td style="text-align: left" valign="top">
<p>US</p>
</td><td style="text-align: left" valign="top">
<p>¬US</p>
</td><td style="text-align: left" valign="top">
<p>Instance</p>
</td><td style="text-align: left" valign="top">
<p>US</p>
</td><td style="text-align: left" valign="top">
<p>¬US</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>1</p>
</td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>1</p>
</td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td></tr><tr><td style="text-align: left" valign="top">
<p>2</p>
</td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>2</p>
</td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td></tr><tr><td style="text-align: left" valign="top">
<p>3</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top">
<p>3</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>4</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top">
<p>4</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>5</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top">
<p>5</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>6</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top">
<p>6</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>7</p>
</td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>7</p>
</td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td></tr><tr><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top"> </td></tr><tr><td style="text-align: left" valign="top"> </td><td colspan="2" style="text-align: center" valign="top">
<p>
<span class="strong"><strong>Category</strong></span>
</p>
</td><td style="text-align: left" valign="top"> </td><td colspan="2" style="text-align: center" valign="top">
<p>
<span class="strong"><strong>Category</strong></span>
</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Instance</p>
</td><td style="text-align: left" valign="top">
<p>Sci. and Tech.</p>
</td><td style="text-align: left" valign="top">
<p>¬Sci. and Tech.</p>
</td><td style="text-align: left" valign="top">
<p>Instance</p>
</td><td style="text-align: left" valign="top">
<p>Sports</p>
</td><td style="text-align: left" valign="top">
<p>¬Sports</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>1</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top">
<p>1</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>2</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top">
<p>2</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>3</p>
</td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>3</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>4</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top">
<p>4</p>
</td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top"> </td></tr><tr><td style="text-align: left" valign="top">
<p>5</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top">
<p>5</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>6</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td><td style="text-align: left" valign="top">
<p>6</p>
</td><td style="text-align: left" valign="top"> </td><td style="text-align: left" valign="top">
<p>✔</p>
</td></tr></tbody></table></div><p>A second problem transformation is to train one binary classifier for each of the labels in the training set. Each classifier predicts whether or not the instance belongs to one label. Our example would require five binary classifiers; the first classifier would predict whether or not <a class="indexterm" id="id279"/>an instance should be classified as <code class="literal">Local</code>, the second classifier would predict whether or not an instance should be classified as <code class="literal">US</code>, and so on. The final prediction is the union of the predictions <a class="indexterm" id="id280"/>from all of the binary classifiers. The transformed training data is shown in the previous figure. This problem transformation ensures that the single-label problems will have the same number of training examples as the multilabel problem, but ignores relationships between the labels.</p><div class="section" title="Multi-label classification performance metrics"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec22"/>Multi-label classification performance metrics</h2></div></div></div><p>Multi-label <a class="indexterm" id="id281"/>classification problems must be assessed using different performance measures than single-label classification problems. Two <a class="indexterm" id="id282"/>of the most common performance metrics are <span class="strong"><strong>Hamming loss</strong></span> and <span class="strong"><strong>Jaccard similarity</strong></span>. Hamming loss is the average fraction of <a class="indexterm" id="id283"/>incorrect labels. Note that Hamming loss is a loss function, and that the perfect score is zero. Jaccard similarity, or the Jaccard index, is the size of the intersection of the predicted labels and the true labels divided by the size of the union of the predicted and true labels. It ranges from zero to one, and one is the perfect score. Jaccard <a class="indexterm" id="id284"/>similarity is calculated by the following <a class="indexterm" id="id285"/>equation:</p><div class="mediaobject"><img alt="Multi-label classification performance metrics" src="graphics/8365OS_04_13.jpg"/></div><div class="informalexample"><pre class="programlisting">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.metrics import hamming_loss
&gt;&gt;&gt; print hamming_loss(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[0.0, 1.0], [1.0, 1.0]]))
0.0
&gt;&gt;&gt; print hamming_loss(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[1.0, 1.0], [1.0, 1.0]]))
0.25
&gt;&gt;&gt; print hamming_loss(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[1.0, 1.0], [0.0, 1.0]]))
0.5
&gt;&gt;&gt; print jaccard_similarity_score(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[0.0, 1.0], [1.0, 1.0]]))
1.0
&gt;&gt;&gt; print jaccard_similarity_score(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[1.0, 1.0], [1.0, 1.0]]))
0.75
&gt;&gt;&gt; print jaccard_similarity_score(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[1.0, 1.0], [0.0, 1.0]]))
0.5</pre></div></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec42"/>Summary</h1></div></div></div><p>In this chapter we discussed generalized linear models, which extend ordinary linear regression to support response variables with non-normal distributions. Generalized linear models use a link function to relate a linear combination of the explanatory variables to the response variable; unlike ordinary linear regression, the relationship does not need to be linear. In particular, we examined the logistic link function, a sigmoid function that returns a value between zero and one for any real number.</p><p>We discussed logistic regression, a generalized linear model that uses the logistic link function to relate explanatory variables to a Bernoulli-distributed response variable. Logistic regression can be used for binary classification, a task in which an instance must be assigned to one of the two classes; we used logistic regression to classify spam and ham SMS messages. We then discussed multi-class classification, a task in which each instance must be assigned one label from a set of labels. We used the one-vs.-all strategy to classify the sentiments of movie reviews. Finally, we discussed multi-label classification, in which instances must be assigned a subset of a set of labels. Having completed our discussion of regression and classification with generalized linear models, we will introduce a non-linear model for regression and classification called the decision tree in the next chapter.</p></div></body></html>