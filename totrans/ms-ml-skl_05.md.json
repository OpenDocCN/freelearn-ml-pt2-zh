["```py\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.grid_search import GridSearchCV\n```", "```py\nif __name__ == '__main__':\n    df = pd.read_csv('data/ad.data', header=None)\n    explanatory_variable_columns = set(df.columns.values)\n    response_variable_column = df[len(df.columns.values)-1]\n    # The last column describes the targets\n    explanatory_variable_columns.remove(len(df.columns.values)-1)\n\n    y = [1 if e == 'ad.' else 0 for e in response_variable_column]\n    X = df[list(explanatory_variable_columns)]\n```", "```py\n    X.replace(to_replace=' *\\?', value=-1, regex=True, inplace=True)\n```", "```py\n    X_train, X_test, y_train, y_test = train_test_split(X, y)\n```", "```py\n    pipeline = Pipeline([\n        ('clf', DecisionTreeClassifier(criterion='entropy'))\n    ])\n```", "```py\n    parameters = {\n        'clf__max_depth': (150, 155, 160),\n        'clf__min_samples_split': (1, 2, 3),\n        'clf__min_samples_leaf': (1, 2, 3)\n    }\n```", "```py\n    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='f1')\n    grid_search.fit(X_train, y_train)\n    print 'Best score: %0.3f' % grid_search.best_score_\n    print 'Best parameters set:'\n    best_parameters = grid_search.best_estimator_.get_params()\n    for param_name in sorted(parameters.keys()):\n        print '\\t%s: %r' % (param_name, best_parameters[param_name])\n\n    predictions = grid_search.predict(X_test)\n    print classification_report(y_test, predictions)\n\nFitting 3 folds for each of 27 candidates, totalling 81 fits\n[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    1.7s\n[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:   15.0s\n[Parallel(n_jobs=-1)]: Done  71 out of  81 | elapsed:   20.7s remaining:    2.9s\n[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:   23.3s finished\nBest score: 0.878\nBest parameters set:\n\tclf__max_depth: 155\n\tclf__min_samples_leaf: 2\n\tclf__min_samples_split: 1\n             precision    recall  f1-score   support\n\n          0       0.97      0.99      0.98       710\n          1       0.92      0.81      0.86       110\n\navg / total       0.96      0.96      0.96       820\n```", "```py\nfrom sklearn.ensemble import RandomForestClassifier\n```", "```py\n    pipeline = Pipeline([\n        ('clf', RandomForestClassifier(criterion='entropy'))\n    ])\n    parameters = {\n        'clf__n_estimators': (5, 10, 20, 50),\n        'clf__max_depth': (50, 150, 250),\n        'clf__min_samples_split': (1, 2, 3),\n        'clf__min_samples_leaf': (1, 2, 3)\n    }\n```", "```py\nFitting 3 folds for each of 108 candidates, totalling 324 fits\n[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    1.1s\n[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:   17.4s\n[Parallel(n_jobs=-1)]: Done 200 jobs       | elapsed:  1.0min\n[Parallel(n_jobs=-1)]: Done 324 out of 324 | elapsed:  1.6min finished\nBest score: 0.936\nBest parameters set:\n   clf__max_depth: 250\n   clf__min_samples_leaf: 1\n   clf__min_samples_split: 3\n   clf__n_estimators: 20\n             precision    recall  f1-score   support\n\n          0       0.97      1.00      0.98       705\n          1       0.97      0.83      0.90       115\n\navg / total       0.97      0.97      0.97       820\n```"]