["```py\nfrom sklearn.datasets import load_digits\ndigits = load_digits()\n```", "```py\ndigits['target']\n# Output: array([0, 1, 2, ..., 8, 9, 8])\n```", "```py\ndigits['data']\n# Output: \n# array([[ 0., 0., 5., ..., 0., 0., 0.], \n#  [ 0., 0., 0., ..., 10., 0., 0.], \n#  ..., \n#  [ 0., 0., 2., ..., 12., 0., 0.], \n#  [ 0., 0., 10., ..., 12., 1., 0.]])\n```", "```py\ndef display_img(img, target, ax):\n    img = img.reshape((8, 8))\n    ax.imshow(img, cmap='gray')\n    ax.set_title(f'Digit: {str(target)}')\n    ax.grid(False)\n```", "```py\nfig, axs = plt.subplots(1, 8, figsize=(15, 10))\n\nfor i in range(8):\n    display_img(digits['data'][i], digits['target'][i], axs[i])\n\nfig.show()\n```", "```py\nfrom sklearn.model_selection import train_test_split\nx, y = digits['data'], digits['target']\nx_train, x_test, y_train, y_test = train_test_split(x, y)\n```", "```py\nfrom sklearn.neighbors import KNeighborsClassifier\n\nclf = KNeighborsClassifier(n_neighbors=11, metric='manhattan')\nclf.fit(x_train, y_train)\ny_test_pred = clf.predict(x_test)\n```", "```py\nfrom sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(clf, x_test, y_test, cmap='Greys')\n```", "```py\nfrom sklearn.neighbors import DistanceMetric\n\npoints = pd.DataFrame(\n    [[1, 2], [4, 6]], columns=['x1', 'x2']\n)\n\nd = [\n  (p, DistanceMetric.get_metric('minkowski', p=p).pairwise(points)[0][-1])\n  for p in [1, 2, 10, 50, 100]\n]\n```", "```py\nfrom sklearn.metrics.pairwise import (\n    euclidean_distances, \n    manhattan_distances, \n    cosine_distances\n)\n\nd0 = manhattan_distances(\n [1.0 * digits['data'][0], 2.0 * digits['data'][0]]\n)[0,1]\n\nd1 = euclidean_distances(\n [1.0 * digits['data'][0], 2.0 * digits['data'][0]]\n)[0,1]\n\nd2 = cosine_distances(\n [1.0 * digits['data'][0], 2.0 * digits['data'][0]]\n)[0,1]\n```", "```py\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\n\nparameters = {\n    'metric':('manhattan','euclidean', 'cosine'), \n    'n_neighbors': range(1, 21)\n}\n\nknn = KNeighborsClassifier()\ngscv = GridSearchCV(knn, param_grid=parameters, scoring='accuracy')\n\ngscv.fit(x_train, y_train)\n```", "```py\nfrom sklearn.metrics import accuracy_score\n\ny_test_pred = gscv.predict(x_test)\naccuracy_score(y_test, y_test_pred)\n```", "```py\nclf = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\nclf.fit(x_train, y_train)\ny_train_pred = clf.predict(x_train)\n```", "```py\nx_train_inv = x_train.max() - x_train \n```", "```py\nimg_inv = x_train_inv[0]\n\nfig, axs = plt.subplots(1, 8, figsize=(14, 5))\n\ndisplay_img(img_inv, y_train[0], axs[0])\n\n_, kneighbors_index_inv = clf.kneighbors(\n    [x_train_inv[0]], \n    n_neighbors=7, \n    return_distance=True\n)\n\nfor i, neighbor_index in enumerate(kneighbors_index_inv[0], 1):\n    display_img(\n        x_train[neighbor_index], \n        y_train[neighbor_index], \n        axs[i]\n    )\n```", "```py\nfrom sklearn.metrics.pairwise import euclidean_distances\n\ndef contrast_distance(x1, x2):\n    _x1, _x2 = np.abs(8 - x1), np.abs(8 - x2)\n    d = euclidean_distances([_x1], [_x2])\n    return d[0][0]\n```", "```py\nclf = KNeighborsClassifier(n_neighbors=3, metric=contrast_distance)\nclf.fit(x_train, y_train)\n```", "```py\nfrom sklearn.neighbors import KNeighborsRegressor\nclf = KNeighborsRegressor(n_neighbors=3, metric='euclidean')\nclf.fit(x_train, y_train)\ny_test_pred = clf.predict(x_test)\n```", "```py\nfrom sklearn.neighbors import NearestCentroid\nclf = NearestCentroid(metric='euclidean')\nclf.fit(x_train, y_train)\n```", "```py\nfig, axs = plt.subplots(1, len(clf.classes_), figsize=(15, 5))\n\nfor i, (centroid, label) in enumerate(zip(clf.centroids_, clf.classes_)):\n    display_img(centroid, label, axs[i])\n\nfig.show()\n```", "```py\ndf = pd.DataFrame(\n    {\n        'x1': np.random.normal(loc=10.0, scale=5.0, size=8),\n        'noise': np.random.normal(loc=0.0, scale=1.0, size=8),\n    }\n)\n\ndf['x2'] = 3 * df['x1'] + df['noise'] \n```", "```py\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nscaler = StandardScaler(with_std=False)\nx = scaler.fit_transform(df[['x1', 'x2']])\n\npca = PCA(n_components=1)\nx_new = pca.fit_transform(x)\n```", "```py\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.random_projection import SparseRandomProjection\nfrom sklearn.decomposition import PCA\nfrom sklearn.neighbors import NeighborhoodComponentsAnalysis\n\nmethods = {\n    'Rand': SparseRandomProjection(n_components=2),\n    'PCA': PCA(n_components=2),\n    'NCA': NeighborhoodComponentsAnalysis(n_components=2, init='random'),\n}\n```", "```py\nfig, axs = plt.subplots(1, 3, figsize=(15, 5))\n\nfor i, (method_name, method_obj) in enumerate(methods.items()):\n\n    scaler = StandardScaler(with_std=False)\n    x_train_scaled = scaler.fit_transform(x_train)\n\n    method_obj.fit(x_train_scaled, y_train)\n    x_train_2d = method_obj.transform(x_train_scaled)\n\n    for target in set(y_train):\n        pd.DataFrame(\n            x_train_2d[\n                y_train == target\n            ], columns=['y', 'x']\n        ).sample(n=20).plot(\n            kind='scatter', x='x', y='y', \n            marker=f'${target}$', s=64, ax=axs[i]\n        )\n        axs[i].set_title(f'{method_name} MNIST')\n```", "```py\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = StandardScaler(with_std=False)\n\nx_train_scaled = scaler.fit_transform(x_train)\nx_test_scaled = scaler.fit_transform(x_test)\n\nmethod_obj.fit(x_train_scaled, y_train)\nx_train_2d = method_obj.transform(x_train_scaled)\nx_test_2d = method_obj.transform(x_test_scaled)\n\nscaler = MinMaxScaler()\nx_train_scaled = scaler.fit_transform(x_train_2d)\nx_test_scaled = scaler.transform(x_test_2d)\n```", "```py\nfrom sklearn.neighbors import KNeighborsClassifier \nfrom sklearn.model_selection import GridSearchCV \nfrom sklearn.metrics import accuracy_score\n\nparameters = {'metric':('manhattan','euclidean'), 'n_neighbors': range(3, 9)}\n\nknn = KNeighborsClassifier()\nclf = GridSearchCV(knn, param_grid=parameters, scoring='accuracy', cv=5)\n\nclf.fit(x_train_scaled, y_train)\ny_test_pred = clf.predict(x_test_scaled)\n\nprint(\n    'MNIST test accuracy score: {:.1%} [k={}, metric={} - {}]'.format(\n        accuracy_score(y_test, y_test_pred), \n        clf.best_params_['n_neighbors'], \n        clf.best_params_['metric'], \n        method_name\n    )\n)\n```", "```py\ndf_explained_variance_ratio = pd.DataFrame(\n    [\n        (component, explained_variance_ratio) \n        for component, explained_variance_ratio in enumerate(pca.explained_variance_ratio_[:32], 1)\n    ], columns=['component', 'explained_variance_ratio']\n)\n```", "```py\nfrom sklearn.neighbors import NearestCentroid\n\nscores = []\nfor n_components in range(1, 33, 1):\n\n    # Scale and transform the features as before \n    clf = NearestCentroid(shrink_threshold=0.01)\n    clf.fit(x_train_embed, y_train)\n    y_test_pred = clf.predict(x_test_embed)\n\nscores.append([n_components, accuracy_score(y_test, y_test_pred)])\n```", "```py\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler(with_std=False)\nx_train_scaled = scaler.fit_transform(x_train)\nx_test_scaled = scaler.transform(x_test)\n```", "```py\nfrom sklearn.decomposition import PCA\nembedder = PCA(n_components=32)\nembedder.fit(x_train, y_train)\n\nx_train_embed = embedder.transform(x_train_scaled)\nx_test_embed = embedder.transform(x_test_scaled)\n\nx_train_restored = embedder.inverse_transform(x_train_embed) \nx_test_restored = embedder.inverse_transform(x_test_embed)\n```", "```py\niscaler = MinMaxScaler((x_train.min(), x_train.max()))\nx_train_restored = iscaler.fit_transform(x_train_restored) \nx_test_restored = iscaler.fit_transform(x_test_restored)\n```", "```py\nfrom sklearn.feature_selection import mutual_info_classif\nmi = mutual_info_classif(x_train, y_train)\n```", "```py\npercent_to_remove = 75\nmi_threshold = np.quantile(mi, 0.01 * percent_to_remove)\ninformative_pixels = (mi >= mi_threshold).reshape((8, 8))\n\nplt.imshow(informative_pixels, cmap='Greys')\nplt.title(f'Pixels kept when {percent_to_remove}% removed')\n```", "```py\nfrom sklearn.feature_selection import SelectPercentile\npercent_to_keep = 100 - percent_to_remove\nselector = SelectPercentile(mutual_info_classif, percentile=percent_to_keep)\n\nx_train_mi = selector.fit_transform(x_train, y_train)\nx_test_mi = selector.transform(x_test)\n```"]