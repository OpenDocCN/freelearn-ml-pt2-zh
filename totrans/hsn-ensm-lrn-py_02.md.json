["```py\n# --- SECTION 1 ---\n# Libraries and data loading\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\ndiabetes = load_diabetes()\n```", "```py\n# --- SECTION 2 ---\n# Split the data into train and test set\ntrain_x, train_y = diabetes.data[:400], diabetes.target[:400]\ntest_x, test_y = diabetes.data[400:], diabetes.target[400:]\n```", "```py\n# --- SECTION 3 ---\n# Instantiate, train and evaluate the model\nols = LinearRegression()\nols.fit(train_x, train_y)\nerr = metrics.mean_squared_error(test_y, ols.predict(test_x))\nr2 = metrics.r2_score(test_y, ols.predict(test_x))\n```", "```py\n# --- SECTION 4 ---\n# Print the model\nprint('---OLS on diabetes dataset.---')\nprint('Coefficients:')\nprint('Intercept (b): %.2f'%ols.intercept_)\nfor i in range(len(diabetes.feature_names)):\n print(diabetes.feature_names[i]+': %.2f'%ols.coef_[i])\nprint('-'*30)\nprint('R-squared: %.2f'%r2, ' MSE: %.2f \\n'%err)\n```", "```py\n---OLS on diabetes dataset.---\nCoefficients:\nIntercept (b): 152.73\nage: 5.03\nsex: -238.41\nbmi: 521.63\nbp: 299.94\ns1: -752.12\ns2: 445.15\ns3: 83.51\ns4: 185.58\ns5: 706.47\ns6: 88.68\n------------------------------\nR-squared: 0.70 MSE: 1668.75\n```", "```py\n# --- SECTION 1 ---\n# Libraries and data loading\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn import metrics\nbc = load_breast_cancer()\n\n# --- SECTION 2 ---\n# Split the data into train and test set\ntrain_x, train_y = bc.data[:400], bc.target[:400]\ntest_x, test_y = bc.data[400:], bc.target[400:]\n\n# --- SECTION 3 ---\n# Instantiate, train and evaluate the model\nlogit = LogisticRegression()\nlogit.fit(train_x, train_y)\nacc = metrics.accuracy_score(test_y, logit.predict(test_x))\n\n# --- SECTION 4 ---\n# Print the model\nprint('---Logistic Regression on breast cancer dataset.---')\nprint('Coefficients:')\nprint('Intercept (b): %.2f'%logit.intercept_)\nfor i in range(len(bc.feature_names)):\n print(bc.feature_names[i]+': %.2f'%logit.coef_[0][i])\nprint('-'*30)\nprint('Accuracy: %.2f \\n'%acc)\nprint(metrics.confusion_matrix(test_y, logit.predict(test_x)))\n```", "```py\n# --- SECTION 1 ---\n# Libraries and data loading\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.cluster import KMeans\nbc = load_breast_cancer()\nbc.data=bc.data[:,:2]\n```", "```py\n# --- SECTION 2 ---\n# Instantiate and train\nkm = KMeans(n_clusters=3)\nkm.fit(bc.data)\n```", "```py\n# --- SECTION 3 ---\n# Create a point mesh to plot cluster areas\n# Step size of the mesh. \nh = .02\n# Plot the decision boundary. For that, we will assign a color to each\nx_min, x_max = bc.data[:, 0].min() - 1, bc.data[:, 0].max() + 1\ny_min, y_max = bc.data[:, 1].min() - 1, bc.data[:, 1].max() + 1\n# Create the actual mesh and cluster it\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\nZ = km.predict(np.c_[xx.ravel(), yy.ravel()])\n# Put the result into a color plot\nZ = Z.reshape(xx.shape)\nplt.figure(1)\nplt.clf()\nplt.imshow(Z, interpolation='nearest',\n extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n aspect='auto', origin='lower',)\n```", "```py\n --- SECTION 4 ---\n# Plot the actual data\nc = km.predict(bc.data)\nr = c == 0\nb = c == 1\ng = c == 2\nplt.scatter(bc.data[r, 0], bc.data[r, 1], label='cluster 1')\nplt.scatter(bc.data[b, 0], bc.data[b, 1], label='cluster 2')\nplt.scatter(bc.data[g, 0], bc.data[g, 1], label='cluster 3')\nplt.title('K-means')\nplt.xlim(x_min, x_max)\nplt.ylim(y_min, y_max)\nplt.xticks(())\nplt.yticks(())\nplt.xlabel(bc.feature_names[0])\nplt.ylabel(bc.feature_names[1])\n`()\nplt.show()\n```"]