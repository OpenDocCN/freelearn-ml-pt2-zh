<html><head></head><body>
<section id="chapter-1-thinking-probabilistically" class="level2 chapterHead" data-number="1.5">&#13;
<h1 class="chapterHead" data-number="1.5">Chapter 1<br/>&#13;
<span id="x1-160001"/>Thinking Probabilistically</h1>&#13;
<blockquote>&#13;
<p>Probability theory is nothing but common sense reduced to calculation. – Pierre Simon Laplace</p>&#13;
</blockquote>&#13;
<p>In this chapter, we will learn about the core concepts of Bayesian statistics and some of the instruments in the Bayesian toolbox. We will use some Python code, but this chapter will be mostly theoretical; most of the concepts we will see here will be revisited many times throughout this book. This chapter, being heavy on the theoretical side, is perhaps a little anxiogenic for the coder in you, but I think it will ease the path to effectively applying Bayesian statistics to your problems.</p>&#13;
<p>In this chapter, we will cover the following topics:</p>&#13;
<ul>&#13;
<li><p>Statistical modeling</p></li>&#13;
<li><p>Probabilities and uncertainty</p></li>&#13;
<li><p>Bayes’ theorem and statistical inference</p></li>&#13;
<li><p>Single-parameter inference and the classic coin-flip problem</p></li>&#13;
<li><p>Choosing priors and why people often don’t like them but should</p></li>&#13;
<li><p>Communicating a Bayesian analysis</p></li>&#13;
</ul>&#13;
<p><span id="x1-16001r1"/></p>&#13;
<section id="statistics-models-and-this-books-approach" class="level3 sectionHead" data-number="1.5.1">&#13;
<h2 class="sectionHead" data-number="1.5.1">1.1 <span id="x1-170001"/>Statistics, models, and this book’s approach</h2>&#13;
<p>Statistics is about collecting, organizing, analyzing, and interpreting data, and hence statistical knowledge is essential for data analysis. Two main statistical methods are used in data analysis:</p>&#13;
<ul>&#13;
<li><p><strong>Exploratory Data Analysis (EDA)</strong>: This is about numerical summaries, such as the mean, mode, standard deviation, and interquartile ranges. EDA is also about visually inspecting the data, using tools you may be already familiar with, such as histograms and scatter plots.</p></li>&#13;
<li><p><strong>Inferential statistics</strong>: This is about making <span id="dx1-17001"/>statements beyond the current data. We may want to understand some particular phenomenon, maybe we want to make predictions for future (yet unobserved) data points, or we need to choose among several competing explanations for the same set of observations. In summary, inferential statistics allow us to draw meaningful insights from a limited set of data and make informed decisions based on the results of our analysis.</p></li>&#13;
</ul>&#13;
<div id="tcolobox-2" class="tcolorbox coolbox">&#13;
<div class="tcolorbox-title">&#13;
<p>A Match Made in Heaven</p>&#13;
</div>&#13;
<div class="tcolorbox-content">&#13;
<p>The focus of this book is on how to perform Bayesian inferential statistics, but we will also use ideas from EDA to summarize, interpret, check, and communicate the results of Bayesian inference.</p>&#13;
</div>&#13;
</div>&#13;
<p>Most introductory statistical courses, at least for non-statisticians, are taught as a collection of recipes that go like this: go to the statistical pantry, pick one tin can and open it, add data to taste, and stir until you obtain a consistent p-value, preferably under 0.05. The main goal of these courses is to teach you how to pick the proper can. I never liked this approach, mainly because the most common result is a bunch of confused people unable to grasp, even at the conceptual level, the unity of the different learned methods. We will take a different approach: we will learn some recipes, but they will be homemade rather than canned food; we will learn how to mix fresh ingredients that will suit different statistical occasions and, more importantly, that will let you apply concepts far beyond the examples in this book.</p>&#13;
<p>Taking this approach is possible for two reasons:</p>&#13;
<ul>&#13;
<li><p><strong>Ontological</strong>: Statistics is a form of modeling unified under the mathematical framework of probability theory. Using a probabilistic approach provides a unified view of what may seem like very disparate methods; statistical methods and machine learning methods look much more similar under the probabilistic lens.</p></li>&#13;
<li><p><strong>Technical</strong>: Modern software, such as PyMC, allows practitioners, just like you and me, to define and solve models in a relatively easy way. Many of these models were unsolvable just a few years ago or required a high level of mathematical and technical sophistication.</p></li>&#13;
</ul>&#13;
<p><span id="x1-17002r19"/></p>&#13;
</section>&#13;
<section id="working-with-data" class="level3 sectionHead" data-number="1.5.2">&#13;
<h2 class="sectionHead" data-number="1.5.2">1.2 <span id="x1-180002"/>Working with data</h2>&#13;
<p>Data is an essential ingredient in statistics and data science. Data comes from several sources, such as experiments, computer simulations, surveys, and field observations. If we are the ones in charge of generating or gathering the data, it is always a good idea to first think carefully about the questions we want to answer and which methods we will use, and only then proceed to get the data. There is a whole branch of statistics dealing with data collection, known as experimental design. In the era of the data deluge, we can sometimes forget that gathering data is not always cheap. For example, while it is true that the <strong>Large Hadron Collider</strong> (<strong>LHC</strong>) produces hundreds of terabytes a day, its construction took years of manual and intellectual labor.</p>&#13;
<p>As a general rule, we can think of the process of generating the data as stochastic, because there is ontological, technical, and/or epistemic uncertainty, that is, the system is intrinsically stochastic, there are technical issues adding noise or restricting us from measuring with arbitrary precision, and/or there are conceptual limitations veiling details from us. For all these reasons, we always need to interpret data in the context of models, including mental and formal ones. Data does not speak but through models.</p>&#13;
<p>In this book, we will assume that we already have collected the data. Our data will also be clean and tidy, something that’s rarely true in the real world. We will make these assumptions to focus on the subject of this book. I just want to emphasize, especially for newcomers to data analysis, that even when not covered in this book, there are important skills that you should learn and practice to successfully work with data.</p>&#13;
<p>A very useful skill when analyzing data is knowing how to write code in a programming language, such as Python. Manipulating data is usually necessary given that we live in a messy world with even messier data, and coding helps to get things done. Even if you are lucky and your data is very clean and tidy, coding will still be very useful since modern Bayesian statistics is done mostly through programming languages such as Python or R. If you want to learn how to use Python for cleaning and manipulating data, you can find a good introduction in <em>Python for Data Analysis</em> by <a href="Bibliography.xhtml#Xmckinney_2022">McKinney</a> [<a href="Bibliography.xhtml#Xmckinney_2022">2022</a>]. <span id="x1-18001r20"/></p>&#13;
</section>&#13;
<section id="bayesian-modeling" class="level3 sectionHead" data-number="1.5.3">&#13;
<h2 class="sectionHead" data-number="1.5.3">1.3 <span id="x1-190003"/>Bayesian modeling</h2>&#13;
<p><span id="dx1-19001"/></p>&#13;
<p>Models are simplified descriptions of a given system or process that, for some reason, we are interested in. Those descriptions are deliberately designed to capture only the most relevant aspects of the system and not to explain every minor detail. This is one reason a more complex model is not always a better one. There are many different kinds of models; in this book, we will restrict ourselves to Bayesian models. We can summarize the Bayesian modeling process using three steps:</p>&#13;
<ol>&#13;
<li><div id="x1-19003x1">&#13;
<p>Given some data and some assumptions on how this data could have been generated, we design a model by combining building blocks known as <strong>probability distributions</strong>. Most of the time these models are crude approximations, but most of the time that’s all we need.</p>&#13;
</div></li>&#13;
<li><div id="x1-19005x2">&#13;
<p>We use Bayes’ theorem to add data to our models and derive the logical consequences of combining the data and our assumptions. We say we are <strong>conditioning</strong> the model on our data.</p>&#13;
</div></li>&#13;
<li><div id="x1-19007x3">&#13;
<p>We evaluate the model, and its predictions, under different criteria, including the data, our expertise on the subject, and sometimes by comparing it to other models.</p>&#13;
</div></li>&#13;
</ol>&#13;
<p>In general, we will find ourselves performing these three steps in an iterative non-linear fashion. We will retrace our steps at any given point: maybe we made a silly coding mistake, or we found a way to change the model and improve it, or we realized that we need to add more data or collect a different kind of data.</p>&#13;
<p>Bayesian models are also known as <strong>probabilistic models</strong> because they are built using probabilities. Why probabilities? Because probabilities are a very useful tool to model uncertainty; we even have good arguments to state they are the correct mathematical concept. So let’s take a walk through <em>the garden of forking paths</em> [<a href="Bibliography.xhtml#Xborges">Borges</a>, <a href="Bibliography.xhtml#Xborges">1944</a>]. <span id="x1-19008r21"/></p>&#13;
</section>&#13;
<section id="a-probability-primer-for-bayesian-practitioners" class="level3 sectionHead" data-number="1.5.4">&#13;
<h2 class="sectionHead" data-number="1.5.4">1.4 <span id="x1-200004"/>A probability primer for Bayesian practitioners</h2>&#13;
<p>In this section, we are going to discuss a few general and important concepts that are key for better understanding Bayesian methods. Additional probability-related concepts will be introduced or elaborated on in future chapters, as we need them. For a detailed study of probability theory, however, I highly recommend the book <em>Introduction to Probability</em> by <a href="Bibliography.xhtml#Xblitzstein_2019">Blitzstein</a> [<a href="Bibliography.xhtml#Xblitzstein_2019">2019</a>]. Those already familiar with the basic elements of probability theory can skip this section or skim it. <span id="x1-20001r1"/></p>&#13;
<section id="sample-space-and-events" class="level4 subsectionHead" data-number="1.5.4.1">&#13;
<h3 class="subsectionHead" data-number="1.5.4.1">1.4.1 <span id="x1-210001"/>Sample space and events</h3>&#13;
<p><span id="dx1-21001"/></p>&#13;
<p>Let’s say we are surveying to see how people feel about the weather in their area. We asked three individuals whether they enjoy sunny weather, with possible responses being “yes” or “no.” The sample space of all possible outcomes can be denoted by <em>S</em> and consists of eight possible combinations:</p>&#13;
<p><em>S</em> = <span class="cmsy-10x-x-109">{</span>(yes, yes, yes), (yes, yes, no), (yes, no, yes), (no, yes, yes), (yes, no, no), (no, yes, no), (no, no, yes), (no, no, no)<span class="cmsy-10x-x-109">}</span></p>&#13;
<p>Here, each element of the sample space represents the responses of the three individuals in the order they were asked. For example, (yes, no, yes) means the first and third people answered “yes” while the second person answered “no.”</p>&#13;
<p>We can define events as subsets of the sample space. For example, event <em>A</em> is when all three individuals answered “yes”:</p>&#13;
<p><em>A</em> = <span class="cmsy-10x-x-109">{</span>(yes, yes, yes)<span class="cmsy-10x-x-109">}</span></p>&#13;
<p>Similarly, we can define event <em>B</em> as when at least one person answered “no,” and then we will have:</p>&#13;
<p><em>B</em> = <span class="cmsy-10x-x-109">{</span>(yes, yes, no), (yes, no, yes), (no, yes, yes), (yes, no, no), (no, yes, no), (no, no, yes), (no, no, no)<span class="cmsy-10x-x-109">}</span></p>&#13;
<p>We can use probabilities as a measure of how likely these events are. Assuming all events are equally likely, the probability of event <em>A</em>, which is the event that all three individuals answered “yes,” is:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file4.jpg" class="math-display" alt=" number of outcomes in A P (A) = ---------------------------- total number of outcomes in S "/>&#13;
</div>&#13;
<p>In this case, there is only one outcome in <em>A</em>, and there are eight outcomes in <em>S</em>. Therefore, the probability of <em>A</em> is:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file5.jpg" class="math-display" alt=" 1 P(A ) = 8 = 0.125 "/>&#13;
</div>&#13;
<p>Similarly, we can calculate the probability of event <em>B</em>, which is the event that at least one person answered “no.” Since there are seven outcomes in <em>B</em> and eight outcomes in <em>S</em>, the probability of <em>B</em> is:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file6.jpg" class="math-display" alt="P(B ) = 7-= 0.875 8 "/>&#13;
</div>&#13;
<p>Considering all events equally likely is just a particular case that makes calculating probabilities easier. This is something called the naive definition of probability since it is restrictive and relies on strong assumptions. However, it is still useful if we are cautious when using it. For instance, it is not true that all yes-no questions have a 50-50 chance. Another example. What is the probability of seeing a purple horse? The right answer can vary a lot depending on whether we’re talking about the natural color of a real horse, a horse from a cartoon, a horse dressed in a parade, etc. Anyway, no matter if the events are equally likely or not, the probability of the entire sample space is always equal to 1. We can see that this is true by computing:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file7.jpg" class="math-display" alt=" number of outcomes in S P (S) = ---------------------------- total number of outcomes in S "/>&#13;
</div>&#13;
<p>1 is the highest value a probability can take. Saying that <em>P</em>(<em>S</em>) = 1 is saying that <em>S</em> is not only very likely, it is certain. If everything that can happen is defined by <em>S</em>, then <em>S</em> will happen.</p>&#13;
<p>If an event is impossible, then its probability is 0. Let’s define the event <em>C</em> as the event of three persons saying “banana”:</p>&#13;
<p><em>C</em> = <span class="cmsy-10x-x-109">{</span>(banana, banana, banana)<span class="cmsy-10x-x-109">}</span></p>&#13;
<p>As <em>C</em> is not part of <em>S</em>, by definition, it cannot happen. Think of this as the questionnaire from our survey only having two boxes, <em>yes</em> and <em>no</em>. By design, our survey is restricting all other possible options.</p>&#13;
<p>We can take advantage of the fact that Python includes sets and define a Python function to compute probabilities following their naive definition:</p>&#13;
<p><span id="x1-21002r1"/> <span id="x1-21003"/><strong>Code 1.1</strong></p>&#13;
<pre id="listing-2" class="source-code"><code>def P(S, A): </code>&#13;
<code>    if set(A).issubset(set(S)): </code>&#13;
<code>        return len(A)/len(S) </code>&#13;
<code>    else: </code>&#13;
<code>        return 0</code></pre>&#13;
<p>I left for the reader the joy of playing with this function.</p>&#13;
<p>One useful way to conceptualize probabilities is as conserved quantities distributed throughout the sample space. This means that if the probability of one event increases, the probability of some other event or events must decrease so that the total probability remains equal to 1. This can be illustrated with a simple example.</p>&#13;
<p>Suppose we ask one person whether it will rain tomorrow, with possible responses of “yes” and “no.” The sample space for possible responses is given by <em>S</em> = <span class="cmsy-10x-x-109">{</span>yes, no<span class="cmsy-10x-x-109">}</span>. An event that will rain tomorrow is represented by <em>A</em> = <span class="cmsy-10x-x-109">{</span>yes<span class="cmsy-10x-x-109">}</span>. If <em>P</em>(<em>A</em>), is 0.5, then the probability of the complement of event <em>A</em>, denoted by <em>P</em><img src="../media/file8.jpg" class="left" data-align="middle" alt="(Ac)"/>, must also be 0.5. If for some reason <em>P</em>(<em>A</em>) increases to 0.8, then <em>P</em><img src="../media/file9.jpg" class="left" data-align="middle" alt=" c (A )"/> must decrease to 0.2. This property holds for disjoint events, which are events that cannot occur simultaneously. For instance, it cannot <em>rain</em> and <em>not rain</em> at the same time tomorrow. You may object that it can rain during the morning and not rain during the afternoon. That is true, but that’s a different sample space!</p>&#13;
<p>So far, we have avoided directly defining probabilities, and instead, we have just shown some of their properties and ways to compute them. A general definition of probability that works for non-equally likely events is as follows. Given a sample space <em>S</em>, and the event <em>A</em>, which is a subset of <em>S</em>, a probability is a function <em>P</em>, which takes <em>A</em> as input and returns a real number between 0 and 1, as output. The function <em>P</em> has some restrictions, defined by the following 3 axioms. Keep in mind that an axiom is a statement that is taken to be true and that we use as the starting point in our reasoning:</p>&#13;
<ol>&#13;
<li><div id="x1-21010x1">&#13;
<p>The probability of an event is a non-negative real number</p>&#13;
</div></li>&#13;
<li><div id="x1-21012x2">&#13;
<p><em>P</em>(<em>S</em>) = 1</p>&#13;
</div></li>&#13;
<li><div id="x1-21014x3">&#13;
<p>If <em>A</em>1<em>,A</em>2<em>,…</em> are disjoint events, meaning they cannot occur simultaneously then <em>P</em>(<em>A</em>1<em>,A</em>2<em>,…</em>) = <em>P</em>(<em>A</em>1) + <em>P</em>(<em>A</em>2) + <em>…</em></p>&#13;
</div></li>&#13;
</ol>&#13;
<p>If this were a book on probability theory, we would likely dedicate a few pages to demonstrating the consequences of these axioms and provide exercises for manipulating probabilities. That would help us to become proficient in manipulating probabilities. However, our main focus is not on those topics. My motivation to present these axioms is just to show that probabilities are well-defined mathematical concepts with rules that govern their operations. They are a particular type of function, and there is no mystery surrounding them. <span id="x1-21015r23"/></p>&#13;
</section>&#13;
<section id="random-variables" class="level4 subsectionHead" data-number="1.5.4.2">&#13;
<h3 class="subsectionHead" data-number="1.5.4.2">1.4.2 <span id="x1-220002"/>Random variables</h3>&#13;
<p><span id="dx1-22001"/> <span id="dx1-22002"/></p>&#13;
<p>A random variable is a function that maps the sample space into the real numbers <span class="msbm-10x-x-109">ℝ </span>(see <em>Figure <a href="#x1-22003r1">1.1</a></em>). Let’s assume the events of interest are the number of a die, the mapping is very simple, we associate <img src="../media/dice_1.png" height="15" alt="PIC"/> with the number 1, <img src="../media/dice_2.png" height="15" alt="PIC"/> with 2, etc. Another simple example is the answer to the question, will it rain tomorrow? We can map “yes” to 1 and “no” to 0. It is common, but not always the case, to use a capital letter for random variables like <em>X</em> and a lowercase letter for their outcomes <em>x</em>. For example, if <em>X</em> represents a single roll of a die, then <em>x</em> represents some specific integer <span class="cmsy-10x-x-109">{</span>1<em>,</em>2<em>,</em>3<em>,</em>4<em>,</em>5<em>,</em>6<span class="cmsy-10x-x-109">}</span>. Thus, we can write <em>P</em>(<em>X</em> = 3) to indicate the probability of getting the value 3, when rolling a die. We can also leave <em>x</em> unspecified, for instance, we can write <em>P</em>(<em>X</em> = <em>x</em>) to indicate the probability of getting some value <em>x</em>, or <em>P</em>(<em>X</em> <span class="cmsy-10x-x-109">≤ </span><em>x</em>), to indicate the probability of getting a value less than or equal to <em>x</em>.</p>&#13;
<p>Being able to map symbols like <img src="../media/dice_1.png" height="15" alt="PIC"/> or strings like “yes” to numbers makes analysis simpler as we already know how to do math with numbers. Random variables are also useful because we can operate with them without directly thinking in terms of the sample space. This feature becomes more and more relevant as the sample space becomes more complex. For example, when simulating molecular systems, we need to specify the position and velocity of each atom; for complex molecules like proteins this means that we will need to track thousands, millions, or even larger numbers. Instead, we can use random variables to summarize certain properties of the system, such as the total energy or the relative angles between certain atoms of the system.</p>&#13;
<p>If you are still confused, that’s fine. The concept of a random variable may sound too abstract at the beginning, but we will see plenty of examples throughout the book that will help you cement these ideas. Before moving on, let me try one analogy that I hope you find useful. Random variables are useful in a similar way to how Python functions are useful. We often encapsulate code within functions, so we can store, reuse, and <em>hide</em> complex manipulations of data into a single call. Even more, once we have a few functions, we can sometimes combine them in many ways, like adding the output of two functions or using the output of one function as the input of the other. We can do all this without functions, but abstracting away the inner workings not only makes the code cleaner, it also helps with understanding and fostering new ideas. Random variables play a similar role in statistics.</p>&#13;
<div class="IMG---Figure">&#13;
<img src="../media/file10.png" alt="PIC"/>&#13;
</div>&#13;
<p class="IMG---Caption"><span id="x1-22003r1"/><strong>Figure 1.1</strong>: A random variable <em>X</em> defined on a sample space with 5 elements <span class="cmsy-10x-x-109">{</span><em>S</em><sub>1</sub><em>,</em><img src="../media/file11.jpg" class="@cdots" alt="⋅⋅⋅"/><em>S</em><sub>5</sub><span class="cmsy-10x-x-109">}</span>, and possible values -1, 2, and <em>π</em></p>&#13;
<p>The mapping between the sample space and <span class="msbm-10x-x-109">ℝ </span>is deterministic. There is no randomness involved. So why do we call it a <em>random</em> variable? Because we can <em>ask</em> the variable for values, and every time we ask, we will get a different number. The randomness comes from the probability associated with the events. In <em>Figure <a href="#x1-22003r1">1.1</a></em>, we have represented <em>P</em> as the size of the circles.</p>&#13;
<p>The two most common types of random variables are discrete and continuous ones. Without going into a proper definition, we are going to say that discrete variables take only discrete values and we usually use integers to represent them, like 1, 5, 42. And continuous variables take real values, so we use floats to work with them, like 3.1415, 1.01, 23.4214, and so on. When we use one or the other is problem-dependent. If we ask people about their favorite color, we will get answers like “red,” “blue,” and “green.” This is an example of a discrete random variable. The answers are categories – there are no intermediate values between “red” and “green.” But if we are studying the properties of light absorption, then discrete values like “red” and “green” may not be adequate and instead working with wavelength could be more appropriate. In that case, we will expect to get values like 650 nm and 510 nm and any number in between, including 579.1. <span id="x1-22004r26"/></p>&#13;
</section>&#13;
<section id="discrete-random-variables-and-their-distributions" class="level4 subsectionHead" data-number="1.5.4.3">&#13;
<h3 class="subsectionHead" data-number="1.5.4.3">1.4.3 <span id="x1-230003"/>Discrete random variables and their distributions</h3>&#13;
<p><span id="dx1-23001"/> <span id="dx1-23002"/></p>&#13;
<p>Instead of calculating the probability that all three individuals answered “yes,” or the probability of getting a 3 when rolling a die, we may be more interested in finding out the <em>list of probabilities</em> for all possible answers or all possible numbers from a die. Once this list is computed, we can inspect it visually or use it to compute other quantities like the probability of getting at least one “no,” the probability of getting an odd number, or the probability of getting a number equal to or larger than 5. The formal name of this <em>list</em> is <strong>probability</strong> <strong>distribution</strong>.</p>&#13;
<p>We can get the empirical probability distribution of a die, by rolling it a few times and tabulating how many times we got each number. To turn each value into a probability and the entire list into a valid probability distribution, we need to <em>normalize</em> the counts. We can do this by dividing the value we got for each number by the number of times we roll the die.</p>&#13;
<p>Empirical distributions are very useful, and we are going to extensively use them. But instead of rolling dice by hand, we are going to use advanced computational methods to do the hard work for us; this will not only save us time and boredom but it will allow us to get samples from really complicated distributions effortlessly. But we are getting ahead of ourselves. Our priority is to concentrate on theoretical distributions, which are central in statistics because, among other reasons, they allow the construction of probabilistic models.</p>&#13;
<p>As we saw, there is nothing random or mysterious about random variables; they are just a type of mathematical function. The same goes for theoretical probability distributions. I like to compare probability distributions with circles. Because we are all familiar with circles even before we get into school, we are not afraid of them and they don’t look mysterious to us. We can define a circle as the geometric space of points on a plane that is equidistant from another point called the center. We can go further and provide a mathematical expression for this definition. If we assume the location of the center is irrelevant, then the circle of radius <em>r</em> can simply be described as the set of all points (<em>x,y</em>) such that:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file12.jpg" class="math-display" alt="x2 + y2 = r2 "/>&#13;
</div>&#13;
<p>From this expression, we can see that given the <strong>parameter</strong> <em>r</em>, the circle is completely defined. This is all we need to plot it and all we need to compute properties such as the perimeter, which is 2<em>πr</em>.</p>&#13;
<p>Now notice that all circles look very <span id="dx1-23003"/>similar to each other and that any two circles with the same value of <em>r</em> are essentially the same objects. Thus we can think of the family of circles, where each member is set apart from the rest precisely by the value of <em>r</em>.</p>&#13;
<p>So far, so good, but why are we talking about circles? Because all this can be directly applied to <span id="dx1-23004"/>probability distributions. Both circles and probability distributions have mathematical expressions that define them, and these expressions have parameters that we can change to define all members of a family of probability distributions. <em>Figure <a href="#x1-23006r2">1.2</a></em> shows four members of one probability <span id="dx1-23005"/>distribution known as BetaBinomial. In <em>Figure <a href="#x1-23006r2">1.2</a></em>, the height of the bars represents the probability of each <em>x</em> value. The values of <em>x</em> below 1 or above 6 have a probability of 0 as they are out of the support of the distribution.</p>&#13;
<div class="IMG---Figure">&#13;
<img src="../media/file13.png" alt="PIC"/>&#13;
</div>&#13;
<p class="IMG---Caption"><span id="x1-23006r2"/><strong>Figure 1.2</strong>: Four members of the BetaBinomial distribution with parameters <em>α</em> and <em>β</em></p>&#13;
<p>This is the mathematical expression for the BetaBinomial distribution:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file14.jpg" class="math-display" alt=" ( ) pmf (x ) = n- B-(x-+-𝛼,n-−-x-+-𝛽)- x B(𝛼,𝛽 ) "/>&#13;
</div>&#13;
<p>pmf stands for <strong>probability mass function</strong>. For discrete <span id="dx1-23007"/>random variables, the pmf is the function that returns probabilities. In mathematical notation, if we have a random variable <em>X</em>, then pmf(<em>x</em>) = <em>P</em>(<em>X</em> = <em>x</em>).</p>&#13;
<p>Understanding or remembering the pmf of the BetaBinomial has zero importance for us. I’m just showing it here so you can see that this is just another function; you put in one number and you get out another number. Nothing weird, at least not in principle. I must concede that to fully understand the <span id="dx1-23008"/>details of the BetaBinomial distribution, we need to know what <img src="../media/file15.jpg" class="left" data-align="middle" alt="( ) nx"/> is, known as the binomial coefficient, and what <em>B</em> is, the Beta function. But that’s not fundamentally different from showing <em>x</em><sup>2</sup> + <em>y</em><sup>2</sup> = <em>r</em><sup>2</sup>.</p>&#13;
<p>Mathematical expressions can be <span id="dx1-23009"/>super useful, as they are concise and we can use them to derive properties from them. But sometimes that can be too much work, even if we are good at math. Visualization can be a good alternative (or complement) to help us understand probability distributions. I cannot fully show this on paper, but if you run the following, you will get an interactive plot that will update every time you move the sliders for the parameters <code>alpha</code>, <code>beta</code>, and <code>n</code>:</p>&#13;
<p><span id="x1-23010r2"/> <span id="x1-23011"/><strong>Code 1.2</strong></p>&#13;
<pre id="listing-3" class="source-code"><code>pz.BetaBinomial(alpha=10, beta=10, n=6).plot_interactive()</code></pre>&#13;
<p><em>Figure <a href="#x1-23013r3">1.3</a></em> shows a static version of this interactive plot. The black dots represent the probabilities for each value of the random variable, while the dotted black line is just a visual aid.</p>&#13;
<div class="IMG---Figure">&#13;
<img src="../media/file16.png" alt="PIC"/>&#13;
</div>&#13;
<p class="IMG---Caption"><span id="x1-23013r3"/><strong>Figure 1.3</strong>: The output of <code>pz.BetaBinomial(alpha=10, beta=10, n=6).plot_interactive()</code></p>&#13;
<p>On the x-axis, we have the support of the BetaBinomial distribution, i.e., the values it can take, <em>x</em> <span class="cmsy-10x-x-109">∈{</span>0<em>,</em>1<em>,</em>2<em>,</em>3<em>,</em>4<em>,</em>5<span class="cmsy-10x-x-109">}</span>. On the y-axis, the probabilities associated with each of those values. The full list is shown in <em>Table <a href="#x1-23014r1">1.1</a></em>.</p>&#13;
<table id="TBL-1" class="tabular">&#13;
<tbody>&#13;
&#13;
<tr id="TBL-1-1-" class="even" style="vertical-align:baseline;">&#13;
<td id="TBL-1-1-1" class="td11" style="text-align: center; white-space: nowrap;"><strong>x value</strong></td>&#13;
<td id="TBL-1-1-2" class="td11" style="text-align: center; white-space: nowrap;"><strong>probability</strong></td>&#13;
</tr>&#13;
&#13;
<tr id="TBL-1-2-" class="even" style="vertical-align:baseline;">&#13;
<td id="TBL-1-2-1" class="td11" style="text-align: center; white-space: nowrap;">0</td>&#13;
<td id="TBL-1-2-2" class="td11" style="text-align: center; white-space: nowrap;">0.047</td>&#13;
</tr>&#13;
<tr id="TBL-1-3-" class="odd" style="vertical-align:baseline;">&#13;
<td id="TBL-1-3-1" class="td11" style="text-align: center; white-space: nowrap;">1</td>&#13;
<td id="TBL-1-3-2" class="td11" style="text-align: center; white-space: nowrap;">0.168</td>&#13;
</tr>&#13;
<tr id="TBL-1-4-" class="even" style="vertical-align:baseline;">&#13;
<td id="TBL-1-4-1" class="td11" style="text-align: center; white-space: nowrap;">2</td>&#13;
<td id="TBL-1-4-2" class="td11" style="text-align: center; white-space: nowrap;">0.285</td>&#13;
</tr>&#13;
<tr id="TBL-1-5-" class="odd" style="vertical-align:baseline;">&#13;
<td id="TBL-1-5-1" class="td11" style="text-align: center; white-space: nowrap;">3</td>&#13;
<td id="TBL-1-5-2" class="td11" style="text-align: center; white-space: nowrap;">0.285</td>&#13;
</tr>&#13;
<tr id="TBL-1-6-" class="even" style="vertical-align:baseline;">&#13;
<td id="TBL-1-6-1" class="td11" style="text-align: center; white-space: nowrap;">4</td>&#13;
<td id="TBL-1-6-2" class="td11" style="text-align: center; white-space: nowrap;">0.168</td>&#13;
</tr>&#13;
<tr id="TBL-1-7-" class="odd" style="vertical-align:baseline;">&#13;
<td id="TBL-1-7-1" class="td11" style="text-align: center; white-space: nowrap;">5</td>&#13;
<td id="TBL-1-7-2" class="td11" style="text-align: center; white-space: nowrap;">0.047</td>&#13;
</tr>&#13;
&#13;
&#13;
</tbody>&#13;
</table>&#13;
<p class="IMG---Caption"><span id="x1-23014r1"/> <span id="x1-23015"/><strong>Table 1.1</strong>: Probabilities for <code>pz.BetaBinomial(alpha=10, beta=10, n=6)</code></p>&#13;
<p>Notice <span id="dx1-23016"/>that for a <code>BetaBinomial(alpha=10, beta=10, n=6) </code>distribution, the probability of values not in <span class="cmsy-10x-x-109">{</span>0<em>,</em>1<em>,</em>2<em>,</em>3<em>,</em>4<em>,</em>5<span class="cmsy-10x-x-109">}</span>, including <span id="dx1-23017"/>values such as <span class="cmsy-10x-x-109">−</span>1<em>,</em>0<em>.</em>5<em>,π,</em>42, is 0.</p>&#13;
<p>We previously mentioned that we can <em>ask</em> a random variable for values and every time we ask, we will get a different number. We can simulate this with PreliZ [<a href="Bibliography.xhtml#Xicazatti2023">Icazatti et al.</a>, <a href="Bibliography.xhtml#Xicazatti2023">2023</a>], a Python library for prior elicitation. Take the following code snippet for instance:</p>&#13;
<p><span id="x1-23018r3"/> <span id="x1-23019"/><strong>Code 1.3</strong></p>&#13;
<pre id="listing-4" class="source-code"><code>pz.BetaBinomial(alpha=10, beta=10, n=6).rvs()</code></pre>&#13;
<p>This will give us an integer between 0 and 5. Which one? We don’t know! But let’s run the following code:</p>&#13;
<p><span id="x1-23021r4"/> <span id="x1-23022"/><strong>Code 1.4</strong></p>&#13;
<pre id="listing-5" class="source-code"><code>plt.hist(pz.BetaBinomial(alpha=2, beta=5, n=5).rvs(1000)) </code>&#13;
<code>pz.BetaBinomial(alpha=2, beta=5, n=5).plot_pdf();</code></pre>&#13;
<p>We will get something similar to <em>Figure <a href="#x1-23026r4">1.4</a></em>. Even when we cannot predict the next value from a random variable, we can predict the <span id="dx1-23025"/>probability of getting any particular value and by the same token, if we get many values, we can predict their overall distribution.</p>&#13;
<div class="IMG---Figure">&#13;
<img src="../media/file17.png" alt="PIC"/>&#13;
</div>&#13;
<p class="IMG---Caption"><span id="x1-23026r4"/><strong>Figure 1.4</strong>: The gray dots represent the pmf of the BetaBinomial sample. In light gray, a histogram of 1,000 draws from that distribution</p>&#13;
<p>In this book, we will sometimes <span id="dx1-23027"/>know the parameters of a given distribution and we will want to get random samples from it. Other times, we are going to be in the opposite scenario: we will have a set of samples and we will want to estimate the parameters of a distribution. Playing back and forth between these two scenarios will become second nature as we move forward <span id="dx1-23028"/>through the pages. <span id="x1-23029r27"/></p>&#13;
</section>&#13;
<section id="continuous-random-variables-and-their-distributions" class="level4 subsectionHead" data-number="1.5.4.4">&#13;
<h3 class="subsectionHead" data-number="1.5.4.4">1.4.4 <span id="x1-240004"/>Continuous random variables and their distributions</h3>&#13;
<p>Probably the <span id="dx1-24001"/>most widely known <span id="dx1-24002"/>continuous probability <span id="dx1-24003"/>distribution is the <strong>Normal distribution</strong>, also <span id="dx1-24004"/>known as the <strong>Gaussian distribution</strong>. Its <strong>probability density function</strong> is:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file18.jpg" class="math-display" alt=" { } 1 1( x − μ)2 pdf(x) = -√----exp − -- ----- σ 2π 2 σ "/>&#13;
</div>&#13;
<p>Again, we only show this <span id="dx1-24005"/>expression to remove the mystery veil. No need to pay too much attention to its details, other than to the fact that this distribution has two parameters <em>μ</em>, which controls the location of the peak of the curve, and <em>σ</em>, which controls the spread of the curve. <em>Figure <a href="#x1-24006r5">1.5</a></em> shows 3 examples from the Gaussian family. If you want to learn more about this distribution, I recommend you watch this video: <a href="https://www.youtube.com/watch?v=cy8r7WSuT1I" class="url">https://www.youtube.com/watch?v=cy8r7WSuT1I</a>.</p>&#13;
<div class="IMG---Figure">&#13;
<img src="../media/file19.png" alt="PIC"/>&#13;
</div>&#13;
<p class="IMG---Caption"><span id="x1-24006r5"/><strong>Figure 1.5</strong>: Three members of the Gaussian family</p>&#13;
<p>If you have been <span id="dx1-24007"/>paying attention, you may have noticed that we said <strong>probability density function</strong> (<strong>pdf</strong>) instead of <strong>probability mass</strong> <strong>function</strong> (<strong>pmf</strong>). This was no typo – they are actually two different objects. Let’s take one step back and think about this; the output of a discrete probability distribution is a probability. The height of the bars in <em>Figure <a href="#x1-23006r2">1.2</a></em> or the height of the dots in <em>Figure <a href="#x1-23013r3">1.3</a></em> are probabilities. Each bar or dot will never be higher than 1 and if you sum all the bars or dots, you will always get 1. Let’s do the same but with the curve in <em>Figure <a href="#x1-24006r5">1.5</a></em>. The first thing to notice is that we don’t have bars or dots; we have a continuous, smooth curve. So maybe we can think that the curve is made up of super thin bars, so thin that we assign one bar for every real value in the support of the distributions, we measure the <span id="dx1-24008"/>height of each bar, and we perform an infinite sum. This is a sensible thing to do, right?</p>&#13;
<p>Well yes, but it is not immediately obvious what are we going to get from this. Will this sum give us exactly 1? Or are we going to get a large number instead? Is the sum finite? Or does the result depend on the parameters of the distribution?</p>&#13;
<p>A proper answer to these questions requires measure theory, and this is a very informal introduction to probability, so we are not going into that rabbit hole. But the answer essentially is that for a continuous <span id="dx1-24009"/>random variable, we can only assign a probability of 0 to every individual value it may take; instead, we can assign densities to them and then we can calculate probabilities for a range of values. Thus, for a Gaussian, the probability of getting exactly the number -2, i.e. the number -2 followed by an infinite number of zeros after the decimal point, is 0. But the probability of getting a number between -2 and 0 is some number larger than 0 and smaller than 1. To find out the exact answer, we need to compute the following:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file20.jpg" class="math-display" alt=" ∫ b P(a &lt; X &lt; b) = pdf(x)dx a "/>&#13;
</div>&#13;
<p>And to compute that, we need to replace the symbols for a concrete quantity. If we replace the pdf by Normal(0<em>,</em>1), and <em>a</em> = <span class="cmsy-10x-x-109">−</span>2, <em>b</em> = 0, we will get that <em>P</em>(<span class="cmsy-10x-x-109">−</span>2 <em>&lt; X &lt;</em> 0) <span class="cmsy-10x-x-109">≈ </span>0<em>.</em>477, which is the shaded area in <em>Figure <a href="#x1-24010r6">1.6</a></em>.</p>&#13;
<div class="IMG---Figure">&#13;
<img src="../media/file21.png" alt="PIC"/>&#13;
</div>&#13;
<p class="IMG---Caption"><span id="x1-24010r6"/><strong>Figure 1.6</strong>: The black line represents the pdf of a Gaussian with parameters mu=0 and sigma=1, the gray area is the probability of a value being larger than -2 and smaller than 0</p>&#13;
<p>You may remember that we can approximate an integral by summing areas of rectangles and the approximation becomes more <span id="dx1-24011"/>and more accurate as we reduce the length of the base of the rectangles (see the Wikipedia entry for <a href="Bibliography.xhtml#Xwikipedia_riemann_2023">Riemann integral</a>). Based on this idea and using PreliZ, we can estimate <em>P</em>(<span class="cmsy-10x-x-109">−</span>2 <em>&lt; X &lt;</em> 0) as:</p>&#13;
<p><span id="x1-24012r5"/> <span id="x1-24013"/><strong>Code 1.5</strong></p>&#13;
<pre id="listing-6" class="source-code"><code>dist = pz.Normal(0, 1) </code>&#13;
<code>a = -2 </code>&#13;
<code>b = 0 </code>&#13;
<code>num = 10 </code>&#13;
<code>x_s = np.linspace(a, b, num) </code>&#13;
<code>base = (b-a)/num </code>&#13;
<code>np.sum(dist.pdf(x_s) * base)</code></pre>&#13;
<p>If we <span id="dx1-24021"/>increase the value of <code>num</code>, we will get a better approximation. <span id="x1-24022r35"/></p>&#13;
</section>&#13;
<section id="cumulative-distribution-function" class="level4 subsectionHead" data-number="1.5.4.5">&#13;
<h3 class="subsectionHead" data-number="1.5.4.5">1.4.5 <span id="x1-250005"/>Cumulative distribution function</h3>&#13;
<p><span id="dx1-25001"/> <span id="dx1-25002"/></p>&#13;
<p>We have seen the pmf and the pdf, but these are not the only ways to characterize distributions. An alternative is the <strong>cumulative distribution</strong> <strong>function</strong> (<strong>cdf</strong>). The cdf of a random variable <em>X</em> is the function <em>F</em><sub><em>X</em></sub> given by <em>F</em><sub><em>X</em></sub>(<em>x</em>) = <em>P</em>(<em>X</em> <span class="cmsy-10x-x-109">≤ </span><em>x</em>). In words, the cdf is the answer to the question: what is the probability of getting a number lower than or equal to <em>x</em>? On the first column of <em>Figure <a href="#x1-25003r7">1.7</a></em>, we can see the pmf and cdf of a BetaBinomial, and in the second column, the pdf and cdf of a Gaussian. Notice how the cdf <em>jumps</em> for the discrete variable but it is smooth for the continuous variable. The height of each jump represents a probability – just compare them with the height of the dots. We can use the plot of the cdf of a continuous variable as visual proof that probabilities are zero for any value of the continuous variable. Just notice how there are no <em>jumps</em> for continuous variables, which is equivalent to saying that the height of the jumps is exactly zero.</p>&#13;
<div class="IMG---Figure">&#13;
<img src="../media/file22.png" alt="PIC"/>&#13;
</div>&#13;
<p class="IMG---Caption"><span id="x1-25003r7"/><strong>Figure 1.7</strong>: The pmf of the BetaBinomial distribution with its corresponding cdf and the pdf of the Normal distribution with its corresponding cdf</p>&#13;
<p>Just by looking at a cdf, it is easier to find what is the probability of getting a number smaller than, let’s say, 1. We just need to go to the value 1 on the x-axis, move up until we cross the black line, and then check the value of the y-axis. For instance, in <em>Figure <a href="#x1-25003r7">1.7</a></em> and for the Normal distribution, we can see that the value lies between 0.75 and 1. Let’s say it is <span class="cmsy-10x-x-109">≈ </span>0<em>.</em>85. This is way harder to do with the pdf because we would need to compare the entire area below 1 to the total area to get the answer. Humans are worse at judging areas than judging heights or lengths. <span id="x1-25004r38"/></p>&#13;
</section>&#13;
<section id="conditional-probability" class="level4 subsectionHead" data-number="1.5.4.6">&#13;
<h3 class="subsectionHead" data-number="1.5.4.6">1.4.6 <span id="x1-260006"/>Conditional probability</h3>&#13;
<p><span id="dx1-26001"/> <span id="dx1-26002"/></p>&#13;
<p>Given two events <em>A</em> and <em>B</em> with <em>P</em>(<em>B</em>) <em>&gt;</em> 0, the probability of <em>A</em> given <em>B</em>, which we write as <em>P</em>(<em>A</em><span class="cmsy-10x-x-109">|</span><em>B</em>) is defined as:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file23.jpg" class="math-display" alt="P(A | B ) = P-(A,-B-) P (B) "/>&#13;
</div>&#13;
<p><em>P</em>(<em>A,B</em>) is the probability that both the event <em>A</em> and event <em>B</em> occur. <em>P</em>(<em>A</em><span class="cmsy-10x-x-109">|</span><em>B</em>) is known as conditional probability, and it is the probability that event <em>A</em> occurs, <strong>conditioned</strong> by the fact that we know (or assume, imagine, hypothesize, etc.) that <em>B</em> has occurred. For example, the probability that the pavement is wet is different from the probability that the pavement is wet if we know it’s raining.</p>&#13;
<p>A <span id="dx1-26003"/>conditional probability can be larger than, smaller than, or equal to the unconditional probability. If knowing <em>B</em> does not provide us with information about <em>A</em>, then <em>P</em>(<em>A</em><span class="cmsy-10x-x-109">|</span><em>B</em>) = <em>P</em>(<em>A</em>). This will be true only if <em>A</em> and <em>B</em> are independent of each other. On the contrary, if knowing <em>B</em> gives us useful information about <em>A</em>, then the conditional probability could be larger or smaller than the unconditional probability, depending on whether knowing <em>B</em> makes <em>A</em> less or more likely. Let’s see a simple example using a fair six-sided die. What is the probability of getting the number 3 if we roll the die? <em>P</em>(die = 3) = <img src="../media/file25.jpg" class="frac" data-align="middle" alt="16"/> since each of the six numbers has the same chance for a fair six-sided die. And what is the probability of getting the number 3 given that we have obtained an odd number? <em>P</em>(die = 3 | die = {1,3,5}) = <img src="../media/file27.jpg" class="frac" data-align="middle" alt="1 3"/>, because if we know we have an odd number, the only possible numbers are <span class="cmsy-10x-x-109">{</span>1<em>,</em>3<em>,</em>5<span class="cmsy-10x-x-109">} </span>and each of them has the same chance. Finally, what is the probability of getting 3 if we have obtained an even number? This is <em>P</em>(die = 3 | die = {2,4,6}) = 0, because if we know the number is even, then the only possible ones are <span class="cmsy-10x-x-109">{</span>2<em>,</em>4<em>,</em>6<span class="cmsy-10x-x-109">} </span>and thus getting a 3 is not possible.</p>&#13;
<p>As we can see from these simple examples, by conditioning on observed data, we are changing the sample space. When asking about <em>P</em>(die = 3), we need to evaluate the sample space <em>S</em> = <span class="cmsy-10x-x-109">{</span>1<em>,</em>2<em>,</em>3<em>,</em>4<em>,</em>5<em>,</em>6<span class="cmsy-10x-x-109">}</span>, but when we <strong>condition</strong> <strong>on</strong> having got an even number, then the new sample space becomes <em>T</em> = <span class="cmsy-10x-x-109">{</span>2<em>,</em>4<em>,</em>6<span class="cmsy-10x-x-109">}</span>.</p>&#13;
<p>Conditional probabilities are at the heart of statistics, irrespective of whether your problem is rolling dice or building self-driving cars.</p>&#13;
<p>The central panel of <em>Figure <a href="#x1-26005r8">1.8</a></em> represents <em>p</em>(<em>A,B</em>) using a grayscale with darker colors for higher probability densities. We see the joint distribution is elongated, indicating that the higher the value of <em>A</em>, the higher the one of <em>B</em>, and vice versa. Knowing the value of <em>A</em> tells us something about the values of <em>B</em> and the other way around. On the top and right <em>margins</em> of <em>Figure <a href="#x1-26005r8">1.8</a></em> we have the <strong>marginal distributions</strong> <em>p</em>(<em>A</em>) and <em>p</em>(<em>B</em>) respectively. To compute the marginal of <em>A</em>, we take <em>p</em>(<em>A,B</em>) and we <span id="dx1-26004"/>average overall values of <em>B</em>, intuitively this is like taking a 2D object, the joint distribution, and projecting it into one dimension. The marginal distribution of <em>B</em> is computed similarly. The dashed lines represent the <strong>conditional probability</strong> <em>p</em>(<em>A</em><span class="cmsy-10x-x-109">|</span><em>B</em>) for 3 different values of <em>B</em>. We get them by slicing the joint <em>p</em>(<em>A,B</em>) at a given value of <em>B</em>. We can think of this as the distribution of <em>A</em> given that we have observed a particular value of <em>B</em>.</p>&#13;
<div class="IMG---Figure">&#13;
<img src="../media/file30.png" alt="PIC"/>&#13;
</div>&#13;
<p class="IMG---Caption"><span id="x1-26005r8"/><strong>Figure 1.8</strong>: Representation of the relationship between the joint <em>p</em>(<em>A,B</em>), the marginals <em>p</em>(<em>A</em>) and <em>p</em>(<em>B</em>), and the conditional <em>p</em>(<em>A</em><span class="cmsy-10x-x-109">|<em>B</em>) probabilities </span></p>&#13;
<p><span id="x1-26006r39"/></p>&#13;
</section>&#13;
<section id="expected-values" class="level4 subsectionHead" data-number="1.5.4.7">&#13;
<h3 class="subsectionHead" data-number="1.5.4.7">1.4.7 <span id="x1-270007"/>Expected values</h3>&#13;
<p><span id="dx1-27001"/> <span id="dx1-27002"/></p>&#13;
<p>If <em>X</em> is a discrete random variable, we can compute its expected value as:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file31.jpg" class="math-display" alt=" ∑ 𝔼 (X ) = xP (X = x) x "/>&#13;
</div>&#13;
<p>This is just the mean or average value.</p>&#13;
<p>You are probably used to computing means or averages of samples or collections of numbers, either by hand, on a calculator, or using Python. But notice that here we are not talking about the mean of a bunch of numbers; we are talking about the mean of a distribution. Once we have defined the parameters of a distribution, we can, in principle, compute its expected values. Those are properties of the distribution in the same way that the perimeter is a property of a circle that gets defined once we set the value of the radius.</p>&#13;
<p>Another expected value is the variance, which we can use to describe the spread of a distribution. The variance appears <em>naturally</em> in many computations in statistics, but in practice, it is often more useful to use the standard deviation, which is the square root of the variance. The reason is that the standard deviation is in the same units as the random variable.</p>&#13;
<p>The <span id="dx1-27003"/>mean and variance are often called the <strong>moments</strong> of a distribution. Other moments are skewness, which tells us about the <span id="dx1-27004"/>asymmetry of a distribution, and the kurtosis, which tells us about the behavior of the tails or the <em>extreme values</em> [<a href="Bibliography.xhtml#Xwestfall2014">Westfall</a>, <a href="Bibliography.xhtml#Xwestfall2014">2014</a>]. <em>Figure <a href="#x1-27006r9">1.9</a></em> shows examples of different <span id="dx1-27005"/>distributions and their mean <em>μ</em>, standard deviation <em>σ</em>, skew <em>γ</em>, and kurtosis <img src="../media/K.png" style="width:0.75em; vertical-align: -0.10em;"/>. Notice that for some distributions, some moments may not be defined or they may be inf.</p>&#13;
<div class="IMG---Figure">&#13;
<img src="../media/file32.png" alt="PIC"/>&#13;
</div>&#13;
<p class="IMG---Caption"><span id="x1-27006r9"/><strong>Figure 1.9</strong>: Four distributions with their first four moments</p>&#13;
<p>Now that we have learned about some of the basic concepts and jargon from probability theory, we can move on to the <span id="dx1-27007"/>moment everyone was waiting for. <span id="x1-27008r40"/></p>&#13;
</section>&#13;
<section id="bayes-theorem" class="level4 subsectionHead" data-number="1.5.4.8">&#13;
<h3 class="subsectionHead" data-number="1.5.4.8">1.4.8 <span id="x1-280008"/>Bayes’ theorem</h3>&#13;
<p>Without further ado, let’s contemplate, in all its majesty, Bayes’ theorem:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file33.jpg" class="math-display" alt=" p(Y-| θ)p(θ) p(θ | Y ) = p(Y) "/>&#13;
</div>&#13;
<p>Well, it’s not that impressive, is it? It <span id="dx1-28001"/>looks like an elementary school formula, and yet, paraphrasing Richard Feynman, this is all you need to know about Bayesian statistics. Learning where Bayes’ theorem comes from will help us understand its meaning. According to the product rule, we have:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file34.jpg" class="math-display" alt="p (θ,Y ) = p(θ | Y ) p(Y ) "/>&#13;
</div>&#13;
<p>This can also be written as:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file35.jpg" class="math-display" alt="p(θ,Y) = p(Y | θ) p(θ) "/>&#13;
</div>&#13;
<p>Given that the terms on the left are equal for both equations, we can combine them and write:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file36.jpg" class="math-display" alt="p(θ | Y) p(Y) = p(Y | θ) p(θ) "/>&#13;
</div>&#13;
<p>On reordering, we get Bayes’ theorem:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file37.jpg" class="math-display" alt=" p(Y | θ)p(θ) p(θ | Y ) =---p(Y)---- "/>&#13;
</div>&#13;
<p>Why is Bayes’ theorem that important? Let’s see.</p>&#13;
<p>First, it says that <em>p</em>(<em>θ</em><span class="cmsy-10x-x-109">|</span><em>Y</em> ) is not necessarily the same as <em>p</em>(<em>Y</em> <span class="cmsy-10x-x-109">|</span><em>θ</em>). This is a very important fact – one that is easy to miss in daily situations, even for people trained in statistics and probability. Let’s use a simple example to clarify why these quantities are not necessarily the same. The probability of a person being the Pope given that this person is Argentinian is not the same as the probability of being Argentinian given that this person is the Pope. As there are around 47,000,000 Argentinians alive and a single one of them is the current Pope, we have <em>p</em>(Pope | Argentinian ) <span class="cmsy-10x-x-109">≈</span><img src="../media/file39.jpg" class="frac" data-align="middle" alt="470100000"/> and we also have <em>p</em>(Argentinian | Pope ) = 1.</p>&#13;
<p>If we replace <em>θ</em> with “hypothesis” and <em>Y</em> with “data,” Bayes’ theorem tells us how to compute the probability of a hypothesis, <em>θ</em>, given <span id="dx1-28002"/>the data, <em>Y</em> , and that’s the way you will find Bayes’ theorem is explained in a lot of places. But, how do we turn a hypothesis into something that we can put inside Bayes’ theorem? Well, we do it by using probability distributions. So, in general, our hypothesis is a hypothesis in a very, very, very narrow sense; we will be more precise if we talk about finding a suitable value for parameters in our models, that is, parameters of probability distributions. By the way, don’t try to set <em>θ</em> to statements such as ”unicorns are real,” unless you are willing to build a realistic probabilistic model of unicorn existence!</p>&#13;
<p>Bayes’ theorem is central to Bayesian statistics. As we will see in <em>Chapter <a href="CH02.xhtml#x1-440002">2</a></em>, using tools such as PyMC frees us of the need to explicitly write Bayes’ theorem every time we build a Bayesian model. Nevertheless, it is important to know the name of its parts because we will constantly refer to them and it is important to understand what each part means because this will help us to <span id="dx1-28003"/>conceptualize models. So, let me rewrite Bayes’ theorem now with labels:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file41.jpg" class="math-display" alt=" posterior ◜likeli◞h◟ood◝p◜r◞io◟r◝ ◜--◞◟-◝ p (Y | θ)p(θ) p(θ | Y) =-------------- p◟(◝Y◜)◞ marginal likelihood "/>&#13;
</div>&#13;
<p>The <strong>prior distribution</strong> should <span id="dx1-28004"/>reflect what we know about the value of the parameter <em>θ</em> before seeing the data, <em>Y</em> . If we know nothing, like Jon Snow, we could use flat priors that do not convey too much information. In general, we can do better than flat priors, as we will learn in this book. The use of priors is why some people still talk about Bayesian statistics as subjective, even when priors are just another assumption that we made when modeling and hence are just as subjective (or objective) as any other assumption, such as likelihoods.</p>&#13;
<p>The <strong>likelihood</strong> is how we will <span id="dx1-28005"/>introduce data in our analysis. It is an expression of the plausibility of the data given the parameters. In some texts, you will find people call this term sampling model, statistical model, or just model. We will stick to the name likelihood and we will model the combination of priors and likelihood.</p>&#13;
<p>The <strong>posterior distribution</strong> is the result of the <span id="dx1-28006"/>Bayesian analysis and reflects all that we know about a problem (given our data and model). The posterior is a probability distribution for the parameters in our model and not a single value. This distribution is a balance between the prior and the likelihood. There is a well-known joke: a Bayesian is one who, vaguely expecting a horse, and catching a glimpse of a donkey, strongly believes they have seen a mule. One excellent way to kill the mood after hearing this joke is to explain that if the likelihood and priors are both vague, you will get a posterior reflecting vague beliefs about seeing a mule rather than strong ones. Anyway, I like the joke, and I like how it captures the idea of a posterior being somehow a compromise between prior and likelihood. Conceptually, we can think of the posterior as the updated prior in light of (new) data. In theory, the posterior from one analysis can be used as the prior for a new analysis (in practice, life can be harder). This makes Bayesian analysis particularly suitable for analyzing data that becomes available in sequential order. One example could be an early warning system for <span id="dx1-28007"/>natural disasters that processes online data coming from meteorological stations and satellites. For more details, read about online machine-learning methods.</p>&#13;
<p>The last term is the <strong>marginal likelihood</strong>, sometimes referred to as the <strong>evidence</strong>. Formally, the marginal likelihood is the probability of <span id="dx1-28008"/>observing the data averaged over all the possible values the parameters can take (as prescribed by the prior). We can write this as <span class="cmex-10x-x-109">∫</span> <sub>Θ</sub><sup/><em>p</em>(<em>Y</em> <span class="cmsy-10x-x-109">|</span><em>θ</em>)<em>p</em>(<em>θ</em>)d<em>θ</em>. We will not really care about the marginal likelihood until <em>Chapter <a href="CH05.xhtml#x1-950005">5</a></em>. But for the moment, we can think of it as a normalization factor that ensures the posterior is a proper pmf or pdf. If we ignore the marginal likelihood, we can write Bayes’ theorem as a proportionality, which is also a common way to write Bayes’ theorem:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file42.jpg" class="math-display" alt="p(θ | Y ) ∝ p(Y | θ)p(θ) "/>&#13;
</div>&#13;
<p>Understanding the exact role of each term in Bayes’ theorem will take some time and practice, and it will require a few examples, but that’s what the rest of this book is for. <span id="x1-28009r22"/></p>&#13;
</section>&#13;
</section>&#13;
<section id="interpreting-probabilities" class="level3 sectionHead" data-number="1.5.5">&#13;
<h2 class="sectionHead" data-number="1.5.5">1.5 <span id="x1-290005"/>Interpreting probabilities</h2>&#13;
<p>Probabilities can be interpreted in various useful ways. For instance, we can think that <em>P</em>(<em>A</em>) = 0<em>.</em>125 means that if we repeat the <span id="dx1-29001"/>survey many times, we would expect all three individuals to answer “yes” about 12.5% of the time. We are interpreting probabilities as the outcome of long-run experiments. This is a very common and useful interpretation. It not only can help us think about probabilities but can also provide an empirical method to estimate probabilities. Do we want to know the probability of a car tire exploding if filled with air beyond the manufacturer’s recommendation? Just inflate 120 tires or so, and you may get a good approximation. This is usually called the frequentist interpretation.</p>&#13;
<p>Another interpretation of probability, usually called subjective or Bayesian interpretation, states that probabilities can be interpreted as measures of an individual’s uncertainty about events. In this interpretation, probabilities are about our state of knowledge of the world and are not necessarily based on repeated trials. Under this definition of probability, it is valid and natural to ask about the probability of life on Mars, the probability of the mass of an electron being 9<em>.</em>1 <span class="cmsy-10x-x-109">× </span>10<sup><span class="cmsy-8">−</span>31</sup> kg, or the probability that the 9<sup>th</sup> of July of 1816 was a sunny day in Buenos Aires. All <span id="dx1-29002"/>these are one-time events. We cannot re-create 1 million universes, each with one Mars, and check how many of them develop life. Of course, we can do this as a mental experiment, so long-term frequencies can still be a valid mental scaffold.</p>&#13;
<p>Sometimes the Bayesian interpretation of probabilities is described in terms of personal beliefs; I don’t like that. I think it can lead to unnecessary confusion as beliefs are generally associated with the notion of faith or unsupported claims. This association can easily lead people to think that Bayesian probabilities, and by extension Bayesian statistics, is less objective or less scientific than alternatives. I think it also helps to generate confusion about the role of prior knowledge in statistics and makes people think that being objective or rational means not using prior information.</p>&#13;
<p>Bayesian methods are as subjective (or objective) as any other well-established scientific method we have. Let me explain myself with an example: life on Mars exists or does not exist; the outcome is binary, a yes-no question. But given that we are not sure about that fact, a sensible course of action is trying to find out how likely life on Mars is. To answer this question any honest and scientific-minded person will use all the relevant geophysical data about Mars, all the relevant biochemical knowledge about necessary conditions for life, and so on. The response will be necessarily about our epistemic state of knowledge, and others could disagree and even get different probabilities. But at least, in principle, they all will be able to provide arguments in favor of their data, their methods, their modeling decisions, and so on. A scientific and rational debate about life on Mars does not admit <em>arguments</em> such as ”an angel told me about tiny green creatures.” Bayesian statistics, however, is just a <span id="dx1-29003"/>procedure to make scientific statements using probabilities as building blocks. <span id="x1-29004r42"/></p>&#13;
</section>&#13;
<section id="probabilities-uncertainty-and-logic" class="level3 sectionHead" data-number="1.5.6">&#13;
<h2 class="sectionHead" data-number="1.5.6">1.6 <span id="x1-300006"/>Probabilities, uncertainty, and logic</h2>&#13;
<p>Probabilities can help <span id="dx1-30001"/>us to quantify uncertainty. If we do not have information about a problem, it is reasonable to <span id="dx1-30002"/>state that every possible event is equally likely. This is equivalent to assigning the same probability to every possible event. In the absence of information, our uncertainty is maximum, and I am not saying this colloquially; this is something we can compute using probabilities. If we know instead that some events are more likely, then this can be formally represented by assigning a higher probability to those events and less to the others. Notice that when we talk about events in stats-speak, we are not restricting ourselves to things that can happen, such as an asteroid crashing into Earth or my auntie’s 60<sup>th</sup> birthday party. An event is just any of the possible values (or a subset of values) a variable can take, such as the event that you are older than 30, the price of a Sachertorte, or the number of bikes that will be sold next year around the world.</p>&#13;
<p>The concept of probability is also related to the subject of logic. Under classical logic, we can only have statements that take the values of true or false. Under the Bayesian definition of probability, certainty is just a special case: a true statement has a probability of 1, and a false statement has a probability of 0. We would assign a probability of 1 to the statement that there is Martian life only after having conclusive data indicating something is growing, reproducing, and doing other activities we associate with living organisms.</p>&#13;
<p>Notice, however, that assigning a probability of 0 is harder because we could always think that there is some Martian spot that is unexplored, or that we have made mistakes with some experiments, or there are several other reasons that could lead us to falsely believe life is absent on Mars even if it is not. This is related to Cromwell’s rule, which states that we should reserve the probabilities of 0 or 1 to logically true or false statements. Interestingly enough, it can be shown that if we want to extend the logic to include uncertainty, we must use probabilities and probability theory.</p>&#13;
<p>As we will soon see, Bayes’ theorem is just a logical consequence of the rules of probability. Thus, we can think of Bayesian statistics as an extension of logic that is useful whenever we are dealing with uncertainty. Thus, one way to justify using the Bayesian method is to recognize that <span id="dx1-30003"/>uncertainty is commonplace. We generally have to deal with incomplete and or noisy data, we are <span id="dx1-30004"/>intrinsically limited by our evolution-sculpted primate brain, and so on.</p>&#13;
<div id="tcolobox-3" class="tcolorbox coolbox">&#13;
<div class="tcolorbox-title">&#13;
<p>The Bayesian Ethos</p>&#13;
</div>&#13;
<div class="tcolorbox-content">&#13;
<p>Probabilities are used to measure the uncertainty we have about parameters, and Bayes’ theorem is a mechanism to correctly update those probabilities in light of new data, hopefully reducing our uncertainty.</p>&#13;
</div>&#13;
</div>&#13;
<p><span id="x1-30005r43"/></p>&#13;
</section>&#13;
<section id="single-parameter-inference" class="level3 sectionHead" data-number="1.5.7">&#13;
<h2 class="sectionHead" data-number="1.5.7">1.7 <span id="x1-310007"/>Single-parameter inference</h2>&#13;
<p>Now that we know what Bayesian statistics is, let’s learn how to do Bayesian statistics with a simple example. We are going to begin inferring a single, unknown parameter. <span id="x1-31001r41"/></p>&#13;
<section id="the-coin-flipping-problem" class="level4 subsectionHead" data-number="1.5.7.1">&#13;
<h3 class="subsectionHead" data-number="1.5.7.1">1.7.1 <span id="x1-320001"/>The coin-flipping problem</h3>&#13;
<p>The coin-flipping problem, or the <span id="dx1-32001"/>BetaBinomial model if you want to sound fancy at parties, is a classical problem in statistics and goes like this: we toss a coin several times and record how many heads and tails we get. Based on this data, we try to answer questions such as, is the coin fair? Or, more generally, how biased is the coin? While this problem may sound dull, we should not underestimate it.</p>&#13;
<p>The coin-flipping problem is a great example to learn the basics of Bayesian statistics because it is a simple model that we can solve and compute with ease. Besides, many real problems consist of binary, mutually exclusive outcomes such as 0 or 1, positive or negative, odds or evens, spam or ham, hotdog or not a hotdog, cat or dog, safe or unsafe, and healthy or unhealthy. Thus, even when we are talking about coins, this model applies to any of those problems. To estimate the bias of a coin, and in general, to answer any questions in a Bayesian setting, we will need data and a probabilistic model. For this example, we will assume that we have already tossed a coin several times and we have a record of the number of observed heads, so the data-gathering part is already done. Getting the model will take a little bit more effort. Since this is our first model, we will explicitly write Bayes’ theorem and do all the necessary math (don’t be afraid, I promise it will be painless) and we will proceed very slowly. From <a href="CH02.xhtml#x1-440002">2</a> onward, we will use PyMC and our computer to do the math for us.</p>&#13;
<p>The first thing we will do is generalize the concept of bias. We will say that a coin with a bias of 1 will always land heads, one with a bias of 0 will always land tails, and one with a bias of 0.5 will land heads <span id="dx1-32002"/>half of the time and tails half of the time. To represent the bias, we will use the parameter <em>θ</em>, and to represent the total number of heads for several tosses, we will use the variable <em>Y</em> . According to Bayes’ theorem, we have to specify the prior, <em>p</em>(<em>θ</em>), and likelihood, <em>p</em>(<em>Y</em> <span class="cmsy-10x-x-109">|</span><em>θ</em>), we will use. Let’s start with the likelihood. <span id="x1-32003r45"/></p>&#13;
</section>&#13;
<section id="choosing-the-likelihood" class="level4 subsectionHead" data-number="1.5.7.2">&#13;
<h3 class="subsectionHead" data-number="1.5.7.2">1.7.2 <span id="x1-330002"/>Choosing the likelihood</h3>&#13;
<p>Let’s assume that only two <span id="dx1-33001"/>outcomes are possible—heads or tails—and let’s also assume that a coin toss does not affect other <span id="dx1-33002"/>tosses, that is, we are assuming coin tosses are independent of each other. We will further assume all coin tosses come from the same distribution. Thus the random variable coin toss is an example of an <strong>independent and identically distributed</strong> (<strong>iid</strong>) variable. I hope you agree that these are very reasonable assumptions to make for our problem. Given these assumptions, a good candidate for the likelihood is the Binomial distribution:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file43.jpg" class="math-display" alt=" ----N-!--- y N− y p(Y | θ) = y!(N − y)! θ (1 − θ) ◟---◝◜---◞ normalizing constant "/>&#13;
</div>&#13;
<p>This is a discrete distribution returning the probability of getting <em>y</em> heads (or, in general, successes) out of <em>N</em> coin tosses (or, in general, trials or experiments) given a fixed value of <em>θ</em>.</p>&#13;
<p><em>Figure <a href="#x1-33003r10">1.10</a></em> shows nine distributions from the Binomial family; each subplot has its legend indicating the values of the parameters. Notice that for this plot, I did not omit the values on the y-axis. I did this so you can check for yourself that if you sum the height of all bars, you will get 1, that is, for discrete distributions, the height of the bars represents actual probabilities.</p>&#13;
<div class="IMG---Figure">&#13;
<img src="../media/file44.png" alt="PIC"/>&#13;
</div>&#13;
<p class="IMG---Caption"><span id="x1-33003r10"/><strong>Figure 1.10</strong>: Nine members of the Binomial family</p>&#13;
<p>The Binomial distribution is a reasonable choice for the likelihood. We can see that <em>θ</em> indicates how likely it is to <span id="dx1-33004"/>obtain a head when tossing a coin. This is easier to see when <em>N</em> = 1 but is valid for any value of <em>N</em>, just compare the value of <em>θ</em> with the height of the bar for <em>y</em> = 1 (heads). <span id="x1-33005r46"/></p>&#13;
</section>&#13;
<section id="choosing-the-prior" class="level4 subsectionHead" data-number="1.5.7.3">&#13;
<h3 class="subsectionHead" data-number="1.5.7.3">1.7.3 <span id="x1-340003"/>Choosing the prior</h3>&#13;
<p><span id="dx1-34001"/></p>&#13;
<p>As a prior, we will use a Beta distribution, which is a very common distribution in Bayesian statistics and looks as follows:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file45.jpg" class="math-display" alt="p(θ) = --Γ (𝛼-+-𝛽)- θ𝛼−1(1− θ)𝛽−1 Γ◟-(𝛼-)+◝◜Γ (𝛽)◞ normalizing constant "/>&#13;
</div>&#13;
<p>If we look carefully, we will see that the Beta distribution looks similar to the Binomial except for the first term. Γ is the Greek uppercase gamma letter, which represents the gamma function, but that’s not really important. What is relevant for us is that the first term is a normalizing constant that ensures the distribution integrates to 1. We can see from the preceding formula that the Beta distribution has two parameters, <em>α</em> and <em>β</em>. <em>Figure <a href="#x1-34002r11">1.11</a></em> shows nine members of the Beta family.</p>&#13;
<div class="IMG---Figure">&#13;
<img src="../media/file46.png" alt="PIC"/>&#13;
</div>&#13;
<p class="IMG---Caption"><span id="x1-34002r11"/><strong>Figure 1.11</strong>: Nine members of the Beta family</p>&#13;
<p>I like the Beta distribution and all the shapes we can get from it, but why are we using it for our model? There are many reasons to use a Beta distribution for this and other problems. One of them is that the Beta distribution is restricted to be between 0 and 1, in the same way our <em>θ</em> parameter is. In general, we use the Beta distribution when we want to model the proportions of a Binomial variable. Another reason is its versatility. As we can see in <em>Figure <a href="#x1-34002r11">1.11</a></em>, the distribution adopts several shapes (all restricted to the [0<em>,</em>1] interval), including a Uniform distribution, Gaussian-like distributions, and U-like distributions.</p>&#13;
<p>As a third reason, the Beta distribution is the conjugate prior to the Binomial distribution (which we are using as the likelihood). A conjugate prior of a likelihood is a prior that, when used in combination with a given likelihood, returns a posterior with the same functional form as the prior. Untwisting the tongue, every time we use a Beta distribution as the prior and a Binomial distribution as the likelihood, we will get a Beta as the posterior distribution. There are other pairs of conjugate priors; for example, the Normal distribution is the conjugate prior to itself. For many years, Bayesian analysis was restricted to the use of conjugate priors. Conjugacy ensures mathematical tractability of the posterior, which is important given that a common problem in Bayesian statistics ends up with a posterior we cannot solve analytically. This was a deal breaker before the development of suitable computational methods to solve probabilistic methods. From <em>Chapter <a href="CH02.xhtml#x1-440002">2</a></em> onwards, we will learn how to use modern computational methods to solve Bayesian problems, whether we choose conjugate priors or not. <span id="x1-34003r47"/></p>&#13;
</section>&#13;
<section id="getting-the-posterior" class="level4 subsectionHead" data-number="1.5.7.4">&#13;
<h3 class="subsectionHead" data-number="1.5.7.4">1.7.4 <span id="x1-350004"/>Getting the posterior</h3>&#13;
<p>Let’s remember that Bayes’ theorem <span id="dx1-35001"/>says the posterior is proportional to the likelihood times the prior. So, for our problem, we have to multiply the Binomial and the Beta distributions:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file47.jpg" class="math-display" alt=" likelihood prior ◜---------◞◟---------◝ ◜----------◞◟-----------◝ p(θ | Y ) =---N-!---θy(1− θ)N −y -Γ-(𝛼+-𝛽-)-θ𝛼− 1(1 − θ)𝛽−1 y!(N − y )! Γ (𝛼) + Γ (𝛽) "/>&#13;
</div>&#13;
<p>We can simplify this expression by dropping all the terms that do not depend on <em>θ</em> and our results will still be valid. Accordingly, we can write:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file48.jpg" class="math-display" alt=" -likelihood--- -----prior---- ◜y ◞◟ N −◝y ◜𝛼−1 ◞◟ 𝛽−◝1 p(θ | Y) ∝ θ) "/>&#13;
</div>&#13;
<p>Reordering it, and noticing this has the form of a Beta distribution, we get:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file49.jpg" class="math-display" alt="p(θ | Y ) = Beta (𝛼prior + y,𝛽prior+N −y) "/>&#13;
</div>&#13;
<p>Based on this analytical expression, we can compute the posterior. <em>Figure <a href="#x1-35014r12">1.12</a></em> shows the results for 3 priors and different <span id="dx1-35002"/>numbers of trials. The following block of code shows the gist to generate <em>Figure <a href="#x1-35014r12">1.12</a></em> (omitting the code necessary for plotting).</p>&#13;
<p><span id="x1-35003r6"/> <span id="x1-35004"/><strong>Code 1.6</strong></p>&#13;
<pre id="listing-7" class="source-code"><code>n_trials = [0, 1, 2, 3, 4, 8, 16, 32, 50, 150] </code>&#13;
<code>n_heads = [0, 1, 1, 1, 1, 4, 6, 9, 13, 48] </code>&#13;
<code>beta_params = [(1, 1), (20, 20), (1, 4)] </code>&#13;
<code> </code>&#13;
<code>x = np.linspace(0, 1, 2000) </code>&#13;
<code>for idx, N in enumerate(n_trials): </code>&#13;
<code>    y = n_heads[idx] </code>&#13;
<code>    for (<em>α</em>_prior, <em>β</em>_prior) in beta_params: </code>&#13;
<code>        posterior = pz.Beta(<em>α</em>_prior + y, <em>β</em>_prior + N - y).pdf(x)</code></pre>&#13;
<div class="IMG---Figure">&#13;
<img src="../media/file50.png" alt="PIC"/>&#13;
</div>&#13;
<p class="IMG---Caption"><span id="x1-35014r12"/><strong>Figure 1.12</strong>: The first subplot shows 3 priors. The rest show successive updates as we get new data</p>&#13;
<p>On the first subplot of <em>Figure <a href="#x1-35014r12">1.12</a></em>, we have zero trials, thus the three curves represent our priors:</p>&#13;
<ul>&#13;
<li><p>The Uniform prior (black): This represents all the possible values for the bias being equally probable a priori.</p></li>&#13;
<li><p>The Gaussian-like prior (dark gray): This is centered and concentrated around 0.5, so this prior is compatible with information indicating that the coin has more or less about the same chance of landing heads or tails. We could also say this prior is compatible with the knowledge that coins are fair.</p></li>&#13;
<li><p>The skewed prior (light gray): This puts most of the weight on a tail-biased outcome.</p></li>&#13;
</ul>&#13;
<p>The rest of the subplots show posterior distributions for successive trials. The number of trials (or coin tosses) and the number of heads are indicated in each subplot’s legend. There is also a black dot at 0.35 representing the true value for <em>θ</em>. Of course, in real problems, we do not know this value, and it is <span id="dx1-35015"/>here just for pedagogical reasons. <em>Figure <a href="#x1-35014r12">1.12</a></em>, can teach us a lot about Bayesian analysis, so grab your coffee, tea, or favorite drink, and let’s take a moment to understand it:</p>&#13;
<ul>&#13;
<li><p>The result of a Bayesian analysis is a posterior distribution – not a single value but a distribution of plausible values given the data and our model.</p></li>&#13;
<li><p>The most probable value is given by the mode of the posterior (the peak of the distribution).</p></li>&#13;
<li><p>The spread of the posterior is proportional to the uncertainty about the value of a parameter; the more spread out the distribution, the less certain we are.</p></li>&#13;
<li><p>Intuitively, we are more confident in a result when we have observed more data supporting that result. Thus, even when numerically <img src="../media/file51.jpg" class="frac" data-align="middle" alt="1 2"/> = <img src="../media/file52.jpg" class="frac" data-align="middle" alt="48"/> = 0<em>.</em>5, seeing four heads out of eight trials gives us more confidence that the bias is 0.5 than observing one head out of two trials. This <span id="dx1-35016"/>intuition is reflected in the posterior, as you can check for yourself if you pay attention to the (black) posterior in the third and sixth subplots; while the mode is the same, the spread (uncertainty) is larger in the third subplot than in the sixth subplot.</p></li>&#13;
<li><p>Given a sufficiently large amount of data, two or more Bayesian models with different priors will tend to converge to the same result. In the limit of infinite data, no matter which prior we use, all of them will provide the same posterior.</p></li>&#13;
<li><p>Remember that infinite is a limit and not a number, so from a practical point of view, we could get practically equivalent posteriors for a finite and relatively small number of data points.</p></li>&#13;
<li><p>How fast posteriors converge to the same distribution depends on the data and the model. We can see that the posteriors arising from the black prior (Uniform) and gray prior (biased towards tails) converge faster to almost the same distribution, while it takes longer for the dark gray posterior (the one arising from the concentrated prior). Even after 150 trials, it is somehow easy to recognize the dark gray posterior as a different distribution from the two others.</p></li>&#13;
<li><p>Something not obvious from the figure is that we will get the same result if we update the posterior sequentially as if we do it all at once. We can compute the posterior 150 times, each time adding one more observation and using the obtained posterior as the new prior, or we can just compute one posterior for the 150 tosses at once. The result will be exactly the same. This feature not only makes perfect sense, but it also leads to a natural way of updating our estimations when we get new data, a situation common in many data-analysis problems.</p></li>&#13;
</ul>&#13;
<p><span id="x1-35017r48"/></p>&#13;
</section>&#13;
<section id="the-influence-of-the-prior" class="level4 subsectionHead" data-number="1.5.7.5">&#13;
<h3 class="subsectionHead" data-number="1.5.7.5">1.7.5 <span id="x1-360005"/>The influence of the prior</h3>&#13;
<p>From the preceding example, it is clear that <span id="dx1-36001"/>priors can influence inferences. That’s fine – priors are supposed to do that. Maybe it would be better to not have priors at all. That would make modeling easier, right? Well, not necessarily. If you are not setting the prior, someone else will be doing it for you. Sometimes this is fine – <em>default priors</em> can be useful and have their place – but sometimes it is better to have more control. Let me explain.</p>&#13;
<p>We can think that every (statistical) model, Bayesian or not, has some kind of prior, even if the prior is not set explicitly. For instance, many procedures typically used in frequentist statistics can be seen as special cases of a Bayesian model under certain conditions, such as flat priors. One common way to <span id="dx1-36002"/>estimate parameters is known as maximum likelihood; this method avoids setting a prior and works just by finding the single value maximizing the likelihood. This value is usually notated by adding a little hat on top of the name of the parameter we are estimating, such as <img src="../media/hat_theta.png" style="width:0.50em;"/>. Contrary to the posterior estimate, which is a distribution, <img src="../media/hat_theta.png" style="width:0.50em;"/> is a point estimate, a number. For the coin-flipping problem, we can compute it analytically:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file53.jpg" class="math-display" alt=" y ˆθ = -- N "/>&#13;
</div>&#13;
<p>If you go back to <em>Figure <a href="#x1-35014r12">1.12</a></em>, you will be able to check for yourself that the mode of the black posterior (the one corresponding to the uniform/flat prior) agrees with the values of <img src="../media/hat_theta.png" style="width:0.50em;"/>, computed for each subplot. This is not a coincidence; it is a consequence of the fact that setting a Uniform prior and then taking the mode of the posterior is equivalent to maximum likelihood.</p>&#13;
<p>We cannot avoid priors, but if we include them in our analysis, we can get some potential benefits. The most direct benefit is that we get a posterior distribution, which is a distribution of plausible values and not only the most probable ones. Having a distribution can be more informative than a single-point estimate, as we saw the width of the distribution is related to the uncertainty we have for the estimate. Another benefit is that computing the posteriors means to average over the prior. This can lead to models that are more difficult to overfit and more robust predictions [<a href="Bibliography.xhtml#Xwilson_2022">Wilson and Izmailov</a>, <a href="Bibliography.xhtml#Xwilson_2022">2022</a>].</p>&#13;
<p>Priors can bring us other benefits. Starting in the next chapter, we are going to use numerical methods to get posteriors. These methods feel like magic, until they don’t. The folk theorem of statistical computing states, ”When <span id="dx1-36003"/>you have computational problems, often there’s a problem with your model” [<a href="Bibliography.xhtml#Xgelman_folk_2008">Gelman</a>, <a href="Bibliography.xhtml#Xgelman_folk_2008">2008</a>]. Sometimes a wise choice of prior can make inference easier or faster. It is important to remark that we are not advocating for setting priors specifically to make inference faster, but it is often the case that by thinking about priors, we can get faster models.</p>&#13;
<p>One advantage of priors, one that is sometimes overlooked, is that having to think about priors can <em>force us</em> to think a little bit deeper about the problem we are trying to solve and the data we have. Sometimes the modeling process leads to a better understanding by itself irrespective of how well we end and fit the data or make predictions. By being explicit about priors, we get more transparent models, meaning they’re easier to criticize, debug (in a broad sense of the word), explain to others, and hopefully improve. <span id="x1-36004r44"/></p>&#13;
</section>&#13;
</section>&#13;
<section id="how-to-choose-priors" class="level3 sectionHead" data-number="1.5.8">&#13;
<h2 class="sectionHead" data-number="1.5.8">1.8 <span id="x1-370008"/>How to choose priors</h2>&#13;
<p>Newcomers to <span id="dx1-37001"/>Bayesian analysis (as well as detractors of this paradigm) are generally a little nervous about how to choose priors. Usually, they are afraid that the prior distribution will not let the data speak for itself! That’s OK, but we have to remember that data does not speak; at best, data murmurs. We can only make sense of data in the context of our models, including mathematical and mental models. There are plenty of examples in the history of science where the same data led people to think differently about the same topics, and this can happen even if you base your opinions on formal models.</p>&#13;
<p>Some people like the idea of using non-informative priors (also known as flat, vague, or diffuse priors). These priors have the least possible amount of impact on the analysis. While it is possible to use them for some problems deriving truly non-informative priors can be hard or just impossible. Additionally, we generally can do better as we usually have some prior information.</p>&#13;
<p>Throughout this book, we will follow the recommendations of Gelman, McElreath, Kruschke, and many others, and we will prefer weakly informative priors. For many problems, we often know something about the values a parameter can take. We may know that a parameter is restricted to being positive, or we may know the approximate range it can take, or whether we expect the value to be close to zero or below/above some value. In such cases, we can use priors to put some weak information in our models without being afraid of being too pushy. Because these priors work to keep the posterior distribution within certain <span id="dx1-37002"/>reasonable bounds, they are also known as regularizing priors.</p>&#13;
<p>Informative priors are very strong priors that convey a lot of information. Using them is also a valid option. Depending on your problem, it could be easy or not to find good-quality information from your domain knowledge and turn it into priors. I used to work on structural bioinformatics. In this field, people have been using, in Bayesian and non-Bayesian ways, all the prior information they could get to study and predict the structure of proteins. This is reasonable because we have been collecting data from thousands of carefully designed <span id="dx1-37003"/>experiments for decades and hence we have a great amount of trustworthy prior information at our disposal. Not using it would be absurd! There is nothing “objective” or “scientific” about throwing away valuable information. If you have reliable prior information, you should use it. Imagine if every time an automotive engineer had to design a new car, they had to start from scratch and reinvent the combustion engine, the wheel, and for that matter, the whole concept of a car.</p>&#13;
<p>PreliZ is a very new Python library for prior elicitation [<a href="Bibliography.xhtml#Xmikkola_2021">Mikkola et al.</a>, <a href="Bibliography.xhtml#Xmikkola_2021">2023</a>, <a href="Bibliography.xhtml#Xicazatti2023">Icazatti et al.</a>, <a href="Bibliography.xhtml#Xicazatti2023">2023</a>]. Its mission is to help you to elicit, represent, and visualize your prior knowledge. For instance, we can ask PreliZ to compute the parameters of a distribution satisfying a set of constraints. Let’s say we want to find the Beta distribution with 90% of the mass between 0.1 and 0.7, then we can write:</p>&#13;
<p><span id="x1-37004r7"/> <span id="x1-37005"/><strong>Code 1.7</strong></p>&#13;
<pre id="listing-8" class="source-code"><code>dist = pz.Beta() </code>&#13;
<code>pz.maxent(dist, 0.1, 0.7, 0.9)</code></pre>&#13;
<p>The result is a Beta distribution with parameters <em>α</em> = 2<em>.</em>5 and <em>β</em> = 3<em>.</em>6 (rounded to the first decimal point). The <code>pz.maxent </code>function <span id="dx1-37008"/>computes the <strong>maximum</strong> <strong>entropy</strong> distribution given the constraints we specified. Why maximum entropy distribution? Because that is equivalent to computing the least informative distribution under those constraints. By default, PreliZ will plot the distribution as shown here:</p>&#13;
<div class="IMG---Figure">&#13;
<img src="../media/file54.png" alt="PIC"/>&#13;
</div>&#13;
<p class="IMG---Caption"><span id="x1-37009r13"/><strong>Figure 1.13</strong>: Maximum entropy Beta distribution with 90% of the mass between 0.1 and 0.7</p>&#13;
<p>As eliciting prior has many facets, PreliZ offers many other ways to elicit priors. If you are interested in learning more about PreliZ, you can check the <span id="dx1-37010"/>documentation at <a href="https://preliz.readthedocs.io" class="url">https://preliz.readthedocs.io</a>.</p>&#13;
<p>Building models is an iterative process; sometimes the iteration takes a few minutes, and sometimes it could take years. Reproducibility matters and transparent assumptions in a model contribute to it. We are free to use more than one prior (or likelihood) for a given analysis if we are not sure about any special one; exploring the effect of different priors can also bring valuable information to the table. Part of the modeling process is about questioning assumptions, and priors (and likelihoods) are just that. Different assumptions will lead to different models and probably different results. By using data and our domain knowledge of the problem, we will be able to compare models and, if necessary, decide on a winner. <em>Chapter <a href="CH05.xhtml#x1-950005">5</a></em> will be devoted to this issue. Since priors have a central role in Bayesian statistics, we will keep discussing them as we face new problems. So if you have doubts and feel a little bit confused about this discussion, just keep calm and don’t worry, people have been confused for <span id="dx1-37011"/>decades and the discussion is still going on. <span id="x1-37012r52"/></p>&#13;
</section>&#13;
<section id="communicating-a-bayesian-analysis" class="level3 sectionHead" data-number="1.5.9">&#13;
<h2 class="sectionHead" data-number="1.5.9">1.9 <span id="x1-380009"/>Communicating a Bayesian analysis</h2>&#13;
<p>Creating reports and communicating results is central to the practice of statistics and data science. In this section, we will briefly discuss some of the peculiarities of this task when working with Bayesian models. In future chapters, we will keep looking at examples of this important matter. <span id="x1-38001r51"/></p>&#13;
<section id="model-notation-and-visualization" class="level4 subsectionHead" data-number="1.5.9.1">&#13;
<h3 class="subsectionHead" data-number="1.5.9.1">1.9.1 <span id="x1-390001"/>Model notation and visualization</h3>&#13;
<p>If you want to communicate the results of an analysis, you should also communicate the model you used. A common notation to succinctly represent probabilistic models is:</p>&#13;
<table style="border: none;">&#13;
<tbody>&#13;
<tr class="odd">&#13;
<td style="border: none;"/>&#13;
<td style="border: none;"><em>θ</em> <span class="cmsy-10x-x-109">∼</span> Beta(<em><em>α</em>,<em>β</em></em>)</td>&#13;
<td style="border: none;"/>&#13;
</tr>&#13;
<tr class="even">&#13;
<td style="border: none;"/>&#13;
<td style="border: none;"><em>y</em> <span class="cmsy-10x-x-109">∼</span> Bin(<em>n</em> = 1<em>,p</em> = <em>θ</em>)</td>&#13;
<td style="border: none;"/>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p>This is just the model we use for the coin-flip example. As you may remember, the <span class="cmsy-10x-x-109">∼ </span>symbol indicates that the variable on the left of it is a random variable distributed according to the distribution on the right. In many contexts, this symbol is used to indicate that a variable takes <em>approximately</em> some value, but when talking about probabilistic models, we will read this symbol out loud, saying <em>is distributed as</em>. Thus, we can say <em>θ</em> is distributed as a Beta with parameters <em>α</em> and <em>β</em>, and <em>y</em> is distributed as a Binomial with parameters <em>n</em> = 1 and <em>p</em> = <em>θ</em>. The very same model can be represented graphically using Kruschke diagrams as in <em>Figure <a href="#x1-39001r14">1.14</a></em>.</p>&#13;
<div class="IMG---Figure">&#13;
<img src="../media/file55.png" alt="PIC"/>&#13;
</div>&#13;
<p class="IMG---Caption"><span id="x1-39001r14"/><strong>Figure 1.14</strong>: A Kruschke diagram of a BetaBinomial model</p>&#13;
<p>On the first level, we have the prior that generates the values for <em>θ</em>, then the likelihood, and on the last line, the data, <em>y</em>. Arrows indicate the relationship between variables and the symbol <span class="cmsy-10x-x-109">∼ </span>indicates the stochastic nature of the variables. All Kruschke diagrams in the book were made using the templates provided by Rasmus Bååth ( <a href="http://www.sumsar.net/blog/2013/10/diy-kruschke-style-diagrams/" class="url">http://www.sumsar.net/blog/2013/10/diy-kruschke-style-diagrams/</a>). <span id="x1-39002r56"/></p>&#13;
</section>&#13;
<section id="summarizing-the-posterior" class="level4 subsectionHead" data-number="1.5.9.2">&#13;
<h3 class="subsectionHead" data-number="1.5.9.2">1.9.2 <span id="x1-400002"/>Summarizing the posterior</h3>&#13;
<p>The result of a Bayesian analysis is a posterior distribution, and all the information about the parameters (given a model and dataset) is contained in the posterior distribution. Thus, by summarizing the posterior, we are summarizing the logical consequences of a model and data. A common practice is to report, for each parameter, the mean (or mode or median) to have an idea of the location of the distribution and some measure of dispersion, such as the standard deviation, to have an idea of uncertainty in our estimates. The standard deviation works well for Normal-like distributions but can be misleading for other types of distributions, such as skewed ones.</p>&#13;
<p>A commonly used device to summarize the spread of a posterior distribution is to use a <strong>Highest-Density Interval</strong> (<strong>HDI</strong>). An HDI is the <span id="dx1-40001"/>shortest interval containing a given portion of the probability density. If we say that the 95% HDI for some analysis is [2<em>,</em>5], we mean that according to our data and model, the parameter in question is between 2 and 5 with a probability of 0.95. There is nothing special about choosing 95%, 50%, or any other value. We are free to choose the 82% HDI interval if we like. Ideally, justifications should be context-dependent and not automatic, but it is okay to settle on some common value like 95%. As a friendly reminder of the arbitrary nature of this choice, the ArviZ default is 94%.</p>&#13;
<p>ArviZ is a Python package for exploratory analysis of Bayesian models, and it has many functions to help us summarize the posterior. One of those functions is <code>az.plot_posterior</code>, which we can use to generate a plot <span id="dx1-40002"/>with the mean and HDI of <em>θ</em>. The distribution does not need to be a posterior distribution; any distribution will work. <em>Figure <a href="#x1-40007r15">1.15</a></em> shows the result for a random sample from a Beta distribution:</p>&#13;
<p><span id="x1-40003r8"/> <span id="x1-40004"/><strong>Code 1.8</strong></p>&#13;
<pre id="listing-9" class="source-code"><code>np.random.seed(1) </code>&#13;
<code>az.plot_posterior({'<em>θ</em>':pz.Beta(4, 12).rvs(1000)})</code></pre>&#13;
<div class="IMG---Figure">&#13;
<img src="../media/file56.png" alt="PIC"/>&#13;
</div>&#13;
<p class="IMG---Caption"><span id="x1-40007r15"/><strong>Figure 1.15</strong>: A KDE of a sample from a Beta distribution with its mean and 94% HDI</p>&#13;
<div id="tcolobox-4" class="tcolorbox coolbox">&#13;
<div class="tcolorbox-title">&#13;
<p>Not Confidence Intervals</p>&#13;
</div>&#13;
<div class="tcolorbox-content">&#13;
<p>If you are familiar with the frequentist paradigm, please note that HDIs are not the same as confidence intervals. In the frequentist framework, parameters are fixed by design; a frequentist confidence interval either contains or does not contain the true value of a parameter. In the Bayesian framework, parameters are random variables, and thus we can talk about the probability of a parameter having specific values or being inside <span id="dx1-40008"/>some interval. The unintuitive nature of confident intervals makes them easily misinterpreted and people often talk about frequentist confidence intervals as if they were Bayesian credible intervals.</p>&#13;
</div>&#13;
</div>&#13;
<p><span id="x1-40009r55"/></p>&#13;
</section>&#13;
</section>&#13;
<section id="summary" class="level3 sectionHead" data-number="1.5.10">&#13;
<h2 class="sectionHead" data-number="1.5.10">1.10 <span id="x1-4100010"/>Summary</h2>&#13;
<p>We began our Bayesian journey with a very brief discussion of statistical modeling, probabilities, conditional probabilities, random variables, probability distributions and Bayes’ theorem. We then used the coin-flipping problem as an excuse to introduce basic aspects of Bayesian modeling and data analysis. We used this classic toy example to convey some of the most important ideas of Bayesian statistics, such as using probability distributions to build models and represent uncertainties. We tried to demystify the use of priors and put them on an equal footing with other elements that are part of the modeling process, such as the likelihood, or even more meta-questions, such as why we are trying to solve a particular problem in the first place.</p>&#13;
<p>We ended the chapter by discussing the interpretation and communication of the results of a Bayesian analysis. We assume there is a true distribution that in general is unknown (and in principle also unknowable), from which we get a finite sample, either by doing an experiment, a survey, an observation, or a simulation. To learn something from the true distribution, given that we have only observed a sample, we build a probabilistic model. A probabilistic model has two basic ingredients: a prior and a likelihood. Using the model and the sample, we perform Bayesian inference and obtain a posterior distribution; this distribution encapsulates all the information about a problem, given our model and data. From a Bayesian perspective, the posterior distribution is the main object of interest and everything else is derived from it, including predictions in the form of a posterior predictive distribution. As the posterior distribution (and any other derived quantity from it) is a consequence of the model and data, the usefulness of Bayesian inferences is restricted by the quality of models and data. Finally, we briefly summarized the main aspects of doing Bayesian data analysis. Throughout the rest of this book, we will revisit these ideas to absorb them and use them as the scaffold of more advanced concepts.</p>&#13;
<p>In the next chapter, we will introduce PyMC, which is a Python library for Bayesian modeling and probabilistic machine learning and will use more features from ArviZ, a Python library for the exploratory analysis of Bayesian models, and PreliZ a Python library for prior elicitation. <span id="x1-41001r60"/></p>&#13;
</section>&#13;
<section id="exercises" class="level3 sectionHead" data-number="1.5.11">&#13;
<h2 class="sectionHead" data-number="1.5.11">1.11 <span id="x1-4200011"/>Exercises</h2>&#13;
<p>We do not know whether the brain works in a Bayesian way, in an approximately Bayesian fashion, or maybe some evolutionary (more or less) optimized heuristics. Nevertheless, we know that we learn by exposing ourselves to data, examples, and exercises… Well you may say that humans never learn, given our record as a species on subjects such as wars or economic systems that prioritize profit and not people’s well-being... Anyway, I recommend you do the proposed exercises at the end of each chapter:</p>&#13;
<ol>&#13;
<li><div id="x1-42002x1">&#13;
<p>Suppose you have a jar with 4 jelly beans: 2 are strawberry-flavored, 1 is blueberry-flavored, and 1 is cinnamon-flavored. You draw one jelly bean at random from the jar.</p>&#13;
<ol style="list-style-type:lower-alpha;">&#13;
<li><div id="x1-42004x1">&#13;
<p>What is the sample space for this experiment?</p>&#13;
</div></li>&#13;
<li><div id="x1-42006x2">&#13;
<p>We define event <em>A</em> as <em>the jelly bean drawn is strawberry-flavored</em> and event <em>B</em> as <em>The jelly bean drawn is not cinnamon-flavored</em>. What are the probabilities of events <em>A</em> and <em>B</em>?</p>&#13;
</div></li>&#13;
<li><div id="x1-42008x3">&#13;
<p>Are events <em>A</em> and <em>B</em> mutually exclusive? Why or why not?</p>&#13;
</div></li>&#13;
</ol>&#13;
</div></li>&#13;
<li><div id="x1-42010x2">&#13;
<p>Previously, we defined a Python function <code>P </code>to compute the probability of an event using the naive definition of probability. Generalize that function to compute the probability of events when they are not all equally likely. Use this new function to compute the probability of events <em>A</em> and <em>B</em> from the previous exercise. Hint: you can pass a third argument with the probability of each event.</p>&#13;
</div></li>&#13;
<li><div id="x1-42012x3">&#13;
<p>Use PreliZ to explore different parameters for the BetaBinomial and Gaussian distributions. Use the methods <code>plot_pdf</code>, <code>plot_cdf</code>, and <code>plot_interactive</code>.</p>&#13;
</div></li>&#13;
<li><div id="x1-42014x4">&#13;
<p>We discussed the probability mass/density functions and the cumulative density function. But there are other ways to represent functions like the percentile point function ppf. Using the <code>plot_ppf </code>method of PreliZ, plot the percentile point function for the BetaBinomial and Gaussian distributions. Can you explain how the ppf is related to the cdf and pmf/pdf?</p>&#13;
</div></li>&#13;
<li><div id="x1-42016x5">&#13;
<p>From the following expressions, which one corresponds to: the probability of being sunny given that it is 9<sup>th</sup> of July of 1816?</p>&#13;
<ol style="list-style-type:lower-alpha;">&#13;
<li><div id="x1-42018x1">&#13;
<p><em>p</em>(sunny)</p>&#13;
</div></li>&#13;
<li><div id="x1-42020x2">&#13;
<p><em>p</em>(sunny<span class="cmsy-10x-x-109">|</span>July)</p>&#13;
</div></li>&#13;
<li><div id="x1-42022x3">&#13;
<p><em>p</em>(sunny<span class="cmsy-10x-x-109">|</span>9 of July of 1816)</p>&#13;
</div></li>&#13;
<li><div id="x1-42024x4">&#13;
<p><em>p</em>(9<sup>th</sup> of July of 1816<span class="cmsy-10x-x-109">|</span>sunny)</p>&#13;
</div></li>&#13;
<li><div id="x1-42026x5">&#13;
<p><img src="../media/file57.jpg" class="frac" data-align="middle" alt="p(sunny,9th of July-of 1816) p(9th of July of 1816)"/></p>&#13;
</div></li>&#13;
</ol>&#13;
</div></li>&#13;
<li><div id="x1-42028x6">&#13;
<p>We showed that the probability of choosing a human at random and picking the Pope is not the same as the probability of the Pope being human. In the animated series Futurama, the (Space) Pope is a reptile. How does this change your previous calculations?</p>&#13;
</div></li>&#13;
<li><div id="x1-42030x7">&#13;
<p>Following the example in <em>Figure <a href="#x1-27006r9">1.9</a></em>, use PreliZ to compute the moments for the SkewNormal distribution for a different combination of parameters. Generate random samples of different sizes, like 10, 100, and 1,000, and see if you can recover the values of the first two moments (mean and variance) from the samples. What do you observe?</p>&#13;
</div></li>&#13;
<li><div id="x1-42032x8">&#13;
<p>Repeat the previous exercise for the Student’s T distribution. Try values of <em>ν</em> like 2, 3, 500. What do you observe?</p>&#13;
</div></li>&#13;
<li><div id="x1-42034x9">&#13;
<p>In the following definition of a probabilistic model, identify the prior and the likelihood:</p>&#13;
<div class="math-display">&#13;
<img src="../media/file58.jpg" class="math-display" alt="Y ∼ Normal (μ,σ) μ ∼ Normal (0,2) σ ∼ HalfNormal (0.75 ) "/>&#13;
</div>&#13;
</div></li>&#13;
<li><div id="x1-42036x10">&#13;
<p>In the previous model, how many parameters will the posterior have? Compare it with the model for the coin-flipping problem.</p>&#13;
</div></li>&#13;
<li><div id="x1-42038x11">&#13;
<p>Write Bayes’ theorem for the model in exercise 9.</p>&#13;
</div></li>&#13;
<li><div id="x1-42040x12">&#13;
<p>Let’s suppose that we have two coins; when we toss the first coin, half of the time it lands on tails and half of the time on heads. The other coin is a loaded coin that always lands on heads. If we take one of the coins at random and get a head, what is the probability that this coin is the unfair one?</p>&#13;
</div></li>&#13;
<li><div id="x1-42042x13">&#13;
<p>Try re-plotting <em>Figure <a href="#x1-35014r12">1.12</a></em> using other priors (<code>beta_params</code>) and other data (<code>trials </code>and <code>data</code>).</p>&#13;
</div></li>&#13;
<li><div id="x1-42044x14">&#13;
<p>Read about the Cromwell rule on Wikipedia: <a href="https://en.wikipedia.org/wiki/Cromwell%27s_rule" class="url">https://en.wikipedia.org/wiki/Cromwell%27s_rule</a>.</p>&#13;
</div></li>&#13;
<li><div id="x1-42046x15">&#13;
<p>Read about probabilities and the Dutch book on Wikipedia: <a href="https://en.wikipedia.org/wiki/Dutch_book" class="url">https://en.wikipedia.org/wiki/Dutch_book</a>.</p>&#13;
</div></li>&#13;
</ol>&#13;
</section>&#13;
<section id="join-our-community-discord-space-1" class="level3 likesectionHead" data-number="1.5.12">&#13;
<h2 class="likesectionHead" data-number="1.5.12"><span id="x1-4300011"/>Join our community Discord space</h2>&#13;
<p>Join our Discord community to meet like-minded people and learn alongside more than 5000 members at: <a href="https://packt.link/bayesian">https://packt.link/bayesian</a></p>&#13;
<p><img src="../media/file1.png" alt="PIC"/></p>&#13;
<p><span id="x1-43001r18"/></p>&#13;
</section>&#13;
</section>&#13;
</body></html>