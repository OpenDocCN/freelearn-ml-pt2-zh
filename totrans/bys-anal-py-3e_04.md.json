["```py\nwith pm.Model() as model_l: \n    *α* = pm.Normal(\"*α*\", mu=0, sigma=1) \n    *β* = pm.Normal(\"*β*\", mu=0, sigma=10) \n    σ = pm.HalfNormal(\"σ\", 5) \n\n    μ = *α* + *β* * x_c[0] \n\n    y_pred = pm.Normal(\"y_pred\", mu=μ, sigma=σ, observed=y_c) \n\n    idata_l = pm.sample(2000, idata_kwargs={\"log_likelihood\": True}) \n    idata_l.extend(pm.sample_posterior_predictive(idata_l)) \n\nwith pm.Model() as model_q: \n    *α* = pm.Normal(\"*α*\", mu=0, sigma=1) \n    *β* = pm.Normal(\"*β*\", mu=0, sigma=10, shape=order) \n    σ = pm.HalfNormal(\"σ\", 5) \n\n    μ = *α* + pm.math.dot(*β*, x_c) \n\n    y_pred = pm.Normal(\"y_pred\", mu=μ, sigma=σ, observed=y_c) \n\n    idata_q = pm.sample(2000, idata_kwargs={\"log_likelihood\": True}) \n    idata_q.extend(pm.sample_posterior_predictive(idata_q))\n```", "```py\nidatas = [idata_l, idata_q] \n\ndef iqr(x, a=-1): \n    \"\"\"interquartile range\"\"\" \n    return np.subtract(*np.percentile(x, [75, 25], axis=a)) \n\nfor idata in idatas: \n    az.plot_bpv(idata, kind=\"t_stat\", t_stat=\"mean\", ax=axes[0]) \n\nfor idata in idatas: \n    az.plot_bpv(idata, kind=\"t_stat\", t_stat=iqr, ax=axes[1])\n```", "```py\naz.loo(idata_l)\n```", "```py\n Computed from 8000 posterior samples and 33 observations log-likelihood matrix.\n\n         Estimate       SE elpd_loo   -14.31     2.67\np_loo        2.40        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct. (-Inf, 0.5]   (good)       33  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n```", "```py\ncmp_df = az.compare({\"model_l\": idata_l, \"model_q\": idata_q})\n```", "```py\nidata_w = az.weight_predictions(idatas, weights=[0.35, 0.65])\n```", "```py\nfrom scipy.special import betaln \n\ndef beta_binom(prior, y): \n    \"\"\" \n    Calculate the marginal probability, analytically, for a BetaBinomial model. \n    prior : tuple \n      alpha and beta parameters for the beta prior \n    y : array \n      array with \"1\" and \"0\" corresponding to success and failure respectively \n    \"\"\" \n    alpha, beta = prior \n    h = np.sum(y) \n    n = len(y) \n    p_y = np.exp(betaln(alpha + h, beta + n - h) - betaln(alpha, beta)) \n\n    return p_y\n```", "```py\ny = np.repeat([1, 0], [50, 50])  # 50 heads, 50 tails \npriors = ((1, 1), (30, 30))  # uniform prior, peaked prior\n```", "```py\nBF = beta_binom(priors[1], y) / beta_binom(priors[0], y) \nprint(round(BF))\n```", "```py\n 5\n```", "```py\nmodels = [] \nidatas = [] \nfor alpha, beta in priors: \n    with pm.Model() as model: \n        a = pm.Beta(\"a\", alpha, beta) \n        yl = pm.Bernoulli(\"yl\", a, observed=y) \n        idata = pm.sample_smc(random_seed=42) \n        models.append(model) \n        idatas.append(idata) \n\nBF_smc = np.exp( \n    idatas[1].sample_stats[\"log_marginal_likelihood\"].mean() \n    - idatas[0].sample_stats[\"log_marginal_likelihood\"].mean() \n) \nprint(np.round(BF_smc).item())\n```", "```py\n 5.0\n```", "```py\nwith pm.Model() as model_uni: \n    a = pm.Beta(\"a\", 1, 1) \n    yl = pm.Bernoulli(\"yl\", a, observed=y) \n    idata_uni = pm.sample(2000, random_seed=42) \n    idata_uni.extend(pm.sample_prior_predictive(8000)) \n\naz.plot_bf(idata_uni, var_name=\"a\", ref_val=0.5)\n```", "```py\nwith pm.Model() as model_conc: \n    a = pm.Beta(\"a\", 30, 30) \n    yl = pm.Bernoulli(\"yl\", a, observed=y) \n    idata_conc = pm.sample(2000, random_seed=42) \n    idata_conc.extend(pm.sample_prior_predictive(8000)) \n\naz.plot_bf(idata_conc, var_name=\"a\", ref_val=0.5)\n```"]