["```py\n#Inherit from the classes BaseEstimator, ClassifierMixin\nclass RidgeClassifier(BaseEstimator, ClassifierMixin):\n\n def __init__(self,param1,param2):\n self.param1 = param1\n self.param2 = param2\n\n def fit(self, X, y = None):\n #do as much work as possible in this method\n return self\n\n def predict(self, X_test):\n #do some work here and return the predictions, y_pred\n return y_pred \n```", "```py\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.datasets import load_breast_cancer\n\nbc = load_breast_cancer() \n\nnew_feature_names = ['_'.join(ele.split()) for ele in bc.feature_names]\n\nX = pd.DataFrame(bc.data,columns = new_feature_names)\ny = bc.target\n```", "```py\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=7, stratify = y)\n```", "```py\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.linear_model import Ridge\n\nclass RidgeClassifier(BaseEstimator, ClassifierMixin):\n\n \"\"\"A Classifier made from Ridge Regression\"\"\"\n\n def __init__(self,alpha=0):\n self.alpha = alpha\n\n def fit(self, X, y = None):\n #pass along the alpha parameter to the internal ridge estimator and perform a fit using it\n self.ridge_regressor = Ridge(alpha = self.alpha) \n self.ridge_regressor.fit(X, y)\n\n #save the seen class labels\n self.class_labels = np.unique(y)\n\n return self\n\n def predict(self, X_test):\n #store the results of the internal ridge regressor estimator\n results = self.ridge_regressor.predict(X_test)\n\n #find the nearest class label\n return np.array([self.class_labels[np.abs(self.class_labels - x).argmin()] for x in results])\n```", "```py\nr_classifier = RidgeClassifier(1.5) \nr_classifier.fit(X_train, y_train)\nr_classifier.score(X_test, y_test)\n\n0.95744680851063835\n```", "```py\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {'alpha': [0,0.5,1.0,1.5,2.0]}\ngs_rc = GridSearchCV(RidgeClassifier(), param_grid, cv = 3).fit(X_train, y_train)\n\ngs_rc.grid_scores_\n\n[mean: 0.94751, std: 0.00399, params: {'alpha': 0},\n mean: 0.95801, std: 0.01010, params: {'alpha': 0.5},\n mean: 0.96063, std: 0.01140, params: {'alpha': 1.0},\n mean: 0.96063, std: 0.01140, params: {'alpha': 1.5},\n mean: 0.96063, std: 0.01140, params: {'alpha': 2.0}]\n```", "```py\nr_classifier.score(X_test, y_test)\n```", "```py\nfrom sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nlr.fit(X_train,y_train)\nlr.score(X_test,y_test)\n\n0.9521276595744681\n```", "```py\n'y ~ mean_radius + mean_texture + mean_perimeter + mean_area + mean_smoothness + mean_compactness + mean_concavity + mean_concave_points + mean_symmetry + mean_fractal_dimension + radius_error + texture_error + perimeter_error + area_error + smoothness_error + compactness_error + concavity_error + concave_points_error + symmetry_error + fractal_dimension_error + worst_radius + worst_texture + worst_perimeter + worst_area + worst_smoothness + worst_compactness + worst_concavity + worst_concave_points + worst_symmetry + worst_fractal_dimension'\n```", "```py\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nfrom sklearn.base import BaseEstimator, ClassifierMixin\n\nfrom sklearn.linear_model import Ridge\n\nclass GEEClassifier(BaseEstimator, ClassifierMixin):\n\n \"\"\"A Classifier made from statsmodels' Generalized Estimating Equations documentation available at: http://www.statsmodels.org/dev/gee.html\n    \"\"\"\n\n def __init__(self,group_by_feature):\n self.group_by_feature = group_by_feature\n\n def fit(self, X, y = None):\n #Same settings as the documentation's example: \n self.fam = sm.families.Poisson()\n self.ind = sm.cov_struct.Exchangeable()\n\n #Auxiliary function: only used in this method within the class\n def expand_X(X, y, desired_group): \n X_plus = X.copy()\n X_plus['y'] = y\n\n #roughly make ten groups\n X_plus[desired_group + '_group'] = (X_plus[desired_group] * 10)//10\n\n return X_plus\n\n #save the seen class labels\n self.class_labels = np.unique(y)\n\n dataframe_feature_names = X.columns\n not_group_by_features = [x for x in dataframe_feature_names if x != self.group_by_feature]\n\n formula_in = 'y ~ ' + ' + '.join(not_group_by_features)\n\n data = expand_X(X,y,self.group_by_feature)\n self.mod = smf.gee(formula_in, \n self.group_by_feature + \"_group\", \n data, \n cov_struct=self.ind, \n family=self.fam)\n\n self.res = self.mod.fit()\n\n return self\n\n def predict(self, X_test):\n #store the results of the internal GEE regressor estimator\n results = self.res.predict(X_test)\n\n #find the nearest class label\n return np.array([self.class_labels[np.abs(self.class_labels - x).argmin()] for x in results])\n\n def print_fit_summary(self):\n print res.summary()\n return self\n```", "```py\ngee_classifier = GEEClassifier('mean_concavity') \ngee_classifier.fit(X_train, y_train)\ngee_classifier.score(X_test, y_test)\n\n0.94680851063829785\n```", "```py\nimport pandas as pd\n\ndata_web_address = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n\ncolumn_names = ['pregnancy_x', \n 'plasma_con', \n 'blood_pressure', \n 'skin_mm', \n 'insulin', \n 'bmi', \n 'pedigree_func', \n 'age', \n 'target']\n\nfeature_names = column_names[:-1]\nall_data = pd.read_csv(data_web_address , names=column_names)\n\nimport numpy as np\nimport pandas as pd\n\nX = all_data[feature_names]\ny = all_data['target']\n```", "```py\nfrom sklearn.model_selection import train_test_split\n X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7,stratify=y)\n```", "```py\ngee_classifier = GEEClassifier('blood_pressure') \ngee_classifier.fit(X_train, y_train)\ngee_classifier.score(X_test, y_test)\n\n0.80519480519480524\n```", "```py\nr_classifier = RidgeClassifier() \nr_classifier.fit(X_train, y_train)\nr_classifier.score(X_test, y_test)\n\n0.76623376623376627\n```", "```py\nimport pickle\n\nf = open('rc_inst.save','wb')\npickle.dump(r_classifier, f, protocol = pickle.HIGHEST_PROTOCOL)\nf.close()\n```", "```py\nimport pickle\n\nf = open('rc_inst.save','rb')\nr_classifier = pickle.load(f)\nf.close()\n```"]