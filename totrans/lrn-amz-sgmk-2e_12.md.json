["```py\nbt.set_hyperparameters(mode='supervised', vector_dim=300, word_ngrams=3, epochs=50)\n```", "```py\n2021-06-14 08:45:30 Starting - Launching requested ML instancesProfilerReport-1623660327: InProgress\n```", "```py\n    from sagemaker.debugger import FrameworkProfile, DetailedProfilingConfig, DataloaderProfilingConfig, PythonProfilingConfig, PythonProfiler\n    framework_profile_params = FrameworkProfile(\n     detailed_profiling_config=DetailedProfilingConfig(), \n     dataloader_profiling_config=DataloaderProfilingConfig(),\n     python_profiling_config=PythonProfilingConfig(\n       python_profiler=PythonProfiler.PYINSTRUMENT)\n    )\n    ```", "```py\n    from sagemaker.debugger import ProfilerConfig \n    profiler_config = ProfilerConfig(\n        system_monitor_interval_millis=100,\n        framework_profile_params=framework_profile_params)\n    ```", "```py\n    tf_estimator = TensorFlow(\n        entry_point='fmnist.py',\n        . . .                        \n        profiler_config=profiler_config)\n    ```", "```py\n/opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.1457.0/AL2012/generic-flavor/src/src/storage/./pooled_storage_manager.h:151: cudaMalloc failed: out of memory\n```", "```py\n    %%sh\n    wget http://files.grouplens.org/datasets/movielens/ml-25m.zip\n    unzip ml-25m.zip\n    ```", "```py\n    num_users=162541\n    num_movies=62423\n    num_ratings=25000095\n    max_movieid=209171\n    num_features=num_users+max_movieid\n    ```", "```py\n    From sagemaker import TrainingInput\n    s3_train_data = TrainingInput (\n        train_data,                                \n        content_type='application/x-recordio-protobuf',\n        input_mode='Pipe')\n    s3_test_data = TrainingInput (\n       test_data,                                        \n       content_type='application/x-recordio-protobuf',                                           \n       input_mode='Pipe')\n    ```", "```py\n2021-06-14 15:02:08 Downloading - Downloading input data\n2021-06-14 15:02:08 Training - Downloading the training image...\n```", "```py\n    $ git clone https://github.com/tensorflow/models.git\n    $ export IMAGENET_USERNAME=YOUR_USERNAME\n    $ export IMAGENET_ACCESS_KEY=YOUR_ACCESS_KEY\n    $ cd models/research/inception/inception/data\n    $ mv imagenet_2012_validation_synset_labels.txt synsets.txt\n    $ nohup bash download_imagenet.sh . synsets.txt >& download.log &\n    ```", "```py\n    $ wget https://raw.githubusercontent.com/juliensimon/aws/master/mxnet/imagenet/build_validation_tree.sh\n    $ chmod 755 build_validation_tree.sh\n    $ cd imagenet/validation\n    $ ../../build_validation_tree.sh\n    $ cd ../..\n    ```", "```py\n    $ sudo yum -y install python-devel python-pip opencv opencv-devel opencv-python\n    $ pip3 install mxnet opencv-python –user\n    $ wget https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/im2rec.py\n    ```", "```py\n    $ cd imagenet\n    $ python3 ../im2rec.py --list --chunks 6 --recursive val validation\n    $ python3 ../im2rec.py --num-thread 16 --resize 224 val_ validation\n    $ python3 ../im2rec.py --list --chunks 140 --recursive train train\n    $ python3 ../im2rec.py --num-thread 16 --resize 224 train_ train\n    ```", "```py\n    $ mkdir -p input/train input/validation\n    $ mv train_*.rec input/train\n    $ mv val_*.rec input/validation\n    $ aws s3 sync input s3://sagemaker-us-east-1-123456789012/imagenet-split/input/\n    ```", "```py\n    prefix = 'imagenet-split'\n    s3_train_path = \n    's3://{}/{}/input/training/'.format(bucket, prefix)\n    s3_val_path = \n    's3://{}/{}/input/validation/'.format(bucket, prefix)\n    s3_output = \n    's3://{}/{}/output/'.format(bucket, prefix)\n    from sagemaker import TrainingInput\n    from sagemaker.session import ShuffleConfig\n    train_data = TrainingInput(\n       s3_train_path\n       shuffle_config=ShuffleConfig(59),\n       content_type='application/x-recordio',\n       input_mode='Pipe')\n    validation_data = TrainingInput(\n       s3_val_path,\n       content_type='application/x-recordio', \n       input_mode='Pipe')\n    s3_channels = {'train': train_data, \n                   'validation': validation_data}\n    ```", "```py\n    from sagemaker import image_uris\n    region_name = boto3.Session().region_name\n    container = image_uris.retrieve(\n        'image-classification', region)\n    ic = sagemaker.estimator.Estimator(\n         container,\n         role= sagemaker.get_execution_role(),\n         instance_count=1,                                 \n         instance_type='ml.p3dn.24xlarge',\n         output_path=s3_output)\n    ```", "```py\n    ic.set_hyperparameters(\n        num_layers=50,                 \n        use_pretrained_model=0,        \n        num_classes=1000,              \n        num_training_samples=1281167,\n        mini_batch_size=1024,\n        epochs=2,\n        kv_store='dist_sync',\n        top_k=3)         \n    ```", "```py\nic.set_hyperparameters(\n    num_layers=50,                 \n    use_pretrained_model=0,        \n    num_classes=1000,              \n    num_training_samples=1281167,\n    mini_batch_size=2736,         # <--------\n    epochs=2,\n    kv_store='dist_sync',\n    top_k=3)         \n```", "```py\nic = sagemaker.estimator.Estimator(\n    container,\n    role,\n    instance_count=2,                 # <--------\n    instance_type='ml.p3dn.24xlarge',\n    output_path=s3_output)\n```", "```py\nic = sagemaker.estimator.Estimator(\n    container,\n    role,\n    instance_count=4,                 # <--------\n    instance_type='ml.p3dn.24xlarge',\n    output_path=s3_output)\n```", "```py\nic = sagemaker.estimator.Estimator(\n    container,\n    role,\n    instance_count=8,                 # <--------\n    instance_type='ml.p3dn.24xlarge',\n    output_path=s3_output)\n```", "```py\n    import smdistributed.dataparallel.tensorflow as sdp\n    sdp.init()\n    ```", "```py\n    gpus = tf.config.experimental.\n                list_physical_devices('GPU')\n    if gpus:\n        tf.config.experimental.set_visible_devices(\n            gpus[sdp.local_rank()], 'GPU')\n    for gpu in gpus:\n        tf.config.experimental.set_memory_growth(\n            gpu, True)\n    ```", "```py\n    batch_size = args.batch_size*sdp.size()\n    lr         = args.learning_rate*sdp.size()\n    ```", "```py\n    loss = tf.losses.CategoricalCrossentropy()\n    opt = tf.optimizers.Adam(lr)\n    sdp.broadcast_variables(model.variables, root_rank=0)\n    sdp.broadcast_variables(opt.variables(), root_rank=0)\n    ```", "```py\n    @tf.function\n    def training_step(images, labels):\n        with tf.GradientTape() as tape:\n            probs = model(images, training=True)\n            loss_value = loss(labels, probs)\n        tape = sdp.DistributedGradientTape(tape)\n        grads = tape.gradient(\n            loss_value, model.trainable_variables)\n        opt.apply_gradients(\n            zip(grads, model.trainable_variables))\n        loss_value = sdp.oob_allreduce(loss_value)\n        return loss_value\n    ```", "```py\n    steps = len(train)//batch_size\n    for e in range(epochs):\n        if sdp.rank() == 0:\n            print(\"Start epoch %d\" % (e))\n        for batch, (images, labels) in \n        enumerate(train.take(steps)):\n            loss_value = training_step(images, labels)\n            if batch%10 == 0 and sdp.rank() == 0:\n                print(\"Step #%d\\tLoss: %.6f\" \n                      % (batch, loss_value))\n    ```", "```py\n    if sdp.rank() == 0:\n        model.save(os.path.join(model_dir, '1'))\n    ```", "```py\n    from sagemaker.tensorflow import TensorFlow\n    tf_estimator = TensorFlow(\n        . . .\n        instance_count=2, \n        instance_type='ml.p3.16xlarge',\n        hyperparameters={'epochs': 10, \n            'learning-rate': 0.0001, 'batch-size': 32},\n        distribution={'smdistributed': \n            {'dataparallel': {'enabled': True}}}\n    )\n    ```", "```py\n    [1,0]<stdout>:Step #0#011Loss: 2.306620\n    [1,0]<stdout>:Step #10#011Loss: 1.185689\n    [1,0]<stdout>:Step #20#011Loss: 0.909270\n    [1,0]<stdout>:Step #30#011Loss: 0.839223\n    [1,0]<stdout>:Step #40#011Loss: 0.772756\n    [1,0]<stdout>:Step #50#011Loss: 0.678521\n    . . .\n    ```", "```py\nhuggingface_estimator = HuggingFace(\n   . . . \n   distribution={'smdistributed': \n                    {'dataparallel':{'enabled': True}}\n                }\n)\n```", "```py\n    mpi_options = {\n       'enabled' : True,\n       'processes_per_host' : 8\n    }\n    ```", "```py\n    smp_options = {\n        'enabled': True,\n        'parameters\": {\n            'microbatches': 2,\n            'partitions': 4\n        }\n    }\n    ```", "```py\n    huggingface_estimator = HuggingFace(\n        . . .\n        instance_type='ml.p3dn.24xlarge',\n        instance_count=1,\n        distribution={'smdistributed': \n            {'modelparallel': smp_options},\n             'mpi': mpi_options}\n    )\n    ```", "```py\n    [ec2-user]$ mount|grep efs\n    127.0.0.1:/ on /mnt/efs/fs1 type nfs4\n    ```", "```py\n    [ec2-user] cd /mnt/efs/fs1\n    [ec2-user] sudo aws s3 sync s3://sagemaker-ap-northeast-2-123456789012/pascalvoc/input input\n    ```", "```py\n    from sagemaker.inputs import FileSystemInput\n    efs_train_data = FileSystemInput(\n                     file_system_id='fs-fe36ef34',\n                     file_system_type='EFS',\n                     directory_path='/input/train')\n    efs_validation_data = FileSystemInput(\n                          file_system_id='fs-fe36ef34',\n                          file_system_type='EFS',\n                          directory_path='/input/validation')\n    data_channels = {'train': efs_train_data, \n                     'validation': efs_validation_data}\n    ```", "```py\n    from sagemaker import image_uris\n    container = image_uris.retrieve('object-detection', \n                                    region)\n    od = sagemaker.estimator.Estimator(\n         container,\n         role=sagemaker.get_execution_role(),\n         instance_count=1,                                         \n         instance_type='ml.p3.2xlarge',                                         \n         output_path=s3_output_location,\n         subnets=['subnet-63715206','subnet-cbf5bdbc',\n                  'subnet-59395b00'],                                        \n         security_group_ids=['sg-0aa0a1c297a49e911']\n    )\n    ```", "```py\n    from sagemaker.inputs import FileSystemInput\n    fsx_train_data = FileSystemInput(\n      file_system_id='fs-07914cf5a60649dc8',\n      file_system_type='FSxLustre',                            \n      directory_path='/bmgbtbmv/pascalvoc/input/train')\n    fsx_validation_data = FileSystemInput(\n      file_system_id='fs-07914cf5a60649dc8',\n      file_system_type='FSxLustre',                            \n      directory_path='/bmgbtbmv/pascalvoc/input/validation')\n    data_channels = {'train': fsx_train_data, \n                     'validation': fsx_validation_data }\n    ```"]