<html><head></head><body>
  <div id="_idContainer431">
    <h1 class="chapterNumber">12</h1>
    <h1 id="_idParaDest-174" class="chapterTitle">Multivariate Forecasting</h1>
    <p class="normal">As you'll have picked up by now if you've been paying attention to this book, the field of time-series has made lots of advances within the last decade. Many extensions and new techniques have popped up for applying machine learning to time-series. In each chapter, we've covered lots of different issues around forecasting, anomaly and drift detection, regression and classification, and approaches including traditional approaches, machine learning with gradient boosting and others, reinforcement learning, online learning, deep learning, and probabilistic models.</p>
    <p class="normal">In this chapter, we'll put some of this into practice in more depth. We've covered mostly univariate time-series so far, but in this chapter, we'll go through an application of forecasting to energy demand. With ongoing energy or supply crises in different parts of the world, this is a very timely subject. We'll work with a multivariate time-series, and we'll do a multi-step forecast using different approaches.</p>
    <p class="normal">We're going to cover the following topics:</p>
    <ul>
      <li class="bullet">Forecasting a Multivariate Time-Series</li>
      <li class="bullet">What's next for time-series?</li>
    </ul>
    <p class="normal">The second section is going to cover an outlook into the future of time-series applications and research. But let's start with a discussion of multivariate series. Then we'll apply a few models to energy demand forecasting.</p>
    <h1 id="_idParaDest-175" class="title">Forecasting a Multivariate Time-Series</h1>
    <p class="normal">Time-series forecasting is an active research topic in academia. Forecasting long-term trends is not only a fun challenge, but has important implications for strategic planning and operations research in real-world applications such as IT operations management, manufacturing, and cyber security.</p>
    <p class="normal">A multivariate time-series<a id="_idIndexMarker892"/> has more than one dependent variable. This means that each dependent variable not only depends on its own past values, but also potentially on the past values of other variables. This introduces complexity such as colinearity, where the dependent variables are not independent, but rather correlated. Colinearity violates the assumptions of many linear models, and it is therefore even more appealing to resort to models that can capture feature interactions.</p>
    <p class="normal">This figure shows an example of a multivariate time-series, COVID deaths in different countries (from the English Wikipedia article about the COVID-19 pandemic):</p>
    <figure class="mediaobject"><img src="../Images/B17577_12_01.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.1: COVID-19 deaths per 100,000 population as an example of a multivariate time-series.</p>
    <p class="normal">COVID fatalities are correlated<a id="_idIndexMarker893"/> between different countries, although they might be shifted, or they might fall into different groups.</p>
    <p class="normal">We've mentioned the Makridakis Competitions, in <em class="chapterRef">Chapter 5</em>, <em class="italic">Introduction to Machine Learning for Time-Series</em>. Spyros Makridakis, the chief organizer, is a professor at the University of Nicosia, and specializes in time-series forecasting. These competitions serve as a benchmark of the best algorithms and researchers and practitioners compete against each other for cash prices. The hope for this competition is that it can inspire and act as catalyst for machine learning, and open up directions for future work.</p>
    <p class="normal">The M4 competition used 100,000 multivariate time-series (from the ForeDeCk database) covering different application domains and temporal scales, and results were published in 2020. 49 contestants or teams submitted point forecasts testing the accuracy of major ML and statistical methods.</p>
    <p class="normal">The M4 organizers, Spyros Makridakis, Evangelos Spiliotis, and Vassilios Assimakopoulos, observed ("<em class="italic">The M4 Competition: 100,000 time-series and 61 forecasting methods"</em>, 2020) that combinations (hybrids or ensembles) of mostly well-established statistical methods tended to be more accurate than either pure statistical or pure ML methods, which performed rather poorly, mostly placed in the second half of the field. Although there's increasing adoption of machine learning methods in solving forecasting challenges, statistical methods remain powerful, especially while dealing with low-granularity data. It should be noted, however, that the datasets didn't include exogenous variables or time-stamps. Deep learning and other machine learning methods could perhaps make better use of higher dimensionality, especially in the presence of collinearity, so this additional information would perhaps have boosted the performance of these models.</p>
    <p class="normal">However, Slawek Smyl from Uber Technologies came in first place, taking home €9000 with a hybrid between a recurrent neural network and a statistical time-series model (Holt-Winters exponential smoothing). These two components were fit concurrently using gradient descent. A seasoned time-series practitioner, Smyl had previously won the <em class="italic">Computational Intelligence in Forecasting International Time-Series Competition 2016</em> using recurrent neural networks. It can be argued that this result shows that pragmatism with machine learning (and deep learning as an extension) can pay off.</p>
    <p class="normal">Economists<a id="_idIndexMarker894"/> have long been working with mixtures in forecasting such as Gaussian mixture models or mixtures of GARCH models. The <code class="Code-In-Text--PACKT-">Skaters</code> library comes with various functionality for ensembles and also does ensembles of ARMA and similar models. You can find an overview of different ensemble models<a id="_idIndexMarker895"/> on the microprediction time-series leaderboard: <a href="https://microprediction.github.io/timeseries-elo-ratings/html_leaderboards/overall.html"><span class="url">https://microprediction.github.io/timeseries-elo-ratings/html_leaderboards/overall.html</span></a></p>
    <p class="normal">More on the machine learning side, a common method for ensembles, particularly in bagging, is training several models and weighting their predictions by their performance. Bagging uses sampling<a id="_idIndexMarker896"/> with replacement to create training samples to fit the base models. The out-of-bag (OOB) error is the mean prediction error of a model on training samples that weren't part of the training set.</p>
    <p class="normal">Ensembles can also be composed of base models of different types, called heterogeneous ensembles. Scikit-learn provides stacking for regression and classification, where a final model<a id="_idIndexMarker897"/> can find coefficients, weighted to the base model predictions, to combine base model predictions.</p>
    <p class="normal">There are still many pain points in industry workflows for time-series analytics. Chief among them is that there aren't many software libraries that support multivariate forecasting. </p>
    <p class="normal">As of September 2021, although it's on the roadmap, multivariate forecasting is not part of the Kats library (even though there's support for multivariate classification). There are <code class="Code-In-Text--PACKT-">VAR</code> and <code class="Code-In-Text--PACKT-">VARMAX</code> models in the <code class="Code-In-Text--PACKT-">statsmodels</code> library; however, there's no support for deseasonalizing multivariate time-series.</p>
    <p class="normal">Salesforce's Merlion library claims to support multivariate forecasts, but it doesn't seem to be part of the current functionality. The <code class="Code-In-Text--PACKT-">Darts</code> library provides several models that would work for multivariate forecasts.</p>
    <p class="normal">Neural networks and ensembles such as Random Forest or boosted decision trees support being trained on multivariate time-series. In <em class="chapterRef">Chapter 7</em>, <em class="italic">Machine Learning Models for Time-Series</em>, we worked with XGBoost to create an ensemble model for time-series forecasting. In the GitHub repository accompanying this book, I've attached a notebook that shows how scikit-learn pipelines and multioutput regressors can be applied to multivariate forecasts. In this chapter, however, we'll focus on deep learning models.</p>
    <p class="normal">Alejandro Pasos Ruiz and colleagues at the University of East Anglia (Norwich, Norfolk, United Kingdom) highlight how multivariate applications have been neglected in their paper "<em class="italic">The great multivariate time-series classification bake off: a review and experimental evaluation of recent algorithmic advances</em>" (2020). There was a large focus on modeling univariate datasets, as is evident not only in the availability of software solutions, but also in datasets, previous competitions, and research.</p>
    <p class="normal">They ran a benchmark<a id="_idIndexMarker898"/> of time-series classification on 30 multivariate time-series from the UEA dataset. They found that three classifiers are significantly more accurate than the dynamic time warping algorithm: HIVE-COTE, CIF, and ROCKET (please refer to <em class="chapterRef">Chapter 4</em>, <em class="italic">Introduction to Machine Learning for Time-Series</em>, for details around these methods); however, the deep learning approach ResNet wasn't very far from these front-runners.</p>
    <p class="normal">In the paper "<em class="italic">Deep learning for time-series classification: a review</em>" by <em class="italic">Hassan Ismail Fawaz</em> and others (2019), one of the findings from a benchmark test was that some deep neural networks can be competitive with other methods. They later followed this up by showing that neural network ensembles are on-par with HIVE-COTE on the same data ("<em class="italic">Deep Neural Network Ensembles for Time-Series Classification</em>," 2019).</p>
    <p class="normal"><em class="italic">Pedro Lara-Benítez</em> and others (2021) did another comparison in their paper "<em class="italic">An Experimental Review on Deep Learning Architectures for Time-Series Forecasting</em>." They ran an Echo State Network (ESN), a Convolutional Neural Network (CNN), a Temporal Convolutional Network (TCN), a fully connected<a id="_idIndexMarker899"/> feedforward network (MLP), and<a id="_idIndexMarker900"/> several recurrent architectures such<a id="_idIndexMarker901"/> as Elman Recurrent Networks, Gated Recurrent Unit (GRU) networks, and Long Short-Term Memory (LSTM) networks. </p>
    <p class="normal">Statistically, based on average<a id="_idIndexMarker902"/> ranks, CNN, MLP, LSTM, TCN, GRU, and ESN were<a id="_idIndexMarker903"/> indistinguishable.</p>
    <p class="normal">On the whole, deep learning models are very promising, and because of their flexibility they can fill the existing gap for multivariate forecasting. I hope to demonstrate in this chapter how useful they can be. </p>
    <p class="normal">We'll be applying the following models in this chapter:</p>
    <ul>
      <li class="bullet">N-BEATS</li>
      <li class="bullet">Amazon's DeepAR</li>
      <li class="bullet">Recurrent neural network (LSTM)</li>
      <li class="bullet">Transformer</li>
      <li class="bullet">Temporal convolutional network (TCN)</li>
      <li class="bullet">Gaussian process</li>
    </ul>
    <p class="normal">We went through the details for most of these methods in <em class="chapterRef">Chapter 10</em>, <em class="italic">Deep Learning for Time-Series</em>, but I'll briefly cover the main features for each in turn.</p>
    <p class="normal"><strong class="keyword">Neural Basis Expansion Analysis for interpretable Time-Series forecasting</strong> (<strong class="keyword">N-BEATS</strong>), presented at the ICLR conference 2020, achieved a 3% improvement over the winner of the M4 competition. The authors demonstrated that a pure deep learning approach, without any time-serie<a id="_idIndexMarker904"/>s-specific components, outperforms statistical<a id="_idIndexMarker905"/> approaches to challenging datasets such as the M3 and M4 competition datasets and the TOURISM dataset. A further advantage of this approach is that it is interpretable (although we won't be focusing on this aspect in the current chapter).</p>
    <p class="normal"><strong class="keyword">DeepAR</strong> is a probabilistic auto-regressive recurrent network model coming out of Amazon Research Germany. They compared the accuracy of the quantile predictions for three different datasets and only compared the forecasting accuracy against a factorization technique (MatFact) and on two datasets (traffic and electricity).</p>
    <p class="normal"><strong class="keyword">Long Short-Term Models</strong> (<strong class="keyword">LSTM</strong>) networks are used for sequence modeling. A great selling point of recurrent neural networks such as LSTMs is that they can learn long-term sequences of data points.</p>
    <p class="normal"><strong class="keyword">Transformers</strong> are attention-based neural networks, originally presented in the 2017 paper "<em class="italic">Attention Is All You Need</em>." Their key features are linear complexity with the number of features and long-term memory, giving us access to any point in the sequence directly. An advantage of transformers over recurrent neural networks is that they are executed in parallel rather than in sequence and therefore run faster in both training and prediction. </p>
    <p class="normal">Transformers were designed to solve sequences problems in <strong class="keyword">Natural Language Processing</strong> (<strong class="keyword">NLP</strong>) tasks; however, they can equally be applied to time-series problems, including forecasting, although such applications don't make use of features more specific to sentences, such as positional encoding.</p>
    <p class="normal">A <strong class="keyword">Temporal Convolutional Network</strong> (<strong class="keyword">TCN</strong>) consists of dilated, causal, 1D convolutional layers with the same input and output lengths. We are using an implementation that includes residual blocks as proposed by Shaojie Bai and others (2018).</p>
    <p class="normal">The last of these methods, <strong class="keyword">Gaussian processes</strong> can't be convincingly categorized as deep learning models; however, they are equivalent to a single-layer fully-connected neural network with an independent and identically distributed prior over its parameters. They can be seen as an infinite-dimensional generalization of multivariate normal distributions.</p>
    <p class="normal">An interesting, additional aspect – although, again, we won't pursue this here – is that many of these methods allow using additional explanatory (exogenous) variables.</p>
    <p class="normal">We'll be using a 10-dimensional time-series of energy demand in different states. The dataset comes from the 2017 Global Energy Forecasting Competition (GEFCom2017).</p>
    <p class="normal">Each variable records the energy<a id="_idIndexMarker906"/> usage in a particular region. This emphasizes the problems with long-term memory – to highlight this, we'll be doing a multi-step forecast.</p>
    <p class="normal">You can find the <code class="Code-In-Text--PACKT-">tensorflow/keras</code> implementations of the models together with utility functions for the data on GitHub in a repository I created for demonstration purposes featuring time-series models <a id="_idIndexMarker907"/>for multivariate and multi-step forecasting, regression, and classification: <a href="https://github.com/benman1/time-series"><span class="url">https://github.com/benman1/time-series</span></a>.</p>
    <p class="normal">Let's jump right into it.</p>
    <h2 id="_idParaDest-176" class="title">Python practice</h2>
    <p class="normal">We'll load the dataset of the energy demand, and we'll apply several forecasting methods. We are using a big dataset and some of these models are quite complex, so training can take a long time. I would advise you to use Google Colab and switch on GPU support, or to reduce the number of iterations or the size of the dataset. I'll mention performance tweaks later when they become relevant.</p>
    <p class="normal">Let's start by installing the library from the GitHub repository mentioned above:</p>
    <pre class="programlisting con"><code class="hljs-con">!pip install git+https://github.com/benman1/time-series
</code></pre>
    <p class="normal">This shouldn't take long. Since the requirements include <code class="Code-In-Text--PACKT-">tensorflow</code> and <code class="Code-In-Text--PACKT-">numpy</code>, I'd recommend installing them into a virtual environment.</p>
    <p class="normal">Then, we'll load the dataset using a utility method in the library and wrap it in a <code class="Code-In-Text--PACKT-">TrainingDataSet</code> class:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> time_series.dataset.utils <span class="hljs-keyword">import</span> get_energy_demand
<span class="hljs-keyword">from</span> time_series.dataset.time_series <span class="hljs-keyword">import</span> TrainingDataSet
train_df = get_energy_demand()
tds = TrainingDataSet(train_df)
</code></pre>
    <p class="normal">If you wanted to speed up the training, you could reduce the number of training samples. For instance, instead of the previous line, you could say: <code class="Code-In-Text--PACKT-">tds = TrainingDataSet(train_df.head(500))</code>.</p>
    <p class="normal">We'll do this for the <code class="Code-In-Text--PACKT-">GaussianProcess</code> later, which can't handle the full dataset.</p>
    <p class="normal">For most of these models, we'll use TensorFlow graph models, which depend on non-eager execution. We'll have to disable eager execution explicitly. Also, for one of the models, we need to set up output of intermediates to avoid a TensorFlow problem: <code class="Code-In-Text--PACKT-">Connecting to invalid output X of source node Y which has Z outputs</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> tensorflow.python.framework.ops <span class="hljs-keyword">import</span> disable_eager_execution
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
disable_eager_execution()  <span class="hljs-comment"># for graph mode</span>
tf.compat.v1.experimental.output_all_intermediates(<span class="hljs-literal">True</span>)
</code></pre>
    <p class="normal">I've set up metrics and plotting methods that we'll use for all the produced forecasts. We can just load them up from the time-series library:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> time_series.utils <span class="hljs-keyword">import</span> evaluate_model
</code></pre>
    <p class="normal">We'll also set the number of epochs in training to <code class="Code-In-Text--PACKT-">100</code> – the same for every model:</p>
    <pre class="programlisting code"><code class="hljs-code">N_EPOCHS = <span class="hljs-number">100</span>
</code></pre>
    <p class="normal">If you find that training is taking very long, you can set this to a lower value so training finishes earlier.</p>
    <p class="normal">Let's go through the different forecasting methods<a id="_idIndexMarker908"/> in turn, <code class="Code-In-Text--PACKT-">DeepAR</code> first:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> time_series.models.deepar <span class="hljs-keyword">import</span> DeepAR
ar_model = DeepAR(tds)
ar_model.instantiate_and_fit(verbose=<span class="hljs-number">1</span>, epochs=N_EPOCHS)
</code></pre>
    <p class="normal">We'll see the summary of the model and then the training error over time (omitted here):</p>
    <figure class="mediaobject"><img src="../Images/B17577_12_02.png" alt="/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_4ElEIb/Screenshot 2021-10-04 at 22.37.08.png"/></figure>
    <p class="packt_figref">Figure 12.2: DeepAR model parameters.</p>
    <p class="normal">This model is relatively<a id="_idIndexMarker909"/> simple, as we can see: only <code class="Code-In-Text--PACKT-">360</code> parameters. Obviously, we could tweak these parameters and add more.</p>
    <p class="normal">We'll then produce predictions on the test dataset:</p>
    <pre class="programlisting code"><code class="hljs-code">y_predicted = ar_model.model.predict(tds.X_test)
evaluate_model(tds=tds, y_predicted=y_predicted,
    columns=train_df.columns, first_n=<span class="hljs-number">10</span>)
</code></pre>
    <p class="normal">We'll see the errors – first the overall error and then for each of the <code class="Code-In-Text--PACKT-">10</code> dimensions:</p>
    <pre class="programlisting con"><code class="hljs-con">MSE: 0.4338
----------
CT: 0.39
MASS: 1.02
ME: 1.13
NEMASSBOST: 1.48
NH: 1.65
RI: 1.48
SEMASS: 1.65
TOTAL: 1.45
VT: 1.23
WCMASS: 1.54
</code></pre>
    <p class="normal">We'll see the plot over the first <code class="Code-In-Text--PACKT-">10</code> time-steps:</p>
    <figure class="mediaobject"><img src="../Images/B17577_12_03.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.3: DeepAR forecasts for 10 time-steps.</p>
    <p class="normal">Let's move<a id="_idIndexMarker910"/> on to the next method: N-BEATS:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> time_series.models.nbeats <span class="hljs-keyword">import</span> NBeatsNet
nb = NBeatsNet(tds)
nb.instantiate_and_fit(verbose=<span class="hljs-number">1</span>, epochs=N_EPOCHS)
y_predicted = nb.model.predict(tds.X_test)
evaluate_model(tds=tds, y_predicted=y_predicted,
    columns=train_df.columns, first_n=<span class="hljs-number">10</span>)
</code></pre>
    <p class="normal">N-BEATS trains two networks. The forward network has <code class="Code-In-Text--PACKT-">1,217,024</code> parameters.</p>
    <p class="normal">Let's see the forecasts:</p>
    <figure class="mediaobject"><img src="../Images/B17577_12_04.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.4: N-BEATS forecasts.</p>
    <p class="normal">LSTM<a id="_idIndexMarker911"/> is next:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> time_series.models.LSTM <span class="hljs-keyword">import</span> LSTM
lstm = LSTM(tds)
lstm.instantiate_and_fit(verbose=<span class="hljs-number">1</span>, epochs=N_EPOCHS)
y_predicted = lstm.model.predict(tds.X_test)
evaluate_model(tds=tds, y_predicted=y_predicted,
    columns=train_df.columns, first_n=<span class="hljs-number">10</span>)
</code></pre>
    <p class="normal">This model takes a lot more parameters than DeepAR:</p>
    <figure class="mediaobject"><img src="../Images/B17577_12_05.png" alt="/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_0VYxgy/Screenshot 2021-10-04 at 22.45.24.png"/></figure>
    <p class="packt_figref">Figure 12.5: LSTM model parameters.</p>
    <p class="normal"><code class="Code-In-Text--PACKT-">45,000</code> parameters – this means<a id="_idIndexMarker912"/> this takes much longer to train than <code class="Code-In-Text--PACKT-">DeepAR</code>.</p>
    <p class="normal">Here we see the forecasts again:</p>
    <figure class="mediaobject"><img src="../Images/B17577_12_06.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.6: LSTM forecasts.</p>
    <p class="normal">Let's do<a id="_idIndexMarker913"/> the transformer:</p>
    <pre class="programlisting code"><code class="hljs-code">trans = Transformer(tds)
trans.instantiate_and_fit(verbose=<span class="hljs-number">1</span>, epochs=N_EPOCHS)
y_predicted = trans.model.predict(tds.X_test)
evaluate_model(tds=tds, y_predicted=y_predicted,
    columns=train_df.columns, first_n=<span class="hljs-number">10</span>)
</code></pre>
    <p class="normal">Here's the forecast plot:</p>
    <figure class="mediaobject"><img src="../Images/B17577_12_07.png" alt="forecast_transformer.png"/></figure>
    <p class="packt_figref">Figure 12.7: Transformer forecasts.</p>
    <p class="normal">This model takes<a id="_idIndexMarker914"/> very long to train and the performance was the worst of the bunch.</p>
    <p class="normal">Our last deep<a id="_idIndexMarker915"/> learning model is the TCN:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> time_series.models.TCN <span class="hljs-keyword">import</span> TCNModel
tcn_model = TCNModel(tds)
tcn_model.instantiate_and_fit(verbose=<span class="hljs-number">1</span>, epochs=N_EPOCHS)
<span class="hljs-built_in">print</span>(tcn_model.model.evaluate(tds.X_test, tds.y_test))
y_predicted = tcn_model.model.predict(tds.X_test)
evaluate_model(tds=tds, y_predicted=y_predicted, columns=train_df.columns, first_n=<span class="hljs-number">10</span>
</code></pre>
    <p class="normal">The forecasts are as follows:</p>
    <figure class="mediaobject"><img src="../Images/B17577_12_08.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.8: TCN forecasts.</p>
    <p class="normal">The Gaussian process, unfortunately, can't deal with our dataset – therefore, we'll only load up a small part. The Gaussian process<a id="_idIndexMarker916"/> also depends on eager execution, so we'll have to restart the kernel, redo the imports, and then execute this. If you have doubts<a id="_idIndexMarker917"/> about how to do this, please have a look at the <code class="Code-In-Text--PACKT-">gaussian_process</code> notebook in the GitHub repository of this book.</p>
    <p class="normal">Here we go:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> time_series.models.gaussian_process <span class="hljs-keyword">import</span> GaussianProcess
tds2d = TrainingDataSet(train_df.head(<span class="hljs-number">500</span>), train_split=<span class="hljs-number">0.1</span>, two_dim=<span class="hljs-literal">True</span>)
gp = GaussianProcess(tds2d)
gp.instantiate_and_fit(maxiter=N_EPOCHS)
y_predicted = gp.predict(tds2d.X_test)[<span class="hljs-number">0</span>].numpy().reshape(-<span class="hljs-number">1</span>, tds.dimensions, tds.n_steps)
evaluate_model(tds=tds, y_predicted=y_predicted,
    columns=train_df.columns, first_n=<span class="hljs-number">10</span>)
</code></pre>
    <p class="normal">The forecast looks like this:</p>
    <figure class="mediaobject"><img src="../Images/B17577_12_09.png" alt="forecast_gp.png"/></figure>
    <p class="packt_figref">Figure 12.9: Gaussian process forecasts.</p>
    <p class="normal">All algorithms (except for the Gaussian process) were trained on <code class="Code-In-Text--PACKT-">99336</code> data points. As mentioned, we've set the training<a id="_idIndexMarker918"/> epochs to <code class="Code-In-Text--PACKT-">100</code>, but there's an early stopping rule that would stop training if the training loss didn't change within <code class="Code-In-Text--PACKT-">5</code> iterations.</p>
    <p class="normal">The models are validated on the test set.</p>
    <p class="normal">Let's check the statistics:</p>
    <table id="table001-8" class="No-Table-Style _idGenTablePara-1">
      <colgroup>
        <col/>
        <col/>
        <col/>
        <col/>
      </colgroup>
      <tbody>
        <tr class="No-Table-Style">
          <td class="No-Table-Style"/>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Parameters</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">MSE (test)</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Epochs</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">DeepAR</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">360</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">0.4338</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">100</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">N-BEATS</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">1,217,024</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">0.1016</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">100</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">LSTM</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">45,410</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">0.1569</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">100</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Transformer</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">51,702</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">0.9314</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">55</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">TCN</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">145,060</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">0.0638</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">100</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Gaussian process</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">8</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">0.4221</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">100</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">ES</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">11.28</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">-</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="normal">Given the huge disparity in the error between the deep learning methods, there might be something off with the implementation of the transformer – I'll try to fix this at some point. </p>
    <p class="normal">I've included a baseline method, <strong class="keyword">Exponential Smoothing</strong> (<strong class="keyword">ES</strong>), in the mix. You can find the code<a id="_idIndexMarker919"/> for this in the time-series repository.</p>
    <p class="normal">This brings the chapter and the book to its conclusion. You can have a look at the repo if you want to understand better what's happening under the hood. You can also tweak the model parameters.</p>
    <h1 id="_idParaDest-177" class="title">What's next for time-series?</h1>
    <p class="normal">We've looked at many aspects of time-series in this book. If you've made it this far, you should have learned how to <a id="_idIndexMarker920"/>analyze time-series, and how to apply traditional time-series forecasts. This is often the main focus of other books on the market; however, we went far beyond.</p>
    <p class="normal">We looked at preprocessing and transformations for time-series as relevant to machine learning. We looked at many examples of applying machine learning both in an unsupervised and supervised context for forecasting and other predictions, anomaly detection, and drift and change point detection. We delved into techniques such as online learning, reinforcement learning, probabilistic models, and deep learning.</p>
    <p class="normal">In each chapter, we've been looking at the most important libraries, sometimes even the cutting edge, and, finally, prevalent industrial applications. We've looked at state-of-the-art models such as HIVE-COTE, preprocessing methods such as ROCKET, and models that adapt to drift (adaptive online models), and we reviewed a number of methods for anomaly detection. </p>
    <p class="normal">We've even looked at scenarios such as switching between time-series models with multi-armed bandits or causal analysis with counterfactuals.</p>
    <p class="normal">Due to their prevalence, time-series modeling and forecasting are crucial in multiple domains and have great economic importance. While traditional and well-established approaches have been dominating, machine learning for time-series is a relatively new research field, having only really just come out of its infancy, and deep learning is a very active forefront of this revolution.</p>
    <p class="normal">The search for good models will carry on, extending to bigger new challenges. One of these, as I hoped to show in the preceding section of this chapter, is making multivariate methods a more practical proposition. </p>
    <p class="normal">The next Makridakis Competition, M5, focuses on hierarchical time-series provided by Walmart (42,000 time-series). Final results will be published in 2022. Machine learning <a id="_idIndexMarker921"/>models can shine at hierarchical regression on time-series, outperforming some well-established models in the literature as shown by <em class="italic">Mahdi Abolghasemi</em> and others ("<em class="italic">Machine learning applications in time-series hierarchical forecasting</em>," 2019) in a benchmark with 61 groups of time-series with different volatilities. Mixed-effects models (with application to groups and hierarchies) for time-series forecasting is also an active area of research.</p>
    <p class="normal">The M6 competition features real-time financial forecasting of S&amp;P500 US stocks and international ETFs. Future competitions might focus on non-linearities such as Black Swan events, time-series with fat tails, and distributions that are important for risk management and decision making.</p>
  </div>


  <div id="_idContainer436">
    <p class="normal"><img src="../Images/Image21868.png" alt=""/></p>
    <p class="normal"><a href="http://packt.com"><span class="url">packt.com</span></a></p>
    <p class="normal">Subscribe to our online digital library for full access to over 7,000 books and videos, as well as industry leading tools to help you plan your personal development and advance your career. For more information, please visit our website.</p>
    <h1 id="_idParaDest-178" class="title">Why subscribe?</h1>
    <ul>
      <li class="bullet">Spend less time learning and more time coding with practical eBooks and Videos from over 4,000 industry professionals</li>
      <li class="bullet">Learn better with Skill Plans built especially for you</li>
      <li class="bullet">Get a free eBook or video every month</li>
      <li class="bullet">Fully searchable for easy access to vital information</li>
      <li class="bullet">Copy and paste, print, and bookmark content</li>
    </ul>
    <p class="normal">Did you know that Packt offers eBook versions of every book published, with PDF and ePub files available? You can upgrade to the eBook version at <a href="http://www.Packt.com"><span class="url">www.Packt.com</span></a> and as a print book customer, you are entitled to a discount on the eBook copy. Get in touch with us at <a href="http://customercare@packtpub.com"><span class="url">customercare@packtpub.com</span></a> for more details.</p>
    <p class="normal">At <a href="http://www.Packt.com"><span class="url">www.Packt.com</span></a>, you can also read a collection of free technical articles, sign up for a range of free newsletters, and receive exclusive discounts and offers on Packt books and eBooks.</p>
<p class="eop"/>
    <h1 id="_idParaDest-179" class="Introduction-Title--PACKT-">Other Books You May Enjoy</h1>
    <p class="normal">If you enjoyed this book, you may be interested in these other books by Packt:</p>
    <p class="normal"><a href="https://www.packtpub.com/product/learn-python-programming-third-edition/9781801815093"><img src="../Images/9781801815093.png" alt=""/></a></p>
    <p class="normal"><strong class="keyword">Learn Python Programming – Third Edition</strong></p>
    <p class="normal">Fabrizio Romano</p>
    <p class="normal">Heinrich Kruger</p>
    <p class="normal">ISBN: 978-1-80181-509-3</p>
    <ul>
      <li class="bullet">Get Python up and running on Windows, Mac, and Linux</li>
      <li class="bullet">Write elegant, reusable, and efficient code in any situation</li>
      <li class="bullet">Avoid common pitfalls like duplication, complicated design, and over-engineering</li>
      <li class="bullet">Understand when to use the functional or object-oriented approach to programming</li>
      <li class="bullet">Build a simple API with FastAPI and program GUI applications with Tkinter</li>
      <li class="bullet">Get an initial overview of more complex topics such as data persistence and cryptography</li>
      <li class="bullet">Fetch, clean, and manipulate data, making efficient use of Python's built-in data structures</li>
    </ul>
<p class="eop"/>
    <p class="normal"><a href="https://www.packtpub.com/product/python-object-oriented-programming-fourth-edition/9781801077262"><img src="../Images/9781801077262.png" alt=""/></a></p>
    <p class="normal"><strong class="keyword">Python Object-Oriented Programming – Fourth Edition</strong></p>
    <p class="normal">Steven F. Lott</p>
    <p class="normal">Dusty Phillips</p>
    <p class="normal">ISBN: 978-1-80107-726-2</p>
    <ul>
      <li class="bullet">Implement objects in Python by creating classes and defining methods</li>
      <li class="bullet">Extend class functionality using inheritance</li>
      <li class="bullet">Use exceptions to handle unusual situations cleanly</li>
      <li class="bullet">Understand when to use object-oriented features, and more importantly, when not to use them</li>
      <li class="bullet">Discover several widely used design patterns and how they are implemented in Python</li>
      <li class="bullet">Uncover the simplicity of unit and integration testing and understand why they are so important</li>
      <li class="bullet">Learn to statically type check your dynamic code</li>
      <li class="bullet">Understand concurrency with asyncio and how it speeds up programs</li>
    </ul>
<p class="eop"/>
    <p class="normal"><a href="https://www.packtpub.com/product/expert-python-programming-fourth-edition/9781801071109"><img src="../Images/9781801071109.png" alt=""/></a></p>
    <p class="normal"><strong class="keyword">Expert Python Programming – Fourth Edition</strong></p>
    <p class="normal">Michał Jaworski</p>
    <p class="normal">Tarek Ziadé</p>
    <p class="normal">ISBN: 978-1-80107-110-9</p>
    <ul>
      <li class="bullet">Explore modern ways of setting up repeatable and consistent Python development environments</li>
      <li class="bullet">Effectively package Python code for community and production use</li>
      <li class="bullet">Learn modern syntax elements of Python programming, such as f-strings, enums, and lambda functions</li>
      <li class="bullet">Demystify metaprogramming in Python with metaclasses</li>
      <li class="bullet">Write concurrent code in Python</li>
      <li class="bullet">Extend and integrate Python with code written in C and C++</li>
    </ul>
<p class="eop"/>
    <h1 id="_idParaDest-180" class="title">Packt is searching for authors like you</h1>
    <p class="normal">If you're interested in becoming an author for Packt, please visit <a href="http://authors.packtpub.com"><span class="url">authors.packtpub.com</span></a> and apply today. We have worked with thousands of developers and tech professionals, just like you, to help them share their insight with the global tech community. You can make a general application, apply for a specific hot topic that we are recruiting an author for, or submit your own idea.</p>
  </div>
  <div id="_idContainer437" class="Basic-Text-Frame">
    <h1 id="_idParaDest-181" class="title">Share Your Thoughts</h1>
    <p class="normal">Now you've finished <em class="italic">Machine Learning for Time-Series with Python</em>, we'd love to hear your thoughts! If you purchased the book from Amazon, please <a href="https://packt.link/r/1801819629"><span class="url">click here to go straight to the Amazon review page</span></a> for this book and share your feedback or leave a review on the site that you purchased it from.</p>
    <p class="normal">Your review is important to us and the tech community and will help us make sure we're delivering excellent quality content.</p>
  </div>


  <div id="_idContainer440" epub:type="index">&#13;
    <p class="Index-Title">Index</p>&#13;
    <p class="Index-Section-Head">A</p>&#13;
    <p class="Index-Level-1">activation function <a href="Chapter_10.xhtml#_idIndexMarker777">264</a></p>&#13;
    <p class="Index-Level-1">activation functions <a href="Chapter_10.xhtml#_idIndexMarker790">266</a></p>&#13;
    <p class="Index-Level-1">AdaBoost <a href="Chapter_4.xhtml#_idIndexMarker282">101</a></p>&#13;
    <p class="Index-Level-1">adaptive learning <a href="Chapter_8.xhtml#_idIndexMarker672">222</a></p>&#13;
    <p class="Index-Level-2">methods <a href="Chapter_8.xhtml#_idIndexMarker673">222</a></p>&#13;
    <p class="Index-Level-1">Adaptive XGBoost <a href="Chapter_8.xhtml#_idIndexMarker674">222</a></p>&#13;
    <p class="Index-Level-1">ADWIN (ADaptive WINdowing) <a href="Chapter_8.xhtml#_idIndexMarker669">220</a></p>&#13;
    <p class="Index-Level-1">agent <a href="Chapter_4.xhtml#_idIndexMarker266">98</a></p>&#13;
    <p class="Index-Level-1">Akaike information criterion (AIC) <a href="Chapter_5.xhtml#_idIndexMarker437">140</a></p>&#13;
    <p class="Index-Level-1">Akaike Information Criterion (AIC) <a href="Chapter_5.xhtml#_idIndexMarker496">156</a></p>&#13;
    <p class="Index-Level-1">AlexNet <a href="Chapter_10.xhtml#_idIndexMarker786">265</a></p>&#13;
    <p class="Index-Level-1">Amazon <a href="Chapter_6.xhtml#_idIndexMarker520">169</a></p>&#13;
    <p class="Index-Level-1">anaconda documentation</p>&#13;
    <p class="Index-Level-2">reference link <a href="Chapter_1.xhtml#_idIndexMarker044">22</a></p>&#13;
    <p class="Index-Level-1">annuities <a href="Chapter_1.xhtml#_idIndexMarker015">7</a></p>&#13;
    <p class="Index-Level-1">anomaly detection <a href="Chapter_4.xhtml#_idIndexMarker248">95</a>, <a href="Chapter_6.xhtml#_idIndexMarker507">164</a>, <a href="Chapter_6.xhtml#_idIndexMarker508">165</a>, <a href="Chapter_6.xhtml#_idIndexMarker511">166</a>, <a href="Chapter_6.xhtml#_idIndexMarker512">167</a>, <a href="Chapter_6.xhtml#_idIndexMarker513">168</a>, <a href="Chapter_6.xhtml#_idIndexMarker546">178</a>, <a href="Chapter_6.xhtml#_idIndexMarker548">179</a>, <a href="Chapter_6.xhtml#_idIndexMarker552">180</a></p>&#13;
    <p class="Index-Level-2">Amazon <a href="Chapter_6.xhtml#_idIndexMarker519">169</a></p>&#13;
    <p class="Index-Level-2">Facebook <a href="Chapter_6.xhtml#_idIndexMarker524">170</a></p>&#13;
    <p class="Index-Level-2">Google Analytics <a href="Chapter_6.xhtml#_idIndexMarker518">169</a></p>&#13;
    <p class="Index-Level-2">implementations <a href="Chapter_6.xhtml#_idIndexMarker531">170</a>, <a href="Chapter_6.xhtml#_idIndexMarker532">171</a>, <a href="Chapter_6.xhtml#_idIndexMarker533">172</a></p>&#13;
    <p class="Index-Level-2">Microsoft <a href="Chapter_6.xhtml#_idIndexMarker515">168</a>, <a href="Chapter_6.xhtml#_idIndexMarker516">169</a></p>&#13;
    <p class="Index-Level-2">Twitter <a href="Chapter_6.xhtml#_idIndexMarker526">170</a></p>&#13;
    <p class="Index-Level-1">Anticipy <a href="Chapter_5.xhtml#_idIndexMarker465">146</a></p>&#13;
    <p class="Index-Level-1">Applied Statistics <a href="Chapter_1.xhtml#_idIndexMarker035">17</a></p>&#13;
    <p class="Index-Level-1">ARCH (Auto-Regressive Conditionally Heteroscedastic) <a href="Chapter_5.xhtml#_idIndexMarker453">143</a></p>&#13;
    <p class="Index-Level-1">area under the curve <a href="Chapter_4.xhtml#_idIndexMarker339">115</a></p>&#13;
    <p class="Index-Level-1">Artificial General Intelligence (AGI) <a href="Chapter_11.xhtml#_idIndexMarker850">298</a></p>&#13;
    <p class="Index-Level-1">astronomy <a href="Chapter_1.xhtml#_idIndexMarker020">11</a>, <a href="Chapter_1.xhtml#_idIndexMarker021">12</a></p>&#13;
    <p class="Index-Level-1">autocorrelation <a href="Chapter_2.xhtml#_idIndexMarker143">58</a>, <a href="Chapter_2.xhtml#_idIndexMarker144">59</a></p>&#13;
    <p class="Index-Level-1">autoencoders (AEs) <a href="Chapter_10.xhtml#_idIndexMarker808">272</a>, <a href="Chapter_10.xhtml#_idIndexMarker812">273</a></p>&#13;
    <p class="Index-Level-1">automated feature extraction <a href="Chapter_3.xhtml#_idIndexMarker233">88</a>, <a href="Chapter_3.xhtml#_idIndexMarker234">89</a></p>&#13;
    <p class="Index-Level-1">autoregressive (AR) <a href="Chapter_5.xhtml#_idIndexMarker411">135</a>, <a href="Chapter_5.xhtml#_idIndexMarker416">136</a></p>&#13;
    <p class="Index-Level-1">Autoregressive Conditional Heteroscedasticity (ARCH) <a href="Chapter_5.xhtml#_idIndexMarker466">146</a></p>&#13;
    <p class="Index-Level-1">Autoregressive Integrated Moving Average (ARIMA) <a href="Chapter_4.xhtml#_idIndexMarker399">129</a></p>&#13;
    <p class="Index-Level-1">autoregressive integrated moving average model (ARIMA) <a href="Chapter_5.xhtml#_idIndexMarker423">138</a></p>&#13;
    <p class="Index-Level-1">autoregressive model <a href="Chapter_5.xhtml#_idIndexMarker412">135</a></p>&#13;
    <p class="Index-Level-1">autoregressive moving average (ARMA) <a href="Chapter_5.xhtml#_idIndexMarker421">137</a></p>&#13;
    <p class="Index-Section-Head">B</p>&#13;
    <p class="Index-Level-1">backcasting <a href="Chapter_4.xhtml#_idIndexMarker245">95</a></p>&#13;
    <p class="Index-Level-1">backpropagation <a href="Chapter_4.xhtml#_idIndexMarker271">99</a>, <a href="Chapter_4.xhtml#_idIndexMarker289">103</a>, <a href="Chapter_10.xhtml#_idIndexMarker780">264</a></p>&#13;
    <p class="Index-Level-1">bagging <a href="Chapter_4.xhtml#_idIndexMarker279">100</a>, <a href="Chapter_4.xhtml#_idIndexMarker283">101</a></p>&#13;
    <p class="Index-Level-2">versus boosting <a href="Chapter_4.xhtml#_idIndexMarker286">102</a></p>&#13;
    <p class="Index-Level-1">bag-of-patterns (BoP) <a href="Chapter_4.xhtml#_idIndexMarker371">122</a></p>&#13;
    <p class="Index-Level-1">Bag-of-Patterns (BOP) <a href="Chapter_4.xhtml#_idIndexMarker378">123</a></p>&#13;
    <p class="Index-Level-1">Bag of SFA Symbols (BOSS) <a href="Chapter_4.xhtml#_idIndexMarker370">122</a></p>&#13;
    <p class="Index-Level-1">Bandit algorithms <a href="Chapter_11.xhtml#_idIndexMarker861">302</a>, <a href="Chapter_11.xhtml#_idIndexMarker863">303</a></p>&#13;
    <p class="Index-Level-1">base learner <a href="Chapter_4.xhtml#_idIndexMarker280">100</a></p>&#13;
    <p class="Index-Level-1">Bayesian Information Criterion (BIC) <a href="Chapter_5.xhtml#_idIndexMarker438">140</a></p>&#13;
    <p class="Index-Level-1">Bayesian Structural Time-Series (BSTS) models <a href="Chapter_9.xhtml#_idIndexMarker697">236</a>, <a href="Chapter_9.xhtml#_idIndexMarker726">242</a>, <a href="Chapter_9.xhtml#_idIndexMarker727">243</a>, <a href="Chapter_9.xhtml#_idIndexMarker728">244</a></p>&#13;
    <p class="Index-Level-2">implementing, in Python <a href="Chapter_9.xhtml#_idIndexMarker758">256</a>, <a href="Chapter_9.xhtml#_idIndexMarker761">257</a>, <a href="Chapter_9.xhtml#_idIndexMarker764">259</a></p>&#13;
    <p class="Index-Level-1">biology <a href="Chapter_1.xhtml#_idIndexMarker018">10</a></p>&#13;
    <p class="Index-Level-1">boosting <a href="Chapter_4.xhtml#_idIndexMarker278">100</a></p>&#13;
    <p class="Index-Level-1">Bootstrapping <a href="Chapter_4.xhtml#_idIndexMarker284">101</a></p>&#13;
    <p class="Index-Level-1">BOSS in Vector Space (BOSS VS) <a href="Chapter_4.xhtml#_idIndexMarker372">122</a></p>&#13;
    <p class="Index-Level-1">Box-Cox transformation <a href="Chapter_3.xhtml#_idIndexMarker178">72</a>, <a href="Chapter_3.xhtml#_idIndexMarker217">81</a>, <a href="Chapter_3.xhtml#_idIndexMarker219">82</a></p>&#13;
    <p class="Index-Level-1">business days</p>&#13;
    <p class="Index-Level-2">extracting, in month <a href="Chapter_3.xhtml#_idIndexMarker232">88</a></p>&#13;
    <p class="Index-Section-Head">C</p>&#13;
    <p class="Index-Level-1">C4.5 algorithm <a href="Chapter_4.xhtml#_idIndexMarker275">100</a></p>&#13;
    <p class="Index-Level-1">cable theory <a href="Chapter_10.xhtml#_idIndexMarker772">263</a></p>&#13;
    <p class="Index-Level-1">Canonical Interval Forest (CIF) <a href="Chapter_4.xhtml#_idIndexMarker366">121</a></p>&#13;
    <p class="Index-Level-1">CART algorithm (Classification And Regression Tree) <a href="Chapter_4.xhtml#_idIndexMarker274">100</a></p>&#13;
    <p class="Index-Level-1">causal filter <a href="Chapter_3.xhtml#_idIndexMarker190">74</a></p>&#13;
    <p class="Index-Level-1">cells <a href="Chapter_10.xhtml#_idIndexMarker781">265</a></p>&#13;
    <p class="Index-Level-1">central limit theorem <a href="Chapter_1.xhtml#_idIndexMarker023">12</a></p>&#13;
    <p class="Index-Level-1">Centre de Mathématiques Appliquées (CMAP) <a href="Chapter_4.xhtml#_idIndexMarker394">129</a></p>&#13;
    <p class="Index-Level-1">change point detection (CPD) <a href="Chapter_6.xhtml#_idIndexMarker534">172</a>, <a href="Chapter_6.xhtml#_idIndexMarker535">173</a>, <a href="Chapter_6.xhtml#_idIndexMarker537">174</a>, <a href="Chapter_6.xhtml#_idIndexMarker539">175</a>, <a href="Chapter_6.xhtml#_idIndexMarker540">176</a>, <a href="Chapter_6.xhtml#_idIndexMarker554">180</a>, <a href="Chapter_6.xhtml#_idIndexMarker555">181</a>, <a href="Chapter_6.xhtml#_idIndexMarker558">182</a></p>&#13;
    <p class="Index-Level-1">classical models <a href="Chapter_5.xhtml#_idIndexMarker400">132</a>, <a href="Chapter_5.xhtml#_idIndexMarker401">133</a></p>&#13;
    <p class="Index-Level-2">ARCH (Auto-Regressive Conditionally Heteroscedastic) <a href="Chapter_5.xhtml#_idIndexMarker452">143</a></p>&#13;
    <p class="Index-Level-2">autoregressive (AR) <a href="Chapter_5.xhtml#_idIndexMarker405">134</a>, <a href="Chapter_5.xhtml#_idIndexMarker410">135</a>, <a href="Chapter_5.xhtml#_idIndexMarker415">136</a></p>&#13;
    <p class="Index-Level-2">GARCH (generalized ARCH) <a href="Chapter_5.xhtml#_idIndexMarker457">144</a></p>&#13;
    <p class="Index-Level-2">model selection <a href="Chapter_5.xhtml#_idIndexMarker430">139</a></p>&#13;
    <p class="Index-Level-2">moving averages (MA) <a href="Chapter_5.xhtml#_idIndexMarker404">134</a></p>&#13;
    <p class="Index-Level-2">order <a href="Chapter_5.xhtml#_idIndexMarker429">139</a>, <a href="Chapter_5.xhtml#_idIndexMarker436">140</a></p>&#13;
    <p class="Index-Level-2">vector autoregression models <a href="Chapter_5.xhtml#_idIndexMarker458">144</a>, <a href="Chapter_5.xhtml#_idIndexMarker461">145</a></p>&#13;
    <p class="Index-Level-1">classification <a href="Chapter_4.xhtml#_idIndexMarker243">95</a>, <a href="Chapter_4.xhtml#_idIndexMarker259">97</a>, <a href="Chapter_4.xhtml#_idIndexMarker325">113</a></p>&#13;
    <p class="Index-Level-1">clustering <a href="Chapter_4.xhtml#_idIndexMarker246">95</a>, <a href="Chapter_6.xhtml#_idIndexMarker541">176</a>, <a href="Chapter_6.xhtml#_idIndexMarker542">177</a></p>&#13;
    <p class="Index-Level-1">coefficient of determination <a href="Chapter_4.xhtml#_idIndexMarker306">107</a>, <a href="Chapter_4.xhtml#_idIndexMarker307">108</a></p>&#13;
    <p class="Index-Level-1">collinearity <a href="Chapter_2.xhtml#_idIndexMarker115">50</a></p>&#13;
    <p class="Index-Level-1">complex cells <a href="Chapter_10.xhtml#_idIndexMarker783">265</a></p>&#13;
    <p class="Index-Level-1">concept drift <a href="Chapter_8.xhtml#_idIndexMarker660">217</a></p>&#13;
    <p class="Index-Level-1">conda <a href="Chapter_1.xhtml#_idIndexMarker043">22</a></p>&#13;
    <p class="Index-Level-1">confidence interval <a href="Chapter_2.xhtml#_idIndexMarker101">45</a></p>&#13;
    <p class="Index-Level-1">confusion matrix <a href="Chapter_4.xhtml#_idIndexMarker326">114</a></p>&#13;
    <p class="Index-Level-1">Contextual bandits <a href="Chapter_11.xhtml#_idIndexMarker866">303</a></p>&#13;
    <p class="Index-Level-1">contingency table <a href="Chapter_8.xhtml#_idIndexMarker668">220</a></p>&#13;
    <p class="Index-Level-1">continuous-time Markov chain (CTMC) <a href="Chapter_9.xhtml#_idIndexMarker716">239</a></p>&#13;
    <p class="Index-Level-1">ConvNets <a href="Chapter_10.xhtml#_idIndexMarker823">276</a></p>&#13;
    <p class="Index-Level-1">Convolutional Neural Network (CNN) <a href="Chapter_12.xhtml#_idIndexMarker900">322</a></p>&#13;
    <p class="Index-Level-1">Convolutional Neural Networks (CNNs) <a href="Chapter_3.xhtml#_idIndexMarker206">77</a></p>&#13;
    <p class="Index-Level-1">correlation heatmap <a href="Chapter_2.xhtml#_idIndexMarker124">53</a></p>&#13;
    <p class="Index-Level-1">correlation matrix <a href="Chapter_2.xhtml#_idIndexMarker123">52</a></p>&#13;
    <p class="Index-Level-1">Correlation Ratio <a href="Chapter_4.xhtml#_idIndexMarker340">115</a>, <a href="Chapter_4.xhtml#_idIndexMarker341">116</a></p>&#13;
    <p class="Index-Level-1">covariate drift <a href="Chapter_8.xhtml#_idIndexMarker656">217</a></p>&#13;
    <p class="Index-Level-1">critical difference (CD) diagrams <a href="Chapter_4.xhtml#_idIndexMarker361">119</a></p>&#13;
    <p class="Index-Level-1">cross-validation <a href="Chapter_4.xhtml#_idIndexMarker295">105</a></p>&#13;
    <p class="Index-Level-1">Cross-Validation Accuracy Weighted Probabilistic Ensemble (CAWPE) <a href="Chapter_4.xhtml#_idIndexMarker383">124</a></p>&#13;
    <p class="Index-Level-1">curve fitting <a href="Chapter_4.xhtml#_idIndexMarker241">94</a></p>&#13;
    <p class="Index-Level-1">cyclic variations <a href="Chapter_2.xhtml#_idIndexMarker131">56</a></p>&#13;
    <p class="Index-Section-Head">D</p>&#13;
    <p class="Index-Level-1">DataFrame <a href="Chapter_1.xhtml#_idIndexMarker059">30</a></p>&#13;
    <p class="Index-Level-1">data preprocessing</p>&#13;
    <p class="Index-Level-2">about <a href="Chapter_3.xhtml#_idIndexMarker159">68</a>, <a href="Chapter_3.xhtml#_idIndexMarker164">69</a></p>&#13;
    <p class="Index-Level-1">data preprocessing, techniques</p>&#13;
    <p class="Index-Level-2">feature engineering <a href="Chapter_3.xhtml#_idIndexMarker162">68</a></p>&#13;
    <p class="Index-Level-2">feature transforms <a href="Chapter_3.xhtml#_idIndexMarker160">68</a></p>&#13;
    <p class="Index-Level-1">dataset shift <a href="Chapter_8.xhtml#_idIndexMarker652">216</a></p>&#13;
    <p class="Index-Level-1">date- and time-related features <a href="Chapter_3.xhtml#_idIndexMarker193">75</a></p>&#13;
    <p class="Index-Level-1">date annotation <a href="Chapter_3.xhtml#_idIndexMarker226">85</a>, <a href="Chapter_3.xhtml#_idIndexMarker227">86</a></p>&#13;
    <p class="Index-Level-1">datetime <a href="Chapter_2.xhtml#_idIndexMarker082">39</a>, <a href="Chapter_2.xhtml#_idIndexMarker085">40</a>, <a href="Chapter_2.xhtml#_idIndexMarker087">41</a></p>&#13;
    <p class="Index-Level-1">decision tree <a href="Chapter_4.xhtml#_idIndexMarker276">100</a></p>&#13;
    <p class="Index-Level-1">decoders <a href="Chapter_10.xhtml#_idIndexMarker811">273</a></p>&#13;
    <p class="Index-Level-1">DeepAR <a href="Chapter_9.xhtml#_idIndexMarker693">236</a>, <a href="Chapter_10.xhtml#_idIndexMarker818">274</a></p>&#13;
    <p class="Index-Level-1">DeepAR model <a href="Chapter_12.xhtml#_idIndexMarker908">325</a>, <a href="Chapter_12.xhtml#_idIndexMarker909">326</a></p>&#13;
    <p class="Index-Level-1">deep learning <a href="Chapter_10.xhtml#_idIndexMarker765">261</a>, <a href="Chapter_10.xhtml#_idIndexMarker767">262</a></p>&#13;
    <p class="Index-Level-1">deep learning approaches</p>&#13;
    <p class="Index-Level-2">typology <a href="Chapter_10.xhtml#_idIndexMarker792">268</a></p>&#13;
    <p class="Index-Level-1">deep learning, for time series <a href="Chapter_10.xhtml#_idIndexMarker793">269</a>, <a href="Chapter_10.xhtml#_idIndexMarker800">270</a>, <a href="Chapter_10.xhtml#_idIndexMarker806">271</a></p>&#13;
    <p class="Index-Level-1">deep Q-Learning <a href="Chapter_11.xhtml#_idIndexMarker869">303</a>, <a href="Chapter_11.xhtml#_idIndexMarker870">304</a>, <a href="Chapter_11.xhtml#_idIndexMarker873">305</a></p>&#13;
    <p class="Index-Level-1">Deep Q-Network (DQN) <a href="Chapter_11.xhtml#_idIndexMarker883">311</a></p>&#13;
    <p class="Index-Level-1">deep reinforcement learning (DRL) <a href="Chapter_11.xhtml#_idIndexMarker858">301</a></p>&#13;
    <p class="Index-Level-1">DeepState <a href="Chapter_9.xhtml#_idIndexMarker694">236</a></p>&#13;
    <p class="Index-Level-1">demography <a href="Chapter_1.xhtml#_idIndexMarker012">6</a>, <a href="Chapter_1.xhtml#_idIndexMarker014">7</a>, <a href="Chapter_1.xhtml#_idIndexMarker016">8</a>, <a href="Chapter_1.xhtml#_idIndexMarker017">9</a></p>&#13;
    <p class="Index-Level-1">dendrites <a href="Chapter_10.xhtml#_idIndexMarker773">263</a></p>&#13;
    <p class="Index-Level-1">descriptive analysis <a href="Chapter_2.xhtml#_idIndexMarker071">36</a></p>&#13;
    <p class="Index-Level-1">differencing <a href="Chapter_5.xhtml#_idIndexMarker425">138</a></p>&#13;
    <p class="Index-Level-1">dilated causal convolutional neural network <a href="Chapter_10.xhtml#_idIndexMarker845">292</a>, <a href="Chapter_10.xhtml#_idIndexMarker846">293</a>, <a href="Chapter_10.xhtml#_idIndexMarker847">294</a>, <a href="Chapter_10.xhtml#_idIndexMarker848">295</a></p>&#13;
    <p class="Index-Level-1">Dirichlet sampling <a href="Chapter_11.xhtml#_idIndexMarker865">303</a></p>&#13;
    <p class="Index-Level-1">discrete-time Markov chain (DTMC) <a href="Chapter_9.xhtml#_idIndexMarker715">239</a></p>&#13;
    <p class="Index-Level-1">distance-based approaches <a href="Chapter_4.xhtml#_idIndexMarker353">118</a></p>&#13;
    <p class="Index-Level-1">dl-4-tsc <a href="Chapter_10.xhtml#_idIndexMarker805">271</a></p>&#13;
    <p class="Index-Level-1">drift <a href="Chapter_8.xhtml#_idIndexMarker651">216</a>, <a href="Chapter_8.xhtml#_idIndexMarker654">217</a>, <a href="Chapter_8.xhtml#_idIndexMarker663">218</a>, <a href="Chapter_8.xhtml#_idIndexMarker664">219</a></p>&#13;
    <p class="Index-Level-2">concept drift <a href="Chapter_8.xhtml#_idIndexMarker661">217</a></p>&#13;
    <p class="Index-Level-2">covariate drift <a href="Chapter_8.xhtml#_idIndexMarker655">217</a></p>&#13;
    <p class="Index-Level-2">probability drift <a href="Chapter_8.xhtml#_idIndexMarker659">217</a></p>&#13;
    <p class="Index-Level-1">drift detection <a href="Chapter_8.xhtml#_idIndexMarker677">224</a>, <a href="Chapter_8.xhtml#_idIndexMarker678">225</a></p>&#13;
    <p class="Index-Level-2">methods <a href="Chapter_8.xhtml#_idIndexMarker665">219</a>, <a href="Chapter_8.xhtml#_idIndexMarker670">220</a>, <a href="Chapter_8.xhtml#_idIndexMarker671">222</a></p>&#13;
    <p class="Index-Level-1">Drift Detection Method (DDM) <a href="Chapter_8.xhtml#_idIndexMarker666">220</a></p>&#13;
    <p class="Index-Level-1">drift transitions <a href="Chapter_8.xhtml#_idIndexMarker653">216</a></p>&#13;
    <p class="Index-Level-1">dropout <a href="Chapter_10.xhtml#_idIndexMarker832">282</a></p>&#13;
    <p class="Index-Level-1">dynamic time warping</p>&#13;
    <p class="Index-Level-2">using, in K-nearest neighbors <a href="Chapter_7.xhtml#_idIndexMarker567">189</a></p>&#13;
    <p class="Index-Level-1">Dynamic time warping (DTW) <a href="Chapter_4.xhtml#_idIndexMarker345">116</a></p>&#13;
    <p class="Index-Level-1">Dynamic Time Warping (DTW) <a href="Chapter_4.xhtml#_idIndexMarker354">118</a>, <a href="Chapter_10.xhtml#_idIndexMarker798">270</a></p>&#13;
    <p class="Index-Level-1">dynamic time wraping</p>&#13;
    <p class="Index-Level-2">K-nearest neighbors, in Python <a href="Chapter_7.xhtml#_idIndexMarker585">193</a>, <a href="Chapter_7.xhtml#_idIndexMarker588">194</a>, <a href="Chapter_7.xhtml#_idIndexMarker590">195</a></p>&#13;
    <p class="Index-Section-Head">E</p>&#13;
    <p class="Index-Level-1">early stopping <a href="Chapter_10.xhtml#_idIndexMarker833">282</a></p>&#13;
    <p class="Index-Level-1">Echo State Network (ESN) <a href="Chapter_12.xhtml#_idIndexMarker899">322</a></p>&#13;
    <p class="Index-Level-1">ECL (Electricity Consuming Load) <a href="Chapter_10.xhtml#_idIndexMarker830">279</a></p>&#13;
    <p class="Index-Level-1">economics <a href="Chapter_1.xhtml#_idIndexMarker025">13</a>, <a href="Chapter_1.xhtml#_idIndexMarker026">14</a></p>&#13;
    <p class="Index-Level-1">elastic ensemble (EE) <a href="Chapter_4.xhtml#_idIndexMarker382">124</a></p>&#13;
    <p class="Index-Level-1">electrocardiogram (ECG) <a href="Chapter_4.xhtml#_idIndexMarker349">118</a></p>&#13;
    <p class="Index-Level-1">electroencephalogram (EEG) <a href="Chapter_4.xhtml#_idIndexMarker350">118</a></p>&#13;
    <p class="Index-Level-1">electroencephalography (EEG) <a href="Chapter_1.xhtml#_idIndexMarker032">16</a>, <a href="Chapter_1.xhtml#_idIndexMarker034">17</a>, <a href="Chapter_2.xhtml#_idIndexMarker149">60</a></p>&#13;
    <p class="Index-Level-1">Electronic Numerical Integrator and Computer (ENIAC) <a href="Chapter_1.xhtml#_idIndexMarker029">15</a>, <a href="Chapter_1.xhtml#_idIndexMarker030">16</a></p>&#13;
    <p class="Index-Level-1">encoders <a href="Chapter_10.xhtml#_idIndexMarker810">273</a></p>&#13;
    <p class="Index-Level-1">epsilon-greedy <a href="Chapter_11.xhtml#_idIndexMarker857">301</a></p>&#13;
    <p class="Index-Level-1">error metrics</p>&#13;
    <p class="Index-Level-2">for time series <a href="Chapter_4.xhtml#_idIndexMarker299">106</a></p>&#13;
    <p class="Index-Level-1">ETT (Electricity Transformer Temperature) <a href="Chapter_10.xhtml#_idIndexMarker829">279</a></p>&#13;
    <p class="Index-Level-1">Euclidean distance <a href="Chapter_4.xhtml#_idIndexMarker343">116</a></p>&#13;
    <p class="Index-Level-1">experience replay technique <a href="Chapter_11.xhtml#_idIndexMarker872">304</a></p>&#13;
    <p class="Index-Level-1">exploration versus exploitation dilemma <a href="Chapter_11.xhtml#_idIndexMarker856">301</a></p>&#13;
    <p class="Index-Level-1">exploratory analysis <a href="Chapter_2.xhtml#_idIndexMarker072">36</a></p>&#13;
    <p class="Index-Level-1">exploratory data analysis (EDA) <a href="Chapter_2.xhtml#_idIndexMarker069">36</a></p>&#13;
    <p class="Index-Level-1">exponential smoothing <a href="Chapter_5.xhtml#_idIndexMarker439">140</a>, <a href="Chapter_5.xhtml#_idIndexMarker441">141</a>, <a href="Chapter_5.xhtml#_idIndexMarker445">142</a></p>&#13;
    <p class="Index-Level-1">Exponential Smoothing (ES) <a href="Chapter_10.xhtml#_idIndexMarker795">269</a>, <a href="Chapter_10.xhtml#_idIndexMarker821">275</a>, <a href="Chapter_12.xhtml#_idIndexMarker919">335</a></p>&#13;
    <p class="Index-Level-1">exponential smoothing model <a href="Chapter_5.xhtml#_idIndexMarker499">157</a>, <a href="Chapter_5.xhtml#_idIndexMarker500">158</a></p>&#13;
    <p class="Index-Level-2">used, for creating forecast <a href="Chapter_5.xhtml#_idIndexMarker498">157</a></p>&#13;
    <p class="Index-Level-1">Extreme Studentized Deviate (ESD) <a href="Chapter_6.xhtml#_idIndexMarker528">170</a></p>&#13;
    <p class="Index-Section-Head">F</p>&#13;
    <p class="Index-Level-1">Facebook <a href="Chapter_6.xhtml#_idIndexMarker523">170</a></p>&#13;
    <p class="Index-Level-1">false alarm ratio <a href="Chapter_4.xhtml#_idIndexMarker338">115</a></p>&#13;
    <p class="Index-Level-1">false negatives (FN) <a href="Chapter_4.xhtml#_idIndexMarker333">115</a></p>&#13;
    <p class="Index-Level-1">false positive rate (FPR) <a href="Chapter_4.xhtml#_idIndexMarker337">115</a></p>&#13;
    <p class="Index-Level-1">false positives (FP) <a href="Chapter_4.xhtml#_idIndexMarker332">115</a></p>&#13;
    <p class="Index-Level-1">feature engineering <a href="Chapter_3.xhtml#_idIndexMarker163">68</a></p>&#13;
    <p class="Index-Level-2">about <a href="Chapter_3.xhtml#_idIndexMarker188">74</a>, <a href="Chapter_3.xhtml#_idIndexMarker192">75</a></p>&#13;
    <p class="Index-Level-2">date- and time-related features <a href="Chapter_3.xhtml#_idIndexMarker194">75</a></p>&#13;
    <p class="Index-Level-2">ROCKET features <a href="Chapter_3.xhtml#_idIndexMarker196">76</a>, <a href="Chapter_3.xhtml#_idIndexMarker201">77</a></p>&#13;
    <p class="Index-Level-2">shapelets <a href="Chapter_3.xhtml#_idIndexMarker207">77</a></p>&#13;
    <p class="Index-Level-1">feature leakage <a href="Chapter_2.xhtml#_idIndexMarker112">49</a></p>&#13;
    <p class="Index-Level-1">feature transforms <a href="Chapter_3.xhtml#_idIndexMarker161">68</a></p>&#13;
    <p class="Index-Level-2">about <a href="Chapter_3.xhtml#_idIndexMarker165">69</a></p>&#13;
    <p class="Index-Level-2">imputation <a href="Chapter_3.xhtml#_idIndexMarker184">73</a></p>&#13;
    <p class="Index-Level-2">log transformation <a href="Chapter_3.xhtml#_idIndexMarker172">71</a></p>&#13;
    <p class="Index-Level-2">power transformation <a href="Chapter_3.xhtml#_idIndexMarker174">71</a></p>&#13;
    <p class="Index-Level-2">scaling <a href="Chapter_3.xhtml#_idIndexMarker167">70</a></p>&#13;
    <p class="Index-Level-1">feedforward propagation <a href="Chapter_10.xhtml#_idIndexMarker778">264</a></p>&#13;
    <p class="Index-Level-1">filters <a href="Chapter_3.xhtml#_idIndexMarker199">76</a></p>&#13;
    <p class="Index-Level-1">forecast</p>&#13;
    <p class="Index-Level-2">creating, with exponential smoothing model <a href="Chapter_5.xhtml#_idIndexMarker497">156</a></p>&#13;
    <p class="Index-Level-1">forecast error <a href="Chapter_4.xhtml#_idIndexMarker304">107</a></p>&#13;
    <p class="Index-Level-1">forecasting <a href="Chapter_4.xhtml#_idIndexMarker244">95</a></p>&#13;
    <p class="Index-Level-1">Forecasting <a href="Chapter_1.xhtml#_idIndexMarker011">6</a></p>&#13;
    <p class="Index-Level-1">fully connected feed-forward neural network <a href="Chapter_4.xhtml#_idIndexMarker270">98</a></p>&#13;
    <p class="Index-Level-1">fully connected network <a href="Chapter_10.xhtml#_idIndexMarker831">281</a>, <a href="Chapter_10.xhtml#_idIndexMarker835">282</a>, <a href="Chapter_10.xhtml#_idIndexMarker836">283</a>, <a href="Chapter_10.xhtml#_idIndexMarker837">284</a>, <a href="Chapter_10.xhtml#_idIndexMarker838">285</a>, <a href="Chapter_10.xhtml#_idIndexMarker839">286</a>, <a href="Chapter_10.xhtml#_idIndexMarker841">288</a></p>&#13;
    <p class="Index-Level-1">Fully Connected Networks (FCNs) <a href="Chapter_10.xhtml#_idIndexMarker815">273</a></p>&#13;
    <p class="Index-Level-1">fully convolutional neural network (FCN) <a href="Chapter_10.xhtml#_idIndexMarker816">273</a></p>&#13;
    <p class="Index-Level-1">fuzzy modeling <a href="Chapter_9.xhtml#_idIndexMarker720">240</a>, <a href="Chapter_9.xhtml#_idIndexMarker723">241</a>, <a href="Chapter_9.xhtml#_idIndexMarker725">242</a></p>&#13;
    <p class="Index-Level-1">fuzzy set theory <a href="Chapter_9.xhtml#_idIndexMarker721">240</a></p>&#13;
    <p class="Index-Level-1">fuzzy time-series</p>&#13;
    <p class="Index-Level-2">implementing, in Python <a href="Chapter_9.xhtml#_idIndexMarker748">252</a>, <a href="Chapter_9.xhtml#_idIndexMarker749">253</a>, <a href="Chapter_9.xhtml#_idIndexMarker752">254</a>, <a href="Chapter_9.xhtml#_idIndexMarker753">255</a>, <a href="Chapter_9.xhtml#_idIndexMarker756">256</a></p>&#13;
    <p class="Index-Section-Head">G</p>&#13;
    <p class="Index-Level-1">GARCH (generalized ARCH) <a href="Chapter_5.xhtml#_idIndexMarker456">144</a></p>&#13;
    <p class="Index-Level-1">Gated Recurrent Unit (GRU) <a href="Chapter_12.xhtml#_idIndexMarker902">323</a></p>&#13;
    <p class="Index-Level-1">Gaussian Process <a href="Chapter_12.xhtml#_idIndexMarker917">333</a>, <a href="Chapter_12.xhtml#_idIndexMarker918">334</a></p>&#13;
    <p class="Index-Level-1">Gaussian Process (GP) <a href="Chapter_10.xhtml#_idIndexMarker804">271</a></p>&#13;
    <p class="Index-Level-1">Generalized Additive Model (GAM) <a href="Chapter_4.xhtml#_idIndexMarker395">129</a>, <a href="Chapter_6.xhtml#_idIndexMarker525">170</a>, <a href="Chapter_9.xhtml#_idIndexMarker702">238</a></p>&#13;
    <p class="Index-Level-1">generalized linear model (GLM) <a href="Chapter_1.xhtml#_idIndexMarker038">19</a></p>&#13;
    <p class="Index-Level-1">Generalized Linear Model (GLM) <a href="Chapter_4.xhtml#_idIndexMarker398">129</a></p>&#13;
    <p class="Index-Level-1">Generalized random shapelet forest (gRFS) <a href="Chapter_4.xhtml#_idIndexMarker358">119</a></p>&#13;
    <p class="Index-Level-1">generative adversarial networks (GANs) <a href="Chapter_10.xhtml#_idIndexMarker766">261</a></p>&#13;
    <p class="Index-Level-1">global max-pooling <a href="Chapter_3.xhtml#_idIndexMarker202">77</a></p>&#13;
    <p class="Index-Level-1">Global Temperature Time Series</p>&#13;
    <p class="Index-Level-2">reference link <a href="Chapter_2.xhtml#_idIndexMarker136">57</a></p>&#13;
    <p class="Index-Level-1">Gluon-TS <a href="Chapter_10.xhtml#_idIndexMarker802">271</a></p>&#13;
    <p class="Index-Level-1">Google Analytics <a href="Chapter_6.xhtml#_idIndexMarker517">169</a></p>&#13;
    <p class="Index-Level-1">Gradient Boosted Regression Tree (GBRT) <a href="Chapter_7.xhtml#_idIndexMarker573">191</a></p>&#13;
    <p class="Index-Level-1">gradient boosted trees</p>&#13;
    <p class="Index-Level-2">implementations <a href="Chapter_4.xhtml#_idIndexMarker288">102</a></p>&#13;
    <p class="Index-Level-1">gradient boosting <a href="Chapter_4.xhtml#_idIndexMarker287">102</a>, <a href="Chapter_7.xhtml#_idIndexMarker571">191</a>, <a href="Chapter_7.xhtml#_idIndexMarker576">192</a>, <a href="Chapter_7.xhtml#_idIndexMarker605">199</a>, <a href="Chapter_7.xhtml#_idIndexMarker606">200</a>, <a href="Chapter_7.xhtml#_idIndexMarker609">201</a>, <a href="Chapter_7.xhtml#_idIndexMarker611">202</a>, <a href="Chapter_7.xhtml#_idIndexMarker615">203</a>, <a href="Chapter_7.xhtml#_idIndexMarker617">204</a></p>&#13;
    <p class="Index-Level-1">Gradient Boosting Machine (GBM) <a href="Chapter_7.xhtml#_idIndexMarker572">191</a></p>&#13;
    <p class="Index-Level-1">Granger causality <a href="Chapter_4.xhtml#_idIndexMarker346">117</a></p>&#13;
    <p class="Index-Level-1">Graphics Processing Units (GPUs) <a href="Chapter_10.xhtml#_idIndexMarker787">265</a></p>&#13;
    <p class="Index-Section-Head">H</p>&#13;
    <p class="Index-Level-1">heterogeneous ensembles <a href="Chapter_12.xhtml#_idIndexMarker897">321</a></p>&#13;
    <p class="Index-Level-1">hidden Markov model (HMM) <a href="Chapter_9.xhtml#_idIndexMarker718">239</a></p>&#13;
    <p class="Index-Level-1">Hierarchical Vote Collective of Transformation-Based Ensembles (HIVE-COTE) <a href="Chapter_4.xhtml#_idIndexMarker379">123</a></p>&#13;
    <p class="Index-Level-1">HIVE-COTE (Hierarchical Vote Collective of Transformation-Based Ensembles) <a href="Chapter_10.xhtml#_idIndexMarker799">270</a></p>&#13;
    <p class="Index-Level-1">Hoeffding Tree <a href="Chapter_8.xhtml#_idIndexMarker647">215</a></p>&#13;
    <p class="Index-Level-1">Holdout <a href="Chapter_8.xhtml#_idIndexMarker635">212</a></p>&#13;
    <p class="Index-Level-1">holiday features <a href="Chapter_3.xhtml#_idIndexMarker223">83</a>, <a href="Chapter_3.xhtml#_idIndexMarker224">84</a>, <a href="Chapter_3.xhtml#_idIndexMarker225">85</a></p>&#13;
    <p class="Index-Level-1">Holtz-Winters method <a href="Chapter_5.xhtml#_idIndexMarker444">142</a></p>&#13;
    <p class="Index-Section-Head">I</p>&#13;
    <p class="Index-Level-1">identify function <a href="Chapter_10.xhtml#_idIndexMarker791">266</a></p>&#13;
    <p class="Index-Level-1">imputation <a href="Chapter_3.xhtml#_idIndexMarker220">82</a>, <a href="Chapter_3.xhtml#_idIndexMarker222">83</a></p>&#13;
    <p class="Index-Level-1">imputation techniques <a href="Chapter_3.xhtml#_idIndexMarker185">73</a></p>&#13;
    <p class="Index-Level-1">InceptionTime <a href="Chapter_10.xhtml#_idIndexMarker813">273</a>, <a href="Chapter_10.xhtml#_idIndexMarker817">274</a></p>&#13;
    <p class="Index-Level-1">inference <a href="Chapter_4.xhtml#_idIndexMarker255">96</a></p>&#13;
    <p class="Index-Level-1">Informer <a href="Chapter_10.xhtml#_idIndexMarker827">278</a>, <a href="Chapter_10.xhtml#_idIndexMarker828">279</a></p>&#13;
    <p class="Index-Level-1">integrated development environment (IDE) <a href="Chapter_1.xhtml#_idIndexMarker054">27</a></p>&#13;
    <p class="Index-Level-1">integration <a href="Chapter_5.xhtml#_idIndexMarker424">138</a></p>&#13;
    <p class="Index-Level-1">interquartile range <a href="Chapter_2.xhtml#_idIndexMarker104">45</a></p>&#13;
    <p class="Index-Section-Head">J</p>&#13;
    <p class="Index-Level-1">JupyterLab <a href="Chapter_1.xhtml#_idIndexMarker052">26</a>, <a href="Chapter_1.xhtml#_idIndexMarker053">27</a></p>&#13;
    <p class="Index-Level-1">Jupyter Notebook <a href="Chapter_1.xhtml#_idIndexMarker050">26</a></p>&#13;
    <p class="Index-Section-Head">K</p>&#13;
    <p class="Index-Level-1">K-Armed Bandit <a href="Chapter_8.xhtml#_idIndexMarker638">212</a></p>&#13;
    <p class="Index-Level-1">Kats installation <a href="Chapter_7.xhtml#_idIndexMarker619">205</a>, <a href="Chapter_7.xhtml#_idIndexMarker621">206</a>, <a href="Chapter_7.xhtml#_idIndexMarker623">207</a></p>&#13;
    <p class="Index-Level-1">kernels <a href="Chapter_3.xhtml#_idIndexMarker198">76</a></p>&#13;
    <p class="Index-Level-1">K-nearest neighbors</p>&#13;
    <p class="Index-Level-2">with dynamic time warping <a href="Chapter_7.xhtml#_idIndexMarker566">189</a></p>&#13;
    <p class="Index-Level-2">with dynamic time wraping, in Python <a href="Chapter_7.xhtml#_idIndexMarker584">193</a>, <a href="Chapter_7.xhtml#_idIndexMarker587">194</a>, <a href="Chapter_7.xhtml#_idIndexMarker591">195</a></p>&#13;
    <p class="Index-Section-Head">L</p>&#13;
    <p class="Index-Level-1">label drift <a href="Chapter_8.xhtml#_idIndexMarker662">217</a></p>&#13;
    <p class="Index-Level-1">least-squares algorithm <a href="Chapter_5.xhtml#_idIndexMarker455">144</a></p>&#13;
    <p class="Index-Level-1">least squares method <a href="Chapter_1.xhtml#_idIndexMarker022">12</a></p>&#13;
    <p class="Index-Level-1">lex parsimoniae <a href="Chapter_5.xhtml#_idIndexMarker432">139</a></p>&#13;
    <p class="Index-Level-1">libraries</p>&#13;
    <p class="Index-Level-2">installing <a href="Chapter_1.xhtml#_idIndexMarker042">22</a>, <a href="Chapter_1.xhtml#_idIndexMarker045">23</a>, <a href="Chapter_1.xhtml#_idIndexMarker048">25</a></p>&#13;
    <p class="Index-Level-1">life table <a href="Chapter_1.xhtml#_idIndexMarker013">7</a></p>&#13;
    <p class="Index-Level-1">Light Gradient Boosting Machine (LightGBM) <a href="Chapter_7.xhtml#_idIndexMarker574">191</a></p>&#13;
    <p class="Index-Level-1">Linear Four Rates <a href="Chapter_8.xhtml#_idIndexMarker667">220</a></p>&#13;
    <p class="Index-Level-1">linear regression (LR) <a href="Chapter_9.xhtml#_idIndexMarker705">238</a></p>&#13;
    <p class="Index-Level-1">line chart <a href="Chapter_2.xhtml#_idIndexMarker119">51</a></p>&#13;
    <p class="Index-Level-1">log transformation <a href="Chapter_3.xhtml#_idIndexMarker171">71</a>, <a href="Chapter_3.xhtml#_idIndexMarker218">82</a></p>&#13;
    <p class="Index-Level-1">log transformations <a href="Chapter_3.xhtml#_idIndexMarker210">78</a>, <a href="Chapter_3.xhtml#_idIndexMarker212">79</a>, <a href="Chapter_3.xhtml#_idIndexMarker214">81</a></p>&#13;
    <p class="Index-Level-1">long short-term memory (LSTM) <a href="Chapter_4.xhtml#_idIndexMarker290">103</a>, <a href="Chapter_10.xhtml#_idIndexMarker785">265</a></p>&#13;
    <p class="Index-Level-1">Long Short-Term Memory (LSTM) <a href="Chapter_12.xhtml#_idIndexMarker903">323</a>, <a href="Chapter_12.xhtml#_idIndexMarker911">329</a></p>&#13;
    <p class="Index-Level-1">long short-term models (LSTMs) <a href="Chapter_10.xhtml#_idIndexMarker796">269</a></p>&#13;
    <p class="Index-Level-1">loss function <a href="Chapter_4.xhtml#_idIndexMarker297">106</a></p>&#13;
    <p class="Index-Section-Head">M</p>&#13;
    <p class="Index-Level-1">machine learning <a href="Chapter_4.xhtml#_idIndexMarker238">93</a>, <a href="Chapter_4.xhtml#_idIndexMarker267">98</a></p>&#13;
    <p class="Index-Level-2">history <a href="Chapter_4.xhtml#_idIndexMarker268">98</a>, <a href="Chapter_4.xhtml#_idIndexMarker272">99</a></p>&#13;
    <p class="Index-Level-2">with time series <a href="Chapter_4.xhtml#_idIndexMarker239">94</a></p>&#13;
    <p class="Index-Level-2">workflow <a href="Chapter_4.xhtml#_idIndexMarker292">103</a>, <a href="Chapter_4.xhtml#_idIndexMarker293">104</a>, <a href="Chapter_4.xhtml#_idIndexMarker294">105</a></p>&#13;
    <p class="Index-Level-1">machine learning algorithms</p>&#13;
    <p class="Index-Level-2">for time series <a href="Chapter_4.xhtml#_idIndexMarker347">117</a></p>&#13;
    <p class="Index-Level-2">query time, versus accuracy <a href="Chapter_4.xhtml#_idIndexMarker385">124</a>, <a href="Chapter_4.xhtml#_idIndexMarker386">125</a></p>&#13;
    <p class="Index-Level-1">machine learning methods</p>&#13;
    <p class="Index-Level-2">for time series <a href="Chapter_7.xhtml#_idIndexMarker559">186</a>, <a href="Chapter_7.xhtml#_idIndexMarker561">187</a></p>&#13;
    <p class="Index-Level-1">magnetoencephalography (MEG) <a href="Chapter_4.xhtml#_idIndexMarker351">118</a></p>&#13;
    <p class="Index-Level-1">Markov assumption <a href="Chapter_9.xhtml#_idIndexMarker714">239</a></p>&#13;
    <p class="Index-Level-1">Markovian <a href="Chapter_9.xhtml#_idIndexMarker712">239</a></p>&#13;
    <p class="Index-Level-1">Markov models <a href="Chapter_9.xhtml#_idIndexMarker710">239</a></p>&#13;
    <p class="Index-Level-2">hidden Markov model (HMM) <a href="Chapter_9.xhtml#_idIndexMarker717">239</a></p>&#13;
    <p class="Index-Level-2">implementing, in Python <a href="Chapter_9.xhtml#_idIndexMarker743">251</a>, <a href="Chapter_9.xhtml#_idIndexMarker745">252</a></p>&#13;
    <p class="Index-Level-1">Markov Process <a href="Chapter_9.xhtml#_idIndexMarker713">239</a></p>&#13;
    <p class="Index-Level-1">Markov property <a href="Chapter_9.xhtml#_idIndexMarker711">239</a></p>&#13;
    <p class="Index-Level-1">Markov switching model</p>&#13;
    <p class="Index-Level-2">implementing, in Python <a href="Chapter_9.xhtml#_idIndexMarker737">248</a>, <a href="Chapter_9.xhtml#_idIndexMarker739">249</a>, <a href="Chapter_9.xhtml#_idIndexMarker741">250</a></p>&#13;
    <p class="Index-Level-1">maximum-likelihood estimation (MLE) <a href="Chapter_5.xhtml#_idIndexMarker434">139</a></p>&#13;
    <p class="Index-Level-1">max pooling <a href="Chapter_3.xhtml#_idIndexMarker203">77</a></p>&#13;
    <p class="Index-Level-1">mean <a href="Chapter_2.xhtml#_idIndexMarker097">44</a></p>&#13;
    <p class="Index-Level-1">mean absolute error (MAE) <a href="Chapter_4.xhtml#_idIndexMarker310">109</a>, <a href="Chapter_4.xhtml#_idIndexMarker314">110</a>, <a href="Chapter_8.xhtml#_idIndexMarker682">228</a></p>&#13;
    <p class="Index-Level-1">mean absolute percentage error (MAPE) <a href="Chapter_9.xhtml#_idIndexMarker709">238</a></p>&#13;
    <p class="Index-Level-1">mean percentage error (MAPE) <a href="Chapter_4.xhtml#_idIndexMarker318">111</a></p>&#13;
    <p class="Index-Level-1">mean relative absolute error (MRAE) <a href="Chapter_4.xhtml#_idIndexMarker309">108</a>, <a href="Chapter_4.xhtml#_idIndexMarker322">113</a></p>&#13;
    <p class="Index-Level-1">mean squared error (MSE) <a href="Chapter_4.xhtml#_idIndexMarker311">109</a>, <a href="Chapter_4.xhtml#_idIndexMarker313">110</a></p>&#13;
    <p class="Index-Level-1">Mean Squared Error (MSE) <a href="Chapter_8.xhtml#_idIndexMarker685">229</a></p>&#13;
    <p class="Index-Level-1">median <a href="Chapter_2.xhtml#_idIndexMarker102">45</a></p>&#13;
    <p class="Index-Level-1">median absolute deviation (MAD) <a href="Chapter_6.xhtml#_idIndexMarker510">165</a></p>&#13;
    <p class="Index-Level-1">median absolute error (MdAE) <a href="Chapter_4.xhtml#_idIndexMarker317">111</a></p>&#13;
    <p class="Index-Level-1">medicine <a href="Chapter_1.xhtml#_idIndexMarker031">16</a>, <a href="Chapter_1.xhtml#_idIndexMarker033">17</a></p>&#13;
    <p class="Index-Level-1">meteorology <a href="Chapter_1.xhtml#_idIndexMarker027">14</a></p>&#13;
    <p class="Index-Level-1">metric <a href="Chapter_4.xhtml#_idIndexMarker298">106</a></p>&#13;
    <p class="Index-Level-1">micro prediction time-series leaderboard</p>&#13;
    <p class="Index-Level-2">reference link <a href="Chapter_12.xhtml#_idIndexMarker895">321</a></p>&#13;
    <p class="Index-Level-1">Microsoft <a href="Chapter_6.xhtml#_idIndexMarker514">168</a></p>&#13;
    <p class="Index-Level-1">MINIROCKET <a href="Chapter_4.xhtml#_idIndexMarker360">119</a>, <a href="Chapter_4.xhtml#_idIndexMarker362">120</a></p>&#13;
    <p class="Index-Level-1">min-max scaling <a href="Chapter_3.xhtml#_idIndexMarker169">70</a></p>&#13;
    <p class="Index-Level-1">model-based imputation <a href="Chapter_3.xhtml#_idIndexMarker187">73</a></p>&#13;
    <p class="Index-Level-1">modeling</p>&#13;
    <p class="Index-Level-2">in Python <a href="Chapter_5.xhtml#_idIndexMarker474">148</a>, <a href="Chapter_5.xhtml#_idIndexMarker479">149</a>, <a href="Chapter_5.xhtml#_idIndexMarker480">150</a>, <a href="Chapter_5.xhtml#_idIndexMarker485">151</a>, <a href="Chapter_5.xhtml#_idIndexMarker487">152</a>, <a href="Chapter_5.xhtml#_idIndexMarker489">153</a>, <a href="Chapter_5.xhtml#_idIndexMarker491">154</a>, <a href="Chapter_5.xhtml#_idIndexMarker492">155</a></p>&#13;
    <p class="Index-Level-1">model selection <a href="Chapter_5.xhtml#_idIndexMarker431">139</a>, <a href="Chapter_8.xhtml#_idIndexMarker687">230</a>, <a href="Chapter_8.xhtml#_idIndexMarker688">231</a>, <a href="Chapter_8.xhtml#_idIndexMarker689">232</a></p>&#13;
    <p class="Index-Level-1">model stacking <a href="Chapter_3.xhtml#_idIndexMarker189">74</a></p>&#13;
    <p class="Index-Level-1">monotonicity <a href="Chapter_3.xhtml#_idIndexMarker175">71</a></p>&#13;
    <p class="Index-Level-1">moving average <a href="Chapter_5.xhtml#_idIndexMarker406">134</a></p>&#13;
    <p class="Index-Level-1">moving average (MA) <a href="Chapter_4.xhtml#_idIndexMarker396">129</a>, <a href="Chapter_9.xhtml#_idIndexMarker704">238</a></p>&#13;
    <p class="Index-Level-1">MrSEQL <a href="Chapter_4.xhtml#_idIndexMarker374">123</a></p>&#13;
    <p class="Index-Level-1">Multi-Armed Bandit <a href="Chapter_8.xhtml#_idIndexMarker637">212</a></p>&#13;
    <p class="Index-Level-1">Multi-Armed Bandit (MAB) <a href="Chapter_11.xhtml#_idIndexMarker862">302</a></p>&#13;
    <p class="Index-Level-1">multi-layer perceptron (MLP) <a href="Chapter_9.xhtml#_idIndexMarker706">238</a></p>&#13;
    <p class="Index-Level-1">multiplicative seasonality <a href="Chapter_5.xhtml#_idIndexMarker450">142</a></p>&#13;
    <p class="Index-Level-1">multivariate analysis <a href="Chapter_2.xhtml#_idIndexMarker079">38</a></p>&#13;
    <p class="Index-Level-1">multivariate time series <a href="Chapter_1.xhtml#_idIndexMarker003">4</a></p>&#13;
    <p class="Index-Level-1">multivariate time-series</p>&#13;
    <p class="Index-Level-2">forecasting <a href="Chapter_12.xhtml#_idIndexMarker892">320</a>, <a href="Chapter_12.xhtml#_idIndexMarker894">321</a>, <a href="Chapter_12.xhtml#_idIndexMarker898">322</a>, <a href="Chapter_12.xhtml#_idIndexMarker904">323</a>, <a href="Chapter_12.xhtml#_idIndexMarker906">324</a></p>&#13;
    <p class="Index-Level-1">multivariate time series classification</p>&#13;
    <p class="Index-Level-2">critical difference diagram <a href="Chapter_4.xhtml#_idIndexMarker391">127</a></p>&#13;
    <p class="Index-Level-1">Multivariate Time Series (MTS) <a href="Chapter_10.xhtml#_idIndexMarker814">273</a></p>&#13;
    <p class="Index-Level-1">Multivariate Unsupervised Symbols and Derivatives <a href="Chapter_4.xhtml#_idIndexMarker377">123</a></p>&#13;
    <p class="Index-Section-Head">N</p>&#13;
    <p class="Index-Level-1">natural language processing (NLP) <a href="Chapter_10.xhtml#_idIndexMarker794">269</a></p>&#13;
    <p class="Index-Level-1">N-BEATS <a href="Chapter_10.xhtml#_idIndexMarker819">275</a></p>&#13;
    <p class="Index-Level-1">nearest neighbor algorithm <a href="Chapter_4.xhtml#_idIndexMarker273">99</a></p>&#13;
    <p class="Index-Level-1">Neural Basis Expansion Analysis for interpretable Time-Series forecasting (N-BEATS) <a href="Chapter_12.xhtml#_idIndexMarker905">323</a>, <a href="Chapter_12.xhtml#_idIndexMarker910">327</a></p>&#13;
    <p class="Index-Level-1">neurites <a href="Chapter_10.xhtml#_idIndexMarker769">262</a></p>&#13;
    <p class="Index-Level-1">neurons <a href="Chapter_10.xhtml#_idIndexMarker768">262</a>, <a href="Chapter_10.xhtml#_idIndexMarker770">263</a>, <a href="Chapter_10.xhtml#_idIndexMarker774">264</a></p>&#13;
    <p class="Index-Level-1">non-linear methods <a href="Chapter_3.xhtml#_idIndexMarker166">70</a></p>&#13;
    <p class="Index-Level-1">normalized mean squared error (NMSE) <a href="Chapter_4.xhtml#_idIndexMarker320">112</a></p>&#13;
    <p class="Index-Level-1">normalized regression metrics <a href="Chapter_4.xhtml#_idIndexMarker321">112</a></p>&#13;
    <p class="Index-Level-1">NumPy <a href="Chapter_1.xhtml#_idIndexMarker055">28</a>, <a href="Chapter_1.xhtml#_idIndexMarker057">29</a></p>&#13;
    <p class="Index-Section-Head">O</p>&#13;
    <p class="Index-Level-1">objective function <a href="Chapter_4.xhtml#_idIndexMarker264">98</a></p>&#13;
    <p class="Index-Level-1">offline learning <a href="Chapter_8.xhtml#_idIndexMarker628">210</a></p>&#13;
    <p class="Index-Level-2">versus online learning <a href="Chapter_8.xhtml#_idIndexMarker632">210</a>, <a href="Chapter_8.xhtml#_idIndexMarker634">211</a></p>&#13;
    <p class="Index-Level-1">online algorithms <a href="Chapter_8.xhtml#_idIndexMarker639">213</a>, <a href="Chapter_8.xhtml#_idIndexMarker644">214</a>, <a href="Chapter_8.xhtml#_idIndexMarker650">215</a></p>&#13;
    <p class="Index-Level-1">online learning <a href="Chapter_8.xhtml#_idIndexMarker629">210</a></p>&#13;
    <p class="Index-Level-2">use cases <a href="Chapter_8.xhtml#_idIndexMarker630">210</a></p>&#13;
    <p class="Index-Level-2">versus offline learning <a href="Chapter_8.xhtml#_idIndexMarker631">210</a>, <a href="Chapter_8.xhtml#_idIndexMarker633">211</a></p>&#13;
    <p class="Index-Level-1">online mean <a href="Chapter_8.xhtml#_idIndexMarker641">213</a></p>&#13;
    <p class="Index-Level-1">online variance <a href="Chapter_8.xhtml#_idIndexMarker642">213</a></p>&#13;
    <p class="Index-Level-1">Our World in Data (OWID) <a href="Chapter_2.xhtml#_idIndexMarker107">46</a></p>&#13;
    <p class="Index-Level-1">outlier detection <a href="Chapter_4.xhtml#_idIndexMarker249">95</a></p>&#13;
    <p class="Index-Level-1">out-of-bag (OOB) error <a href="Chapter_12.xhtml#_idIndexMarker896">321</a></p>&#13;
    <p class="Index-Level-1">out-of-sample testing <a href="Chapter_4.xhtml#_idIndexMarker296">105</a></p>&#13;
    <p class="Index-Section-Head">P</p>&#13;
    <p class="Index-Level-1">pandas <a href="Chapter_1.xhtml#_idIndexMarker058">30</a>, <a href="Chapter_1.xhtml#_idIndexMarker062">31</a>, <a href="Chapter_2.xhtml#_idIndexMarker089">41</a>, <a href="Chapter_2.xhtml#_idIndexMarker092">42</a>, <a href="Chapter_2.xhtml#_idIndexMarker094">43</a></p>&#13;
    <p class="Index-Level-1">paydays</p>&#13;
    <p class="Index-Level-2">obtaining <a href="Chapter_3.xhtml#_idIndexMarker228">86</a></p>&#13;
    <p class="Index-Level-1">Pearson correlation coefficient <a href="Chapter_2.xhtml#_idIndexMarker116">50</a></p>&#13;
    <p class="Index-Level-1">percentile <a href="Chapter_2.xhtml#_idIndexMarker105">45</a></p>&#13;
    <p class="Index-Level-1">perceptron <a href="Chapter_4.xhtml#_idIndexMarker269">98</a>, <a href="Chapter_10.xhtml#_idIndexMarker779">264</a></p>&#13;
    <p class="Index-Level-1">perceptron model <a href="Chapter_10.xhtml#_idIndexMarker775">264</a></p>&#13;
    <p class="Index-Level-1">periodogram <a href="Chapter_2.xhtml#_idIndexMarker158">64</a></p>&#13;
    <p class="Index-Level-1">Piecewise Aggregate Approximation (PAA) <a href="Chapter_4.xhtml#_idIndexMarker368">121</a></p>&#13;
    <p class="Index-Level-1">pip <a href="Chapter_1.xhtml#_idIndexMarker047">25</a></p>&#13;
    <p class="Index-Level-1">Pmdarima <a href="Chapter_5.xhtml#_idIndexMarker464">146</a></p>&#13;
    <p class="Index-Level-1">policy-based learning <a href="Chapter_11.xhtml#_idIndexMarker854">300</a></p>&#13;
    <p class="Index-Level-1">Positive Proportion Value (PPV) <a href="Chapter_3.xhtml#_idIndexMarker204">77</a></p>&#13;
    <p class="Index-Level-1">power function <a href="Chapter_3.xhtml#_idIndexMarker176">71</a></p>&#13;
    <p class="Index-Level-1">power transformations <a href="Chapter_3.xhtml#_idIndexMarker211">78</a>, <a href="Chapter_3.xhtml#_idIndexMarker213">79</a>, <a href="Chapter_3.xhtml#_idIndexMarker215">81</a></p>&#13;
    <p class="Index-Level-2">Box-Cox transformation <a href="Chapter_3.xhtml#_idIndexMarker179">72</a></p>&#13;
    <p class="Index-Level-2">Yeo-Johnson transformation <a href="Chapter_3.xhtml#_idIndexMarker181">72</a></p>&#13;
    <p class="Index-Level-1">power transforms <a href="Chapter_3.xhtml#_idIndexMarker173">71</a></p>&#13;
    <p class="Index-Level-1">precision <a href="Chapter_4.xhtml#_idIndexMarker331">114</a></p>&#13;
    <p class="Index-Level-1">prediction <a href="Chapter_4.xhtml#_idIndexMarker256">96</a></p>&#13;
    <p class="Index-Level-1">prediction error <a href="Chapter_4.xhtml#_idIndexMarker302">107</a></p>&#13;
    <p class="Index-Level-1">Prequential Evaluation <a href="Chapter_8.xhtml#_idIndexMarker636">212</a></p>&#13;
    <p class="Index-Level-1">Principal Component Analysis (PCA) <a href="Chapter_10.xhtml#_idIndexMarker809">272</a></p>&#13;
    <p class="Index-Level-1">probabilistic libraries <a href="Chapter_9.xhtml#_idIndexMarker698">237</a></p>&#13;
    <p class="Index-Level-1">probabilistic models <a href="Chapter_9.xhtml#_idIndexMarker691">236</a></p>&#13;
    <p class="Index-Level-2">for time-series <a href="Chapter_9.xhtml#_idIndexMarker692">236</a></p>&#13;
    <p class="Index-Level-1">probability <a href="Chapter_9.xhtml#_idIndexMarker690">235</a></p>&#13;
    <p class="Index-Level-1">probability drift <a href="Chapter_8.xhtml#_idIndexMarker658">217</a></p>&#13;
    <p class="Index-Level-1">probability ranking principle (PRP) <a href="Chapter_11.xhtml#_idIndexMarker868">303</a></p>&#13;
    <p class="Index-Level-1">Prophet model <a href="Chapter_9.xhtml#_idIndexMarker695">236</a>, <a href="Chapter_9.xhtml#_idIndexMarker700">237</a></p>&#13;
    <p class="Index-Level-2">forecasting model <a href="Chapter_9.xhtml#_idIndexMarker701">237</a>, <a href="Chapter_9.xhtml#_idIndexMarker703">238</a></p>&#13;
    <p class="Index-Level-2">implementing, in Python <a href="Chapter_9.xhtml#_idIndexMarker731">245</a>, <a href="Chapter_9.xhtml#_idIndexMarker733">246</a>, <a href="Chapter_9.xhtml#_idIndexMarker735">247</a></p>&#13;
    <p class="Index-Level-1">Proximity Forest (PF) <a href="Chapter_4.xhtml#_idIndexMarker364">121</a></p>&#13;
    <p class="Index-Level-1">Pruned Exact Linear Time (Pelt) <a href="Chapter_6.xhtml#_idIndexMarker536">174</a></p>&#13;
    <p class="Index-Level-1">pytest documentation</p>&#13;
    <p class="Index-Level-2">reference link <a href="Chapter_1.xhtml#_idIndexMarker067">33</a></p>&#13;
    <p class="Index-Level-1">Python</p>&#13;
    <p class="Index-Level-2">best practice <a href="Chapter_1.xhtml#_idIndexMarker063">31</a>, <a href="Chapter_1.xhtml#_idIndexMarker064">32</a></p>&#13;
    <p class="Index-Level-2">for time series <a href="Chapter_1.xhtml#_idIndexMarker036">18</a>, <a href="Chapter_1.xhtml#_idIndexMarker037">19</a>, <a href="Chapter_1.xhtml#_idIndexMarker040">21</a>, <a href="Chapter_1.xhtml#_idIndexMarker041">22</a></p>&#13;
    <p class="Index-Level-2">modeling <a href="Chapter_5.xhtml#_idIndexMarker475">148</a>, <a href="Chapter_5.xhtml#_idIndexMarker478">149</a>, <a href="Chapter_5.xhtml#_idIndexMarker481">150</a>, <a href="Chapter_5.xhtml#_idIndexMarker484">151</a>, <a href="Chapter_5.xhtml#_idIndexMarker486">152</a>, <a href="Chapter_5.xhtml#_idIndexMarker488">153</a>, <a href="Chapter_5.xhtml#_idIndexMarker490">154</a>, <a href="Chapter_5.xhtml#_idIndexMarker493">155</a></p>&#13;
    <p class="Index-Level-2">practice <a href="Chapter_6.xhtml#_idIndexMarker543">177</a></p>&#13;
    <p class="Index-Level-1">Python exercise <a href="Chapter_9.xhtml#_idIndexMarker729">245</a></p>&#13;
    <p class="Index-Level-2">about <a href="Chapter_7.xhtml#_idIndexMarker577">192</a></p>&#13;
    <p class="Index-Level-2">BSTS model, implementing <a href="Chapter_9.xhtml#_idIndexMarker757">256</a>, <a href="Chapter_9.xhtml#_idIndexMarker760">257</a>, <a href="Chapter_9.xhtml#_idIndexMarker762">258</a>, <a href="Chapter_9.xhtml#_idIndexMarker763">259</a></p>&#13;
    <p class="Index-Level-2">fuzzy time-series model, implementing <a href="Chapter_9.xhtml#_idIndexMarker747">252</a>, <a href="Chapter_9.xhtml#_idIndexMarker750">253</a>, <a href="Chapter_9.xhtml#_idIndexMarker751">254</a>, <a href="Chapter_9.xhtml#_idIndexMarker754">255</a>, <a href="Chapter_9.xhtml#_idIndexMarker755">256</a></p>&#13;
    <p class="Index-Level-2">gradient boosting <a href="Chapter_7.xhtml#_idIndexMarker604">199</a>, <a href="Chapter_7.xhtml#_idIndexMarker607">200</a>, <a href="Chapter_7.xhtml#_idIndexMarker608">201</a>, <a href="Chapter_7.xhtml#_idIndexMarker610">202</a>, <a href="Chapter_7.xhtml#_idIndexMarker614">203</a>, <a href="Chapter_7.xhtml#_idIndexMarker616">204</a></p>&#13;
    <p class="Index-Level-2">Kats installation <a href="Chapter_7.xhtml#_idIndexMarker618">205</a>, <a href="Chapter_7.xhtml#_idIndexMarker620">206</a>, <a href="Chapter_7.xhtml#_idIndexMarker624">207</a></p>&#13;
    <p class="Index-Level-2">K-nearest neighbors, with dynamic time wraping <a href="Chapter_7.xhtml#_idIndexMarker583">193</a>, <a href="Chapter_7.xhtml#_idIndexMarker586">194</a>, <a href="Chapter_7.xhtml#_idIndexMarker589">195</a></p>&#13;
    <p class="Index-Level-2">Markov switching model, implementing <a href="Chapter_9.xhtml#_idIndexMarker736">248</a>, <a href="Chapter_9.xhtml#_idIndexMarker738">249</a>, <a href="Chapter_9.xhtml#_idIndexMarker740">250</a>, <a href="Chapter_9.xhtml#_idIndexMarker742">251</a>, <a href="Chapter_9.xhtml#_idIndexMarker744">252</a></p>&#13;
    <p class="Index-Level-2">Prophet model, implementing <a href="Chapter_9.xhtml#_idIndexMarker730">245</a>, <a href="Chapter_9.xhtml#_idIndexMarker732">246</a>, <a href="Chapter_9.xhtml#_idIndexMarker734">247</a></p>&#13;
    <p class="Index-Level-2">Silverkite <a href="Chapter_7.xhtml#_idIndexMarker592">195</a>, <a href="Chapter_7.xhtml#_idIndexMarker594">197</a>, <a href="Chapter_7.xhtml#_idIndexMarker598">198</a>, <a href="Chapter_7.xhtml#_idIndexMarker600">199</a></p>&#13;
    <p class="Index-Level-2">virtual environment <a href="Chapter_7.xhtml#_idIndexMarker579">192</a>, <a href="Chapter_7.xhtml#_idIndexMarker581">193</a></p>&#13;
    <p class="Index-Level-1">Python libraries <a href="Chapter_5.xhtml#_idIndexMarker462">145</a></p>&#13;
    <p class="Index-Level-2">datetime <a href="Chapter_2.xhtml#_idIndexMarker083">39</a>, <a href="Chapter_2.xhtml#_idIndexMarker084">40</a>, <a href="Chapter_2.xhtml#_idIndexMarker086">41</a></p>&#13;
    <p class="Index-Level-2">pandas <a href="Chapter_2.xhtml#_idIndexMarker090">41</a>, <a href="Chapter_2.xhtml#_idIndexMarker091">42</a>, <a href="Chapter_2.xhtml#_idIndexMarker093">43</a>, <a href="Chapter_2.xhtml#_idIndexMarker095">44</a></p>&#13;
    <p class="Index-Level-2">requirements <a href="Chapter_2.xhtml#_idIndexMarker081">39</a></p>&#13;
    <p class="Index-Level-2">Statsmodels <a href="Chapter_5.xhtml#_idIndexMarker467">146</a>, <a href="Chapter_5.xhtml#_idIndexMarker471">147</a></p>&#13;
    <p class="Index-Level-1">Python practice</p>&#13;
    <p class="Index-Level-2">about <a href="Chapter_11.xhtml#_idIndexMarker874">305</a></p>&#13;
    <p class="Index-Level-2">anomaly detection <a href="Chapter_6.xhtml#_idIndexMarker545">178</a>, <a href="Chapter_6.xhtml#_idIndexMarker547">179</a>, <a href="Chapter_6.xhtml#_idIndexMarker551">180</a></p>&#13;
    <p class="Index-Level-2">change point detection (CPD) <a href="Chapter_6.xhtml#_idIndexMarker553">180</a>, <a href="Chapter_6.xhtml#_idIndexMarker556">181</a>, <a href="Chapter_6.xhtml#_idIndexMarker557">182</a></p>&#13;
    <p class="Index-Level-2">recommendations <a href="Chapter_11.xhtml#_idIndexMarker875">305</a>, <a href="Chapter_11.xhtml#_idIndexMarker876">306</a>, <a href="Chapter_11.xhtml#_idIndexMarker877">307</a>, <a href="Chapter_11.xhtml#_idIndexMarker878">308</a>, <a href="Chapter_11.xhtml#_idIndexMarker879">309</a>, <a href="Chapter_11.xhtml#_idIndexMarker880">310</a></p>&#13;
    <p class="Index-Level-2">requirements <a href="Chapter_6.xhtml#_idIndexMarker544">177</a></p>&#13;
    <p class="Index-Level-2">trading, with DQN <a href="Chapter_11.xhtml#_idIndexMarker882">310</a>, <a href="Chapter_11.xhtml#_idIndexMarker884">311</a>, <a href="Chapter_11.xhtml#_idIndexMarker885">312</a>, <a href="Chapter_11.xhtml#_idIndexMarker886">313</a>, <a href="Chapter_11.xhtml#_idIndexMarker887">314</a>, <a href="Chapter_11.xhtml#_idIndexMarker889">315</a>, <a href="Chapter_11.xhtml#_idIndexMarker890">316</a>, <a href="Chapter_11.xhtml#_idIndexMarker891">317</a></p>&#13;
    <p class="Index-Level-1">Python Practice <a href="Chapter_8.xhtml#_idIndexMarker676">223</a></p>&#13;
    <p class="Index-Level-1">Pytorch-forecasting <a href="Chapter_10.xhtml#_idIndexMarker807">271</a></p>&#13;
    <p class="Index-Section-Head">Q</p>&#13;
    <p class="Index-Level-1">Quantile Transformation <a href="Chapter_3.xhtml#_idIndexMarker183">73</a></p>&#13;
    <p class="Index-Level-1">quartile <a href="Chapter_2.xhtml#_idIndexMarker103">45</a></p>&#13;
    <p class="Index-Section-Head">R</p>&#13;
    <p class="Index-Level-1">random forest <a href="Chapter_4.xhtml#_idIndexMarker285">102</a></p>&#13;
    <p class="Index-Level-1">Random Interval Features (RIF) <a href="Chapter_4.xhtml#_idIndexMarker381">124</a></p>&#13;
    <p class="Index-Level-1">Random Interval Spectral Ensemble (RISE) <a href="Chapter_4.xhtml#_idIndexMarker380">124</a></p>&#13;
    <p class="Index-Level-1">recall <a href="Chapter_4.xhtml#_idIndexMarker327">114</a></p>&#13;
    <p class="Index-Level-1">receiver operator curve (ROC) <a href="Chapter_4.xhtml#_idIndexMarker335">115</a></p>&#13;
    <p class="Index-Level-1">recurrent neural network <a href="Chapter_10.xhtml#_idIndexMarker842">289</a>, <a href="Chapter_10.xhtml#_idIndexMarker843">290</a>, <a href="Chapter_10.xhtml#_idIndexMarker844">291</a></p>&#13;
    <p class="Index-Level-1">recurrent neural networks (RNNs) <a href="Chapter_10.xhtml#_idIndexMarker820">275</a></p>&#13;
    <p class="Index-Level-1">regression <a href="Chapter_4.xhtml#_idIndexMarker242">95</a>, <a href="Chapter_4.xhtml#_idIndexMarker258">97</a>, <a href="Chapter_4.xhtml#_idIndexMarker301">107</a>, <a href="Chapter_8.xhtml#_idIndexMarker679">225</a>, <a href="Chapter_8.xhtml#_idIndexMarker680">226</a>, <a href="Chapter_8.xhtml#_idIndexMarker683">228</a>, <a href="Chapter_8.xhtml#_idIndexMarker684">229</a></p>&#13;
    <p class="Index-Level-1">Regularized Greedy Forest (RGF) <a href="Chapter_7.xhtml#_idIndexMarker575">191</a></p>&#13;
    <p class="Index-Level-1">reinforcement learning <a href="Chapter_4.xhtml#_idIndexMarker250">95</a>, <a href="Chapter_4.xhtml#_idIndexMarker265">98</a></p>&#13;
    <p class="Index-Level-1">reinforcement learning <a href="Chapter_4.xhtml#_idIndexMarker253">96</a></p>&#13;
    <p class="Index-Level-1">reinforcement learning (RL)</p>&#13;
    <p class="Index-Level-2">about <a href="Chapter_11.xhtml#_idIndexMarker849">298</a>, <a href="Chapter_11.xhtml#_idIndexMarker851">299</a>, <a href="Chapter_11.xhtml#_idIndexMarker855">301</a></p>&#13;
    <p class="Index-Level-2">for time-series <a href="Chapter_11.xhtml#_idIndexMarker859">301</a></p>&#13;
    <p class="Index-Level-1">r-error (RE) <a href="Chapter_4.xhtml#_idIndexMarker308">108</a></p>&#13;
    <p class="Index-Level-1">residual <a href="Chapter_4.xhtml#_idIndexMarker303">107</a></p>&#13;
    <p class="Index-Level-1">residual sum of squares <a href="Chapter_4.xhtml#_idIndexMarker305">107</a></p>&#13;
    <p class="Index-Level-1">ResNets <a href="Chapter_10.xhtml#_idIndexMarker788">266</a></p>&#13;
    <p class="Index-Level-1">River library <a href="Chapter_8.xhtml#_idIndexMarker645">214</a></p>&#13;
    <p class="Index-Level-1">ROCKET <a href="Chapter_4.xhtml#_idIndexMarker359">119</a></p>&#13;
    <p class="Index-Level-1">ROCKET features <a href="Chapter_3.xhtml#_idIndexMarker197">76</a>, <a href="Chapter_3.xhtml#_idIndexMarker235">90</a>, <a href="Chapter_3.xhtml#_idIndexMarker236">91</a></p>&#13;
    <p class="Index-Level-1">root mean squared error (RMSE) <a href="Chapter_4.xhtml#_idIndexMarker312">109</a>, <a href="Chapter_4.xhtml#_idIndexMarker315">110</a>, <a href="Chapter_9.xhtml#_idIndexMarker708">238</a></p>&#13;
    <p class="Index-Level-1">root mean square deviation (RMSD) <a href="Chapter_4.xhtml#_idIndexMarker316">110</a></p>&#13;
    <p class="Index-Level-1">root mean squared logarithmic error (RMSLE) <a href="Chapter_4.xhtml#_idIndexMarker323">113</a></p>&#13;
    <p class="Index-Level-1">run chart <a href="Chapter_2.xhtml#_idIndexMarker120">51</a></p>&#13;
    <p class="Index-Section-Head">S</p>&#13;
    <p class="Index-Level-1">scale-invariant features (SIFT) <a href="Chapter_4.xhtml#_idIndexMarker355">118</a></p>&#13;
    <p class="Index-Level-1">scaling methods <a href="Chapter_3.xhtml#_idIndexMarker168">70</a></p>&#13;
    <p class="Index-Level-1">scatter plot <a href="Chapter_2.xhtml#_idIndexMarker125">54</a></p>&#13;
    <p class="Index-Level-1">scikit-learn <a href="Chapter_8.xhtml#_idIndexMarker643">214</a></p>&#13;
    <p class="Index-Level-1">scikit-learn project</p>&#13;
    <p class="Index-Level-2">reference link <a href="Chapter_1.xhtml#_idIndexMarker066">33</a></p>&#13;
    <p class="Index-Level-1">SciPy <a href="Chapter_1.xhtml#_idIndexMarker056">28</a></p>&#13;
    <p class="Index-Level-1">season</p>&#13;
    <p class="Index-Level-2">obtaining, for specific date <a href="Chapter_3.xhtml#_idIndexMarker229">87</a></p>&#13;
    <p class="Index-Level-1">Seasonal ARIMA (SARIMA) <a href="Chapter_9.xhtml#_idIndexMarker707">238</a></p>&#13;
    <p class="Index-Level-1">Seasonal Autoregression (SAR) <a href="Chapter_5.xhtml#_idIndexMarker427">138</a></p>&#13;
    <p class="Index-Level-1">Seasonal Auto Regressive Integrative Moving Average models (SARIMA) <a href="Chapter_5.xhtml#_idIndexMarker426">138</a></p>&#13;
    <p class="Index-Level-1">seasonality <a href="Chapter_2.xhtml#_idIndexMarker129">56</a></p>&#13;
    <p class="Index-Level-2">identifying <a href="Chapter_2.xhtml#_idIndexMarker135">56</a>, <a href="Chapter_2.xhtml#_idIndexMarker138">57</a>, <a href="Chapter_2.xhtml#_idIndexMarker142">58</a>, <a href="Chapter_2.xhtml#_idIndexMarker146">59</a>, <a href="Chapter_2.xhtml#_idIndexMarker148">60</a>, <a href="Chapter_2.xhtml#_idIndexMarker153">61</a>, <a href="Chapter_2.xhtml#_idIndexMarker155">63</a>, <a href="Chapter_2.xhtml#_idIndexMarker157">64</a></p>&#13;
    <p class="Index-Level-1">seasonal moving average (SMA) <a href="Chapter_5.xhtml#_idIndexMarker428">139</a></p>&#13;
    <p class="Index-Level-1">segmentation <a href="Chapter_4.xhtml#_idIndexMarker247">95</a></p>&#13;
    <p class="Index-Level-1">Self-Organizing Maps (SOM) <a href="Chapter_9.xhtml#_idIndexMarker724">242</a></p>&#13;
    <p class="Index-Level-1">sensitivity <a href="Chapter_4.xhtml#_idIndexMarker330">114</a></p>&#13;
    <p class="Index-Level-1">SEQL <a href="Chapter_4.xhtml#_idIndexMarker373">123</a></p>&#13;
    <p class="Index-Level-1">shapelets <a href="Chapter_3.xhtml#_idIndexMarker208">78</a>, <a href="Chapter_3.xhtml#_idIndexMarker237">91</a></p>&#13;
    <p class="Index-Level-2">advantages <a href="Chapter_3.xhtml#_idIndexMarker209">78</a></p>&#13;
    <p class="Index-Level-1">Shapelets <a href="Chapter_4.xhtml#_idIndexMarker356">119</a></p>&#13;
    <p class="Index-Level-1">Shapelet Transform Classifier (STC) <a href="Chapter_4.xhtml#_idIndexMarker357">119</a></p>&#13;
    <p class="Index-Level-1">Silverkite <a href="Chapter_7.xhtml#_idIndexMarker593">195</a>, <a href="Chapter_7.xhtml#_idIndexMarker595">197</a>, <a href="Chapter_7.xhtml#_idIndexMarker599">198</a>, <a href="Chapter_7.xhtml#_idIndexMarker601">199</a></p>&#13;
    <p class="Index-Level-1">Silverkite algorithm <a href="Chapter_7.xhtml#_idIndexMarker569">190</a>, <a href="Chapter_7.xhtml#_idIndexMarker570">191</a>, <a href="Chapter_9.xhtml#_idIndexMarker696">236</a></p>&#13;
    <p class="Index-Level-1">simple cells <a href="Chapter_10.xhtml#_idIndexMarker782">265</a></p>&#13;
    <p class="Index-Level-1">simple exponential smoothing (SES) <a href="Chapter_5.xhtml#_idIndexMarker440">140</a>, <a href="Chapter_5.xhtml#_idIndexMarker443">141</a>, <a href="Chapter_5.xhtml#_idIndexMarker446">142</a>, <a href="Chapter_5.xhtml#_idIndexMarker451">143</a></p>&#13;
    <p class="Index-Level-1">simple moving average <a href="Chapter_5.xhtml#_idIndexMarker407">134</a></p>&#13;
    <p class="Index-Level-1">skip connections <a href="Chapter_10.xhtml#_idIndexMarker789">266</a></p>&#13;
    <p class="Index-Level-1">Sktime-DL <a href="Chapter_10.xhtml#_idIndexMarker801">271</a></p>&#13;
    <p class="Index-Level-1">Spearman rank correlation <a href="Chapter_2.xhtml#_idIndexMarker127">56</a></p>&#13;
    <p class="Index-Level-1">standard deviation <a href="Chapter_2.xhtml#_idIndexMarker098">44</a></p>&#13;
    <p class="Index-Level-1">standard error (SE) <a href="Chapter_2.xhtml#_idIndexMarker099">45</a></p>&#13;
    <p class="Index-Level-1">stationarity <a href="Chapter_1.xhtml#_idIndexMarker008">6</a>, <a href="Chapter_2.xhtml#_idIndexMarker133">56</a>, <a href="Chapter_5.xhtml#_idIndexMarker418">136</a>, <a href="Chapter_5.xhtml#_idIndexMarker419">137</a></p>&#13;
    <p class="Index-Level-1">stationary process <a href="Chapter_5.xhtml#_idIndexMarker417">136</a></p>&#13;
    <p class="Index-Level-1">stationary processes <a href="Chapter_2.xhtml#_idIndexMarker134">56</a></p>&#13;
    <p class="Index-Level-1">Statsmodels <a href="Chapter_5.xhtml#_idIndexMarker463">146</a>, <a href="Chapter_5.xhtml#_idIndexMarker472">147</a></p>&#13;
    <p class="Index-Level-1">Statsmodels library</p>&#13;
    <p class="Index-Level-2">using, for modeling <a href="Chapter_5.xhtml#_idIndexMarker473">147</a></p>&#13;
    <p class="Index-Level-1">Structured Query Language (SQL) <a href="Chapter_1.xhtml#_idIndexMarker060">30</a></p>&#13;
    <p class="Index-Level-1">style guide for PEP 8</p>&#13;
    <p class="Index-Level-2">reference link <a href="Chapter_1.xhtml#_idIndexMarker065">32</a></p>&#13;
    <p class="Index-Level-1">sunlight hours</p>&#13;
    <p class="Index-Level-2">obtaining, for specific day <a href="Chapter_3.xhtml#_idIndexMarker231">87</a></p>&#13;
    <p class="Index-Level-1">supervised algorithms, for regression and classification</p>&#13;
    <p class="Index-Level-2">implementations <a href="Chapter_4.xhtml#_idIndexMarker392">128</a>, <a href="Chapter_4.xhtml#_idIndexMarker393">129</a></p>&#13;
    <p class="Index-Level-1">supervised learning <a href="Chapter_4.xhtml#_idIndexMarker251">96</a>, <a href="Chapter_4.xhtml#_idIndexMarker257">97</a></p>&#13;
    <p class="Index-Level-1">Support Vector Machines (SVMs) <a href="Chapter_4.xhtml#_idIndexMarker291">103</a>, <a href="Chapter_10.xhtml#_idIndexMarker803">271</a></p>&#13;
    <p class="Index-Level-1">Suspended Particulate Matter (SPM) <a href="Chapter_2.xhtml#_idIndexMarker126">55</a></p>&#13;
    <p class="Index-Level-1">Symbolic Aggregate ApproXimation (SAX) <a href="Chapter_4.xhtml#_idIndexMarker367">121</a></p>&#13;
    <p class="Index-Level-1">Symbolic Fourier Approximation (SFA) <a href="Chapter_4.xhtml#_idIndexMarker369">122</a></p>&#13;
    <p class="Index-Level-1">symmetric mean absolute percentage error (SMAPE) <a href="Chapter_4.xhtml#_idIndexMarker319">111</a></p>&#13;
    <p class="Index-Level-1">synapses <a href="Chapter_10.xhtml#_idIndexMarker771">263</a></p>&#13;
    <p class="Index-Section-Head">T</p>&#13;
    <p class="Index-Level-1">Temporal Convolutional Network (TCN) <a href="Chapter_10.xhtml#_idIndexMarker824">276</a>, <a href="Chapter_12.xhtml#_idIndexMarker901">322</a>, <a href="Chapter_12.xhtml#_idIndexMarker915">331</a>, <a href="Chapter_12.xhtml#_idIndexMarker916">333</a></p>&#13;
    <p class="Index-Level-1">Temporal Dictionary Ensemble (TDE) <a href="Chapter_4.xhtml#_idIndexMarker384">124</a></p>&#13;
    <p class="Index-Level-1">Temporal Difference (TD) learning <a href="Chapter_11.xhtml#_idIndexMarker852">299</a></p>&#13;
    <p class="Index-Level-1">Temporal Fusion Transformer (TFT) <a href="Chapter_10.xhtml#_idIndexMarker826">278</a></p>&#13;
    <p class="Index-Level-1">Theil's U <a href="Chapter_4.xhtml#_idIndexMarker324">113</a></p>&#13;
    <p class="Index-Level-1">Theta method <a href="Chapter_5.xhtml#_idIndexMarker442">141</a></p>&#13;
    <p class="Index-Level-1">Thompson sampling <a href="Chapter_11.xhtml#_idIndexMarker864">303</a></p>&#13;
    <p class="Index-Level-1">time series <a href="Chapter_1.xhtml#_idIndexMarker002">3</a></p>&#13;
    <p class="Index-Level-2">characteristics <a href="Chapter_1.xhtml#_idIndexMarker005">4</a>, <a href="Chapter_1.xhtml#_idIndexMarker007">5</a></p>&#13;
    <p class="Index-Level-2">comparing <a href="Chapter_4.xhtml#_idIndexMarker342">116</a></p>&#13;
    <p class="Index-Level-2">machine learning methods, using <a href="Chapter_7.xhtml#_idIndexMarker560">186</a>, <a href="Chapter_7.xhtml#_idIndexMarker562">187</a></p>&#13;
    <p class="Index-Level-2">working with, in Python <a href="Chapter_2.xhtml#_idIndexMarker080">38</a></p>&#13;
    <p class="Index-Level-1">time-series <a href="Chapter_12.xhtml#_idIndexMarker920">335</a>, <a href="Chapter_12.xhtml#_idIndexMarker921">336</a></p>&#13;
    <p class="Index-Level-2">reference link <a href="Chapter_12.xhtml#_idIndexMarker907">324</a></p>&#13;
    <p class="Index-Level-2">reinforcement learning (RL) <a href="Chapter_11.xhtml#_idIndexMarker860">301</a></p>&#13;
    <p class="Index-Level-2">unsupervised methods <a href="Chapter_6.xhtml#_idIndexMarker502">162</a>, <a href="Chapter_6.xhtml#_idIndexMarker504">163</a>, <a href="Chapter_6.xhtml#_idIndexMarker505">164</a></p>&#13;
    <p class="Index-Level-1">Time Series <a href="Chapter_1.xhtml#_idIndexMarker010">6</a></p>&#13;
    <p class="Index-Level-2">offline learning <a href="Chapter_8.xhtml#_idIndexMarker627">210</a></p>&#13;
    <p class="Index-Level-2">online learning <a href="Chapter_8.xhtml#_idIndexMarker626">210</a></p>&#13;
    <p class="Index-Level-1">time series analysis <a href="Chapter_1.xhtml#_idIndexMarker009">6</a></p>&#13;
    <p class="Index-Level-1">time series analysis (TSA) <a href="Chapter_2.xhtml#_idIndexMarker068">36</a>, <a href="Chapter_2.xhtml#_idIndexMarker074">37</a>, <a href="Chapter_2.xhtml#_idIndexMarker076">38</a></p>&#13;
    <p class="Index-Level-1">time series classification algorithms</p>&#13;
    <p class="Index-Level-2">critical difference diagram <a href="Chapter_4.xhtml#_idIndexMarker389">126</a>, <a href="Chapter_4.xhtml#_idIndexMarker390">127</a></p>&#13;
    <p class="Index-Level-1">Time Series Combination of Heterogeneous and Integrated Embedding Forest (TS-CHIEF) <a href="Chapter_4.xhtml#_idIndexMarker365">121</a></p>&#13;
    <p class="Index-Level-1">time series data</p>&#13;
    <p class="Index-Level-2">examples <a href="Chapter_1.xhtml#_idIndexMarker001">2</a></p>&#13;
    <p class="Index-Level-1">time-series data <a href="Chapter_1.xhtml#_idIndexMarker000">2</a></p>&#13;
    <p class="Index-Level-1">time series datasets <a href="Chapter_4.xhtml#_idIndexMarker240">94</a></p>&#13;
    <p class="Index-Level-1">time series forecasting <a href="Chapter_4.xhtml#_idIndexMarker262">97</a></p>&#13;
    <p class="Index-Level-1">Time Series Forest (TSF) <a href="Chapter_4.xhtml#_idIndexMarker363">120</a></p>&#13;
    <p class="Index-Level-1">time series machine learning algorithms</p>&#13;
    <p class="Index-Level-2">detailed taxonomy <a href="Chapter_4.xhtml#_idIndexMarker387">125</a>, <a href="Chapter_4.xhtml#_idIndexMarker388">126</a></p>&#13;
    <p class="Index-Level-1">time series machine learning flywheel <a href="Chapter_2.xhtml#_idIndexMarker075">38</a></p>&#13;
    <p class="Index-Level-1">time series regression <a href="Chapter_4.xhtml#_idIndexMarker300">107</a></p>&#13;
    <p class="Index-Level-1">transformer <a href="Chapter_12.xhtml#_idIndexMarker913">330</a>, <a href="Chapter_12.xhtml#_idIndexMarker914">331</a></p>&#13;
    <p class="Index-Level-1">transformer architectures <a href="Chapter_10.xhtml#_idIndexMarker825">277</a></p>&#13;
    <p class="Index-Level-1">trend <a href="Chapter_2.xhtml#_idIndexMarker130">56</a></p>&#13;
    <p class="Index-Level-2">identifying <a href="Chapter_2.xhtml#_idIndexMarker132">56</a>, <a href="Chapter_2.xhtml#_idIndexMarker137">57</a>, <a href="Chapter_2.xhtml#_idIndexMarker140">58</a>, <a href="Chapter_2.xhtml#_idIndexMarker145">59</a>, <a href="Chapter_2.xhtml#_idIndexMarker147">60</a>, <a href="Chapter_2.xhtml#_idIndexMarker152">61</a>, <a href="Chapter_2.xhtml#_idIndexMarker154">62</a>, <a href="Chapter_2.xhtml#_idIndexMarker156">63</a></p>&#13;
    <p class="Index-Level-1">triple exponential smoothing <a href="Chapter_5.xhtml#_idIndexMarker448">142</a></p>&#13;
    <p class="Index-Level-1">true positive rate <a href="Chapter_4.xhtml#_idIndexMarker329">114</a></p>&#13;
    <p class="Index-Level-1">true positive rate (TPR) <a href="Chapter_4.xhtml#_idIndexMarker336">115</a></p>&#13;
    <p class="Index-Level-1">true positives (TP) <a href="Chapter_4.xhtml#_idIndexMarker334">115</a></p>&#13;
    <p class="Index-Level-1">Twitter <a href="Chapter_6.xhtml#_idIndexMarker527">170</a></p>&#13;
    <p class="Index-Section-Head">U</p>&#13;
    <p class="Index-Level-1">UAE (University of East Anglia) <a href="Chapter_4.xhtml#_idIndexMarker352">118</a></p>&#13;
    <p class="Index-Level-1">UCR (University of California, Riverside) <a href="Chapter_4.xhtml#_idIndexMarker348">118</a></p>&#13;
    <p class="Index-Level-1">unit imputation <a href="Chapter_3.xhtml#_idIndexMarker186">73</a>, <a href="Chapter_3.xhtml#_idIndexMarker221">82</a></p>&#13;
    <p class="Index-Level-1">univariate analysis <a href="Chapter_2.xhtml#_idIndexMarker078">38</a></p>&#13;
    <p class="Index-Level-1">univariate series <a href="Chapter_1.xhtml#_idIndexMarker004">4</a></p>&#13;
    <p class="Index-Level-1">Universidade Federal de Minas Gerais (UFMG) <a href="Chapter_9.xhtml#_idIndexMarker746">252</a></p>&#13;
    <p class="Index-Level-1">unsupervised learning <a href="Chapter_4.xhtml#_idIndexMarker252">96</a>, <a href="Chapter_4.xhtml#_idIndexMarker263">97</a></p>&#13;
    <p class="Index-Level-1">unsupervised methods</p>&#13;
    <p class="Index-Level-2">for time-series <a href="Chapter_6.xhtml#_idIndexMarker501">162</a>, <a href="Chapter_6.xhtml#_idIndexMarker503">163</a>, <a href="Chapter_6.xhtml#_idIndexMarker506">164</a></p>&#13;
    <p class="Index-Section-Head">V</p>&#13;
    <p class="Index-Level-1">validation <a href="Chapter_7.xhtml#_idIndexMarker563">187</a>, <a href="Chapter_7.xhtml#_idIndexMarker565">188</a></p>&#13;
    <p class="Index-Level-1">value-based learning <a href="Chapter_11.xhtml#_idIndexMarker853">300</a></p>&#13;
    <p class="Index-Level-1">variables <a href="Chapter_2.xhtml#_idIndexMarker096">44</a>, <a href="Chapter_2.xhtml#_idIndexMarker100">45</a>, <a href="Chapter_2.xhtml#_idIndexMarker108">46</a>, <a href="Chapter_2.xhtml#_idIndexMarker109">47</a>, <a href="Chapter_2.xhtml#_idIndexMarker110">48</a>, <a href="Chapter_2.xhtml#_idIndexMarker111">49</a></p>&#13;
    <p class="Index-Level-2">relationships <a href="Chapter_2.xhtml#_idIndexMarker114">49</a>, <a href="Chapter_2.xhtml#_idIndexMarker118">50</a>, <a href="Chapter_2.xhtml#_idIndexMarker121">52</a></p>&#13;
    <p class="Index-Level-1">vector autoregression models <a href="Chapter_5.xhtml#_idIndexMarker459">144</a>, <a href="Chapter_5.xhtml#_idIndexMarker460">145</a></p>&#13;
    <p class="Index-Level-1">Vector Autoregressions (VAR) <a href="Chapter_4.xhtml#_idIndexMarker397">129</a></p>&#13;
    <p class="Index-Level-1">Vector Autoregression (VAR) <a href="Chapter_5.xhtml#_idIndexMarker402">133</a></p>&#13;
    <p class="Index-Level-1">Very Fast Decision Tree (VFDT) <a href="Chapter_8.xhtml#_idIndexMarker648">215</a></p>&#13;
    <p class="Index-Level-1">virtual environment <a href="Chapter_7.xhtml#_idIndexMarker580">193</a></p>&#13;
    <p class="Index-Section-Head">W</p>&#13;
    <p class="Index-Level-1">walk-forward validation <a href="Chapter_7.xhtml#_idIndexMarker564">188</a></p>&#13;
    <p class="Index-Level-1">weak learner <a href="Chapter_4.xhtml#_idIndexMarker281">100</a></p>&#13;
    <p class="Index-Level-1">WEASEL+MUSE <a href="Chapter_4.xhtml#_idIndexMarker375">123</a></p>&#13;
    <p class="Index-Level-1">window-based features <a href="Chapter_3.xhtml#_idIndexMarker191">75</a></p>&#13;
    <p class="Index-Level-1">Wold�s decomposition <a href="Chapter_5.xhtml#_idIndexMarker420">137</a></p>&#13;
    <p class="Index-Level-1">Word Extraction for Time Series Classification <a href="Chapter_4.xhtml#_idIndexMarker376">123</a></p>&#13;
    <p class="Index-Section-Head">Y</p>&#13;
    <p class="Index-Level-1">Yeo-Johnson transformation <a href="Chapter_3.xhtml#_idIndexMarker182">72</a></p>&#13;
    <p class="Index-Section-Head">Z</p>&#13;
    <p class="Index-Level-1">Z-score normalization <a href="Chapter_3.xhtml#_idIndexMarker170">70</a></p>&#13;
  </div>&#13;
  <div id="_idContainer441">&#13;
    <h1 id="_idParaDest-182" class="Introduction-Title--PACKT-">Index</h1>&#13;
  </div>&#13;
</body></html>