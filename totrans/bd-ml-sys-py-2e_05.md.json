["```py\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<posts>\n...\n <row Id=\"4572748\" PostTypeId=\"2\" ParentId=\"4568987\" CreationDate=\"2011-01-01T00:01:03.387\" Score=\"4\" ViewCount=\"\" Body=\"&lt;p&gt;IANAL, but &lt;a href=&quot;http://support.apple.com/kb/HT2931&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt; indicates to me that you cannot use the loops in your application:&lt;/p&gt;\n\n&lt;blockquote&gt;\n  &lt;p&gt;...however, individual audio loops may\n  not be commercially or otherwise\n  distributed on a standalone basis, nor\n  may they be repackaged in whole or in\n  part as audio samples, sound effects\n  or music beds.&quot;&lt;/p&gt;\n\n  &lt;p&gt;So don't worry, you can make\n  commercial music with GarageBand, you\n  just can't distribute the loops as\n  loops.&lt;/p&gt;\n&lt;/blockquote&gt;\n\" OwnerUserId=\"203568\" LastActivityDate=\"2011-01-01T00:01:03.387\" CommentCount=\"1\" />\n…\n</posts>\n\n```", "```py\nId <TAB> ParentId <TAB> IsAccepted <TAB> TimeToAnswer <TAB> Score <TAB> Text\n```", "```py\n def fetch_posts():\n for line in open(\"data.tsv\", \"r\"):\n post_id, text = line.split(\"\\t\")\n yield int(post_id), text.strip()\n\n```", "```py\n>>> all_answers = [q for q,v in meta.items() if v['ParentId']!=-1]\n>>> Y = np.asarray([meta[answerId]['Score']>0 for answerId in all_answers])\n\n```", "```py\n>>> from sklearn import neighbors\n>>> knn = neighbors.KNeighborsClassifier(n_neighbors=2)\n>>> print(knn)\nKNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski', n_neighbors=2, p=2, weights='uniform')\n\n```", "```py\n>>> knn.fit([[1],[2],[3],[4],[5],[6]], [0,0,0,1,1,1])\n>>> knn.predict(1.5)\narray([0])\n>>> knn.predict(37)\narray([1])\n>>> knn.predict(3)\narray([0])\n\n```", "```py\n>>> knn.predict_proba(1.5)\narray([[ 1.,  0.]])\n>>> knn.predict_proba(37)\narray([[ 0.,  1.]])\n>>> knn.predict_proba(3.5)\narray([[ 0.5,  0.5]])\n\n```", "```py\nimport re\ncode_match = re.compile('<pre>(.*?)</pre>',\n re.MULTILINE | re.DOTALL)\nlink_match = re.compile('<a href=\"http://.*?\".*?>(.*?)</a>', \n re.MULTILINE | re.DOTALL)\ntag_match = re.compile('<[^>]*>', \n re.MULTILINE | re.DOTALL)\n\ndef extract_features_from_body(s):\n link_count_in_code = 0\n # count links in code to later subtract them \n for match_str in code_match.findall(s):\n link_count_in_code += len(link_match.findall(match_str))\n\n return len(link_match.findall(s)) – link_count_in_code\n\n```", "```py\nX = np.asarray([extract_features_from_body(text) for post_id, text in\n                fetch_posts() if post_id in all_answers])\nknn = neighbors.KNeighborsClassifier()\nknn.fit(X, Y)\n\n```", "```py\nfrom sklearn.cross_validation import KFold\nscores = []\n\ncv = KFold(n=len(X), k=10, indices=True)\n\nfor train, test in cv:\n X_train, y_train = X[train], Y[train]\n X_test, y_test = X[test], Y[test]\n clf = neighbors.KNeighborsClassifier()\n clf.fit(X, Y)\n scores.append(clf.score(X_test, y_test))\n\nprint(\"Mean(scores)=%.5f\\tStddev(scores)=%.5f\"\\\n %(np.mean(scores), np.std(scores)))\n\n```", "```py\nMean(scores)=0.50250    Stddev(scores)=0.055591\n\n```", "```py\ndef extract_features_from_body(s):\n num_code_lines = 0     link_count_in_code = 0\n code_free_s = s\n\n # remove source code and count how many lines\n for match_str in code_match.findall(s):\n num_code_lines += match_str.count('\\n')\n code_free_s = code_match.sub(\"\", code_free_s)\n\n # Sometimes source code contains links, \n # which we don't want to count\n link_count_in_code += len(link_match.findall(match_str))\n\n links = link_match.findall(s)\n link_count = len(links)\n link_count -= link_count_in_code\n html_free_s = re.sub(\" +\", \" \", \n tag_match.sub('',  code_free_s)).replace(\"\\n\", \"\")\n link_free_s = html_free_s\n\n # remove links from text before counting words\n for link in links:\n if link.lower().startswith(\"http://\"):\n link_free_s = link_free_s.replace(link,'')\n\n num_text_tokens = html_free_s.count(\" \")\n\n return num_text_tokens, num_code_lines, link_count\n\n```", "```py\nMean(scores)=0.59800    Stddev(scores)=0.02600\n\n```", "```py\nMean(scores)=0.61400    Stddev(scores)= 0.02154\n\n```", "```py\n>>> from sklearn.linear_model import LogisticRegression\n>>> clf = LogisticRegression()\n>>> print(clf)\nLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, penalty=l2, tol=0.0001)\n>>> clf.fit(X, y)\n>>> print(np.exp(clf.intercept_), np.exp(clf.coef_.ravel()))\n[ 0.09437188] [ 1.80094112]\n>>> def lr_model(clf, X):\n...     return 1 / (1 + np.exp(-(clf.intercept_ + clf.coef_*X)))\n>>> print(\"P(x=-1)=%.2f\\tP(x=7)=%.2f\"%(lr_model(clf, -1), lr_model(clf, 7)))\nP(x=-1)=0.05    P(x=7)=0.85\n\n```", "```py\n>>> from sklearn.metrics import precision_recall_curve\n>>> precision, recall, thresholds = precision_recall_curve(y_test,\n    clf.predict(X_test))\n\n```", "```py\n>>> medium = np.argsort(scores)[int(len(scores) / 2)]\n>>> thresholds = np.hstack(([0],thresholds[medium]))\n>>> idx80 = precisions>=0.8\n>>> print(\"P=%.2f R=%.2f thresh=%.2f\" % (precision[idx80][0], recall[idx80][0], threshold[idx80][0]))\nP=0.80 R=0.37 thresh=0.59\n\n```", "```py\n>>> thresh80 = threshold[idx80][0]\n>>> probs_for_good = clf.predict_proba(answer_features)[:,1]\n>>> answer_class = probs_for_good>thresh80\n\n```", "```py\n>>> from sklearn.metrics import classification_report\n>>> print(classification_report(y_test, clf.predict_proba [:,1]>0.63, target_names=['not accepted', 'accepted']))\n\n precision    recall  f1-score   support\nnot accepted         0.59      0.85      0.70       101\naccepted             0.73      0.40      0.52        99\navg / total          0.66      0.63      0.61       200\n\n```", "```py\n>>> import pickle\n>>> pickle.dump(clf, open(\"logreg.dat\", \"w\"))\n>>> clf = pickle.load(open(\"logreg.dat\", \"r\"))\n\n```"]