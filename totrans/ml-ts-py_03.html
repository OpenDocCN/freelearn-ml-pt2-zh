<html><head></head><body>
  <div id="_idContainer167">
    <h1 class="chapterNumber">4</h1>
    <h1 id="_idParaDest-64" class="chapterTitle">Introduction to Machine Learning for Time-Series</h1>
    <p class="normal">In previous chapters, we've talked about time-series, time-series analysis, and preprocessing. In this chapter, we'll talk about machine learning for time-series. <strong class="keyword">Machine learning</strong> is <a id="_idIndexMarker238"/>the study of algorithms that improve through experience. These algorithms or models can make systematic, repeatable, validated decisions based on data. This chapter is meant to give an introduction given both the context and the technical background to much of what we'll use in the remainder of this book. </p>
    <p class="normal">We'll go through different kinds of problems and applications of machine learning in time-series, and types of analyses relevant to machine learning and time-series analysis. We'll explain the main machine learning problems with time-series, such as forecasting, classification, regression, segmentation, and anomaly detection. We'll then review the basics of machine learning as relevant to time-series. Then, we'll look at the history and current uses of machine learning for time-series.</p>
    <p class="normal">We're going to cover the following topics:</p>
    <ul>
      <li class="bullet">Machine learning with time-series<ul>
          <li class="bullet-l2">Supervised, unsupervised, and reinforcement learning</li>
          <li class="bullet-l2">History of Machine Learning</li>
        </ul>
      </li>
      <li class="bullet">Machine learning workflow<ul>
          <li class="bullet-l2">Cross-validation</li>
          <li class="bullet-l2">Error metrics for time-series</li>
          <li class="bullet-l2">Comparing time-series</li>
        </ul>
      </li>
      <li class="bullet">Machine learning algorithms for time-series</li>
    </ul>
    <p class="normal">We'll start with a general introduction to machine learning with time-series.</p>
    <h1 id="_idParaDest-65" class="title">Machine learning with time-series</h1>
    <p class="normal">In this section, I'll give an introduction to applications and the main categories of machine learning with time-series.</p>
    <p class="normal">Machine learning<a id="_idIndexMarker239"/> approaches for time-series are crucial in domains such as economics, medicine, meteorology, demography, and many others. Time-Series datasets<a id="_idIndexMarker240"/> are ubiquitous and occur in domains as diverse as healthcare, economics, social sciences, Internet-of-Things applications, operations management, digital marketing, cloud infrastructure, the simulation of robotic systems, and others. These datasets are of immense practical importance, as they can be leveraged to forecast and predict the detection of anomalies more effectively, thereby supporting decision making. </p>
    <p class="normal">The technical applications within machine learning for time-series abound in techniques. A few applications are as follows:</p>
    <ul>
      <li class="bullet">Curve fitting</li>
      <li class="bullet">Regression</li>
      <li class="bullet">Classification</li>
      <li class="bullet">Forecasting</li>
      <li class="bullet">Segmentation/clustering</li>
      <li class="bullet">Anomaly detection</li>
      <li class="bullet">Reinforcement learning</li>
    </ul>
    <p class="normal">We will examine these technical applications in this book. These different applications have different statistical methods and models behind them that can overlap.</p>
    <p class="normal">Let's go briefly through some of these applications for an overview of what to expect in the chapters to come.</p>
    <p class="normal"><strong class="keyword">Curve fitting</strong> is the <a id="_idIndexMarker241"/>task of fitting a mathematical function (a curve) to a series of points. The mathematical function is defined by parameters, and the parameters are adapted to fit the time-series through optimization. Curve fitting can be employed as a visual aid on graphs or for inference (extrapolation).</p>
    <p class="normal"><strong class="keyword">Regression</strong> is an <a id="_idIndexMarker242"/>umbrella term for statistical approaches for finding relationships between independent variables (features) and independent variables (targets). For instance, we could be predicting the exact temperature based on the release of carbon dioxide and methane. If there's more than one outcome variable, this is called multi-target (or multi-output). An example of this could be predicting the temperature for different locations at the same time.</p>
    <p class="normal">When the problem is assigning labels to a time-series (or a part of it), this is called <strong class="keyword">classification</strong>. The main<a id="_idIndexMarker243"/> difference to regression is that the prediction is categorical rather than continuous. The model that's used for classification is often referred to as a classifier. Classification can be binary, when there are precisely two classes, or multi-class, when there are more categories. An example would be detecting eye movements or epilepsy in EEG signals.</p>
    <p class="normal">Making predictions about the future is <a id="_idIndexMarker244"/>called <strong class="keyword">forecasting</strong>. Forecasting can be based only on the time-series values itself or on other variables. The techniques can range from curve fitting to extrapolating, from analysis of the current trends and variability to complex machine learning techniques. For example, we could be forecasting global temperatures based on the data of the last 100 years, or we could be forecasting the economic wellbeing of a nation. The antonym of forecasting is <strong class="keyword">backcasting</strong>, where we <a id="_idIndexMarker245"/>make predictions about the past. We could be backcasting temperatures backward in time from before we have data available.</p>
    <p class="normal"><strong class="keyword">Segmentation</strong>, or <strong class="keyword">clustering</strong>, is the<a id="_idIndexMarker246"/> process of grouping parts of the time-series into <a id="_idIndexMarker247"/>clusters (or segments) of different regimes, behaviors, or baselines. An example would be different activity levels in brain waves.</p>
    <p class="normal">Within the context of <a id="_idIndexMarker248"/>time-series, <strong class="keyword">anomaly detection</strong>, also known as <strong class="keyword">outlier detection</strong>, is the<a id="_idIndexMarker249"/> task of identifying events that are rare or outside the norm. These could be novel, changes of regime, noise, or just exceptions. A rather crude example would be an outage of the electricity grid detectable in a sudden drop of the voltage. More subtle perhaps, by way of an example, would be an increase in the number of calls to a call center within a certain period. In both cases, anomaly detection could provide actionable business insights. Techniques in anomaly detection can range from simple thresholding or statistics to a set of rules, to pattern-based approaches based on the time-series distribution.</p>
    <p class="normal">Finally, <strong class="keyword">reinforcement learning</strong> is the<a id="_idIndexMarker250"/> practice of learning based on maximizing expected rewards from a series of decisions. Reinforcement learning algorithms are employed in environments where there's a high level of uncertainty. This could mean that the conditions are unstable (high variation) or there's a general lack of information. Applications are bidding and pricing algorithms in stock trading or general auctions, and control tasks.</p>
    <p class="normal">Let's dive into a bit more detail about what these terms mean.</p>
    <h2 id="_idParaDest-66" class="title">Supervised, unsupervised, and reinforcement learning </h2>
    <p class="normal">Machine<a id="_idIndexMarker251"/> learning<a id="_idIndexMarker252"/> can be broadly categorized into supervised, unsupervised, and <a id="_idIndexMarker253"/>reinforcement learning, as this diagram shows:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_01.png" alt="taxonomy.png"/></figure>
    <p class="packt_figref">Figure 4.1: Dividing machine learning into categories</p>
    <p class="normal">In <strong class="keyword">supervised</strong> learning, the features <a id="_idIndexMarker254"/>are mapped<a id="_idIndexMarker255"/> to outcomes <img src="../Images/B17577_04_001.png" alt="" style="height: 1em;"/>in a process <a id="_idIndexMarker256"/>called <strong class="keyword">prediction</strong> (sometimes <strong class="keyword">inference</strong>).</p>
    <p class="normal">In the supervised case, parameters are estimated from labeled observations. We need to have the outcome available for each observation as the <strong class="keyword">target</strong> column (or columns, in the plural).</p>
    <p class="normal">Therefore, the machine learning algorithm finds a mapping from X to Y.</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_002.png" alt="" style="height: 2em;"/></figure>
    <p class="normal">The function <img src="../Images/B17577_04_003.png" alt="" style="height: 1em;"/> is just one possible mapping or model of the input distribution X to the output distribution Y.</p>
    <p class="normal">Supervised machine learning <a id="_idIndexMarker257"/>can be categorized into classification and<a id="_idIndexMarker258"/> regression. In regression, our targets are continuous, and the goal is to predict the value.</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_004.png" alt="" style="height: 2em;"/></figure>
    <p class="normal">The target Y can be real-valued, either a single value or a higher dimensionality (multioutput).</p>
    <p class="normal">The labels match the dataset in length, but there can be several labels for each observation as well (multi-output).</p>
    <p class="normal">An example would be the number of products sold in a shop on a specific day or the amount of oil coming through a pipeline over the next month. The features could include current sales, demand, or day of the week.</p>
    <p class="normal">In <strong class="keyword">classification</strong>, the goal is to predict the class of the observation. In this case, <img src="../Images/B17577_04_005.png" alt="" style="height: 1em;"/> could be drawn from a <a id="_idIndexMarker259"/>categorical distribution, a distribution consisting of ordinal values, for example, integers as in <img src="../Images/B17577_04_006.png" alt="" style="height: 1em;"/>.</p>
    <p class="normal">Sometimes, we want to find a function that would give us probabilities or scores for given observations:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_007.png" alt="" style="height: 1.8em;"/></figure>
    <p class="normal">In practical terms, regression and<a id="_idIndexMarker260"/> classification are very similar problems, and often<a id="_idIndexMarker261"/> regression and classification algorithms can be applied interchangeably. However, understanding the distinction is crucial to dealing with any specific problem in an appropriate manner.</p>
    <p class="normal">In time-series <strong class="keyword">forecasting</strong>, the <a id="_idIndexMarker262"/>historical values are extrapolated into the future. The only features are the past values. For example, we could be estimating the calls into a call center over the next month based on calls during the last 2 years. The forecasting task could be univariate, relying on and extrapolating a single feature, or multivariate, where multiple features are projected into the future.</p>
    <p class="normal">In <strong class="keyword">unsupervised</strong> learning, the <a id="_idIndexMarker263"/>algorithm's task is to categorize observations based on their features. Examples of unsupervised learning are clustering or recommender algorithms.</p>
    <p class="normal">In most of the book, we'll be talking about supervised algorithms, although we'll also talk about unsupervised tasks such as change detection and clustering.</p>
    <p class="normal">The mapping function, f, predicts an outcome <img src="../Images/B17577_04_008.png" alt="" style="height: 1em;"/>Each function is specified by a set of parameters, and the optimization results in a set of parameters that minimizes the mismatch between Y and <img src="../Images/B17577_04_009.png" alt="" style="height: 1em;"/>. Usually, this is done heuristically.</p>
    <p class="normal">The match (mismatch) between Y and <img src="../Images/B17577_04_010.png" alt="" style="height: 1em;"/> is measured by an error function, <img src="../Images/B17577_04_011.png" alt="" style="height: 1em;"/>, so the optimization consists of estimating parameters <img src="../Images/B17577_04_012.png" alt="" style="height: 1em;"/> for the function f that minimizes the error:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_013.png" alt="" style="height: 2.5em;"/></figure>
    <p class="normal">In this formula, since the <a id="_idIndexMarker264"/>error function is part of the optimization, <img src="../Images/B17577_04_014.png" alt="" style="height: 1em;"/> is called the <strong class="keyword">objective function</strong>.</p>
    <p class="normal">In <strong class="keyword">reinforcement learning</strong>, an <a id="_idIndexMarker265"/>agent is interacting with the environment through actions and gets feedback in <a id="_idIndexMarker266"/>the shape of rewards. You can find out more about reinforcement learning for time-series in <em class="chapterRef">Chapter 11</em>, <em class="italic">Reinforcement Learning for Time-Series</em>.</p>
    <p class="normal">Contrary to the situation in supervised learning, no labeled data is available, but rather the environment is explored and exploited based on the expectation of cumulative rewards.</p>
    <p class="normal"><strong class="keyword">Machine learning</strong>, the study <a id="_idIndexMarker267"/>of algorithms that improve with experience, can be traced back to the 1960s when statistical methods (discussed in <em class="chapterRef">Chapter 1</em>, <em class="italic">Time-Series with Python</em>) were discovered. Let's start with a brief history of machine learning to give some context. This will provide some more terminology and a basic idea of the principal directions in machine learning. We'll give some more detailed context in the appropriate chapters.</p>
    <h2 id="_idParaDest-67" class="title">History of machine learning</h2>
    <p class="normal">Biological neural <a id="_idIndexMarker268"/>networks were conceptualized as a mathematical model by Warren McCulloch and Walter Pitts in 1943 in what was the foundation of artificial neural networks. </p>
    <p class="normal">Frank Rosenblatt developed the<a id="_idIndexMarker269"/> so-called <strong class="keyword">perceptron</strong> in 1958, which is a <strong class="keyword">fully connected feed-forward neural network</strong> in today's terms. This schematic shows a perceptron with<a id="_idIndexMarker270"/> two input neurons and a single output neuron (based on an image on Wikimedia Commons):</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_03.png" alt="/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_SIwGeX/Screenshot 2021-08-15 at 18.23.06.png"/></figure>
    <p class="packt_figref">Figure 4.3: Perceptron</p>
    <p class="normal">The connections to the output neuron <em class="italic">y</em> have weights <em class="italic">w</em><sub class="" style="font-style: italic;">1</sub> and <em class="italic">w</em><sub class="" style="font-style: italic;">2</sub>. This is a simple linear model.</p>
    <p class="normal">Another important step was how<a id="_idIndexMarker271"/> errors can be propagated backward through the network. The basics of <strong class="keyword">backpropagation</strong> were published by Henry J. Kelley shortly afterward (1960) as a mechanism for training these networks.</p>
    <p class="normal">This research was<a id="_idIndexMarker272"/> dealt a severe blow, however, when, in 1969, Marvin Minsky and Seymour Papert published the book "<em class="italic">Perceptrons</em>", which included a simple proof that linear functions (as in the 2-layer perceptron) could not model non-linear functions. According to the authors, this meant that perceptrons, wouldn't be useful or interesting in practice. The fact that perceptrons could have more than two layers, parameters of which could be learned via backpropagation, was glossed over in the book. Research in artificial neural networks only picked up again in the 1980s.</p>
    <p class="normal">The <strong class="keyword">nearest neighbor algorithm</strong> was <a id="_idIndexMarker273"/>described by Evelyn Fix and Joseph Hodges in 1951, and then expanded in 1967 by Thomas Cover and Peter E. Hart. The nearest neighbor algorithm can be applied to both classification and regression. It works by retrieving the k most similar instances between a new data point, and all known instances in the dataset (k is a parameter). In the case of classification, the algorithm votes for the most frequent label; in the case of regression, it averages the labels.</p>
    <p class="normal">Another important milestone was the development of the decision tree algorithm. The ID3 decision tree algorithm (Iterative Dichotomiser 3) was published by Ross Quinlan in a 1979 paper and is the precursor to decision trees used today. </p>
    <p class="normal">The <strong class="keyword">CART</strong> algorithm (<strong class="keyword">Classification And Regression Tree</strong>) was published<a id="_idIndexMarker274"/> by Leo Breiman in 1984. The <strong class="keyword">C4.5</strong> algorithm, a <a id="_idIndexMarker275"/>descendant of ID3, came out in 1992 (Ross Quinlan) and is regarded today as a landmark in machine learning.</p>
    <p class="normal">What was revolutionary about the decision tree is that it consists of step functions that partition the feature space of the data points into pockets that have a similar outcome. While many machine learning algorithms struggle when there are many interactions to consider, decision trees thrive in these situations. The following diagram illustrates what a decision tree<a id="_idIndexMarker276"/> looks like:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_04.png" alt="../../../../Desktop/Screenshot%202021-04-26%20at%2000.09"/></figure>
    <p class="packt_figref">Figure 4.4: Decision tree</p>
    <p class="normal">Each node or split in the tree is a single question based on the value of a feature. At each iteration during the tree construction, a statistical function called a split criterion is applied to decide on the best feature to query. Typical choices for a split criterion are the Gini impurity or information entropy, which both minimize the variability of the targets within branches.</p>
    <p class="normal">Decision trees, in turn, form <a id="_idIndexMarker277"/>the basis of ensemble techniques such as the random forest or gradient boosted trees. There are two main ensemble techniques: boosting<a id="_idIndexMarker278"/> and bagging. <strong class="keyword">Boosting</strong> was invented by Robert Schapire in 1990, and consists of incrementally<a id="_idIndexMarker279"/> adding base learners in a cascade. A <strong class="keyword">base learner</strong> (also <strong class="keyword">weak learner</strong>) is a very <a id="_idIndexMarker280"/>simple model that in itself is only weakly correlated<a id="_idIndexMarker281"/> to the targets. Each time when adding a new base learner to the existing ones, the importance (weights) of data points in the training set are rebalanced. </p>
    <p class="normal">This means that in each iteration, the algorithm comes to grips with more and more samples that it struggles with, leading to higher precision with each new addition of a base learner.</p>
    <p class="normal">This formed the basis<a id="_idIndexMarker282"/> for <strong class="keyword">AdaBoost</strong>, an adaptive boosting algorithm, which won its inventors, Yoav Freund and Robert Schapire, the Gödel Prize, a prestigious recognition for outstanding papers in the area of theoretical computer science.</p>
    <p class="normal">This illustration (from Wikipedia) shows how each base classifier is trained subsequently on different subsets of the dataset, where weights are changed for each new training:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_05.png" alt="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Ensemble_Boosting.svg/1024px-Ensemble_Boosting.svg.png"/></figure>
    <p class="packt_figref">Figure 4.5: Boosting</p>
    <p class="normal"><strong class="keyword">Bagging</strong> is the<a id="_idIndexMarker283"/> basis for the random forest, and was invented in 1994 by Leo Breiman. Bagging consists of two parts, the bootstrap and aggregation. <strong class="keyword">Bootstrapping</strong> is sampling <a id="_idIndexMarker284"/>with replacements from the training set. A separate model can be trained on each sample in isolation. These models together form an ensemble. The predictions from the individual models can then be aggregated into a combined decision, for example, by taking the mean.</p>
    <p class="normal">The following diagram (source: Wikipedia) shows how a bagged ensemble is trained and used for prediction. This is how a <strong class="keyword">random forest</strong> (Leo Breiman, 2001) learns <a id="_idIndexMarker285"/>with the decision tree as a base learner.</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_06.png" alt="https://upload.wikimedia.org/wikipedia/commons/b/bd/Bagging_for_Classification_with_descripitons.png"/></figure>
    <p class="packt_figref">Figure 4.6: Bagging</p>
    <p class="normal">The following table shows the<a id="_idIndexMarker286"/> main differences between bagging and boosting:</p>
    <table id="table001-2" class="No-Table-Style _idGenTablePara-1">
      <colgroup>
        <col/>
        <col/>
        <col/>
      </colgroup>
      <tbody>
        <tr class="No-Table-Style">
          <td class="No-Table-Style"/>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Bagging</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Boosting</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Base learners are trained:</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Independently (can be learned in parallel)</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Sequentially</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Weights are:</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Left unchanged</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Changed after every iteration</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Base learners are weighted:</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Equally</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">According to training performance</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="packt_figref">Figure 4.7: Differences between bagging and boosting</p>
    <p class="normal"><strong class="keyword">Gradient boosting</strong> (developed by Friedman and others) is a further extension of boosting with Unhyphenate. In <a id="_idIndexMarker287"/>gradient boosting, new weak learners are added in a fashion that they are maximally correlated with the negative gradient of the loss function. These are some popular implementations<a id="_idIndexMarker288"/> for gradient boosted trees:</p>
    <ul>
      <li class="bullet">CatBoost (by Andrey Gulin and others at Yandex)</li>
      <li class="bullet">Light Gradient Boosting Machine (LightGBM, at Microsoft)</li>
      <li class="bullet">XGBoost</li>
    </ul>
    <p class="normal">Backpropagation<a id="_idIndexMarker289"/> was rediscovered in 1986 by David Rumelhart, Geoffrey Hinton, and Ronald J. Williams. Shortly after, deeper networks were developed that could be applied to more interesting problems that attracted attention.</p>
    <p class="normal">Between 1995 and 1997, Sepp Hochreiter and Jürgen Schmidhuber proposed a recurrent neural network architecture, the <strong class="keyword">long short-term memory</strong> (<strong class="keyword">LSTM</strong>). For many years, LSTMs constituted the state-of-the-art <a id="_idIndexMarker290"/>for many applications in voice recognition, translation, and more. Today, recurrent neural networks, have been largely replaced by transformers or ConvNets, even for sequence modeling tasks. With LSTM's high demands on computing resources, some people go as far as regarding the LSTM as obsolete given the alternatives.</p>
    <p class="normal"><strong class="keyword">Support Vector Machines</strong> (<strong class="keyword">SVMs</strong>) were<a id="_idIndexMarker291"/> developed in the early 1990s at AT&amp;T Bell Laboratories by Vladimir Vapnik and colleagues based on statistical learning frameworks described by Vapnik and Chervonenkis. In classification, SVMs maximize the distance between the two categories in a projected space. As part of the training, a hyperplane, called a support vector, is constructed that separates positive and negative examples.</p>
    <p class="normal">In the next section, we'll go through the basics of machine learning modeling and scientific practices in model validation.</p>
    <h1 id="_idParaDest-68" class="title">Machine learning workflow</h1>
    <p class="normal">In the next section, we'll go through the basics of time-series and machine learning.</p>
    <p class="normal">Machine learning mostly deals with<a id="_idIndexMarker292"/> numerical data that is in tabular form as a matrix of size <img src="../Images/B17577_04_015.png" alt="" style="height: 0.8em;"/>. The layout is generally in a way that each row <img src="../Images/B17577_04_016.png" alt="" style="height: 1em;"/> represents an observation, and each column <img src="../Images/B17577_04_017.png" alt="" style="height: 1em;"/> represents a feature.</p>
    <p class="normal">In time-series problems, the column related to time doesn't necessarily serve as a feature, but rather as an index to slice and order the dataset. Time columns can, however, be transformed into features, as we'll see in <em class="chapterRef">Chapter 3</em>, <em class="italic">Preprocessing time-series</em>.</p>
    <p class="normal">Each observation is described by a vector of M features. Although a few machine learning algorithms can deal with non-numerical data internally, typically, each feature is either numerical or gets converted to numbers before feeding it into a machine learning algorithm. An example of a conversion is representing Male as 0 and Female as 1. Put simply, each feature can be defined as follows:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_018.png" alt="" style="height: 2em;"/></figure>
    <p class="normal">The machine learning workflow<a id="_idIndexMarker293"/> can be separated into three processes, as shown in the following diagram. I've added data loading and time-series analysis, which informs machine learning.</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_07.png" alt="machine_learning_workflow_cropped.png"/></figure>
    <p class="packt_figref">Figure 4.8: Machine learning workflow</p>
    <p class="normal">We first must transform (or preprocess) our data, train or fit a model, and then we can apply the trained model to new data. This diagram, very simplistic perhaps, puts the focus on the three different stages of the machine learning process. Each stage comes with its own challenges and particularities for time-series data.</p>
    <p class="normal">This can also <a id="_idIndexMarker294"/>help to think about the data flow from input to transform to training to prediction. We should keep in mind the available historical data and its limitations, as well as the future data points that are to be used for predictions.</p>
    <p class="normal">In the next section, we'll discuss the general principles of cross-validation.</p>
    <h2 id="_idParaDest-69" class="title">Cross-validation </h2>
    <p class="normal">Here's a well-known saying in <a id="_idIndexMarker295"/>machine learning attributed to George Box, whom we've encountered several times already in this book: "All models are wrong, but some are useful."</p>
    <p class="normal">Machine learning algorithms make repeatable decisions and, given the correct controls, these decisions can be free from the cognitive biases that underlie much of human decision making. The point is to make sure that our <a id="_idIndexMarker296"/>model is useful by validating performance. In machine learning, the process of testing a model on data it hasn't seen in training is called cross-validation (sometimes, <strong class="keyword">out-of-sample testing</strong>). </p>
    <p class="normal">To ensure that parameters estimated on a dataset of limited size are still valid for more data, we must go through a validation that makes sure that the quality holds up. For validation, we usually split the dataset into at least two parts, the training set and the test set. We estimate parameters on a training set, and then run the model on the test set to get an idea of the quality of the model on unseen data points. This is illustrated in the following diagram:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_08.png" alt=""/></figure>
    <p class="packt_figref">Figure 4.9: Cross-validation</p>
    <p class="normal">Usually, in machine learning we would shuffle points randomly before splitting between training and test. However, in time-series, we would take older data points for training and newer points for testing. For instance, having 1 year of data available on the email opening propensities of customers, we would train a model on 9 months' worth of data, validate our model on 2 months' worth of data, and test the final performance on the dataset. </p>
    <p class="normal">The use of validation and test can be seen as a nested process in the sense that the test set checks the main testing process that involves the validation dataset. Often, the separation of validation and test sets is omitted, so the dataset is split only into training and test sets.</p>
    <p class="normal">A note about terminology: while a <strong class="keyword">loss function</strong> is<a id="_idIndexMarker297"/> part of the optimization for training your model, a <strong class="keyword">metric</strong> is <a id="_idIndexMarker298"/>used to evaluate your model. The evaluation can be post-hoc, after training, or during training as additional information. In this section, we'll discuss both metrics and loss functions.</p>
    <p class="normal">It is good practice to start a project with an assessment of how to measure performance. We need to choose how to measure performance to translate the business problem into a metric or a loss. Some algorithms allow flexibility in the choice of objective functions, others don't, but we can measure performance with a different metric.</p>
    <p class="normal">Next, we'll be discussing error and loss metrics for regression and classification. </p>
    <h2 id="_idParaDest-70" class="title">Error metrics for time-series</h2>
    <p class="normal">Time-series data is defined <a id="_idIndexMarker299"/>as a set of data points containing details about different points in time. Generally, time-series data contains data points sampled or observed at an equal interval of time. </p>
    <p class="normal">For the different applications that we discussed earlier, we need to be able to quantify the performance of the model, be it a regression, classification, or another type of model, and choose a metric that captures the performance we want to achieve. Once we have chosen a metric for our model, we can then build and train models to improve them. Often, we'd start with a simpler model and then try to improve on the performance of this simpler model as a baseline. In the end, we want to find the model that is best according to our metric.</p>
    <p class="normal">In this section, we'll discuss commonly used performance measures and their properties. Generally, for an error measure, the smaller the values, the better the prediction (or the forecast). In changing the parameters of our model, we want to reduce the error.</p>
    <p class="normal">There's not just a single metric that's apt for the purpose of any arbitrary application or dataset. Depending on the dataset, you might have to search and try different error metrics and see which one best captures your objective. In some circumstances, you might even want to define your own metric.</p>
    <h3 id="_idParaDest-71" class="title">Regression</h3>
    <p class="normal">Time-Series regression<a id="_idIndexMarker300"/> is the task of identifying patterns and signals in the features in relation to the behavior of time-series, for example, how skill improves with the time invested in practice. </p>
    <p class="normal">During training, when your <a id="_idIndexMarker301"/>regression model gives a result on the training set, we can utilize a metric that compares the model output to the training set values, and during validation, we can calculate the same measure to know how good our regression predictions line up to the validation set targets. The error metric summarizes the difference between the values predicted by your machine learning model and the actual values.</p>
    <p class="normal">If <img src="../Images/B17577_04_019.png" alt="" style="height: 1em;"/> is a<a id="_idIndexMarker302"/> prediction of <a id="_idIndexMarker303"/>the model<a id="_idIndexMarker304"/> for time step <em class="italic">t</em>, and the actual target value is <em class="italic">y</em><sub class="" style="font-style: italic;">t</sub>, intuitively, for a particular point, <em class="italic">t</em>, of our dataset, the <strong class="keyword">forecast error</strong> (also <strong class="keyword">prediction error</strong> or <strong class="keyword">residual</strong>) is the difference between the actual values of the target and the values our model predicts:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_020.png" alt="" style="height: 2em;"/></figure>
    <p class="normal">This compares the actual target Y to the predicted targets <img src="../Images/B17577_04_021.png" alt="" style="height: 1em;"/>. According to this formula, the error is negative if the prediction is <a id="_idIndexMarker305"/>higher than the actual target value. The <strong class="keyword">sum of squares of the residuals</strong> (SS, also <strong class="keyword">residual sum of squares</strong>) ignores the direction of the error:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_022.png" alt="" style="height: 2.5em;"/></figure>
    <p class="normal">While both the residual and the squared residual could already be used to measure the performance of predictions over a time-series, they are not commonly used as a regression metric or loss. </p>
    <p class="normal">Let's start with the most commonly used <a id="_idIndexMarker306"/>metric for regression: the <strong class="keyword">coefficient of determination</strong>. This is a relatively simple formula based on a ratio of the sum of the squares of the residuals, SS, and the total sum of squares, TSS, a measure of the variability:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_023.png" alt="" style="height: 2.5em;"/></figure>
    <p class="normal">In this fraction, the nominator is the sum of the squares of the residuals, SS, the unexplained variance. </p>
    <p class="normal">The denominator is TSS, the total sum of squares. This is defined as <img src="../Images/B17577_04_024.png" alt="" style="height: 3.5em;"/>, where <img src="../Images/B17577_04_025.png" alt="" style="height: 1em;"/> is the mean of the series, <img src="../Images/B17577_04_026.png" alt="" style="height: 3em;"/>. The total sum of squares represents the explained variance of the time-series.</p>
    <p class="normal">Basically, we are measuring the summed squares of residuals in relation to the total variance of the time-series. This fraction, between 0 and 1, where 0 is best – no error at all, is inverted by subtracting from 1, so that finally 0 is worst and 1 is best. </p>
    <p class="normal">When expanded, this looks as follows:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_027.png" alt="" style="height: 3em;"/></figure>
    <p class="normal"><img src="../Images/B17577_04_028.png" alt="" style="height: 1em;"/> expresses the proportion of the variance in the dependent variable that is predictable from the independent variable. As mentioned, it is bounded between 0 and 1, where 1 means there's a perfect relationship, and 0 means there's no relationship at all. </p>
    <p class="normal">The <a id="_idIndexMarker307"/>coefficient of determination, <img src="../Images/B17577_04_029.png" alt="" style="height: 1em;"/>, is not an error measure since an error measure expresses the distribution of residuals so that high is bad and low is good. We could, however, express an error measure, let's call <a id="_idIndexMarker308"/>it the <strong class="keyword">r-error (RE)</strong>, very similar to the above, as:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_030.png" alt="" style="height: 3em;"/></figure>
    <p class="normal">This is rarely used<a id="_idIndexMarker309"/> in practice. An error measure very similar to RE is the <strong class="keyword">mean relative absolute error</strong> (<strong class="keyword">MRAE</strong>), which we'll discuss further ahead.</p>
    <p class="normal">Naively, we could take the average error, where we just take the mean over the forecast error – the mean error:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_031.png" alt="" style="height: 3.2em;"/></figure>
    <p class="normal">Here, <em class="italic">N</em> is the number of points (or the number of discrete time steps). We calculate the error for each point and then take the mean over all these errors.</p>
    <p class="normal">If the ME is positive, the model systematically underestimates the targets, if it's positive, it overestimates the targets on the whole. While this can be useful, it's a serious problem for an error metric, however, because the effects of positive and negative errors cancel each other out. Therefore, a low ME does not mean that predictions are good, rather that the average is close to zero. </p>
    <p class="normal">Furthermore, most regression models include a constant term that is equal to the mean of the target, so this value would be exactly 0. In conclusion, our naïve measure is useless in practical settings. </p>
    <p class="normal">I've included the ME for discussion of why most measures that are commonly used discard the direction of the error and for highlighting the importance of the main components of the basic error metrics:</p>
    <ul>
      <li class="bullet">The residual operation</li>
      <li class="bullet">The integration</li>
    </ul>
    <p class="normal">In the case of the ME, the residual operation is the identify function, which means the residual doesn't change. More often, the square or absolute functions are used. The integration of the errors is often the (arithmetic) mean, but sometimes the median; however, it can be a more complex operation.</p>
    <p class="normal">In practice, the<a id="_idIndexMarker310"/> most popular error <a id="_idIndexMarker311"/>metrics are the mean squared error (MSE), mean absolute error (MAE), and the root mean squared error (RMSE). These most <a id="_idIndexMarker312"/>important error metrics are defined in the following table:</p>
    <table id="table002-1" class="No-Table-Style _idGenTablePara-1">
      <colgroup>
        <col/>
        <col/>
      </colgroup>
      <tbody>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Metric Name</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Definition</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <figure class="mediaobject">Mean squared error</figure>
          </td>
          <td class="No-Table-Style">
            <figure class="mediaobject"><img src="../Images/B17577_04_032.png" alt="" style="height: 1.76em;"/></figure>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <figure class="mediaobject">Mean absolute error</figure>
          </td>
          <td class="No-Table-Style">
            <figure class="mediaobject"><img src="../Images/B17577_04_033.png" alt="" style="height: 1.76em;"/></figure>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <figure class="mediaobject">Root mean squared error</figure>
          </td>
          <td class="No-Table-Style">
            <figure class="mediaobject"><img src="../Images/B17577_04_034.png" alt="" style="height: 0.76em;"/></figure>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="packt_figref">Figure 4.10: Popular regression metrics</p>
    <p class="normal">With the <strong class="keyword">mean squared error (MSE)</strong>, we <a id="_idIndexMarker313"/>calculate the residual for each point, then square them, so positive and negative errors don't cancel each other out. Then we take the mean over these squared errors. An MSE of 0 indicates perfect performance. This can happen with toy datasets that you can play around with for fun; however, in practice, this will only happen if you made a mistake in building your dataset or in validation, because real life is always more complex than you can capture with a model.</p>
    <p class="normal">The <strong class="keyword">mean absolute error (MAE)</strong> is very<a id="_idIndexMarker314"/> similar to the MSE, only instead of squaring the residuals, we take their absolute values. As opposed to the MSE, all errors contribute in linear proportion (rather than being squared).</p>
    <p class="normal">A major difference between taking the absolute versus taking the square is in how outliers or extreme values are treated. The square function forces a higher weight on values that are very different. With the MSE, the error grows quadratically instead of linearly as is the case with the MAE. This means that the MSE punishes extreme values much more strongly and, as a result, it is less robust to outliers in the dataset than the MAE. The distribution of the errors is a major concern in choosing an error metric that's right for the job.</p>
    <p class="normal">Another common metric is <a id="_idIndexMarker315"/>the <strong class="keyword">root mean squared error (RMSE)</strong>, or <strong class="keyword">root mean square deviation (RMSD),</strong> which, as the name suggests, is the square root of the <a id="_idIndexMarker316"/>MSE. In that sense, RMSE is a scaled version of the MSE. Which one to take between the two is a presentation choice – both of them would lead to the same models.</p>
    <p class="normal">What makes the RMSE interesting as a choice is that it comes in the same units and scale as the predicted variable, which makes it more intuitive. Finally, the RMSE is equivalent to the standard deviation or the error. This connection between standard deviation and the distribution of errors is quite meaningful, and you can summarize the error distribution with other measures such as the standard error or confidence interval (both of which we've discussed in <em class="chapterRef">Chapter 2</em>, <em class="italic">Time-Series Analysis with Python</em>).</p>
    <p class="normal">There are many more metrics and they all have their purpose. The following table sums up a few more popular error metrics in time-series modeling:</p>
    <table id="table003" class="No-Table-Style _idGenTablePara-1">
      <colgroup>
        <col/>
        <col/>
      </colgroup>
      <tbody>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Metric Name</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Definition</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Median absolute error</p>
          </td>
          <td class="No-Table-Style">
            <figure class="mediaobject"><img src="../Images/B17577_04_035.png" alt="" style="height: 1.5em;"/></figure>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Mean absolute percentage error</p>
          </td>
          <td class="No-Table-Style">
            <figure class="mediaobject"><img src="../Images/B17577_04_036.png" alt="" style="height: 4.22em;"/></figure>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Symmetric mean absolute percentage error</p>
          </td>
          <td class="No-Table-Style">
            <figure class="mediaobject"><img src="../Images/B17577_04_037.png" alt="" style="height: 4.22em;"/></figure>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Normalized mean squared error</p>
          </td>
          <td class="No-Table-Style">
            <figure class="mediaobject"><img src="../Images/B17577_04_038.png" alt="" style="height: 2.7em;"/></figure>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="packt_figref">Figure 4.11: More metrics for regression</p>
    <p class="normal">The <strong class="keyword">median absolute error (MdAE)</strong> is <a id="_idIndexMarker317"/>similar to the MAE. However, instead of the mean operation for integration, a different average, the median, is employed. Since the median is unaffected by values at the tails, this measure is even more robust than the MAE.</p>
    <p class="normal">The <strong class="keyword">mean percentage error (MAPE)</strong> is<a id="_idIndexMarker318"/> the mean average error normalized by the target. 0 represents a perfect model, and higher than 1 means the model's predictions are systematically higher than the targets. The MAPE doesn't have an upper bound. Additionally, since it deals with percentages in terms of the target (scaling or dividing by the targets), positive and negative residuals are treated differently. As a result, if the prediction is bigger than the target, the MAPE is higher than for the same error in the other direction. Therefore, depending on the sign of the residual, the MAPE is higher or lower! </p>
    <p class="normal">The common choice for the denominator is the target; however, you can also scale by the mean of the prediction and <a id="_idIndexMarker319"/>target. This is called the <strong class="keyword">symmetric mean absolute percentage error (SMAPE)</strong>. The SMAPE has not only a lower bound but also an upper bound, which makes the percentage much easier to interpret.</p>
    <p class="normal">Scaling can have different benefits as well. If you want to compare models validated on different datasets, the measures presented before wouldn't be helpful. The split between training, validation, and test sets is randomized, so when you compare model performances, any of these measures would confound the effects of dataset variance in the validation set and the effect of the model performance itself.</p>
    <p class="normal">Therefore, the <strong class="keyword">normalized mean squared error (NMSE)</strong> is particularly intuitive as a presentation choice over the <a id="_idIndexMarker320"/>MSE because it scales the model's performance with the deviation. The NMSE normalizes the MSE obtained after dividing it by the target variance.</p>
    <p class="normal">There are lots of other error measures. Some error measures compare predictions against predictions of a naïve model that returns the average target value.</p>
    <p class="normal">The prediction performance of this naïve model is:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_039.png" alt="" style="height: 3.5em;"/></figure>
    <p class="normal">We can normalize prediction errors by dividing the prediction error by this naïve prediction error.</p>
    <p class="normal">This way, we can<a id="_idIndexMarker321"/> define several other measures:</p>
    <table id="table004" class="No-Table-Style _idGenTablePara-1">
      <colgroup>
        <col/>
        <col/>
      </colgroup>
      <tbody>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <figure class="mediaobject"><strong class="keyword">Metric Name</strong></figure>
          </td>
          <td class="No-Table-Style">
            <figure class="mediaobject"><strong class="keyword">Definition</strong></figure>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <figure class="mediaobject">Mean relative absolute error</figure>
          </td>
          <td class="No-Table-Style">
            <figure class="mediaobject"><img src="../Images/B17577_04_040.png" alt="" style="height: 4.5em;"/></figure>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <figure class="mediaobject">Median relative absolute error</figure>
          </td>
          <td class="No-Table-Style">
            <figure class="mediaobject"><img src="../Images/B17577_04_041.png" alt="" style="height: 3.33em;"/></figure>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <figure class="mediaobject">Relative root mean squared error</figure>
          </td>
          <td class="No-Table-Style">
            <figure class="mediaobject"><img src="../Images/B17577_04_042.png" alt="" style="height: 6.11em;"/></figure>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="packt_figref">Figure 4.12: Normalized regression metrics</p>
    <p class="normal">All these measures should be intuitive if you have the idea of the naïve model in mind and you want to compare the performance of the naïve model with the same error metric by dividing. </p>
    <p class="normal">The <strong class="keyword">mean relative absolute error</strong> (<strong class="keyword">MRAE</strong>) is very similar to the coefficient of determination, with<a id="_idIndexMarker322"/> the only difference being that the MRAE takes the averages rather than the sums.</p>
    <p class="normal">Another error is<a id="_idIndexMarker323"/> the <strong class="keyword">root mean squared logarithmic error</strong> (<strong class="keyword">RMSLE</strong>).</p>
    <table id="table005" class="No-Table-Style _idGenTablePara-1">
      <colgroup>
        <col/>
        <col/>
      </colgroup>
      <tbody>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-"><strong class="keyword">Metric Name</strong></p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-"><strong class="keyword">Definition</strong></p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Root mean squared logarithmic error</p>
          </td>
          <td class="No-Table-Style">
            <figure class="mediaobject"><img src="../Images/B17577_04_043.png" alt="" style="height: 4.8em;"/></figure>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="packt_figref">Figure 4.13: Root mean squared logarithmic error</p>
    <p class="normal">In the case of the RMSLE, you take the log of the residuals as the basic operation. This is to avoid penalizing large differences in the error when both predicted and true values are very high values. Because of the inflection point of the logarithm at 1, the RMLSE has the unique property that it penalizes the underestimation of the actual value more severely than it does for overestimation. This can be useful when the distributions of errors don't follow a normal distribution similar to the scaling operations that we've discussed in <em class="chapterRef">Chapter 3</em>, <em class="italic">Preprocessing Time-Series</em>.</p>
    <p class="normal">We could extend the number of metrics if we take into account metrics based on entropy, such as Theil's Uncertainty. <strong class="keyword">Theil's U</strong> is a<a id="_idIndexMarker324"/> normalized measure of the total prediction error. U is between 0 and 1, where 0 means a perfect fit. It is based on the concept of conditional entropy, and can also be used as a measure of uncertainty or even as a correlation measure in categorical-categorical cases.</p>
    <p class="normal">As these headers say, the first two concentrate on quantifying the performance of models. The last section is useful for distance-based models, which are often used as a solid baseline for performance.</p>
    <p class="normal">Let's switch over to error metrics for classification tasks.</p>
    <h3 id="_idParaDest-72" class="title">Classification</h3>
    <p class="normal">Many metrics are specific to more <a id="_idIndexMarker325"/>binary classification (where there are exactly two classes), although some of them can be extended to the case of multi-class classification, where the number of classes is bigger than two.</p>
    <p class="normal">In binary classification, we can contrast the prediction against the actual outcome in a <strong class="keyword">confusion matrix</strong>, where <a id="_idIndexMarker326"/>predictions and actual outcomes are cross-tabulated like this:</p>
    <table id="table006" class="Basic-Table _idGenTablePara-1">
      <colgroup>
        <col/>
        <col/>
        <col/>
        <col/>
      </colgroup>
      <tbody>
        <tr class="Basic-Table">
          <td class="Basic-Table"/>
          <td class="Basic-Table"/>
          <td class="Basic-Table" colspan="2">
            <figure class="mediaobject"><strong class="keyword">Actual outcome</strong></figure>
          </td>
        </tr>
        <tr class="Basic-Table">
          <td class="Basic-Table"/>
          <td class="Basic-Table"/>
          <td class="Basic-Table">
            <figure class="mediaobject">false</figure>
          </td>
          <td class="Basic-Table">
            <figure class="mediaobject">true</figure>
          </td>
        </tr>
        <tr class="Basic-Table">
          <td class="Basic-Table" rowspan="2">
            <figure class="mediaobject"><strong class="keyword">Predicted outcome</strong></figure>
          </td>
          <td class="Basic-Table">
            <figure class="mediaobject">false</figure>
          </td>
          <td class="Basic-Table">
            <figure class="mediaobject">true negative (TN)</figure>
          </td>
          <td class="Basic-Table">
            <figure class="mediaobject">false negative (FN)</figure>
          </td>
        </tr>
        <tr class="Basic-Table">
          <td class="Basic-Table">
            <figure class="mediaobject">true</figure>
          </td>
          <td class="Basic-Table">
            <figure class="mediaobject">false positive (FP)</figure>
          </td>
          <td class="Basic-Table">
            <figure class="mediaobject">true positive (TP)</figure>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="packt_figref">Figure 4.14: Confusion matrix</p>
    <p class="normal">This is a crucial visualization for classification tasks, and many measures are based on summarizing this.</p>
    <p class="normal">Two of the most important metrics for classification are precision and recall. <strong class="keyword">Recall</strong> is the ratio of the number of correctly predicted positive instances across <a id="_idIndexMarker327"/>all positive instances. We can also state this in terms of the confusion matrix as follows:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_044.png" alt="" style="height: 2.5em;"/></figure>
    <p class="normal">Recall is also<a id="_idIndexMarker328"/> called the <strong class="keyword">true positive rate</strong> or <strong class="keyword">sensitivity</strong>. It focuses on the true predictions, ignoring the <a id="_idIndexMarker329"/>negative instances; however, we might also want to know how accurate the positive <a id="_idIndexMarker330"/>predictions are. This<a id="_idIndexMarker331"/> is <strong class="keyword">precision</strong> defined as:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_045.png" alt="" style="height: 2.5em;"/></figure>
    <p class="normal">We can visualize these two metrics as follows:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_09.png" alt="/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/(A Document Being Saved By screencaptureui 12)/Screenshot 2021-04-26 at 00.05.38.png"/></figure>
    <p class="packt_figref">Figure 4.15: False positives (FP), true positives (TP), and false negatives (FN)</p>
    <p class="normal">In this graph, <strong class="keyword">false positives</strong> (<strong class="keyword">FP</strong>), <strong class="keyword">true positives</strong> (<strong class="keyword">TP</strong>), and <strong class="keyword">false negatives</strong> (<strong class="keyword">FN</strong>) are shown. You<a id="_idIndexMarker332"/> can see instances that <a id="_idIndexMarker333"/>are actually true, instances that are classified <a id="_idIndexMarker334"/>as true by the model, and the intersection of the two – instances that are true and that the model classifies as true.</p>
    <p class="normal">We can quickly count and calculate precision and recall. We have four true positives and six false positives. The precision for this example is therefore <img src="../Images/B17577_04_046.png" alt="" style="height: 2.22em;"/>.</p>
    <p class="normal">We have four false negatives. The recall is <img src="../Images/B17577_04_047.png" alt="" style="height: 2.22em;"/>.</p>
    <p class="normal">Both recall and precision are obviously important, so why not integrate them? The <img src="../Images/B17577_04_048.png" alt="" style="height: 1em;"/> score is the harmonic mean of precision and sensitivity:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_049.png" alt="" style="height: 3.31em;"/></figure>
    <p class="normal">We can also parametrize the relative importance of recall and precision. This is a generalized version of the <img src="../Images/B17577_04_050.png" alt="" style="height: 1em;"/> score, the <img src="../Images/B17577_04_051.png" alt="" style="height: 1em;"/> score:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_052.png" alt="" style="height: 2.9em;"/></figure>
    <p class="normal">Another very useful metric comes <a id="_idIndexMarker335"/>from the <strong class="keyword">receiver operator curve (ROC)</strong>, which plots <a id="_idIndexMarker336"/>the <strong class="keyword">true positive rate</strong> (<strong class="keyword">TPR</strong>) against <a id="_idIndexMarker337"/>the <strong class="keyword">false positive rate</strong> (<strong class="keyword">FPR</strong>) at various threshold settings. The <strong class="keyword">false positive rate</strong>, also called the <strong class="keyword">false alarm ratio</strong>, is defined analogously to the true<a id="_idIndexMarker338"/> positive rate (recall) as:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_053.png" alt="" style="height: 2.5em;"/></figure>
    <p class="normal">An ROC graph shows the relationship between sensitivity and specificity, with the general idea being that it is very hard to do both and find all positive instances (sensitivity) and to do them correctly. More often than not, you have to compromise between sensitivity and specificity. This <a id="_idIndexMarker339"/>plot illustrates how well your model maneuvers this issue. The <strong class="keyword">area under the curve</strong> summarizes the plot and is a metric that's often used in practice.</p>
    <p class="normal">Another less common metric is <a id="_idIndexMarker340"/>the <strong class="keyword">Correlation Ratio</strong>, which was introduced by Karl Pearson as a measure of categorical-continuous association:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_054.png" alt="" style="height: 3.5em;"/></figure>
    <p class="normal">where <img src="../Images/B17577_04_055.png" alt="" style="height: 1em;"/><span class="mediaobject"> </span>is the number of observations in category <em class="italic">x</em>, and we define:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_056.png" alt="" style="height: 3.8em;"/></figure>
    <p class="normal">The correlation ratio <a id="_idIndexMarker341"/>is based on the variance within individual categories and the variance across the whole population. <img src="../Images/B17577_04_057.png" alt="" style="height: 1em;"/> is in the range [0,1] where 0 means a category is not associated, and 1 means a category is associated with absolute certainty.</p>
    <p class="normal">In the next section, we'll examine similarity measures between time-series.</p>
    <h2 id="_idParaDest-73" class="title">Comparing time-series</h2>
    <p class="normal">Similarity measures have<a id="_idIndexMarker342"/> applications in time-series indexing for retrieval in search, clustering, forecasting, regression, and classification, but if we want to decide whether two temporal sequences are similar, how do we measure the similarity?</p>
    <p class="normal">The simplest would be to use the Pearson correlation coefficient; however, other measures can be more informative.</p>
    <p class="normal">We'll go through a series of measures to compare a pair of time-series:</p>
    <ul>
      <li class="bullet">Euclidean distance</li>
      <li class="bullet">Dynamic time warping</li>
      <li class="bullet">Granger causality</li>
    </ul>
    <p class="normal">The <strong class="keyword">Euclidean distance</strong>, a generic<a id="_idIndexMarker343"/> distance, is applicable to any pair of vectors, including time-series:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_058.png" alt="" style="height: 3.8em;"/></figure>
    <p class="normal">The Euclidean distance<a id="_idIndexMarker344"/> can be useful; however, in practice, for time-series you can do better. You can take the Euclidean distance over the time-series that has been transformed by the fast Fourier transformed to a frequency domain.</p>
    <p class="normal">Intuitively, the exact time position and its duration of events in time-series can vary. <strong class="keyword">Dynamic time warping</strong> (<strong class="keyword">DTW</strong>) is one of<a id="_idIndexMarker345"/> the algorithms for measuring similarity between two temporal sequences, which may vary in speed. Intuitively, the exact time position and its duration of events in time-series can vary. A similarity measure between time-series should be able to deal with these kinds of shifts and elongations.</p>
    <p class="normal">In general, DTW is a method that calculates an optimal match between two given time sequences with certain restrictions and rules according to a heuristic. Basically, it attempts to match indexes from the first sequence to indexes from the other sequence. DTW is an edit distance – it expresses the cost of transforming a sequence t1 into t2.</p>
    <p class="normal">DTW has been applied to automatic speech recognition because of its ability to cope with different speeds. DTW, however, fails at quantifying dissimilarity between non-matching sequences.</p>
    <p class="normal">DTW is applied to each feature dimension independently and then the distances can be summed up. Alternatively, the warping can cover all features simultaneously by calculating the distance between two points as the Euclidean distance across all dimensions. Thus, this Dependent Warping (<img src="../Images/B17577_04_059.png" alt="" style="height: 1em;"/>) is a multivariate approach.</p>
    <p class="normal"><strong class="keyword">Granger causality</strong> determines <a id="_idIndexMarker346"/>if a time-series can help to forecast another time-series. Although the question of true causality in the measure is debatable, the measure considers values of one series prior in time to values of the other, and it can be argued that the measure shows a temporal relationship or a relationship in the predictive sense.</p>
    <p class="normal">Granger causality is quite intuitive in both its idea and its formulation. Its two principles are (simplified):</p>
    <ol>
      <li class="numbered">The cause must precede the effect</li>
      <li class="numbered">The cause has a unique effect on the result</li>
    </ol>
    <p class="normal">Therefore, if we can fit a model that shows that X and Y have a relationship in which Y systematically follows X, this is taken to mean that X Granger causes Y.</p>
    <h1 id="_idParaDest-74" class="title">Machine learning algorithms for time-series</h1>
    <p class="normal">An important distinction in machine learning for time-series is the one between univariate and multivariate, in which algorithms are univariate, which means that they can only work with a single <a id="_idIndexMarker347"/>feature, or multi-variate, which means that they work with many features.</p>
    <p class="normal">In univariate datasets, each case has a single series and a class label. Earlier models (classical modeling) focused on univariate datasets and applications. This is also reflected in the availability of datasets. </p>
    <p class="normal">One of the most important repositories for time-series datasets, the <strong class="keyword">UCR</strong> (<strong class="keyword">University of California, Riverside</strong>) archive, which was released first in 2002, has provided <a id="_idIndexMarker348"/>a valuable resource for univariate time-series. It now contains about 120 datasets, but is lacking multivariate datasets. Furthermore, the M competitions (especially M3, 4, and 5) have a lot of available time-series datasets.</p>
    <p class="normal">Multivariate time-series are datasets that have multiple feature dimensions. Many real-life datasets are <a id="_idIndexMarker349"/>inherently multivariate – multivariate cases are much more frequent in<a id="_idIndexMarker350"/> practice than univariate. Examples include human activity recognition, diagnoses based on an <strong class="keyword">electrocardiogram</strong> (<strong class="keyword">ECG</strong>), <strong class="keyword">electroencephalogram</strong> (<strong class="keyword">EEG</strong>), <strong class="keyword">magnetoencephalography</strong> (<strong class="keyword">MEG</strong>), and <a id="_idIndexMarker351"/>systems monitoring.</p>
    <p class="normal">Only recently (Anthony Bagnall and others, 2018) created the <strong class="keyword">UAE</strong> (<strong class="keyword">University of East Anglia</strong>) archive with <a id="_idIndexMarker352"/>30 multivariate datasets. Another archive for multivariate datasets is the MTS archive.</p>
    <p class="normal">In the next section, we'll briefly discuss distance-based approaches.</p>
    <h2 id="_idParaDest-75" class="title">Distance-based approaches</h2>
    <p class="normal">In the k-nearest-neighbor<a id="_idIndexMarker353"/> approaches (kNN for short), which we mentioned earlier, training examples are stored, and then, at inference time when a prediction for a new data point is required, the prediction is based on the closest k neighbors. This requires a distance measure between examples.</p>
    <p class="normal">I've introduced two measures for time-series, <strong class="keyword">Dynamic Time Warping</strong> (<strong class="keyword">DTW</strong>) and Euclidean distances, earlier in this chapter. Many <a id="_idIndexMarker354"/>distance-based approaches take either of these as a distance measure.</p>
    <p class="normal">Another approach that has been tried is extracting features from time-series, and then storing these<a id="_idIndexMarker355"/> extracted features for retrieval with kNN. These features include shapelets or <strong class="keyword">scale-invariant features</strong> (<strong class="keyword">SIFT</strong>). SIFT features are extracted from time-series as shapes surrounding the extremum (Adeline Bailly and others, 2015).</p>
    <p class="normal">We've discussed shapelets and ROCKET in separate sections in <em class="chapterRef">Chapter 3</em>, <em class="italic">Preprocessing Time-Series</em>, so we'll keep their descriptions brief, but focus on their applications in machine learning.</p>
    <h2 id="_idParaDest-76" class="title">Shapelets</h2>
    <p class="normal">We've discussed shapelets in <em class="chapterRef">Chapter 3</em>, <em class="italic">Preprocessing Time-Series</em>, so we'll keep it brief here. Shapelets for <a id="_idIndexMarker356"/>time-series were presented in the research paper "<em class="italic">Time-Series Shapelets</em>: <em class="italic">a novel technique that allows accurate, interpretable and fast classification</em>" (Lexiang Ye and Eamonn Keogh, 2011). The basic idea of shapelets is decomposing the time-series into discriminative subsections (called <strong class="keyword">Shapelets</strong>). A few methods have been presented that are based on shapelet features.</p>
    <p class="normal">The <strong class="keyword">Shapelet Transform Classifier</strong> (<strong class="keyword">STC</strong>; Hills and others, 2014) consists of taking the shapelets as feature<a id="_idIndexMarker357"/> transformation and then feeding the shapelets into a machine learning algorithm. They tested the C4.5 decision tree, Naïve Bayes, 1NN, SVM, and a rotation forest, but didn't find any significant differences between these methods in a classification setting.</p>
    <p class="normal">The <strong class="keyword">Generalized random shapelet forest</strong> (<strong class="keyword">gRFS</strong>; Karlsson and others, 2016) follows the idea of the random forest. Each<a id="_idIndexMarker358"/> tree is built on a distinct set of shapelets of random length, which are extracted from one random dimension for each tree. A decision tree is trained on top of these shapelets. These random shapelet trees are then integrated as the ensemble model, which is the gRFS.</p>
    <h2 id="_idParaDest-77" class="title">ROCKET</h2>
    <p class="normal">We've explained <a id="_idIndexMarker359"/>ROCKET in <em class="chapterRef">Chapter 3</em>, <em class="italic">Preprocessing Time-Series</em>. Each input feature gets transformed separately by 10,000 random kernels (this number can be changed). In practice, this is a very fast process. These transformed features can be fed into a machine learning algorithm. Its inventors, Angus Dempster, François Petitjean, and Geoff Webb, recommended a linear model in the original publication (2019).</p>
    <p class="normal">Recently, a new variant, MINIROCKET, was published that is about 75 times faster than ROCKET while maintaining <a id="_idIndexMarker360"/>roughly the same accuracy – <em class="italic">MINIROCKET: A Very Fast (Almost) Deterministic Transform for Time-Series Classification</em> (<em class="italic">Angus Dempster, Daniel F. Schmidt, and Geoff Webb, 2020</em>).</p>
    <p class="normal">In machine learning research, <strong class="keyword">critical difference (CD) diagrams</strong> are<a id="_idIndexMarker361"/> a powerful visualization tool for comparing outcomes of multiple algorithms. The average ranks indicate how algorithms stack up in relation to each other (a lower rank is better). Algorithmic results are compared statistically – a horizontal line links algorithms, where the differences between them can't be statistically separated.</p>
    <p class="normal">Here's a critical difference diagram that<a id="_idIndexMarker362"/> illustrates the comparative performances of MiniRocket with other algorithms (from the MiniRocket repo by Dempster and others):</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_10.png" alt=""/></figure>
    <p class="packt_figref">Figure 4.16: Mean rank of MiniRocket in terms of accuracy versus other state-of-the-art approaches on 109 datasets of the UCR archive</p>
    <p class="normal">The numbers show the rank of the algorithms across 109 datasets in the test. We can see that MiniRocket is better than Rocket, but worse than TS-CHIEF and HIVE-COTE, although the difference between them is not statistically significant.</p>
    <p class="normal">We'll discuss InceptionTime in <em class="chapterRef">Chapter 10</em>, <em class="italic">Deep Learning for Time-Series</em>. Some of the other methods mentioned will be introduced in the following sections.</p>
    <h2 id="_idParaDest-78" class="title">Time-Series Forest and Canonical Interval Forest</h2>
    <p class="normal">The main innovation of<a id="_idIndexMarker363"/> the <strong class="keyword">Time-Series Forest</strong> (<strong class="keyword">TSF</strong>; by Houtao Deng and others, 2013) was the introduction of the entrance gain as a split criterion for the tree nodes. They showed that an ensemble classifier based on simple features such as mean, deviation, and slope outperforms 1NN classifiers with DTW while being computationally efficient (due to parallelism).</p>
    <p class="normal">The <strong class="keyword">Proximity Forest (PF)</strong>, introduced <a id="_idIndexMarker364"/>by a group of researchers lead by Geoff Webb, is a tree ensemble based on the similarity of each time-series to a set of reference time-series (distance-based features). They found that PF attains a classification performance comparable to BOSS and Shapelet Transforms.</p>
    <p class="normal"><strong class="keyword">TS-CHIEF</strong>, short for <strong class="keyword">Time-Series Combination of Heterogeneous and Integrated Embedding Forest</strong>, comes <a id="_idIndexMarker365"/>from the same group (Ahmed Shifaz, Charlotte Pelletier, François Petitjean, and Geoff Webb, 2020), and it extends PF with dictionary-based (BOSS) and interval-based (RISE) splitters while keeping the original features introduced with PF. The authors claim that depending on the dataset size, it can run between 900 times and 46,000 times faster than HIVE-COTE.</p>
    <p class="normal">The idea of the <strong class="keyword">Canonical Interval Forest</strong> (<strong class="keyword">CIF</strong>; by Matthew Middlehurst, James Large, and Anthony Bagnall, 2020) was <a id="_idIndexMarker366"/>to extend the TSF with the catch22 features. It is an ensemble of time-series trees based on the 22 Catch22 features and summary statistics extracted from phase-dependent intervals. They also used the entrance gain criterion for the trees.</p>
    <p class="normal">In the next section, we describe the evolution of symbolic approaches, from BOSS to the <strong class="keyword">Temporal Dictionary Ensemble</strong> (<strong class="keyword">TDE</strong>).</p>
    <h2 id="_idParaDest-79" class="title">Symbolic approaches</h2>
    <p class="normal">Symbolic approaches are methods that transform a numeric time-series to symbols from an alphabet.</p>
    <p class="normal"><strong class="keyword">Symbolic Aggregate ApproXimation</strong> (<strong class="keyword">SAX</strong>) was <a id="_idIndexMarker367"/>first published by Eamonn Keogh and Jessica Lin in 2002. It extends <strong class="keyword">Piecewise Aggregate Approximation</strong> (<strong class="keyword">PAA</strong>), which <a id="_idIndexMarker368"/>calculates averages within equal segments of the time-series. In SAX, these averages are then quantized (binned), so the alphabet corresponds to intervals of the original numerical values. The two important parameters are the number of segments in PAA and the number of bins.</p>
    <p class="normal">The plot below (from Thach Le Nguyen's MrSEQL repository on GitHub) illustrates how SAX works:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_11.png" alt="https://github.com/lnthach/Mr-SEQL/raw/master/figs/sax_demo.png"/></figure>
    <p class="packt_figref">Figure 4.17: SAX</p>
    <p class="normal">You can see the segments as a grid along the <em class="italic">x</em> axis and the bins as a grid along the <em class="italic">y</em> axis. Each segment is then replaced with its mean value. The time-series is discretized by replacing it in each segment with the bin ID (letter in the plot).</p>
    <p class="normal"><strong class="keyword">Symbolic Fourier Approximation </strong>(<strong class="keyword">SFA</strong>; Patrick Schäfer and Mikael Högqvist, 2012) also transforms a time-series to a<a id="_idIndexMarker369"/> symbolic representation, but using the frequency domain. The dimensionality of the dataset is first reduced by performing Discrete Fourier Transformation, low-pass filtered, and then quantized.</p>
    <p class="normal">The <strong class="keyword">Bag of SFA Symbols (BOSS; </strong>Patrick Schäfer, 2015 and 2016) is based on histograms of n-grams<a id="_idIndexMarker370"/> to form a <strong class="keyword">bag-of-patterns</strong> (<strong class="keyword">BoP</strong>) from SFA representations. BOSS has <a id="_idIndexMarker371"/>been extended as <strong class="keyword">BOSS in Vector Space</strong> (<strong class="keyword">BOSS VS</strong>). The BOSS VS <a id="_idIndexMarker372"/>classifier is one to four orders of magnitude faster than the state of the art and significantly more accurate than the 1-NN DTW. </p>
    <p class="normal">Contract BOSS (cBOSS; Matthew Middlehurst, William Vickers, and Anthony Bagnall, 2019) speeds up BOSS by introducing a new parameter limiting the number of base models.</p>
    <p class="normal"><strong class="keyword">SEQL </strong>(Thach Le Nguyen, Severin Gsponer, and Georgiana Ifrim, 2017) is a symbolic sequence learning algorithm that <a id="_idIndexMarker373"/>selects the most discriminative subsequences for a linear model using greedy gradient descent. This is illustrated here (from the MrSEQL GitHub repo):</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_12.png" alt="/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/(A Document Being Saved By screencaptureui 11)/Screenshot 2021-04-25 at 23.48.05.png"/></figure>
    <p class="packt_figref">Figure 4.18: SEQL</p>
    <p class="normal">The multiple representation <a id="_idIndexMarker374"/>sequence learner (<strong class="keyword">MrSEQL</strong>; Thach Le Nguyen, Severin Gsponer, Iulia Ilie, and Georgiana Ifrim, 2019) is extending SEQL by selecting transformed features across multiple resolutions and multiple domains.</p>
    <p class="normal"><strong class="keyword">WEASEL+MUSE</strong> (Patrick Schäfer and Ulf Leser, 2017 and 2018) consists<a id="_idIndexMarker375"/> of two stages. WEASEL<a id="_idIndexMarker376"/> stands for <strong class="keyword">Word Extraction for Time-Series Classification</strong>, while MUSE stands for <strong class="keyword">Multivariate Unsupervised Symbols and Derivatives</strong>. This deserves emphasizing – while WEASEL is a<a id="_idIndexMarker377"/> univariate method, MUSE extends the method for multivariate problems. </p>
    <p class="normal">In a first step, WEASEL derives features from windows at multiple lengths from the truncated Fourier transform and discretization. This acts in a way similar to a low-pass filter, keeping only the first <em class="italic">l</em> coefficients. These coefficients are then discretized into an alphabet of fixed size and counted<a id="_idIndexMarker378"/> as <strong class="keyword">Bag-of-Patterns</strong> (<strong class="keyword">BOP</strong>) in histograms. This is done in isolation for each feature.</p>
    <p class="normal">In a second step (MUSE), the histogram features are concatenated across dimensions, and a statistical test, the χ2 test, is used for filter-based feature selection, resulting in a much smaller but more discriminative feature set.</p>
    <p class="normal">These BOPs are then fed into a logistic regression algorithm for classification.</p>
    <h2 id="_idParaDest-80" class="title">HIVE-COTE</h2>
    <p class="normal">The <strong class="keyword">Hierarchical Vote Collective of Transformation-Based Ensembles</strong> (<strong class="keyword">HIVE-COTE</strong>) is the current <a id="_idIndexMarker379"/>state of the art in terms of classification accuracy. </p>
    <p class="normal">Proposed in 2016 and adapted in 2020 (Anthony Bagnall and others, 2020), it's an ensemble method that combines a heterogeneous collection of different methods:</p>
    <ul>
      <li class="bullet"><strong class="keyword">Shapelet Transform Classifier</strong> (<strong class="keyword">STC</strong>)</li>
      <li class="bullet"><strong class="keyword">Time-Series Forest</strong> (<strong class="keyword">TSF</strong>)</li>
      <li class="bullet"><strong class="keyword">Contractable Bag of Symbolic-Fourier Approximation Symbols</strong> (<strong class="keyword">CBOSS</strong>)</li>
      <li class="bullet"><strong class="keyword">Random Interval Spectral Ensemble</strong> (<strong class="keyword">RISE</strong>)</li>
    </ul>
    <p class="normal"><strong class="keyword">Random Interval Spectral Ensemble (RISE</strong>) is a<a id="_idIndexMarker380"/> tree-based time-series classification algorithm, originally introduced as <strong class="keyword">Random Interval Features</strong> (<strong class="keyword">RIF</strong>) at <a id="_idIndexMarker381"/>the same time as HIVE-COTE (Jason Lines, Sarah Taylor, and Anthony Bagnall, 2016). At each iteration of RISE, a set of Fourier, autocorrelation, and partial autocorrelation features are extracted, and a decision tree is trained. RISE's runtime complexity is quadratic to the series length, which can be a problem, and a new version has been released, <strong class="keyword">c-RISE</strong> (<em class="italic">c</em> for <em class="italic">contract</em>), where the algorithm can be stopped earlier.</p>
    <p class="normal">The runtime complexity of HIVE-COTE, the quadratic runtime to the length of the series, is one of the biggest obstacles to its adoption. STC and another model, the <strong class="keyword">elastic ensemble</strong> (<strong class="keyword">EE</strong>) were <a id="_idIndexMarker382"/>the two slowest base models in the original algorithm from 2016. One of the main differences of the new version (1.0) includes dropping EE. They re-implemented STC and BOSS to make them more efficient, and they replaced RISE with c-RISE.</p>
    <p class="normal">Each of these base learners is trained separately. The base learners are weighted probabilistically based on<a id="_idIndexMarker383"/> a <strong class="keyword">Cross-Validation</strong> <strong class="keyword">Accuracy Weighted Probabilistic Ensemble</strong> (<strong class="keyword">CAWPE</strong>) structure (James Large, Jason Lines, and Anthony Bagnall, 2019).</p>
    <p class="normal">In publications <a id="_idIndexMarker384"/>postdating HIVE-COTE 1.0, the group showed that the ensemble is even stronger when replacing the CIF with the TSF (2020) and when replacing BOSS with the <strong class="keyword">Temporal Dictionary Ensemble</strong> (<strong class="keyword">TDE</strong>, 2021).</p>
    <p class="normal">In the next section, we will discuss the performance and trade-offs of different approaches.</p>
    <h2 id="_idParaDest-81" class="title">Discussion</h2>
    <p class="normal">Generally, there's a trade-off between accuracy and prediction times, and in these methods, there's a huge difference in time complexity and model accuracy. This chart illustrates this <a id="_idIndexMarker385"/>compromise (from Patrick Schäfer's GitHub repository of SFA):</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_13.png" alt=""/></figure>
    <p class="packt_figref">Figure 4.19: Machine learning algorithms: query time versus accuracy</p>
    <p class="normal">Features could be the result <a id="_idIndexMarker386"/>of simple operations or themselves be the outcome of machine learning models. We could imagine second-order features as the combination of the original features, and third-order features as the combination of second-order features, and so on, a potentially large preprocessing pipeline, where features are combined and created.</p>
    <p class="normal">We can sum up the <a id="_idIndexMarker387"/>different algorithms in this table:</p>
    <table id="table007" class="No-Table-Style _idGenTablePara-1">
      <colgroup>
        <col/>
        <col/>
        <col/>
      </colgroup>
      <tbody>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Type</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Univariate</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Multivariate</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Distance-based</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">DTW, Proximity Forest (PF)</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">DTW-D</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Dictionary-based/Symbolic</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">BOSS, CBOSS, S-BOSS, WEASEL, Temporal Dictionary Ensemble (TDE), SAX-VSM, BOSS</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">WEASEL+MUSE</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Shapelets</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">The Shapelet Transform Classifier (STC), MrSEQL</p>
          </td>
          <td class="No-Table-Style"/>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Interval and Spectral-based</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Time-Series Forest (TSF), Random Interval Spectral Ensemble (RISE)</p>
          </td>
          <td class="No-Table-Style"/>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Deep learning</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">ResNet, FCN, InceptionTime</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">TapNet</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Ensemble</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">The Hierarchical Vote Collective of Transformation-based Ensembles (HIVE-COTE), Time-Series Combination of Heterogeneous and Integrated Embeddings Forest (TS-CHIEF)</p>
          </td>
          <td class="No-Table-Style"/>
        </tr>
      </tbody>
    </table>
    <p class="packt_figref">Figure 4.20: Detailed taxonomy of time-series machine learning algorithms</p>
    <p class="normal">This classification <a id="_idIndexMarker388"/>is far from perfect, but hopefully useful. TDE is both an ensemble and a dictionary-based model. HIVE-COTE is based on BOSS features. Furthermore, the two featurization methods – Random Convolutional Kernel Transform (ROCKET) and Canonical Time-Series Characteristics (Catch22), operate on features individually; however, machine learning algorithms that train on and predict based on these features as inputs can therefore work in a multivariate setting. The ROCKET features together with a linear classifier were indeed found to be highly competitive with multivariate approaches. Because of the high dimensionality, the machine learning model can potentially take interactions between the original features into account.</p>
    <p class="normal">A review paper that I would highly recommend to readers is "<em class="italic">The great multivariate time-series classification bake-off</em>", by Alejandro Pasos Ruiz, Michael Flynn, and Anthony Bagnall (2020). It compares state-of-the-art algorithms (16 of which were included in the analysis) on 26 multivariate <a id="_idIndexMarker389"/>datasets from the UAE archive. The approaches included the following:</p>
    <ul>
      <li class="bullet">Dynamic time warping</li>
      <li class="bullet">MUSE+WEASEL</li>
      <li class="bullet">RISE</li>
      <li class="bullet">CBOSS</li>
      <li class="bullet">TSF</li>
      <li class="bullet">gRSF</li>
      <li class="bullet">ROCKET</li>
      <li class="bullet">HIVE-COTE 1.0</li>
      <li class="bullet">CIF</li>
      <li class="bullet">ResNet</li>
      <li class="bullet">STC</li>
    </ul>
    <p class="normal">The critical difference diagram (as found on <a href="http://timeseriesclassification.com"><span class="url">timeseriesclassification.com</span></a>) shows the rank of the algorithms across 26 datasets in the test. Links between algorithms show that the differences between them can't be statistically separated (based on the Wilcoxon rank-sum test):</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_14.png" alt="../../../../Desktop/Screenshot%202021-04-25%20at%2021.24"/></figure>
    <p class="packt_figref">Figure 4.21 Critical difference diagram of time-series classification algorithms</p>
    <p class="normal">They found a clique of<a id="_idIndexMarker390"/> top-performing classifiers, with ROCKET at the top achieving a considerable improvement in at least an order of magnitude less time. ROCKET was followed by HIVE-COTE and CIF.</p>
    <p class="normal">In a study from 2019, Hassan Fawaz and others compared deep learning algorithms for time-series across 12 multivariate datasets from the MTSC archive. The fully connected convolutional network (FCN) was best, followed by ResNet – on 85 univariate datasets from the UCR repository, ResNet beat FCN to the top spot (winning on 50 out of 85 datasets). In a separate comparison involving just ResNet with some of the state-of-the-art non-deep learning methods on both univariate and multivariate datasets, they found that ResNet's performance was behind HIVE-COTE, although not significantly worse across datasets, while beating other approaches such as BOSS and 1NN with DTW (the latter to a statistically significant degree). We'll talk more about this paper in <em class="chapterRef">Chapter 10</em>, <em class="italic">Deep Learning for Time-Series</em>.</p>
    <p class="normal">In another comparison study on<a id="_idIndexMarker391"/> multivariate time-series classification on 20 datasets from the MTSC archive (Bhaskar Dhariyal, Thach Le Nguyen, Severin Gsponer, and Georgiana Ifrim, 2020), it was established that ROCKET won on 14 datasets and was much better than most deep learning algorithms, while at the same time being the fastest method – ROCKET's runtime on the 20 datasets was 34 minutes, while the DTW ran for days.</p>
    <p class="normal">Here's the critical diagram created with Hassan Fawaz's Python script from their results:</p>
    <figure class="mediaobject"><img src="../Images/B17577_04_15.png" alt="../../../../Downloads/Machine-Learning%20for%20Time-Series%20with%20Python/mtsc_cd-di"/></figure>
    <p class="packt_figref">Figure 4.22: Critical difference diagram of multivariate time-series classification</p>
    <p class="normal">Many different feature sets were tried, the best of which (<code class="Code-In-Text--PACKT-">9_stat_MulPAA</code>) didn't end up far off.</p>
    <h2 id="_idParaDest-82" class="title">Implementations</h2>
    <p class="normal">Great algorithms would be worth much less in practice without software that provides them in a way that makes them easy to use and reliable to use in a production setting of a company. Alternatively, implementing algorithms from scratch can take time, and is not without complications. Therefore, it's a boon that there are many reliable, available implementations in Python.</p>
    <p class="normal">The following table summarizes implementations<a id="_idIndexMarker392"/> of supervised algorithms for regression and classification:</p>
    <table id="table008" class="No-Table-Style _idGenTablePara-1">
      <colgroup>
        <col/>
        <col/>
        <col/>
      </colgroup>
      <tbody>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Algorithm</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">sktime</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Pyts</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Autoregressive Integrated Moving Average (ARIMA)</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">X</p>
          </td>
          <td class="No-Table-Style"/>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">DTW</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">X</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">X</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">BATS</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">X</p>
          </td>
          <td class="No-Table-Style"/>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">MUSE+WEASEL</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">X</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">X</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">MrSEQL</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">X</p>
          </td>
          <td class="No-Table-Style"/>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">ROCKET</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">X</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">X</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">BOSS</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">X</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">X</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Bag-of-SFA Symbols in Vector Space (BOSSVS)</p>
          </td>
          <td class="No-Table-Style"/>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">X</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">CBOSS</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">X</p>
          </td>
          <td class="No-Table-Style"/>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">SAX-VSM</p>
          </td>
          <td class="No-Table-Style"/>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">X</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">RISE</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">X</p>
          </td>
          <td class="No-Table-Style"/>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">HIVE-COTE</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">X</p>
          </td>
          <td class="No-Table-Style"/>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Time-Series Forest</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">X</p>
          </td>
          <td class="No-Table-Style"/>
        </tr>
      </tbody>
    </table>
    <figure class="mediaobject">Figure 4.23: Pyts versus SkTime implementations of machine learning algorithms</figure>
    <p class="normal">It's not an<a id="_idIndexMarker393"/> accident that sktime has so many implementations. It is actively used in research activity by the group around Anthony Bagnall at the University of East Anglia. Pyts is being maintained by Johann Faouzi and Hicham Janati, postdoctoral fellows at the Paris <a id="_idIndexMarker394"/>Brain Institute and the <strong class="keyword">Centre de Mathématiques Appliquées</strong> (<strong class="keyword">CMAP</strong>) in Rémy. Johann Faouzi is also behind the tslearn library that implements time-series analysis and feature extraction algorithms.</p>
    <p class="normal">I've omitted deep learning algorithms from the table, which are often implemented as part of different libraries. Please note that sktime allows use of the prophet forecaster through the same interface. For example, the sktime-DL library implements ResNet, InceptionTime, and TapNet algorithms, and dl-4-tsc implements more than a dozen deep learning models. We'll come to deep learning model implementations in <em class="chapterRef">Chapter 10</em>, <em class="italic">Deep Learning for Time-Series</em>.</p>
    <p class="normal">Facebook's Prophet<a id="_idIndexMarker395"/> contains a single model, a special<a id="_idIndexMarker396"/> case of the<strong class="keyword"> Generalized Additive Model</strong> (<strong class="keyword">GAM</strong>). The Statsmodels library<a id="_idIndexMarker397"/> contains <a id="_idIndexMarker398"/>a GAM as well as linear <a id="_idIndexMarker399"/>regression models and a <strong class="keyword">Generalized Linear Model</strong> (<strong class="keyword">GLM</strong>), <strong class="keyword">moving average</strong> (<strong class="keyword">MA</strong>), <strong class="keyword">Autoregressive Integrated Moving Average</strong> (<strong class="keyword">ARIMA</strong>), and <strong class="keyword">Vector Autoregressions</strong> (<strong class="keyword">VAR</strong>).</p>
    <p class="normal">The Darts library provides a consistent interface to several models for time-series processing and forecasting. It includes both classical and deep learning algorithms:</p>
    <ul>
      <li class="bullet">Exponential smoothing</li>
      <li class="bullet">ARIMA</li>
      <li class="bullet">Temporal convolutional network</li>
      <li class="bullet">Transformer</li>
      <li class="bullet">N-BEATS</li>
    </ul>
    <p class="normal">This concludes our overview of time-series machine learning libraries in Python.</p>
    <h1 id="_idParaDest-83" class="title">Summary</h1>
    <p class="normal">In this chapter, we've talked about both the context and the technical background of machine learning with time-series. Machine learning algorithms or models can make systematic, repeatable, validated decisions based on data. We explained the main machine learning problems with time-series such as forecasting, classification, regression, segmentation, and anomaly detection. We then reviewed the basics of machine learning as relevant to time-series, and we looked at the history and current uses of machine learning for time-series.</p>
    <p class="normal">We discussed different types of methods based on the approach and features used. Furthermore, we discussed many algorithms, concentrating on state-of-the-art machine learning approaches.</p>
    <p class="normal">I will discuss approaches including deep learning or classical models, such as autoregressive and moving averages, in chapters dedicated to them (for example, in <em class="chapterRef">chapter 5</em>, <em class="italic">Time-Series Forecasting with Moving Averages and Autoregressive Models</em>, and <em class="chapterRef">chapter 10</em>, <em class="italic">Deep Learning for Time-Series</em>).</p>
  </div>
</body></html>