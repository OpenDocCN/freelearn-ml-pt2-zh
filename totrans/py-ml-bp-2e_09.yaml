- en: Building a Chatbot
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Imagine for a moment that you're sitting alone in a quiet, spacious room. To
    your right is a small table with a stack of white printer paper and a single black
    pen. In front of you is what seems to be a large, red cube with a tiny opening—slightly
    smaller than the size of a mail slot. An inscription just above the slot invites
    you to write down a question and pass it through the slot. As it happens, you
    speak Mandarin; so, you write down your question in Mandarin on one of the sheets
    and insert it into the opening. A few moments pass, and then slowly, an answer
    emerges. It's also written in Chinese and is the just the sort of answer you might
    have expected. So, what did you ask? *Are you a person or a computer?* And the
    response? *Why yes, yes I am*.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: This thought experiment is based on philosopher John Searle's Chinese Room Argument.
    The premise of the experiment is that if there were a person in the room who spoke
    no Chinese, but had a set of rules that allowed them to perfectly map English
    characters to Chinese characters, they could appear to the questioner to understand
    Chinese without actually having any understanding of it. Searle's argument was
    that algorithmic procedures that produce an intelligible output can't be said
    to have an *understanding* of that output. They lack a *mind*. His thought experiment
    was an attempt to combat the ideas of *strong AI*, or the notion that the human
    brain is essentially just a *wet machine*. Searle didn't believe that AI could
    be said to have consciousness, no matter how sophisticated its behavior appeared
    to an outside observer.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Searle published this experiment in 1980\. 31 years later, Siri would be released
    on the iPhone 4S. For anyone who has used Siri, it's clear that we have a long
    way to go before we might be confronted with uncertainty of whether the agent
    we are speaking to has a mind (though we might doubt it in people we know to be
    human). Despite the clunkiness these agents, or chatbots, have demonstrated in
    the past, the field is rapidly advancing.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we're going to learn how to construct a chatbot from scratch.
    Along the way, we'll learn more about the history of the field and its future
    prospects.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll cover the following topics in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: The Turing Test
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The history of chatbots
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The design of chatbots
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a chatbot
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Turing Test
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 30 years before Searle's Chinese Room, Alan Turing posed the question, *can
    machines think?* in one of his more famous papers. Being the practical genius
    he was, he decided not to tackle that question head on, but to instead pose it
    in the framework of the *problem of other minds*. This problem asks, *how do we
    truly know that other people have minds like our own?* Since we can only observe
    their behavior—and not the inner workings of their mind—we must take it on faith
    that they are like us. Turing proposed that if a machine could behave as if it
    were intelligent, then we should view it as such. This, in a nutshell, is the
    *Turing Test*. Passing the test means convincing humans that a machine is a fellow
    human.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: You might be wondering at this point, *has a program ever successfully passed
    the Turing Test?* And the answer is that there really is no official Turing Test.
    The closest thing to an official test is the Loebner Prize. This is a contest
    held yearly that awards modest prizes to those chatbots that appear the most convincingly
    human to a panel of judges. If this sounds rigorous and academic, it has been
    described as anything but. Loebner himself is said to be quite the character,
    frequently professing his love of wine, marijuana, and prostitutes. His sponsorship
    for the contest is said to have been a product of his total distain for labor
    of any kind.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, by this point, you'll have realized that any claims about *passing
    the Turing Test *are more spectacle than actual science. Despite this, Turing's
    original concept is a useful construct.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: The history of chatbots
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I still remember the day my father sat me down in front of his IBM XT with
    its black-and-green flickering monitor and asked me to talk to *it*. The conversation
    went something like the following:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '>Hello. How are you feeling today?'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '>Hi. Who is this?'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '>Hi there... How are you today?'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '>I''m fine. You didn''t tell me who you are.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '>We should be discussing you, not me.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '>We should? Why?'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '>Let''s change focus a bit... Tell me about your family.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '>You are impossible to have a conversation with.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '>Can you elaborate on that?'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '>You are killing me.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '>Perhaps you would like me to be killing you.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '>OK, you are freaking me out.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '>Perhaps you''re really talking about yourself?'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '>What?? That makes no sense.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '>How would an answer to that help you?'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '>END'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '>Very interesting.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '>QUIT'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '>Thank you for talking with me.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '>#$###$#@@....'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: The *it* I was talking to was a program called **ELIZA**. Written in the mid-1960s
    at MIT's Artificial Intelligence Lab by Joseph Weizenbaum, ELIZA was created to
    mimic the responses of a Rogerian psychotherapist. Though nearly comical when
    examined in any depth, the program was capable of convincing some users that they
    were chatting to an actual human—a remarkable feat considering it was a scant
    200 lines of code that used randomization and regular expressions to parrot back
    responses. Even today, this simple program remains a staple of popular culture.
    If you ask Siri who ELIZA is, she'll tell you she's a friend and a brilliant psychiatrist.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: If ELIZA was an early example of chatbots, what have we seen since that time?
    In recent years, there has been an explosion of new chatbots. The most notable
    of these is Cleverbot.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Cleverbot was released to the world using the web in 1997\. In the years since,
    the bot has racked up hundreds of millions of conversions, and, unlike early chatbots,
    Cleverbot, as its name suggests, appears to become more intelligent with each
    conversion. Though the exact details of the workings of the algorithm are difficult
    to find, it's said to work by recording all conversations in a database and finding
    the most appropriate response by identifying the most similar questions and responses
    in the database.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: 'I made up a nonsensical question, shown as follows, and you can see that it
    found something similar to the object of my question in terms of a string match:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c726d9f1-a00b-4a60-a52c-0909e423500b.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
- en: 'I persisted:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1ee74215-5384-4f54-83c4-1c1df46de9ca.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
- en: And, again, I got something... similar?
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: You'll also notice that topics can persist across the conversation. In response,
    I was asked to go into more detail and justify my answer. This is one of the things
    that appears to make Cleverbot, well, clever.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: While chatbots that learn from humans can be quite amusing, they can also have
    a darker side.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Several years ago, Microsoft released a chatbot named Tay on to Twitter. People
    were invited to ask Tay questions, and Tay would respond in accordance with her
    *personality*. Microsoft had apparently programmed the bot to appear to be a 19-year-old
    American girl. She was intended to be your virtual *bestie*; the only problem
    was that she started tweeting out extremely racist remarks.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: As a result of these unbelievably inflammatory tweets, Microsoft was forced
    to pull Tay off Twitter and issue an apology.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '"As many of you know by now, on Wednesday we launched a chatbot called Tay.
    We are deeply sorry for the unintended offensive and hurtful tweets from Tay,
    which do not represent who we are or what we stand for, nor how we designed Tay.
    Tay is now offline and we''ll look to bring Tay back only when we are confident
    we can better anticipate malicious intent that conflicts with our principles and
    values."'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: -March 25, 2016 Official Microsoft Blog
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Clearly, brands that want to release chatbots into the wild in the future should
    take a lesson from this debacle and plan for users to attempt to manipulate them
    to display the worst of human behavior.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，未来那些希望将聊天机器人投入市场的品牌应该从这次的失败中吸取教训，并计划好让用户尝试操控它们，展示人类最糟糕的行为。
- en: There's no doubt that brands are embracing chatbots. Everyone from Facebook
    to Taco Bell is getting in on the game.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 毋庸置疑，品牌们正在拥抱聊天机器人。从 Facebook 到 Taco Bell，每个品牌都在加入这场游戏。
- en: 'Witness the TacoBot:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 见证 TacoBot：
- en: '![](img/99d3a529-9e70-49f4-9478-89c70df123e8.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/99d3a529-9e70-49f4-9478-89c70df123e8.png)'
- en: Yes, it's a real thing. And, despite the stumbles, like Tay, there's a good
    chance the future of UI looks a lot like TacoBot. One last example might even
    help explain why.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，它真的是个现实存在的东西。尽管像 Tay 这样的失败让人跌倒，但未来的用户界面很可能会像 TacoBot 那样。最后的一个例子甚至可能帮助解释其中的原因。
- en: 'Quartz recently launched an app that turns news into a conversation. Rather
    than lay out the day''s stories as a flat list, you are engaged in a chat as if
    you were getting news from a friend:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Quartz 最近推出了一款将新闻转化为对话的应用。与其将当天的新闻按平铺方式展示，它让你参与一场对话，就像是从朋友那里获取新闻一样：
- en: '![](img/230650be-ef8d-4ccb-b59f-00e15d4e6267.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/230650be-ef8d-4ccb-b59f-00e15d4e6267.png)'
- en: 'David Gasca, a PM at Twitter, describes his experience using the app in a post
    on Medium. He describes how the conversational nature invoked feelings normally
    only triggered in human relationships:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Twitter 的项目经理 David Gasca 在 Medium 上发布了一篇文章，描述了他使用该应用的体验。他讲述了这种对话式的设计如何唤起通常只在人与人关系中才会触发的情感：
- en: '"Unlike a simple display ad, in a conversational relationship with my app I
    feel like I owe something to it: I want to click. At the most subconscious level
    I feel the need to reciprocate and not let the app down: "The app has given me
    this content. It''s been very nice so far and I enjoyed the GIFs. I should probably
    click since it''s asking nicely."'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: “与简单的展示广告不同，在与我的应用建立对话关系时，我感觉自己欠它什么：我想要点击。在最潜意识的层面，我感到需要回报，不想让应用失望：‘应用给了我这个内容。到目前为止非常好，我很喜欢这些
    GIF。我应该点击一下，因为它很有礼貌地请求了。’”
- en: 'If that experience is universal—and I expect it is—this could be the next big
    thing in advertising, and I have no doubt that advertising profits will drive
    UI design:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这种体验是普遍的——我相信是——这可能会成为广告的下一个大趋势，我毫不怀疑广告利润将推动用户界面设计的发展：
- en: '"The more the bot acts like a human, the more it will be treated like a human."'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: “机器人越像人类，就越会被当作人类对待。”
- en: -Mat Webb, Technologist and Co-Author of Mind Hacks
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: -Mat Webb，技术专家，Mind Hacks 的合著者
- en: At this point, you're probably dying to know how these things work, so let's
    get on with it!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 到这时，你可能迫不及待地想知道这些东西是如何工作的，那我们就继续吧！
- en: The design of chatbots
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聊天机器人的设计
- en: 'The original ELIZA application was 200-odd lines of code. The Python NLTK implementation
    is similarly short. An excerpt is provided from NLTK''s website ([http://www.nltk.org/_modules/nltk/chat/eliza.html](http://www.nltk.org/_modules/nltk/chat/eliza.html)):'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 原始的 ELIZA 应用程序大约是 200 行代码。Python 的 NLTK 实现也同样简短。以下是 NLTK 网站上的一段摘录（[http://www.nltk.org/_modules/nltk/chat/eliza.html](http://www.nltk.org/_modules/nltk/chat/eliza.html)）：
- en: '![](img/cd034e74-d600-432f-8611-380af2fee11e.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cd034e74-d600-432f-8611-380af2fee11e.png)'
- en: As you can see from the code, input text was parsed and then matched against
    a series of regular expressions. Once the input was matched, a randomized response
    (that sometimes echoed back a portion of the input) was returned. So, something
    such as, *I need a taco* would trigger a response of, *Would it really help you
    to get a taco?* Obviously, the answer is yes, and, fortunately, we have advanced
    to the point that technology can provide you one (bless you, TacoBot), but this
    was early days still. Shockingly, some people actually believed ELIZA was a real
    human.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 从代码中可以看到，输入文本首先被解析，然后与一系列正则表达式进行匹配。一旦输入匹配成功，系统会返回一个随机的回应（有时会回响部分输入内容）。所以，像 *我需要一个塔可*
    这样的输入会触发一个回应：*你真的需要一个塔可吗？* 显然，答案是“是的”，而且幸运的是，我们已经发展到技术可以提供它（感谢你，TacoBot），但那时仍是初期阶段。令人震惊的是，有些人真的相信
    ELIZA 是一个真实的人类。
- en: But what about more advanced bots? How are they built?
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 那么更先进的机器人呢？它们是如何构建的？
- en: Surprisingly, most chatbots you're likely to encounter aren't even using **machine
    learning** (**ML**); they're what's known as **retrieval-based** models. This
    means responses are predefined according to the question and the context. The
    most common architecture for these bots is something called **Artificial Intelligence
    Markup Language** (**AIML**). AIML is an XML-based schema for representing how
    the bot should interact given the user's input. It's really just a more advanced
    version of how ELIZA works.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at how responses are generated using AIML. First, all input
    are preprocessed to normalize them. This means when you input *Waaazzup???* it''s
    mapped to *WHAT IS UP*. This preprocessing step funnels down the myriad ways of
    saying the same thing into one input that can run against a single rule. Punctuation
    and other extraneous input are removed as well at this point. Once that''s complete,
    the input is matched against the appropriate rule. The following is a sample template:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'That is the basic setup, but you can also layer in wildcards, randomization,
    and prioritization schemes. For example, the following pattern uses wildcard matching:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here, the `*` wildcard matches one or more words before `FOR ME` and then repeats
    those back in the output template. If the user were to type in `Dance for me!`,
    the response would be `I'm a bot. I don't dance. Ever`.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, these rules don't make for anything that approximates any type
    of real intelligence, but there are a few tricks that strengthen the illusion.
    One of the better ones is the ability to generate responses conditioned on a topic.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, here''s a rule that invokes a topic:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Once the topic is set, the rules specific to that context can be matched:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let''s see what this interaction might look like:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '>I like turtles!'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '>I feel like this whole turtle thing could be a problem. What do you like about
    them?'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '>I like how they hide in their shell.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '>I wish, like a turtle, I could hide from this conversation.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: You can see that the continuity across the conversation adds a measure of realism.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: You're probably thinking that this can't be state of the art in this age of
    deep learning, and you're right. While most bots are rule-based, the next generation
    of chatbots are emerging, and they're based on neural networks.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: In 2015, Oriol Vinyas and Quoc Le of Google published a paper, [http://arxiv.org/pdf/1506.05869v1.pdf](https://arxiv.org/pdf/1506.05869v1.pdf),
    that described the construction of a neural network based on sequence-to-sequence
    models. This type of model maps an input sequence, such as *ABC*, to and output
    sequence, such as *XYZ*. These inputs and outputs might be translations from one
    language to another, for example. In the case of their work here, the training
    data was not language translation, but rather tech support transcripts and movie
    dialogues. While the results from both models are interesting, it was the interactions
    based on the movie model that stole the headlines.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are sample interactions taken from the paper:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0dce3fa1-0caf-44b3-bfec-863d7afe8cb6.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
- en: 'None of this was explicitly encoded by humans or present in the training set
    as asked, and, yet, looking at this, it''s frighteningly like speaking with a
    human. But let''s see more:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/591bc3ed-fb58-47f6-ac3e-77da623bd8ad.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
- en: 'Notice that the model is responding with what appears to be knowledge of gender
    (**he**, **she**), **place** (England), and career (**player**). Even questions
    of meaning, ethics, and morality are fair game:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7d841798-609f-4249-8237-a9b8092442e4.png)![](img/7dc81f71-3e26-4ae0-8cd0-2f5652b4ad62.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
- en: If that transcript doesn't give you a slight chill, there's a chance you might
    already be some sort of AI.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: I wholeheartedly recommend reading the entire paper. It isn't overly technical,
    and it will definitely give you a glimpse of where the technology is headed.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: We've talked a lot about the history, types, and design of chatbots, but let's
    now move on to building our own. We'll take two approaches to this. This first
    will use a technique we saw in previously, cosine similarity, and the second will
    leverage sequence-to-sequence learning.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Building a chatbot
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, having seen what's possible in terms of chatbots, you most likely want
    to build the best, most state-of-the-art, Google-level bot out there, right? Well,
    just put that out of your mind for now because we're going start by doing the
    exact opposite. We're going to build the most amazingly awful bot ever!
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: This may sound disappointing, but if your goal is just to build something very
    cool and engaging (that doesn't take hours and hours to construct), this is a
    great place to start.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: We're going to leverage the training data derived from a set of real conversations
    with Cleverbot. The data was collected from [http://notsocleverbot.jimrule.com](http://notsocleverbot.jimrule.com).
    This site is perfect, as it has people submit the most absurd conversations they
    had with Cleverbot.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at a sample conversation between Cleverbot and a user from
    the site:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6d9fb676-13dc-4bb1-b64c-9a172256926b.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
- en: While you are free to use the techniques for web scraping that we used in earlier
    chapters to collect the data, you can find a `.csv` of the data in the GitHub
    repo for this chapter.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll start again in our Jupyter Notebook. We''ll load, parse, and examine
    the data. We''ll first import pandas and the Python regular expressions library,
    `re`. We''re also going to set the option in pandas to widen our column width
    so we can see the data better:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now we''ll load in our data:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The preceding code results in the following output:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a48abdb7-bcff-42f5-9d55-c7da9f2aed78.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
- en: 'Since we''re only interested in the first column, the conversation data, we''ll
    parse that out:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The preceding code results in the following output:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/63ee8de3-1c46-4190-afb9-bad34daa3a40.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
- en: 'You should be able to make out that we have interactions between **User** and
    **Cleverbot**, and that either can initiate the conversation. To get the data
    in the format we need, we''ll have to parse it into question-and-response pairs.
    We aren''t necessarily concerned with who says what, but with matching up each
    response to each question. You''ll see why in a bit. Let''s now do a bit of regular
    expression magic on the text:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The preceding code results in the following output:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b8069791-f4f5-4908-851f-585e4ef3b2d7.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
- en: OK, lots of code there. What just happened? We first created a list to hold
    our question-and-response tuples. We then passed our conversations through a function
    to split them into those pairs using regular expressions.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we set it all into a pandas DataFrame with columns labelled `q` and
    `a`.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 'We''re now going to apply a bit of algorithm magic to match up the closest
    question to the one a user inputs:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In the preceding code, we imported our tf-idf vectorization library and the
    cosine similarity library. We then used our training data to create a tf-idf matrix.
    We can now use this to transform our own new questions and measure the similarity
    to existing questions in our training set. Let''s do that now:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The preceding code results in the following output:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/66fa20ef-b27f-44e2-8af5-bae861983084.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
- en: 'What are we looking at here? This is the cosine similarity between the question
    I asked and the top-five closest questions. On the left is the index, and on the
    right is the cosine similarity. Let''s take a look at those:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This results in the following output:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e0f4a09b-d60c-4db2-a958-9e0b0ee6411a.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
- en: As you can see, nothing is exactly the same, but there are definitely some similarities.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now take a look at the response:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The preceding code results in the following output:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6f020de1-b522-4912-ba1e-52f45a718d23.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
- en: OK, so our bot seems to have an attitude already. Let's push further.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll create a handy function so that we can test a number of statements easily:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This results in the following output:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c9a792e9-1f44-42d2-946b-9b3736c2d8b0.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
- en: 'We have clearly created a monster, so we''ll continue:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This results in the following output:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9377dd8e-c551-4e69-8e32-709f149a06c1.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
- en: 'I''m enjoying this. Let''s keep rolling with it:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](img/beab46df-ae86-4fba-9292-b72e5ce81c0d.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
- en: '[PRE15]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](img/15082c21-bd1f-4d20-ad70-d46420b6a5db.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
- en: '[PRE16]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![](img/265ec47e-43b4-4108-8508-f84206c682d4.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
- en: '[PRE17]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](img/4b18b671-7d88-47a2-aee5-9ee79c643ede.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
- en: '[PRE18]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![](img/25bd083c-6922-4dd8-a00b-390058199df7.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
- en: '[PRE19]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![](img/f9571b10-2ff4-4cba-bb2b-d493ba9a961e.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
- en: Remarkably, this may be one of the best conversations I've had in a while, bot
    or not.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: Now while this was a fun little project, let's now move on to a more advanced
    modeling technique using sequence-to-sequence modeling.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Sequence-to-sequence modeling for chatbots
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this next task, we'll leverage a couple libraries discussed in [Chapter
    8](5df6fae8-a5c0-4fab-8508-baef0085b4f5.xhtml), *Classifying Images with Convolutional
    Neural Networks*, TensorFlow and Keras. Both can be `pip` installed if you haven't
    done that already.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: 'We''re also going to use the type of advanced modeling discussed earlier in
    the chapter; it''s a type of deep learning called **sequence-to-sequence modeling**.
    This is frequently used in machine translation and question-answering applications,
    as it allows us to map an input sequence of any length to an output sequence of
    any length:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2b04592c-6902-4403-870e-4266daf360c7.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
- en: 'Source: https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Francois Chollet has an excellent introduction to this type of model on the
    blog for Keras: [https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html).
    It's worth a read.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: 'We''re going to make heavy use of his example code to build out our model.
    While his example uses machine translation, English to French, we''re going to
    repurpose it for question-answering using our Cleverbot dataset:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: 'Set the imports:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Set up the training parameters:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We'll use these to start. We can examine the success of our model and then adjust
    as necessary.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step in data processing will be to take our data, get it in the proper
    format, and then vectorize it. We''ll go step by step:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This creates lists for our questions and answers (the targets) as well as sets
    for the individual characters in our questions and answers. This model will actually
    work by generating one character at a time:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s limit our question-and-answer pairs to 50 characters or fewer. This
    will help speed up our training:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Let''s set up our input and target text lists:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The preceding code gets our data in the proper format. Note that we add a tab
    (`\t`) and a newline (`\n`) character to the target texts. This will serve as
    our start and stop tokens for the decoder.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the input texts and the target texts:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The preceding code generates the following output:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3318e65a-0fc7-4a07-8620-8d81902c6079.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
- en: '[PRE26]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The preceding code generates the following output:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0e4cad67-bd2e-41bf-a7d0-19bb870fe629.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
- en: 'Let''s take a look at those input and target-character sets now:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The preceding code generates the following output:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/32be9bf4-34e1-4e41-bc29-af5e999cf409.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
- en: '[PRE28]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The preceding code generates the following output:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a1f54278-2513-40d3-ae69-42a7a06014d5.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
- en: 'Next, we''ll do some additional preparation for the data that will feed into
    the model. Although data can be fed in any length and returned in any length,
    we need to add padding up to the max length of the data for the model to work:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The preceding code generates the following output:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/34094ae5-2198-4796-afd4-066b044361a9.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
- en: 'Next, we''ll vectorize our data using one-hot encoding:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Let''s take a look at one of these vectors:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The preceding code generates the following output:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bc180728-de1a-4d09-bc5d-68c4f6a3e34b.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
- en: From the preceding figure, you'll notice that we have a one-hot encoded vector
    of our character data, which will be used in our model.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: 'We now set up our sequence-to-sequence model-encoder and -decoder LSTMs:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Then we move on to the model itself:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: In the preceding code, we defined our model using our encoder and decoder input
    and our decoder output. We then compile it, fit it, and save it.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: We set up the model to use 1,000 samples. Here, we also split the data 80/20
    to training and validation, respectively. We also set our epochs at 100, so this
    will essentially run for 100 cycles. On a standard MacBook Pro, this may take
    around an hour to complete.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: 'Once that cell is run, the following output will be generated:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ad208163-5986-4a4d-b6d4-95b800737727.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
- en: 'The next step is our inference step. We''ll use the states generated from this
    model to feed into our next model to generate our output:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The preceding code generates the following output:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/57a91f41-a7da-468e-a92a-7589eb73593c.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
- en: As you can see, the results of our model are quite repetitive. But then we only
    used 1,000 samples and the responses were generated one character at a time, so
    this is actually fairly impressive.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: If you want better results, rerun the model using more sample data and more
    epochs.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, I have provide some of the more humorous output I''ve noted from much
    longer training periods:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e99022f7-f9da-4cf0-8a12-fb58d03c72ff.png)![](img/6936b02e-4137-4c66-ad25-1e9291112554.png)![](img/7ed8edd3-c574-482d-9d93-d184a8e3f59e.png)![](img/4096f414-dfd7-46c7-a6e0-efb90b3712bd.png)![](img/78e8de23-1a8e-488e-b326-a2e01a4bbf44.png)![](img/c60b8d01-7f73-4862-b039-3ae1cbcea5c3.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
- en: Summary
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we took a full tour of the chatbot landscape. It's clear that
    we're on the cusp of an explosion of these types of applications. The *Conversational
    UI* revolution is just about to begin. Hopefully, this chapter has inspired you
    to create your own bot, but if not, we hope you have a much richer understanding
    of how these applications work and how they'll shape our future.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: 'I''ll let the app say the final words:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
