["```py\n    df = pd.read_csv('linear_classifier.csv')\n    df.head()\n    ```", "```py\n    plt.figure(figsize=(10, 7))\n    for label, label_class in df.groupby('labels'):\n        plt.scatter(label_class.values[:,0], label_class.values[:,1],\n                    label=f'Class {label}', marker=label, c='k')\n    plt.legend()\n    plt.title(\"Linear Classifier\");\n    ```", "```py\n    # Fit a linear regression model\n    model = LinearRegression()\n    model.fit(df.x.values.reshape((-1, 1)), df.y.values.reshape((-1, 1)))\n    # Print out the parameters\n    print(f'y = {model.coef_[0][0]}x + {model.intercept_[0]}')\n    ```", "```py\n    # Plot the trendline\n    trend = model.predict(np.linspace(0, 10).reshape((-1, 1)))\n    plt.figure(figsize=(10, 7))\n    for label, label_class in df.groupby('labels'):\n        plt.scatter(label_class.values[:,0], label_class.values[:,1],\n                    label=f'Class {label}', marker=label, c='k')\n    plt.plot(np.linspace(0, 10), trend, c='k', label='Trendline')\n    plt.legend()\n    plt.title(\"Linear Classifier\");\n    ```", "```py\n    # Make predictions\n    y_pred = model.predict(df.x.values.reshape((-1, 1)))\n    pred_labels = []\n    for _y, _y_pred in zip(df.y, y_pred):\n        if _y < _y_pred:\n            pred_labels.append('o')\n        else:\n            pred_labels.append('x')\n    df['Pred Labels'] = pred_labels\n    df.head()\n    ```", "```py\n    plt.figure(figsize=(10, 7))\n    for idx, label_class in df.iterrows():\n        if label_class.labels != label_class['Pred Labels']:\n            label = 'D'\n            s=70\n        else:\n            label = label_class.labels\n            s=50\n        plt.scatter(label_class.values[0], label_class.values[1],\n                    label=f'Class {label}', marker=label, c='k', s=s)\n    plt.plot(np.linspace(0, 10), trend, c='k', label='Trendline')\n    plt.title(\"Linear Classifier\");\n    incorrect_class = mlines.Line2D([], [], color='k', marker='D',\n                              markersize=10, label='Incorrect Classification');\n    plt.legend(handles=[incorrect_class]);\n    ```", "```py\n    import struct\n    import numpy as np\n    import gzip\n    import urllib.request\n    import matplotlib.pyplot as plt\n    from array import array\n    from sklearn.linear_model import LogisticRegression\n    ```", "```py\n    request = urllib.request.urlopen('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz')\n    with open('train-images-idx3-ubyte.gz', 'wb') as f:\n        f.write(request.read())\n    request = urllib.request.urlopen('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz')\n    with open('t10k-images-idx3-ubyte.gz', 'wb') as f:\n        f.write(request.read())\n    ```", "```py\n    request = urllib.request.urlopen('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz')\n    with open('train-labels-idx1-ubyte.gz', 'wb') as f:\n        f.write(request.read())\n    request = urllib.request.urlopen('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz')\n    with open('t10k-labels-idx1-ubyte.gz', 'wb') as f:\n        f.write(request.read())\n    ```", "```py\n    !dir *.gz\n    ```", "```py\n    with gzip.open('train-images-idx3-ubyte.gz', 'rb') as f:\n        magic, size, rows, cols = struct.unpack(\">IIII\", f.read(16))\n        img = np.array(array(\"B\", f.read())).reshape((size, rows, cols))\n    with gzip.open('train-labels-idx1-ubyte.gz', 'rb') as f:\n        magic, size = struct.unpack(\">II\", f.read(8))\n        labels = np.array(array(\"B\", f.read()))\n    with gzip.open('t10k-images-idx3-ubyte.gz', 'rb') as f:\n        magic, size, rows, cols = struct.unpack(\">IIII\", f.read(16))\n        img_test = np.array(array(\"B\", f.read())).reshape((size, rows, cols))\n    with gzip.open('t10k-labels-idx1-ubyte.gz', 'rb') as f:\n        magic, size = struct.unpack(\">II\", f.read(8))\n        labels_test = np.array(array(\"B\", f.read()))\n    ```", "```py\n    for i in range(10):\n        plt.subplot(2, 5, i + 1)\n        plt.imshow(img[i], cmap='gray');\n        plt.title(f'{labels[i]}');\n        plt.axis('off')\n    ```", "```py\n    samples_0_1 = np.where((labels == 0) | (labels == 1))[0]\n    images_0_1 = img[samples_0_1]\n    labels_0_1 = labels[samples_0_1]\n    samples_0_1_test = np.where((labels_test == 0) | (labels_test == 1))\n    images_0_1_test = img_test[samples_0_1_test].reshape((-1, rows * cols))\n    labels_0_1_test = labels_test[samples_0_1_test]\n    ```", "```py\n    sample_0 = np.where((labels == 0))[0][0]\n    plt.imshow(img[sample_0], cmap='gray');\n    ```", "```py\n    sample_1 = np.where((labels == 1))[0][0]\n    plt.imshow(img[sample_1], cmap='gray');\n    ```", "```py\n    images_0_1 = images_0_1.reshape((-1, rows * cols))\n    images_0_1.shape\n    ```", "```py\n    model = LogisticRegression(solver='liblinear')\n    model.fit(X=images_0_1, y=labels_0_1)\n    ```", "```py\n    model.score(X=images_0_1, y=labels_0_1)\n    ```", "```py\n    model.predict(images_0_1) [:2]\n    ```", "```py\n    model.predict_proba(images_0_1)[:2]\n    ```", "```py\n    model.score(X=images_0_1_test, y=labels_0_1_test)\n    ```", "```py\n    with gzip.open('train-images-idx3-ubyte.gz', 'rb') as f:\n        magic, size, rows, cols = struct.unpack(\">IIII\", f.read(16))\n        img = np.array(array(\"B\", f.read())).reshape((size, rows, cols))\n    with gzip.open('train-labels-idx1-ubyte.gz', 'rb') as f:\n        magic, size = struct.unpack(\">II\", f.read(8))\n        labels = np.array(array(\"B\", f.read()))\n    with gzip.open('t10k-images-idx3-ubyte.gz', 'rb') as f:\n        magic, size, rows, cols = struct.unpack(\">IIII\", f.read(16))\n        img_test = np.array(array(\"B\", f.read())).reshape((size, rows, cols))\n    with gzip.open('t10k-labels-idx1-ubyte.gz', 'rb') as f:\n        magic, size = struct.unpack(\">II\", f.read(8))\n        labels_test = np.array(array(\"B\", f.read()))\n    ```", "```py\n    np.random.seed(0) # Give consistent random numbers\n    selection = np.random.choice(len(img), 5000)\n    selected_images = img[selection]\n    selected_labels = labels[selection]\n    ```", "```py\n    selected_images = selected_images.reshape((-1, rows * cols))\n    selected_images.shape\n    ```", "```py\n    # selected_images = selected_images / 255.0\n    # img_test = img_test / 255.0\n    ```", "```py\n    model = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=500, tol=0.1)\n    model.fit(X=selected_images, y=selected_labels)\n    ```", "```py\n    model.score(X=selected_images, y=selected_labels)\n    ```", "```py\n    model.predict(selected_images)[:2]\n    ```", "```py\n    plt.subplot(1, 2, 1)\n    plt.imshow(selected_images[0].reshape((28, 28)), cmap='gray');\n    plt.axis('off');\n    plt.subplot(1, 2, 2)\n    plt.imshow(selected_images[1].reshape((28, 28)), cmap='gray');\n    plt.axis('off');\n    ```", "```py\n    model.predict_proba(selected_images)[0]\n    ```", "```py\n    model.score(X=img_test.reshape((-1, rows * cols)), y=labels_test)\n    ```", "```py\n    selected_images = selected_images / 255.0\n    img_test = img_test / 255.0\n    ```", "```py\n    model.score(X=selected_images, y=selected_labels)\n    ```", "```py\n    model.score(X=img_test.reshape((-1, rows * cols)), y=labels_test)\n    ```", "```py\ndef scale_input(x):\n    mean_x = x.mean()\n    x = x â€“ mean_x\n    max_x = x / no.max(abs(x))\n    return x\n```", "```py\n    import struct\n    import numpy as np\n    import gzip\n    import urllib.request\n    import matplotlib.pyplot as plt\n    from array import array\n    from sklearn.linear_model import LinearRegression\n    ```", "```py\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    from sklearn.linear_model import LogisticRegression\n    ```", "```py\n    selected_features = [\n        '', # List features here\n    ]\n    ```", "```py\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    from sklearn.neighbors import KNeighborsClassifier as KNN\n    ```", "```py\n    df = pd.read_csv('iris-data.csv')\n    df.head()\n    ```", "```py\n    markers = {\n        'Iris-setosa': {'marker': 'x', 'facecolor': 'k', 'edgecolor': 'k'},\n        'Iris-versicolor': {'marker': '*', 'facecolor': 'none', 'edgecolor': 'k'},\n        'Iris-virginica': {'marker': 'o', 'facecolor': 'none', 'edgecolor': 'k'},\n    }\n    plt.figure(figsize=(10, 7))\n    for name, group in df.groupby('Species'):\n        plt.scatter(group['Sepal Length'], group['Petal Width'], \n                    label=name,\n                    marker=markers[name]['marker'],\n                    facecolors=markers[name]['facecolor'],\n                    edgecolor=markers[name]['edgecolor'])\n    plt.title('Species Classification Sepal Length vs Petal Width');\n    plt.xlabel('Sepal Length (mm)');\n    plt.ylabel('Petal Width (mm)');\n    plt.legend();\n    ```", "```py\n    df_test = df.iloc[134]\n    df = df.drop([134]) # Remove the sample\n    df_test\n    ```", "```py\n    plt.figure(figsize=(10, 7))\n    for name, group in df.groupby('Species'):\n        plt.scatter(group['Sepal Length'], group['Petal Width'], \n                    label=name,\n                    marker=markers[name]['marker'],\n                    facecolors=markers[name]['facecolor'],\n                    edgecolor=markers[name]['edgecolor'])\n\n    plt.scatter(df_test['Sepal Length'], df_test['Petal Width'], label='Test Sample', c='k', marker='D')\n    plt.title('Species Classification Sepal Length vs Petal Width');\n    plt.xlabel('Sepal Length (mm)');\n    plt.ylabel('Petal Width (mm)');\n    plt.legend();\n    ```", "```py\n    model = KNN(n_neighbors=3)\n    model.fit(X=df[['Petal Width', 'Sepal Length']], y=df.Species)\n    ```", "```py\n    model.score(X=df[['Petal Width', 'Sepal Length']], y=df.Species)\n    ```", "```py\n    model.predict(df_test[['Petal Width', 'Sepal Length']].values.reshape((-1, 2)))[0]\n    ```", "```py\n    df.iloc[134].Species\n    ```", "```py\n    import numpy as np\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    from matplotlib.colors import ListedColormap\n    from sklearn.neighbors import KNeighborsClassifier as KNN\n    ```", "```py\n    df = pd.read_csv('iris-data.csv')\n    df.head()\n    ```", "```py\n    labelled_species = [\n        'Iris-setosa',\n        'Iris-versicolor',\n        'Iris-virginica',\n    ]\n    for idx, label in enumerate(labelled_species):\n        df.Species = df.Species.replace(label, idx)\n    df.head()\n    ```", "```py\n    model = KNN(n_neighbors=3)\n    model.fit(X=df[['Sepal Length', 'Petal Width']], y=df.Species)\n    ```", "```py\n    spacing = 0.1 # 0.1mm\n    petal_range = np.arange(df['Petal Width'].min() - 1, df['Petal Width'].max() + 1, spacing)\n    sepal_range = np.arange(df['Sepal Length'].min() - 1, df['Sepal Length'].max() + 1, spacing)\n    ```", "```py\n    xx, yy = np.meshgrid(sepal_range, petal_range) # Create the mesh\n    ```", "```py\n    xx\n    ```", "```py\n    yy\n    ```", "```py\n    pred_x = np.c_[xx.ravel(), yy.ravel()] # Concatenate the results\n    pred_x\n    ```", "```py\n    pred_y = model.predict(pred_x).reshape(xx.shape)\n    pred_y\n    ```", "```py\n    # Create color maps\n    cmap_light = ListedColormap(['#F6A56F', '#6FF6A5', '#A56FF6'])\n    cmap_bold = ListedColormap(['#E6640E', '#0EE664', '#640EE6'])\n    ```", "```py\n    markers = {\n        'Iris-setosa': {'marker': 'x', 'facecolor': 'k', 'edgecolor': 'k'},\n        'Iris-versicolor': {'marker': '*', 'facecolor': 'none', 'edgecolor': 'k'},\n        'Iris-virginica': {'marker': 'o', 'facecolor': 'none', 'edgecolor': 'k'},\n    }\n    plt.figure(figsize=(10, 7))\n    for name, group in df.groupby('Species'):\n        species = labelled_species[name]\n        plt.scatter(group['Sepal Length'], group['Petal Width'],\n                    c=cmap_bold.colors[name],\n                    label=labelled_species[name],\n                    marker=markers[species]['marker']\n                   )\n    plt.title('Species Classification Sepal Length vs Petal Width');\n    plt.xlabel('Sepal Length (mm)');\n    plt.ylabel('Petal Width (mm)');\n    plt.legend();\n    ```", "```py\n    plt.figure(figsize=(10, 7))\n    plt.pcolormesh(xx, yy, pred_y, cmap=cmap_light);\n    plt.scatter(df['Sepal Length'], df['Petal Width'], c=df.Species, cmap=cmap_bold, edgecolor='k', s=20);\n    plt.title('Species Decision Boundaries Sepal Length vs Petal Width');\n    plt.xlabel('Sepal Length (mm)');\n    plt.ylabel('Petal Width (mm)');\n    ```", "```py\n    import struct\n    import numpy as np\n    import gzip\n    import urllib.request\n    import matplotlib.pyplot as plt\n    from array import array\n    from sklearn.neighbors import KNeighborsClassifier as KNN\n    ```", "```py\n    df = pd.DataFrame()\n    df['Outlook'] = [\n        'sunny', 'sunny', 'overcast', 'rain', 'rain', 'rain',\n        'overcast', 'sunny', 'sunny', 'rain', 'sunny',\n        'overcast', 'overcast', 'rain'\n    ]\n    df['Temperature'] = [\n        'hot', 'hot', 'hot', 'mild', 'cool', 'cool', 'cool',\n        'mild', 'cool', 'mild', 'mild', 'mild', 'hot', 'mild',\n    ]\n    df['Humidity'] = [\n        'high', 'high', 'high', 'high', 'normal', 'normal', 'normal', \n        'high', 'normal', 'normal', 'normal', 'high', 'normal', 'high'\n    ]\n    df['Windy'] = [\n        'Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Weak', 'Weak',\n        'Strong', 'Strong', 'Weak', 'Strong'\n    ]\n    df['Decision'] = [\n        'N', 'N', 'P', 'P', 'P', 'N', 'P', 'N', 'P', 'P',\n        'P', 'P', 'P', 'N'\n    ]\n    df\n    ```", "```py\n    # Probability of P\n    p_p = len(df.loc[df.Decision == 'P']) / len(df)\n    # Probability of N\n    p_n = len(df.loc[df.Decision == 'N']) / len(df)\n    entropy_decision = -p_n * np.log2(p_n) - p_p * np.log2(p_p)\n    print(f'H(S) = {entropy_decision:0.4f}')\n    ```", "```py\n    def f_entropy_decision(data):\n        p_p = len(data.loc[data.Decision == 'P']) / len(data)\n        p_n = len(data.loc[data.Decision == 'N']) / len(data)\n        return -p_n * np.log2(p_n) - p_p * np.log2(p_p)\n    ```", "```py\n    IG_decision_Outlook = entropy_decision # H(S)\n    # Create a string to print out the overall equation\n    overall_eqn = 'Gain(Decision, Outlook) = Entropy(Decision)' \n    # Iterate through the values for outlook and compute the probabilities\n    # and entropy values\n    for name, Outlook in df.groupby('Outlook'):\n        num_p = len(Outlook.loc[Outlook.Decision == 'P'])\n        num_n = len(Outlook.loc[Outlook.Decision != 'P'])\n        num_Outlook = len(Outlook)\n        print(f'p(Decision=P|Outlook={name}) = {num_p}/{num_Outlook}')\n        print(f'p(Decision=N|Outlook={name}) = {num_n}/{num_Outlook}')    \n        print(f'p(Decision|Outlook={name}) = {num_Outlook}/{len(df)}')\n        print(f'Entropy(Decision|Outlook={name}) = '\\\n             f'-{num_p}/{num_Outlook}.log2({num_p}/{num_Outlook}) - '\\\n             f'{num_n}/{num_Outlook}.log2({num_n}/{num_Outlook})')\n\n        entropy_decision_outlook = 0\n\n        # Cannot compute log of 0 so add checks\n        if num_p != 0:\n            entropy_decision_outlook -= (num_p / num_Outlook) \\\n                * np.log2(num_p / num_Outlook)\n\n        # Cannot compute log of 0 so add checks\n        if num_n != 0:\n            entropy_decision_outlook -= (num_n / num_Outlook) \\\n                * np.log2(num_n / num_Outlook)\n\n        IG_decision_Outlook -= (num_Outlook / len(df)) * entropy_decision_outlook\n        print()\n        overall_eqn += f' - p(Decision|Outlook={name}).'\n        overall_eqn += f'Entropy(Decision|Outlook={name})'\n    print(overall_eqn)\n    print(f'Gain(Decision, Outlook) = {IG_decision_Outlook:0.4f}')\n    ```", "```py\n    def IG(data, column, ent_decision=entropy_decision):\n        IG_decision = ent_decision\n        for name, temp in data.groupby(column):\n            p_p = len(temp.loc[temp.Decision == 'P']) / len(temp)\n            p_n = len(temp.loc[temp.Decision != 'P']) / len(temp)\n            entropy_decision = 0\n            if p_p != 0:\n                entropy_decision -= (p_p) * np.log2(p_p)\n            if p_n != 0:\n                entropy_decision -= (p_n) * np.log2(p_n)\n            IG_decision -= (len(temp) / len(df)) * entropy_decision\n        return IG_decision\n    ```", "```py\n    for col in df.columns[:-1]:\n        print(f'Gain(Decision, {col}) = {IG(df, col):0.4f}')\n    ```", "```py\n    for name, temp in df.groupby('Outlook'):\n        print('-' * 15)\n        print(name)\n        print('-' * 15)\n        print(temp)\n        print('-' * 15)\n    ```", "```py\n    df_next = df.loc[df.Outlook != 'overcast']\n    df_next\n    ```", "```py\n    df_sunny = df_next.loc[df_next.Outlook == 'sunny']\n    ```", "```py\n    entropy_decision = f_entropy_decision(df_sunny)\n    entropy_decision\n    ```", "```py\n    for col in df_sunny.columns[1:-1]:\n        print(f'Gain(Decision, {col}) = {IG(df_sunny, col, entropy_decision):0.4f}')\n    ```", "```py\n    for name, temp in df_sunny.groupby('Humidity'):\n        print('-' * 15)\n        print(name)\n        print('-' * 15)\n        print(temp)\n        print('-' * 15)\n    ```", "```py\n    df_rain = df_next.loc[df_next.Outlook == 'rain']\n    entropy_decision = f_entropy_decision(df_rain)\n    entropy_decision\n    ```", "```py\n    for col in df_rain.columns[1:-1]:\n        print(f'Gain(Decision, {col}) = {IG(df_rain, col, entropy_decision):0.4f}')\n    ```", "```py\n    for name, temp in df_rain.groupby('Windy'):\n        print('-' * 15)\n        print(name)\n        print('-' * 15)\n        print(temp)\n        print('-' * 15)\n    ```", "```py\n    import numpy as np\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    from sklearn.tree import DecisionTreeClassifier\n    ```", "```py\n    df = pd.read_csv('iris-data.csv')\n    df.head()\n    ```", "```py\n    np.random.seed(10)\n    samples = np.random.randint(0, len(df), 10)\n    df_test = df.iloc[samples]\n    df = df.drop(samples)\n    ```", "```py\n    model = DecisionTreeClassifier()\n    model = model.fit(df[['Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width']], df.Species)\n    model.score(df[['Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width']], df.Species)\n    ```", "```py\n    model.score(df_test[['Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width']], df_test.Species)\n    ```", "```py\n    !conda install python-graphviz\n    ```", "```py\n    import graphviz\n    from sklearn.tree import export_graphviz\n    ```", "```py\n    dot_data = export_graphviz(model, out_file=None)\n    graph = graphviz.Source(dot_data)\n    graph\n    ```"]