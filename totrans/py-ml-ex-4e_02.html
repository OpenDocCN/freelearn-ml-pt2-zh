<html><head></head><body>
  <div class="Basic-Text-Frame" id="_idContainer089">
    <h1 class="chapterNumber">2</h1>
    <h1 class="chapterTitle" id="_idParaDest-59">Building a Movie Recommendation Engine with Naïve Bayes</h1>
    <p class="normal">As promised, in this chapter, we will kick off our supervised learning journey with machine learning classification, and specifically, binary classification. The goal of the chapter is to build a movie recommendation system, which is a good starting point for learning classification from a real-life example—movie streaming service providers are already doing this, and we can do the same.</p>
    <p class="normal">In this chapter, you will learn the fundamental concepts of classification, including what it does and its various types and applications, with a focus on solving a binary classification problem using a simple, yet powerful, algorithm, Naïve Bayes. Finally, the chapter will demonstrate how to fine-tune a model, which is an important skill that every data science or machine learning practitioner should learn.</p>
    <p class="normal">We will go into detail on the following topics:</p>
    <ul>
      <li class="bulletList">Getting started with classification</li>
      <li class="bulletList">Exploring Naïve Bayes</li>
      <li class="bulletList">Implementing Naïve Bayes</li>
      <li class="bulletList">Building a movie recommender with Naïve Bayes</li>
      <li class="bulletList">Evaluating classification performance</li>
      <li class="bulletList">Tuning models with cross-validation</li>
    </ul>
    <h1 class="heading-1" id="_idParaDest-60">Getting started with classification</h1>
    <p class="normal">Movie recommendation can be framed<a id="_idIndexMarker178"/> as a machine learning classification problem. If it is predicted that you’ll like a movie because you’ve liked or watched similar movies, for example, then it will be on your recommended list; otherwise, it won’t. Let’s get started by learning the important concepts of machine learning classification.</p>
    <p class="normal"><strong class="keyWord">Classification</strong> is one of the main instances of supervised learning. Given a training set of data containing observations and their associated categorical outputs, the goal of classification is to learn<a id="_idIndexMarker179"/> a general rule<a id="_idIndexMarker180"/> that correctly<a id="_idIndexMarker181"/> maps the <strong class="keyWord">observations</strong> (also called <strong class="keyWord">features</strong> or <strong class="keyWord">predictive variables</strong>) to the target <strong class="keyWord">categories</strong> (also called <strong class="keyWord">labels</strong> or <strong class="keyWord">classes</strong>). Putting it another way, a trained classification<a id="_idIndexMarker182"/> model will be generated<a id="_idIndexMarker183"/> after the model<a id="_idIndexMarker184"/> learns from the features and targets of training samples, as shown in the first half of <em class="italic">Figure 2.1</em>. When new or unseen data comes in, the trained model will be able to determine their desired class memberships. Class information will be predicted based on the known input features using the trained classification model, as displayed in the second half of <em class="italic">Figure 2.1</em>:</p>
    <figure class="mediaobject"><img alt="" role="presentation" src="../Images/B21047_02_01.png"/></figure>
    <p class="packt_figref">Figure 2.1: The training and prediction stages in classification</p>
    <p class="normal">In general, there are three types of classification based on the possibility of class output—<strong class="keyWord">binary</strong>, <strong class="keyWord">multiclass</strong>, and <strong class="keyWord">multi-label classification</strong>. We will cover them one by one in this section.</p>
    <h2 class="heading-2" id="_idParaDest-61">Binary classification</h2>
    <p class="normal">Binary classification classifies<a id="_idIndexMarker185"/> observations into one of two possible classes. Spam email filtering<a id="_idIndexMarker186"/> we encounter every day is a typical use case of binary classification, which identifies email messages (input observations) as spam or not spam (output classes). Customer churn prediction is another frequently mentioned example, where a prediction system<a id="_idIndexMarker187"/> takes in customer segment data and activity data from <strong class="keyWord">customer relationship management</strong> (<strong class="keyWord">CRM</strong>) systems and identifies which customers are likely to churn.</p>
    <p class="normal">Another application in the marketing and advertising industry is click-through prediction for online ads—that is, whether or not an ad will be clicked, given users’ interest information and browsing history. Last but not least, binary classification is also being employed in biomedical science, for example, in early cancer diagnosis, classifying patients into high- or low-risk groups based on MRI images.</p>
    <p class="normal">As demonstrated in <em class="italic">Figure 2.2</em>, binary classification tries to find a way to separate data into two classes (denoted by dots and crosses):</p>
    <figure class="mediaobject"><img alt="" role="presentation" src="../Images/B21047_02_02.png"/></figure>
    <p class="packt_figref">Figure 2.2: Binary classification example</p>
    <p class="normal">Don’t forget that predicting<a id="_idIndexMarker188"/> whether a person likes a movie is also a binary<a id="_idIndexMarker189"/> classification problem.</p>
    <h2 class="heading-2" id="_idParaDest-62">Multiclass classification</h2>
    <p class="normal">This type of classification<a id="_idIndexMarker190"/> is also<a id="_idIndexMarker191"/> referred to as <strong class="keyWord">multinomial classification</strong>. It allows more than two possible<a id="_idIndexMarker192"/> classes, as opposed to only two in binary cases. Handwritten digit recognition is a common instance of classification and has a long history of research and development since the early 1900s. A classification system, for example, can learn to read and understand handwritten ZIP codes (digits from 0 to 9 in most countries) by which envelopes are automatically sorted.</p>
    <p class="normal">Handwritten digit recognition has become a <em class="italic">“Hello, World!”</em> in the journey of studying machine learning, and the scanned<a id="_idIndexMarker193"/> document dataset constructed by the <strong class="keyWord">National Institute of Standards and Technology</strong> (<strong class="keyWord">NIST</strong>), called <strong class="keyWord">Modified National Institute of Standards and Technology</strong> (<strong class="keyWord">MNIST</strong>), is a benchmark dataset frequently<a id="_idIndexMarker194"/> used to test and evaluate multiclass classification models. <em class="italic">Figure 2.3</em> shows four samples taken from the MNIST dataset, representing the digits “<code class="inlineCode">9</code>,” “<code class="inlineCode">2</code>,” “<code class="inlineCode">1</code>,” and “<code class="inlineCode">3</code>,” respectively:</p>
    <figure class="mediaobject"><img alt="" role="presentation" src="../Images/B21047_02_03.png"/></figure>
    <p class="packt_figref">Figure 2.3: Samples from the MNIST dataset</p>
    <p class="normal">As another example, in <em class="italic">Figure 2.4</em>, the multiclass classification<a id="_idIndexMarker195"/> model tries to find segregation<a id="_idIndexMarker196"/> boundaries to separate data into the following three different classes (denoted by dots, crosses, and triangles):</p>
    <figure class="mediaobject"><img alt="A picture containing screenshot, diagram  Description automatically generated" src="../Images/B21047_02_04.png"/></figure>
    <p class="packt_figref">Figure 2.4: Multiclass classification example</p>
    <h2 class="heading-2" id="_idParaDest-63">Multi-label classification</h2>
    <p class="normal">In the first two types<a id="_idIndexMarker197"/> of classification, target classes are mutually<a id="_idIndexMarker198"/> exclusive and a sample is assigned <em class="italic">one, and only one</em>, label. It is the opposite in multi-label classification. Increasing research attention has been drawn to multi-label classification by the nature of the combination of categories in modern applications. For example, a picture that captures a sea and a sunset can simultaneously belong to both conceptual scenes, whereas it can only be an image of either a cat or dog in a binary case, or one type of fruit among oranges, apples, and bananas in a multiclass case. Similarly, adventure films are often combined with other genres, such as fantasy, science fiction, horror, and drama.</p>
    <p class="normal">Another typical application is protein function classification, as a protein may have more than one function—storage, antibody, support, transport, and so on.</p>
    <p class="normal">A typical approach to solving an <em class="italic">n</em>-label classification problem is to transform it into a set of <em class="italic">n</em> binary classification problems, where each binary classification problem is handled by an individual binary classifier.</p>
    <p class="normal">Refer to <em class="italic">Figure 2.5</em> to see the restructuring of a multi-label classification problem into a multiple-binary classification problem:</p>
    <figure class="mediaobject"><img alt="A diagram of a multi-label classifier  Description automatically generated with medium confidence" src="../Images/B21047_02_05.png"/></figure>
    <p class="packt_figref">Figure 2.5: Transforming three-label classification into three independent binary classifications</p>
    <p class="normal">Using the protein function classification<a id="_idIndexMarker199"/> example once more, we can transform<a id="_idIndexMarker200"/> it into several binary classifications, such as: Is it for storage? Is it for antibodies? Is it for support? </p>
    <p class="normal">To solve problems like these, researchers have developed<a id="_idIndexMarker201"/> many powerful classification algorithms, among which Naïve Bayes, <strong class="keyWord">Support Vector Machines</strong> (<strong class="keyWord">SVMs</strong>), decision trees, logistic regression, and neural networks are often used.</p>
    <p class="normal">In the following sections, we will cover the mechanics of Naïve Bayes and its in-depth implementation, along with other important concepts, including classifier tuning and classification performance evaluation. Stay tuned for upcoming chapters that cover the other classification algorithms.</p>
    <h1 class="heading-1" id="_idParaDest-64">Exploring Naïve Bayes</h1>
    <p class="normal">The <strong class="keyWord">Naïve Bayes</strong> classifier belongs to the family<a id="_idIndexMarker202"/> of probabilistic classifiers. It computes<a id="_idIndexMarker203"/> the probabilities of each predictive <strong class="keyWord">feature</strong> (also referred to as an <strong class="keyWord">attribute</strong> or <strong class="keyWord">signal</strong>) of the data belonging<a id="_idIndexMarker204"/> to each class<a id="_idIndexMarker205"/> in order to make a prediction of the probability distribution over all classes. Of course, from the resulting probability distribution, we can conclude the most likely class that the data sample is associated with. What Naïve Bayes does specifically, as its name indicates, is as follows:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Bayes</strong>: As in, it maps the probability<a id="_idIndexMarker206"/> of observed input features given a possible class to the probability of the class given observed pieces of evidence based on Bayes’ theorem.</li>
      <li class="bulletList"><strong class="keyWord">Naïve</strong>: As in, it simplifies probability<a id="_idIndexMarker207"/> computation by assuming that predictive features are mutually independent.</li>
    </ul>
    <p class="normal">I will explain Bayes’ theorem with examples in the next section.</p>
    <h2 class="heading-2" id="_idParaDest-65">Bayes’ theorem by example</h2>
    <p class="normal">It is important to understand<a id="_idIndexMarker208"/> Bayes’ theorem before diving into the classifier. Let <em class="italic">A</em> and <em class="italic">B</em> denote any two events. Events could be that <em class="italic">it will rain tomorrow, two kings are drawn from a deck of cards, or a person has cancer</em>. In Bayes’ theorem, <em class="italic">P</em>(<em class="italic">A</em> | <em class="italic">B</em>) is the probability that <em class="italic">A</em> occurs given that <em class="italic">B</em> is true. It can be computed as follows:</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_001.png"/></p>
    <p class="normal">Here, <em class="italic">P</em>(<em class="italic">B</em> | <em class="italic">A</em>) is the probability of observing <em class="italic">B</em> given that <em class="italic">A</em> occurs, while <em class="italic">P</em>(<em class="italic">A</em>) and <em class="italic">P</em>(<em class="italic">B</em>) are the probability that <em class="italic">A</em> and <em class="italic">B</em> occur, respectively. Is that too abstract? Let’s consider the following concrete examples:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Example 1</strong>: Given two coins, one is unfair, with 90% of flips getting a head and 10% getting a tail, while the other one is fair. Randomly pick one coin and flip it. What is the probability that this coin is the unfair one, if we get a head?</li>
    </ul>
    <p class="normal-one">We can solve this by first denoting <em class="italic">U</em> for the event of picking the unfair coin, <em class="italic">F</em> for the fair coin, and <em class="italic">H</em> for the event of getting a head. So, the probability that the unfair coin has been picked when we get a head, <em class="italic">P(U |H)</em>, can be calculated with the following:</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_002.png"/></p>
    <p class="normal-one">As we know, <em class="italic">P</em>(<em class="italic">H</em> | <em class="italic">U</em>) is <code class="inlineCode">0.9</code>. <em class="italic">P</em>(<em class="italic">U</em>) is <code class="inlineCode">0.5</code> because we randomly pick a coin out of two. However, deriving the probability of getting a head, <em class="italic">P</em>(<em class="italic">H</em>), is not that straightforward, as two events can lead to the following, where <em class="italic">U</em> is when the unfair coin is picked, and <em class="italic">F</em> is when the fair coin is picked:</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_003.png"/></p>
    <p class="normal-one">Now, <em class="italic">P</em>(<em class="italic">U</em>|<em class="italic">H</em>) becomes the following:</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_004.png"/></p>
    <p class="normal-one">So, under Bayes’ theorem, the probability<a id="_idIndexMarker209"/> that the unfair coin has been picked when we get a head is <code class="inlineCode">0.64</code>.</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Example 2</strong>: Suppose a physician reported the following cancer screening test scenario among 10,000 people:</li>
    </ul>
    <table class="table-container" id="table001-1">
      <tbody>
        <tr>
          <td class="table-cell"/>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Cancer</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">No Cancer</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Total</strong></p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Test Positive</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal">80</p>
          </td>
          <td class="table-cell">
            <p class="normal">900</p>
          </td>
          <td class="table-cell">
            <p class="normal">980</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Test Negative</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal">20</p>
          </td>
          <td class="table-cell">
            <p class="normal">9000</p>
          </td>
          <td class="table-cell">
            <p class="normal">9020</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Total</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal">100</p>
          </td>
          <td class="table-cell">
            <p class="normal">9900</p>
          </td>
          <td class="table-cell">
            <p class="normal">10000</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="packt_figref">Table 2.1: Example of a cancer screening result</p>
    <p class="normal-one">This indicates that 80 out of 100 cancer patients are correctly diagnosed, while the other 20 are not; cancer is falsely detected in 900 out of 9,900 healthy people.</p>
    <p class="normal-one">If the result of this screening test on a person is positive, what is the probability that they actually have cancer? Let’s assign the event of having cancer and positive testing results as <em class="italic">C</em> and <em class="italic">Pos</em>, respectively. So we have <em class="italic">P</em>(<em class="italic">Pos</em> |<em class="italic">C</em>) = <code class="inlineCode">80/100</code> = <code class="inlineCode">0.8</code>, <em class="italic">P</em>(<em class="italic">C</em>) = <code class="inlineCode">100/10000</code> = <code class="inlineCode">0.01</code>, and <em class="italic">P</em>(<em class="italic">Pos</em>) = <code class="inlineCode">980/10000</code> = <code class="inlineCode">0.098</code>.</p>
    <p class="normal-one">We can apply Bayes’ theorem to calculate <em class="italic">P</em>(<em class="italic">C</em>|<em class="italic">Pos</em>):</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_005.png"/></p>
    <p class="normal-one">Given a positive screening<a id="_idIndexMarker210"/> result, the chance that the subject has cancer is 8.16%, which is significantly higher than the one under the general assumption (100/10000=1%) without the subject undergoing the screening.</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Example 3</strong>: Three machines, <em class="italic">A</em>, <em class="italic">B</em>, and <em class="italic">C</em>, in a factory account for 35%, 20%, and 45% of bulb production. The fraction of defective bulbs produced by each machine is 1.5%, 1%, and 2%, respectively. A bulb produced by this factory was identified as defective, which is denoted as event <em class="italic">D</em>. What are the probabilities that this bulb was manufactured by machine <em class="italic">A</em>, <em class="italic">B</em>, or <em class="italic">C</em>, respectively?</li>
    </ul>
    <p class="normal-one">Again, we can simply follow Bayes’ theorem:</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_006.png"/></p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_007.png"/></p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_008.png"/></p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_009.png"/></p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_010.png"/></p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_011.png"/></p>
    <p class="normal-one">So, under Bayes’ theorem, the probabilities that this bulb was manufactured by machine <em class="italic">A</em>, <em class="italic">B</em>, or <em class="italic">C</em>, are <code class="inlineCode">0.323</code>, <code class="inlineCode">0.123</code>, and <code class="inlineCode">0.554</code> respectively.</p>
    <p class="normal-one">Also, either way, we do<a id="_idIndexMarker211"/> not even need to calculate <em class="italic">P</em>(<em class="italic">D</em>) since we know that the following is the case:</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_012.png"/></p>
    <p class="normal">We also know the following concept:</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_013.png"/></p>
    <p class="normal">So, we have the following formula:</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_014.png"/></p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_015.png"/></p>
    <p class="normal">This shortcut approach<a id="_idIndexMarker212"/> gave us the same results as the original method, but faster. Now that you understand Bayes’ theorem as the backbone of Naïve Bayes, we can easily move forward with the classifier itself.</p>
    <h2 class="heading-2" id="_idParaDest-66">The mechanics of Naïve Bayes</h2>
    <p class="normal">Let’s start by discussing the magic<a id="_idIndexMarker213"/> behind the algorithm—how Naïve Bayes works. Given a data sample, <em class="italic">x</em>, with <em class="italic">n</em> features, <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">1</sub>, <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">2</sub>,..., <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">n</sub> (<em class="italic">x</em> represents a feature vector and <em class="italic">x</em> = (<em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">1</sub>, <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">2</sub>,..., <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">n</sub>)), the goal of Naïve Bayes is to determine the probabilities that this sample belongs to each of <em class="italic">K</em> possible classes <em class="italic">y</em><sub class="subscript-italic" style="font-style: italic;">1</sub>, <em class="italic">y</em><sub class="subscript-italic" style="font-style: italic;">2</sub>,..., <em class="italic">y</em><sub class="subscript-italic" style="font-style: italic;">K</sub>, which is <em class="italic">P(y</em><sub class="subscript-italic" style="font-style: italic;">K</sub><em class="italic"> |x)</em> or <em class="italic">P</em>(<em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">1</sub>, <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">2</sub>,..., <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">n</sub>), where <em class="italic">k</em> = 1, 2, …, <em class="italic">K</em>.</p>
    <p class="normal">This looks no different from what we have just dealt with: <em class="italic">x</em> or <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">1</sub>, <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">2</sub>,..., <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">n</sub>. This is a joint event where a sample that has observed feature values <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">1</sub>, <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">2</sub>,..., <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">n</sub>. <em class="italic">y</em><sub class="subscript-italic" style="font-style: italic;">K</sub> is the event that the sample belongs to class <em class="italic">k</em>. We can apply Bayes’ theorem right away:</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_016.png"/></p>
    <p class="normal">Let’s look at each component in detail:</p>
    <ul>
      <li class="bulletList"><em class="italic">P</em>(<em class="italic">y</em><sub class="subscript-italic" style="font-style: italic;">k</sub>) portrays how classes are distributed, with no further knowledge of observation features. Thus, it is also called <strong class="keyWord">prior</strong> in Bayesian probability<a id="_idIndexMarker214"/> terminology. Prior can be either predetermined (usually in a uniform manner where each class has an equal chance of occurrence) or learned from a set of training samples.</li>
      <li class="bulletList"><em class="italic">P</em>(<em class="italic">y</em><sub class="subscript-italic" style="font-style: italic;">k</sub><em class="italic"> </em>|<em class="italic">x</em>), in contrast to prior <em class="italic">P</em>(<em class="italic">y</em><sub class="subscript-italic" style="font-style: italic;">k</sub>), is the <strong class="keyWord">posterior</strong>, with extra knowledge<a id="_idIndexMarker215"/> of observation.</li>
      <li class="bulletList"><em class="italic">P</em>(<em class="italic">x </em>|<em class="italic">y</em><sub class="subscript-italic" style="font-style: italic;">K</sub>), or <em class="italic">P</em>(<em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">1</sub><em class="italic">, x</em><sub class="subscript-italic" style="font-style: italic;">2</sub><em class="italic">,..., x</em><sub class="subscript-italic" style="font-style: italic;">n</sub><em class="italic"> </em>|<em class="italic">y</em><sub class="subscript-italic" style="font-style: italic;">k</sub>), is the joint distribution of <em class="italic">n</em> features, given that the sample belongs to class <em class="italic">y</em><sub class="subscript-italic" style="font-style: italic;">k</sub>. This is how likely the features with such values co-occur. This<a id="_idIndexMarker216"/> is named <strong class="keyWord">likelihood</strong> in Bayesian terminology. Obviously, the likelihood will be difficult to compute as the number of features increases. In Naïve Bayes, this is solved thanks to the feature independence assumption. The joint conditional distribution of <em class="italic">n</em> features can be expressed as the joint product of individual feature conditional distributions:</li>
    </ul>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_017.png"/></p>
    <p class="normal-one">Each conditional distribution can be efficiently learned from a set of training samples.</p>
    <ul>
      <li class="bulletList"><em class="italic">P</em>(<em class="italic">x</em>), also called <strong class="keyWord">evidence</strong>, solely depends on the overall distribution<a id="_idIndexMarker217"/> of features, which<a id="_idIndexMarker218"/> is not specific to certain classes and is therefore a normalization constant. As a result, posterior is proportional to prior and likelihood:</li>
    </ul>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_018.png"/></p>
    <p class="normal"><em class="italic">Figure 2.6</em> summarizes how a Naïve Bayes classification model is trained and applied to new data:</p>
    <figure class="mediaobject"><img alt="" role="presentation" src="../Images/B21047_02_06.png"/></figure>
    <p class="packt_figref">Figure 2.6: Training and prediction stages in Naïve Bayes classification</p>
    <p class="normal">A Naïve Bayes classification model is trained using labeled data, where each instance is associated<a id="_idIndexMarker219"/> with a class label. During training, the model learns the probability distribution of the features given each class. This involves calculating the likelihood of observing each feature value given each class. Once trained, the model can be applied to new, unlabeled data. To classify a new instance, the model calculates the probability of each class given the observed features using Bayes’ theorem.</p>
    <p class="normal">Let’s see a Naïve Bayes classifier in action through a simplified example of movie recommendation before we jump to the implementations of Naïve Bayes. Given four (pseudo) users, whether they like each of three movies, <em class="italic">m</em><sub class="subscript-italic" style="font-style: italic;">1</sub><em class="italic">, m</em><sub class="subscript-italic" style="font-style: italic;">2</sub><em class="italic">,</em> and <em class="italic">m</em><sub class="subscript-italic" style="font-style: italic;">3</sub> (indicated as 1 or 0), and whether they like a target movie (denoted as event <em class="italic">Y</em>) or not (denoted as event <em class="italic">N</em>), as shown in the following table, we are asked to predict how likely it is that another user will like that movie:</p>
    <table class="table-container" id="table002-1">
      <tbody>
        <tr>
          <td class="table-cell"/>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">ID</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">m1</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">m2</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">m3</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Whether the user likes the target movie</strong></p>
          </td>
        </tr>
        <tr>
          <td class="table-cell" rowspan="4">
            <p class="normal"><strong class="keyWord">Training data</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Y</strong></p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">2</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">N</strong></p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">3</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Y</strong></p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">4</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Y</strong></p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Testing case</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal">5</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">?</strong></p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="packt_figref">Table 2.2: Toy data example for a movie recommendation</p>
    <p class="normal">Whether users like three<a id="_idIndexMarker220"/> movies, <em class="italic">m</em><sub class="subscript-italic" style="font-style: italic;">1</sub><em class="italic">, m</em><sub class="subscript-italic" style="font-style: italic;">2</sub><em class="italic">,</em> and <em class="italic">m</em><sub class="subscript-italic" style="font-style: italic;">3</sub>, are features (signals) that we can utilize to predict the target class. The training data we have are the four samples with both ratings and target information.</p>
    <p class="normal">Now, let’s first compute the prior, <em class="italic">P</em>(<em class="italic">Y</em>) and <em class="italic">P</em>(<em class="italic">N</em>). From the training set, we can easily get the following:</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_019.png"/></p>
    <p class="normal">Alternatively, we can also impose an assumption of a uniform prior that <em class="italic">P</em>(<em class="italic">Y</em>) = 50%, for example.</p>
    <p class="normal">For simplicity, we will denote the event that a user likes three movies or not as <em class="italic">f</em><sub class="subscript">1</sub><em class="italic">, f</em><sub class="subscript">2</sub><em class="italic">,</em> and <em class="italic">f</em><sub class="subscript">3</sub>, respectively. To calculate posterior <em class="italic">P</em>(<em class="italic">Y| x</em>)<em class="italic">,</em> where <em class="italic">x</em> = (1, 1, 0), the first step is to compute the likelihoods, <em class="italic">P</em>(<em class="italic">f</em><sub class="subscript">1</sub><em class="italic"> = 1</em>|<em class="italic"> Y</em>), <em class="italic">P</em>(<em class="italic">f</em><sub class="subscript">2</sub><em class="italic"> = 1 Y</em>), and <em class="italic">P</em>(<em class="italic">f</em><sub class="subscript">3</sub><em class="italic"> = 0</em>|<em class="italic"> Y</em>), and similarly, <em class="italic">P</em>(<em class="italic">f</em><sub class="subscript">1</sub><em class="italic"> = 1</em>|<em class="italic"> N</em>), <em class="italic">P</em>(<em class="italic">f</em><sub class="subscript">2</sub><em class="italic"> = 1</em>|<em class="italic"> N</em>), and <em class="italic">P</em>(<em class="italic">f</em><sub class="subscript">3</sub><em class="italic"> = 0</em>|<em class="italic"> N</em>), based on the training set. However, you may notice that since <em class="italic">f</em><sub class="subscript">1</sub><em class="italic"> = 1</em> was not seen in the <em class="italic">N</em> class, we will get <em class="italic">P</em>(<em class="italic">f</em><sub class="subscript">1</sub><em class="italic"> = 1</em>|<em class="italic">N</em>)<em class="italic"> = 0</em>. Consequently, we will have the following:</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_020.png"/></p>
    <p class="normal">This means we will recklessly predict class = <em class="italic">Y</em> by any means.</p>
    <p class="normal">To eliminate the zero-multiplication factor, the unknown likelihood, we usually assign an initial value of 1 to each feature, that is, we start counting each possible value of a feature from one. This<a id="_idIndexMarker221"/> technique is also known as <strong class="keyWord">Laplace smoothing</strong>. With this amendment, we now have the following:</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_021.png"/></p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_022.png"/></p>
    <p class="normal">Here, given class <em class="italic">N</em>, 0 + 1 means there are zero likes of <em class="italic">m</em><sub class="subscript">1</sub> plus + 1 smoothing; 1 + 2 means there is one data point (ID = 2) plus 2 (2 possible values) + 1 smoothing. Given class <em class="italic">Y</em>, 1 + 1 means there is one like of <em class="italic">m</em><sub class="subscript">1</sub> (ID = 4) plus + 1 smoothing; 3 + 2 means there are 3 data points (ID = 1, 3, 4) plus 2 (2 possible values) + 1 smoothing.</p>
    <p class="normal">Similarly, we can compute<a id="_idIndexMarker222"/> the following:</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_023.png"/></p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_024.png"/></p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_025.png"/></p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_026.png"/></p>
    <p class="normal">Now, we can compute the ratio between two posteriors as follows:</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_027.png"/></p>
    <p class="normal">Also, remember this:</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_028.png"/></p>
    <p class="normal">So, finally, we have the following:</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_029.png"/></p>
    <p class="normal">There is a <code class="inlineCode">92.1%</code> chance that the new user will like the target movie.</p>
    <p class="normal">I hope that you now<a id="_idIndexMarker223"/> have a solid understanding of Naïve Bayes after going through the theory and a toy example. Let’s get ready for its implementation in the next section.</p>
    <h1 class="heading-1" id="_idParaDest-67">Implementing Naïve Bayes</h1>
    <p class="normal">After calculating the movie<a id="_idIndexMarker224"/> preference example by hand, as promised, we are going to implement Naïve Bayes from scratch. After that, we will implement it using the <code class="inlineCode">scikit-learn</code> package.</p>
    <h2 class="heading-2" id="_idParaDest-68">Implementing Naïve Bayes from scratch</h2>
    <p class="normal">Before we develop the model, let’s define the toy dataset we just worked with:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">import</span><span class="language-python"> numpy </span><span class="hljs-con-keyword">as</span><span class="language-python"> np</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">X_train = np.array([</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    [</span><span class="hljs-con-number">0</span><span class="language-python">, </span><span class="hljs-con-number">1</span><span class="language-python">, </span><span class="hljs-con-number">1</span><span class="language-python">],</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    [</span><span class="hljs-con-number">0</span><span class="language-python">, </span><span class="hljs-con-number">0</span><span class="language-python">, </span><span class="hljs-con-number">1</span><span class="language-python">],</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    [</span><span class="hljs-con-number">0</span><span class="language-python">, </span><span class="hljs-con-number">0</span><span class="language-python">, </span><span class="hljs-con-number">0</span><span class="language-python">],</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    [</span><span class="hljs-con-number">1</span><span class="language-python">, </span><span class="hljs-con-number">1</span><span class="language-python">, </span><span class="hljs-con-number">0</span><span class="language-python">]])</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">Y_train = [</span><span class="hljs-con-string">'Y'</span><span class="language-python">, </span><span class="hljs-con-string">'</span><span class="hljs-con-string">N'</span><span class="language-python">, </span><span class="hljs-con-string">'Y'</span><span class="language-python">, </span><span class="hljs-con-string">'Y'</span><span class="language-python">]</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">X_test = np.array([[</span><span class="hljs-con-number">1</span><span class="language-python">, </span><span class="hljs-con-number">1</span><span class="language-python">, </span><span class="hljs-con-number">0</span><span class="language-python">]])</span>
</code></pre>
    <p class="normal">For the model, starting<a id="_idIndexMarker225"/> with the prior, we first group the data by label and record their indices by classes:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">def</span><span class="language-python"> </span><span class="hljs-con-title">get_label_indices</span><span class="language-python">(</span><span class="hljs-con-params">labels</span><span class="language-python">):</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    </span><span class="hljs-con-string">"""</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    Group samples based on their labels and return indices</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    @param labels: list of labels</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    @return: dict, {class1: [indices], class2: [indices]}</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    """</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    </span><span class="hljs-con-keyword">from</span><span class="language-python"> collections </span><span class="hljs-con-keyword">import</span><span class="language-python"> defaultdict</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    label_indices = defaultdict(</span><span class="hljs-con-built_in">list</span><span class="language-python">)</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    </span><span class="hljs-con-keyword">for</span><span class="language-python"> index, label </span><span class="hljs-con-keyword">in</span><span class="language-python"> </span><span class="hljs-con-built_in">enumerate</span><span class="language-python">(labels):</span>
<span class="hljs-con-meta">...</span> <span class="language-python">        label_indices[label].append(index)</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    </span><span class="hljs-con-keyword">return</span><span class="language-python"> label_indices</span>
</code></pre>
    <p class="normal">Take a look at what we get:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">label_indices = get_label_indices(Y_train)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-built_in">print</span><span class="language-python">(</span><span class="hljs-con-string">'label_indices:\n'</span><span class="language-python">, label_indices)</span>
    label_indices:
    defaultdict(&lt;class 'list'&gt;, {'Y': [0, 2, 3], 'N': [1]})
</code></pre>
    <p class="normal">With <code class="inlineCode">label_indices</code>, we calculate the prior:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">def</span><span class="language-python"> </span><span class="hljs-con-title">get_prior</span><span class="language-python">(</span><span class="hljs-con-params">label_indices</span><span class="language-python">):</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    </span><span class="hljs-con-string">"""</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    Compute prior based on training samples</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    @param label_indices: grouped sample indices by class</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    @return: dictionary, with class label as key, corresponding</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">             prior as the value</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    """</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    prior = {label: </span><span class="hljs-con-built_in">len</span><span class="language-python">(indices) </span><span class="hljs-con-keyword">for</span><span class="language-python"> label, indices </span><span class="hljs-con-keyword">in</span>
<span class="hljs-con-meta">...</span> <span class="language-python">                                     label_indices.items()}</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    total_count = </span><span class="hljs-con-built_in">sum</span><span class="language-python">(prior.values())</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    </span><span class="hljs-con-keyword">for</span><span class="language-python"> label </span><span class="hljs-con-keyword">in</span><span class="language-python"> prior:</span>
<span class="hljs-con-meta">...</span> <span class="language-python">        prior[label] /= total_count</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    </span><span class="hljs-con-keyword">return</span><span class="language-python"> prior</span>
</code></pre>
    <p class="normal">Take a look at the computed prior:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">prior = get_prior(label_indices)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-built_in">print</span><span class="language-python">(</span><span class="hljs-con-string">'Prior:'</span><span class="language-python">, prior)</span>
 Prior: {'Y': 0.75, 'N': 0.25}
</code></pre>
    <p class="normal">With <code class="inlineCode">prior</code> calculated, we continue with <code class="inlineCode">likelihood</code>, which is the conditional probability, <code class="inlineCode">P(feature|class)</code>:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">def</span><span class="language-python"> </span><span class="hljs-con-title">get_likelihood</span><span class="language-python">(</span><span class="hljs-con-params">features, label_indices, smoothing=</span><span class="hljs-con-number">0</span><span class="language-python">):</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    </span><span class="hljs-con-string">"""</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    Compute likelihood based on training samples</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    @param features: matrix of features</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    @param label_indices: grouped sample indices by class</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    @param smoothing: integer, additive smoothing parameter</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    @return: dictionary, with class as key, corresponding</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">             conditional probability P(feature|class) vector </span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">             as value</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    """</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    likelihood = {}</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    </span><span class="hljs-con-keyword">for</span><span class="language-python"> label, indices </span><span class="hljs-con-keyword">in</span><span class="language-python"> label_indices.items():</span>
<span class="hljs-con-meta">...</span> <span class="language-python">        likelihood[label] = features[indices, :].</span><span class="hljs-con-built_in">sum</span><span class="language-python">(axis=</span><span class="hljs-con-number">0</span><span class="language-python">)</span>
<span class="hljs-con-meta">...</span> <span class="language-python">                               + smoothing</span>
<span class="hljs-con-meta">...</span> <span class="language-python">        total_count = </span><span class="hljs-con-built_in">len</span><span class="language-python">(indices)</span>
<span class="hljs-con-meta">...</span> <span class="language-python">        likelihood[label] = likelihood[label] /</span>
<span class="hljs-con-meta">...</span> <span class="language-python">                                (total_count + </span><span class="hljs-con-number">2</span><span class="language-python"> * smoothing)</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    </span><span class="hljs-con-keyword">return</span><span class="language-python"> likelihood</span>
</code></pre>
    <p class="normal">We set the <code class="inlineCode">smoothing</code> value<a id="_idIndexMarker226"/> to 1 here, which can also be 0 for no smoothing, or any other positive value, as long as a higher classification performance is achieved:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">smoothing = </span><span class="hljs-con-number">1</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">likelihood = get_likelihood(X_train, label_indices, smoothing)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-built_in">print</span><span class="language-python">(</span><span class="hljs-con-string">'Likelihood:\n'</span><span class="language-python">, likelihood)</span>
Likelihood:
 {'Y': array([0.4, 0.6, 0.4]), 'N': array([0.33333333, 0.33333333, 0.66666667])}
</code></pre>
    <p class="normal">If you ever find any of this confusing, feel free to check <em class="italic">Figure 2.7</em> to refresh your memory:</p>
    <figure class="mediaobject"><img alt="A screenshot of a computer  Description automatically generated with low confidence" src="../Images/B21047_02_07.png"/></figure>
    <p class="packt_figref">Figure 2.7: A simple example of computing prior and likelihood</p>
    <p class="normal">With prior and likelihood ready, we can<a id="_idIndexMarker227"/> now compute posterior for the testing/new samples:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">def</span><span class="language-python"> </span><span class="hljs-con-title">get_posterior</span><span class="language-python">(</span><span class="hljs-con-params">X, prior, likelihood</span><span class="language-python">):</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    </span><span class="hljs-con-string">"""</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    Compute posterior of testing samples, based on prior and</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    likelihood</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    @param X: testing samples</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    @param prior: dictionary, with class label as key,</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">                  corresponding prior as the value</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    @param likelihood: dictionary, with class label as key,</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">                       corresponding conditional probability</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">                           vector as value</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    @return: dictionary, with class label as key, corresponding</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">             posterior as value</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">    """</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    posteriors = []</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    </span><span class="hljs-con-keyword">for</span><span class="language-python"> x </span><span class="hljs-con-keyword">in</span><span class="language-python"> X:</span>
<span class="hljs-con-meta">...</span> <span class="language-python">        </span><span class="hljs-con-comment"># posterior is proportional to prior * likelihood</span>
<span class="hljs-con-meta">...</span> <span class="language-python">        posterior = prior.copy()</span>
<span class="hljs-con-meta">...</span> <span class="language-python">        </span><span class="hljs-con-keyword">for</span><span class="language-python"> label, likelihood_label </span><span class="hljs-con-keyword">in</span><span class="language-python"> likelihood.items():</span>
<span class="hljs-con-meta">...</span> <span class="language-python">            </span><span class="hljs-con-keyword">for</span><span class="language-python"> index, bool_value </span><span class="hljs-con-keyword">in</span><span class="language-python"> </span><span class="hljs-con-built_in">enumerate</span><span class="language-python">(x):</span>
<span class="hljs-con-meta">...</span> <span class="language-python">                posterior[label] *= likelihood_label[index] </span><span class="hljs-con-keyword">if</span>
<span class="hljs-con-meta">...</span> <span class="language-python">                  bool_value </span><span class="hljs-con-keyword">else</span><span class="language-python"> (</span><span class="hljs-con-number">1</span><span class="language-python"> - likelihood_label[index])</span>
<span class="hljs-con-meta">...</span> <span class="language-python">        </span><span class="hljs-con-comment"># normalize so that all sums up to 1</span>
<span class="hljs-con-meta">...</span> <span class="language-python">        sum_posterior = </span><span class="hljs-con-built_in">sum</span><span class="language-python">(posterior.values())</span>
<span class="hljs-con-meta">...</span> <span class="language-python">        </span><span class="hljs-con-keyword">for</span><span class="language-python"> label </span><span class="hljs-con-keyword">in</span><span class="language-python"> posterior:</span>
<span class="hljs-con-meta">...</span> <span class="language-python">            </span><span class="hljs-con-keyword">if</span><span class="language-python"> posterior[label] == </span><span class="hljs-con-built_in">float</span><span class="language-python">(</span><span class="hljs-con-string">'</span><span class="hljs-con-string">inf'</span><span class="language-python">):</span>
<span class="hljs-con-meta">...</span> <span class="language-python">                posterior[label] = </span><span class="hljs-con-number">1.0</span>
<span class="hljs-con-meta">...</span> <span class="language-python">            </span><span class="hljs-con-keyword">else</span><span class="language-python">:</span>
<span class="hljs-con-meta">...</span> <span class="language-python">                posterior[label] /= sum_posterior</span>
<span class="hljs-con-meta">...</span> <span class="language-python">        posteriors.append(posterior.copy())</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    </span><span class="hljs-con-keyword">return</span><span class="language-python"> posteriors</span>
</code></pre>
    <p class="normal">Now, let’s predict the class of our one sample test set using this prediction function:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">posterior = get_posterior(X_test, prior, likelihood)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-built_in">print</span><span class="language-python">(</span><span class="hljs-con-string">'Posterior:\n'</span><span class="language-python">, posterior)</span>
Posterior:
 [{'Y': 0.9210360075805433, 'N': 0.07896399241945673}]
</code></pre>
    <p class="normal">This is exactly what we got<a id="_idIndexMarker228"/> previously. We have successfully developed Naïve Bayes from scratch and we can now move on to the implementation using <code class="inlineCode">scikit-learn</code>.</p>
    <h2 class="heading-2" id="_idParaDest-69">Implementing Naïve Bayes with scikit-learn</h2>
    <p class="normal">Coding from scratch and implementing<a id="_idIndexMarker229"/> your own solutions is the best way<a id="_idIndexMarker230"/> to learn about machine learning models. Of course, you can take a shortcut by directly<a id="_idIndexMarker231"/> using the <code class="inlineCode">BernoulliNB</code> module (<a href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html"><span class="url">https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html</span></a>) from the scikit-learn API:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">from</span><span class="language-python"> sklearn.naive_bayes </span><span class="hljs-con-keyword">import</span><span class="language-python"> BernoulliNB</span>
</code></pre>
    <p class="normal">Let’s initialize a model with a smoothing factor (specified as <code class="inlineCode">alpha</code> in <code class="inlineCode">scikit-learn</code>) of <code class="inlineCode">1.0</code>, and <code class="inlineCode">prior</code> learned from the training set (specified as <code class="inlineCode">fit_prior=True</code> in <code class="inlineCode">scikit-learn</code>):</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">clf = BernoulliNB(alpha=</span><span class="hljs-con-number">1.0</span><span class="language-python">, fit_prior=</span><span class="hljs-con-literal">True</span><span class="language-python">)</span>
</code></pre>
    <p class="normal">To train the Naïve Bayes classifier with the <code class="inlineCode">fit</code> method, we use the following line of code:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">clf.fit(X_train, Y_train)</span>
</code></pre>
    <p class="normal">To obtain the predicted probability results with the <code class="inlineCode">predict_proba</code> method, we use the following lines of code:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">pred_prob = clf.predict_proba(X_test)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-built_in">print</span><span class="language-python">(</span><span class="hljs-con-string">'[scikit-learn] Predicted probabilities:\n'</span><span class="language-python">, pred_prob)</span>
[scikit-learn] Predicted probabilities:
 [[0.07896399 0.92103601]]
</code></pre>
    <p class="normal">Finally, we do the following to directly acquire the predicted class with the <code class="inlineCode">predict</code> method (0.5 is the default threshold, and if the predicted probability of class <code class="inlineCode">Y</code> is greater than 0.5, class <code class="inlineCode">Y</code> is assigned; otherwise, <code class="inlineCode">N</code> is used):</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">pred = clf.predict(X_test)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-built_in">print</span><span class="language-python">(</span><span class="hljs-con-string">'[scikit-learn] Prediction:'</span><span class="language-python">, pred)</span>
[scikit-learn] Prediction: ['Y']
</code></pre>
    <p class="normal">The prediction results using scikit-learn<a id="_idIndexMarker232"/> are consistent with what we got using<a id="_idIndexMarker233"/> our own solution. Now that we’ve implemented the algorithm both from scratch and using <code class="inlineCode">scikit-learn</code>, why don’t we use it to solve the movie recommendation problem?</p>
    <h1 class="heading-1" id="_idParaDest-70">Building a movie recommender with Naïve Bayes</h1>
    <p class="normal">After the toy example, it is now time to build a movie<a id="_idIndexMarker234"/> recommender (or, more specifically, movie preference classifier) using a real dataset. We herein<a id="_idIndexMarker235"/> use a movie rating dataset (<a href="https://grouplens.org/datasets/movielens/"><span class="url">https://grouplens.org/datasets/movielens/</span></a>). The movie rating data was collected by the GroupLens Research group from the MovieLens website (<a href="http://movielens.org"><span class="url">http://movielens.org</span></a>).</p>
    <p class="normal">For demonstration purposes, we will use the stable small dataset, MovieLens 1M Dataset (which can be downloaded from <a href="https://files.grouplens.org/datasets/movielens/ml-1m.zip"><span class="url">https://files.grouplens.org/datasets/movielens/ml-1m.zip</span></a> or <a href="https://grouplens.org/datasets/movielens/1m/"><span class="url">https://grouplens.org/datasets/movielens/1m/</span></a>) for <code class="inlineCode">ml-1m.zip</code> (size: 1 MB) file). It has around 1 million ratings, ranging from 1 to 5 with half-star increments, given by 6,040 users on 3,706 movies (last updated September 2018).</p>
    <p class="normal">Unzip the <code class="inlineCode">ml-1m.zip</code> file and you will see the following four files:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">movies.dat</code>: It contains the movie information in the format of <code class="inlineCode">MovieID::Title::Genres</code>.</li>
      <li class="bulletList"><code class="inlineCode">ratings.dat</code>: It contains user movie ratings in the format of <code class="inlineCode">UserID::MovieID::Rating::Timestamp</code>. We will only be using data from this file in this chapter.</li>
      <li class="bulletList"><code class="inlineCode">users.dat</code>: It contains user information in the format of <code class="inlineCode">UserID::Gender::Age::Occupation::Zip-code</code>.</li>
      <li class="bulletList"><code class="inlineCode">README</code></li>
    </ul>
    <p class="normal">Let’s attempt to predict whether a user likes a particular movie<a id="_idIndexMarker236"/> based on how they rate other movies (again, ratings are from 1 to 5).</p>
    <h2 class="heading-2" id="_idParaDest-71">Preparing the data</h2>
    <p class="normal">First, we import all the necessary<a id="_idIndexMarker237"/> modules and read the <code class="inlineCode">ratings.dat</code> into a <code class="inlineCode">pandas</code> DataFrame object:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">import</span><span class="language-python"> numpy </span><span class="hljs-con-keyword">as</span><span class="language-python"> np</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">import</span><span class="language-python"> pandas </span><span class="hljs-con-keyword">as</span><span class="language-python"> pd</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">data_path = </span><span class="hljs-con-string">'ml-1m/ratings.dat'</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">df = pd.read_csv(data_path, header=</span><span class="hljs-con-literal">None</span><span class="language-python">, sep=</span><span class="hljs-con-string">'::'</span><span class="language-python">, engine=</span><span class="hljs-con-string">'python'</span><span class="language-python">)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">df.columns = [</span><span class="hljs-con-string">'user_id'</span><span class="language-python">, </span><span class="hljs-con-string">'movie_id'</span><span class="language-python">, </span><span class="hljs-con-string">'rating'</span><span class="language-python">, </span><span class="hljs-con-string">'timestamp'</span><span class="language-python">]</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-built_in">print</span><span class="language-python">(df)</span>
         user_id  movie_id  rating  timestamp
0              1      1193       5  978300760
1              1       661       3  978302109
2              1       914       3  978301968
3              1      3408       4  978300275
4              1      2355       5  978824291
<span class="hljs-con-meta">...</span> <span class="language-python">         ...       ...     ...        ...</span>
1000204     6040      1091       1  956716541
1000205     6040      1094       5  956704887
1000206     6040       562       5  956704746
1000207     6040      1096       4  956715648
1000208     6040      1097       4  956715569
[1000209 rows x 4 columns]
</code></pre>
    <p class="normal">Now, let’s see how many unique users and movies are in this million-row dataset:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">n_users = df[</span><span class="hljs-con-string">'user_id'</span><span class="language-python">].nunique()</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">n_movies = df[</span><span class="hljs-con-string">'movie_id'</span><span class="language-python">].nunique()</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-built_in">print</span><span class="language-python">(</span><span class="hljs-con-string">f"Number of users: </span><span class="hljs-con-subst">{n_users}</span><span class="hljs-con-string">"</span><span class="language-python">)</span>
Number of users: 6040
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-built_in">print</span><span class="language-python">(</span><span class="hljs-con-string">f"Number of movies: </span><span class="hljs-con-subst">{n_movies}</span><span class="hljs-con-string">"</span><span class="language-python">)</span>
Number of movies: 3706
</code></pre>
    <p class="normal">Next, we will construct a 6,040 (the number of users) by 3,706 (the number of movies) matrix where each row contains movie ratings from a user, and each column represents a movie, using the following function:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">def</span><span class="language-python"> </span><span class="hljs-con-title">load_user_rating_data</span><span class="language-python">(</span><span class="hljs-con-params">df, n_users, n_movies</span><span class="language-python">):</span>
<span class="hljs-con-meta">...</span> <span class="language-python">   data = np.zeros([n_users, n_movies], dtype=np.intc)</span>
              movie_id_mapping = {}
              for user_id, movie_id, rating in zip(df['user_id'], df['movie_id'], df['rating']):
                    user_id = int(user_id) - 1
                    if movie_id not in movie_id_mapping:
                         movie_id_mapping[movie_id] = len(movie_id_mapping)
                   data[user_id, movie_id_mapping[movie_id]] = rating
              return data, movie_id_mapping
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">data, movie_id_mapping = load_user_rating_data(df, n_users, n_movies)</span>
</code></pre>
    <p class="normal">Besides the rating matrix <code class="inlineCode">data</code>, we also<a id="_idIndexMarker238"/> record the <code class="inlineCode">movie ID</code> to column index mapping. The column index is from 0 to 3,705 as we have 3,706 movies.</p>
    <p class="normal">It is always recommended to analyze the data distribution in order to identify if there is a class imbalance issue in the dataset. We do the following:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">values, counts = np.unique(data, return_counts=</span><span class="hljs-con-literal">True</span><span class="language-python">)</span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-keyword">for</span><span class="language-python"> value, count </span><span class="hljs-con-keyword">in</span><span class="language-python"> </span><span class="hljs-con-built_in">zip</span><span class="language-python">(values, counts):</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    </span><span class="hljs-con-built_in">print</span><span class="language-python">(</span><span class="hljs-con-string">f'Number of rating </span><span class="hljs-con-subst">{value}</span><span class="hljs-con-string">: </span><span class="hljs-con-subst">{count}</span><span class="hljs-con-string">'</span><span class="language-python">)</span>
Number of rating 0: 21384031
Number of rating 1: 56174
Number of rating 2: 107557
Number of rating 3: 261197
Number of rating 4: 348971
Number of rating 5: 226310
</code></pre>
    <p class="normal">As you can see, most ratings are unknown; for the known ones, 35% are of rating 4, followed by 26% of rating 3, 23% of rating 5, and then 11% and 6% of ratings 2 and 1, respectively.</p>
    <p class="normal">Since most ratings are unknown, we take the movie with the most known ratings as our target movie for easier prediction validation. We look for rating counts for each movie as follows:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-built_in">print</span><span class="language-python">(df[</span><span class="hljs-con-string">'movie_id'</span><span class="language-python">].value_counts())</span>
2858    3428
260     2991
1196    2990
1210    2883
480     2672
        ...
3458       1
2226       1
1815       1
398        1
2909       1
Name: movie_id, Length: 3706, dtype: int64
</code></pre>
    <p class="normal">So, the target movie is ID, and we will treat ratings<a id="_idIndexMarker239"/> of other movies as features. We only use rows with ratings available for the target movie so we can validate how good the prediction is. We construct the dataset accordingly as follows:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">target_movie_id = </span><span class="hljs-con-number">2858</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">X_raw = np.delete(data, movie_id_mapping[target_movie_id], axis=</span><span class="hljs-con-number">1</span><span class="language-python">)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">Y_raw = data[:, movie_id_mapping[target_movie_id]]</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">X = X_raw[Y_raw &gt; </span><span class="hljs-con-number">0</span><span class="language-python">]</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">Y = Y_raw[Y_raw &gt; </span><span class="hljs-con-number">0</span><span class="language-python">]</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-built_in">print</span><span class="language-python">(</span><span class="hljs-con-string">'Shape of X:'</span><span class="language-python">, X.shape)</span>
Shape of X: (3428, 3705)
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-built_in">print</span><span class="language-python">(</span><span class="hljs-con-string">'Shape of Y:'</span><span class="language-python">, Y.shape)</span>
Shape of Y: (3428,)
</code></pre>
    <p class="normal">We can consider movies with ratings greater than 3 as being liked (being recommended):</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">recommend = </span><span class="hljs-con-number">3</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">Y[Y &lt;= recommend] = </span><span class="hljs-con-number">0</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">Y[Y &gt; recommend] = </span><span class="hljs-con-number">1</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">n_pos = (Y == </span><span class="hljs-con-number">1</span><span class="language-python">).</span><span class="hljs-con-built_in">sum</span><span class="language-python">()</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">n_neg = (Y == </span><span class="hljs-con-number">0</span><span class="language-python">).</span><span class="hljs-con-built_in">sum</span><span class="language-python">()</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-built_in">print</span><span class="language-python">(</span><span class="hljs-con-string">f'</span><span class="hljs-con-subst">{n_pos}</span><span class="hljs-con-string"> positive samples and </span><span class="hljs-con-subst">{n_neg}</span><span class="hljs-con-string"> negative samples.'</span><span class="language-python">)</span>
2853 positive samples and 575 negative samples.
</code></pre>
    <p class="normal">As a rule of thumb in solving classification problems, we need to always analyze the label distribution and see how balanced (or imbalanced) the dataset is.</p>
    <div class="note">
      <p class="normal"> <strong class="keyWord">Best practice</strong></p>
      <p class="normal">Dealing with imbalanced datasets in classification problems requires careful consideration and appropriate techniques to ensure that the model effectively learns from the data and produces reliable predictions. Here are several strategies to address<a id="_idIndexMarker240"/> class imbalance:</p>
      <ul>
        <li class="bulletList"><strong class="keyWord">Oversampling</strong>: We can increase the number of instances in the minority class by generating synthetic samples or duplicating existing ones.</li>
        <li class="bulletList"><strong class="keyWord">Undersampling</strong>: We can decrease the number of instances in the majority class by randomly removing samples. Note that we can even combine oversampling and undersampling for a more balanced dataset.</li>
        <li class="bulletList"><strong class="keyWord">Class weighting</strong>: We can also assign higher weights to minority class samples during model training. In this way, we penalize misclassifications of the minority class more heavily.</li>
      </ul>
    </div>
    <p class="normal">Next, to comprehensively<a id="_idIndexMarker241"/> evaluate our classifier’s performance, we can randomly split the dataset into two sets, the training and testing sets, which simulate learning data and prediction data, respectively. Generally, the proportion of the original dataset to include in the testing split can be 20%, 25%, 30%, or 33.3%.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Best practice</strong></p>
      <p class="normal">Here are some guidelines<a id="_idIndexMarker242"/> for choosing the testing split:</p>
      <ul>
        <li class="bulletList"><strong class="keyWord">Small datasets</strong>: If you have a small dataset (e.g., less than a few thousand samples), a larger testing split (e.g., 25% to 30%) may be appropriate to ensure that you have enough data for training and testing.</li>
        <li class="bulletList"><strong class="keyWord">Medium to large datasets</strong>: For medium to large datasets (e.g., tens of thousands to millions of samples), a smaller testing split (e.g., 20%) may still provide enough data for evaluation while allowing more data to be used for training. A 20% testing split is a common choice in such cases.</li>
        <li class="bulletList"><strong class="keyWord">Simple models</strong>: Less complex models are generally less prone to overfitting, so using a smaller test set split may work.</li>
        <li class="bulletList"><strong class="keyWord">Complex models</strong>: Complex models<a id="_idIndexMarker243"/> like deep learning models can be more prone to overfitting. Hence, a larger test set split (e.g., 30%) is recommended. </li>
      </ul>
    </div>
    <p class="normal">We use the <code class="inlineCode">train_test_split</code> function from <code class="inlineCode">scikit-learn</code> to do the random splitting and to preserve the percentage of samples for each class:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">from</span><span class="language-python"> sklearn.model_selection </span><span class="hljs-con-keyword">import</span><span class="language-python"> train_test_split</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">X_train, X_test, Y_train, Y_test = train_test_split(X, Y,</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    test_size=</span><span class="hljs-con-number">0.2</span><span class="language-python">, random_state=</span><span class="hljs-con-number">42</span><span class="language-python">)</span>
</code></pre>
    <div class="note">
      <p class="normal">It is a good practice to assign a fixed <code class="inlineCode">random_state</code> (for example, <code class="inlineCode">42</code>) during experiments and exploration in order to guarantee that the same training and testing sets are generated every time the program runs. This allows us to make sure that the classifier functions and performs well on a fixed dataset before we incorporate randomness and proceed further.</p>
    </div>
    <p class="normal">We check the training and testing sizes as follows:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-built_in">print</span><span class="language-python">(</span><span class="hljs-con-built_in">len</span><span class="language-python">(Y_train), </span><span class="hljs-con-built_in">len</span><span class="language-python">(Y_test))</span>
2742 686
</code></pre>
    <p class="normal">Another good thing<a id="_idIndexMarker244"/> about the <code class="inlineCode">train_test_split</code> function is that the resulting training and testing sets will have the same class ratio.</p>
    <h2 class="heading-2" id="_idParaDest-72">Training a Naïve Bayes model</h2>
    <p class="normal">Next, we train a Naïve Bayes model<a id="_idIndexMarker245"/> on the training set. You may notice that the values of the input features are from 0 to 5, as opposed to 0 or 1 in our toy example. Hence, we<a id="_idIndexMarker246"/> use the <code class="inlineCode">MultinomialNB</code> module (<a href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"><span class="url">https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html</span></a>) from scikit-learn instead of the <code class="inlineCode">BernoulliNB</code> module, as <code class="inlineCode">MultinomialNB</code> can work with integer features as well as fractional counts. We import the module, initialize a model with a smoothing factor of <code class="inlineCode">1.0</code> and <code class="inlineCode">prior</code> learned from the training set, and train this model against the training set as follows:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">from</span><span class="language-python"> sklearn.naive_bayes </span><span class="hljs-con-keyword">import</span><span class="language-python"> MultinomialNB</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">clf = MultinomialNB(alpha=</span><span class="hljs-con-number">1.0</span><span class="language-python">, fit_prior=</span><span class="hljs-con-literal">True</span><span class="language-python">)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">clf.fit(X_train, Y_train)</span>
</code></pre>
    <p class="normal">Then, we use the trained model<a id="_idIndexMarker247"/> to make predictions on the testing set. We get the predicted probabilities as follows:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">prediction_prob = clf.predict_proba(X_test)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-built_in">print</span><span class="language-python">(prediction_prob[</span><span class="hljs-con-number">0</span><span class="language-python">:</span><span class="hljs-con-number">10</span><span class="language-python">])</span>
[[7.50487439e-23 1.00000000e+00]
 [1.01806208e-01 8.98193792e-01]
 [3.57740570e-10 1.00000000e+00]
 [1.00000000e+00 2.94095407e-16]
 [1.00000000e+00 2.49760836e-25]
 [7.62630220e-01 2.37369780e-01]
 [3.47479627e-05 9.99965252e-01]
 [2.66075292e-11 1.00000000e+00]
 [5.88493563e-10 9.99999999e-01]
 [9.71326867e-09 9.99999990e-01]]
</code></pre>
    <p class="normal">For each testing sample, we output the probability of class 0, followed by the probability of class 1.</p>
    <p class="normal">We get the predicted class for the test set as follows:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">prediction = clf.predict(X_test)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-built_in">print</span><span class="language-python">(prediction[:</span><span class="hljs-con-number">10</span><span class="language-python">])</span>
[[1. 1. 1. 0. 0. 0. 1. 1. 1. 1.]
</code></pre>
    <p class="normal">Finally, we evaluate the model’s performance with classification accuracy, which is the proportion of correct predictions:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">accuracy = clf.score(X_test, Y_test)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-built_in">print</span><span class="language-python">(</span><span class="hljs-con-string">f'The accuracy is: </span><span class="hljs-con-subst">{accuracy*</span><span class="hljs-con-number">100</span><span class="hljs-con-subst">:</span><span class="hljs-con-number">.1</span><span class="hljs-con-subst">f}</span><span class="hljs-con-string">%'</span><span class="language-python">)</span>
The accuracy is: 71.6%
</code></pre>
    <p class="normal">The classification accuracy is around 72%, which means that the Naïve Bayes classifier we’ve constructed accurately suggests movies to users about three quarters of the time. Ideally, we could also utilize movie genre information from the <code class="inlineCode">movies.dat</code> file, and user demographics (gender, age, occupation, and ZIP code) information from the <code class="inlineCode">users.dat</code> file. Obviously, movies in similar genres tend to attract similar users, and users of similar demographics likely have similar movie preferences. We will leave it as an exercise for you to explore further.</p>
    <p class="normal">So far, we have covered in depth the first machine learning<a id="_idIndexMarker248"/> classifier and evaluated its performance by prediction accuracy. Are there any other classification metrics? Let’s see in the next section.</p>
    <h1 class="heading-1" id="_idParaDest-73">Evaluating classification performance</h1>
    <p class="normal">Beyond accuracy, there are several metrics<a id="_idIndexMarker249"/> we can use to gain more insight and avoid class imbalance effects. These are as follows:</p>
    <ul>
      <li class="bulletList">Confusion matrix</li>
      <li class="bulletList">Precision</li>
      <li class="bulletList">Recall</li>
      <li class="bulletList">F1 score</li>
      <li class="bulletList">The area under the curve</li>
    </ul>
    <p class="normal">A <strong class="keyWord">confusion matrix</strong> summarizes testing instances by their predicted values and true values, presented as a contingency table:</p>
    <figure class="mediaobject"><img alt="A picture containing text, screenshot, font, number  Description automatically generated" src="../Images/B21047_02_08.png"/></figure>
    <p class="packt_figref">Figure 2.8: Contingency table for a confusion matrix</p>
    <p class="normal">To illustrate this, we can compute the confusion matrix of our Naïve Bayes classifier. We use the <code class="inlineCode">confusion_matrix</code> function from <code class="inlineCode">scikit-learn</code> to compute it, but it is very easy to code it ourselves:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">from</span><span class="language-python"> sklearn.metrics </span><span class="hljs-con-keyword">import</span><span class="language-python"> confusion_matrix</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-built_in">print</span><span class="language-python">(confusion_matrix(Y_test, prediction, labels=[</span><span class="hljs-con-number">0</span><span class="language-python">, </span><span class="hljs-con-number">1</span><span class="language-python">]))</span>
[[ 60  47]
 [148 431]]
</code></pre>
    <p class="normal">As you can see from the resulting confusion<a id="_idIndexMarker250"/> matrix, there are 47 false positive cases (where the model misinterprets a dislike as a like for a movie), and 148 false negative cases (where it fails to detect a like for a movie). Hence, classification accuracy is just the proportion of all true cases:</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_030.png"/></p>
    <p class="normal"><strong class="keyWord">Precision</strong> measures the fraction of positive calls that are correct, which are the following, in our case:</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_031.png"/></p>
    <p class="normal"><strong class="keyWord">Recall</strong>, on the other hand, measures the fraction of true positives that are correctly identified, which are the following in our case:</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_032.png"/></p>
    <p class="normal">Recall<a id="_idIndexMarker251"/> is also called the <strong class="keyWord">true positive rate</strong>.</p>
    <p class="normal">The <strong class="keyWord">f1 score</strong> comprehensively includes<a id="_idIndexMarker252"/> both the precision<a id="_idIndexMarker253"/> and the recall and equates to their <strong class="keyWord">harmonic mean</strong>:</p>
    <p class="center"><img alt="" role="presentation" src="../Images/B21047_02_033.png"/></p>
    <p class="normal">We tend to value the <strong class="keyWord">f1</strong> score above precision or recall alone.</p>
    <p class="normal">Let’s compute these three measurements using corresponding functions from <code class="inlineCode">scikit-learn</code>, as follows:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">from</span><span class="language-python"> sklearn.metrics </span><span class="hljs-con-keyword">import</span><span class="language-python"> precision_score, recall_score, f1_score</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">precision_score(Y_test, prediction, pos_label=</span><span class="hljs-con-number">1</span><span class="language-python">)</span>
0.9016736401673641
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">recall_score(Y_test, prediction, pos_label=</span><span class="hljs-con-number">1</span><span class="language-python">)</span>
0.7443868739205527
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">f1_score(Y_test, prediction, pos_label=</span><span class="hljs-con-number">1</span><span class="language-python">)</span>
0.815515610217597
</code></pre>
    <p class="normal">On the other hand, the negative (dislike) class can also be viewed as positive, depending on the context. For example, assign the <code class="inlineCode">0</code> class as <code class="inlineCode">pos_label</code> and we have the following:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">f1_score(Y_test, prediction, pos_label=</span><span class="hljs-con-number">0</span><span class="language-python">)</span>
0.38095238095238093
</code></pre>
    <p class="normal">To obtain the precision, recall, and f1 score for each class, instead of exhausting all class labels in the three function calls as shown earlier, a quicker way is to call the <code class="inlineCode">classification_report</code> function:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">from</span><span class="language-python"> sklearn.metrics </span><span class="hljs-con-keyword">import</span><span class="language-python"> classification_report</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">report = classification_report(Y_test, prediction)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-built_in">print</span><span class="language-python">(report)</span>
              precision    recall  f1-score   support
         0.0       0.29      0.56      0.38       107
         1.0       0.90      0.74      0.82       579
   micro avg       0.72      0.72      0.72       686
   macro avg       0.60      0.65      0.60       686
weighted avg       0.81      0.72      0.75       686
</code></pre>
    <p class="normal">Here, <code class="inlineCode">weighted avg</code> is the weighted average according to the proportions of the class.</p>
    <p class="normal">The classification report provides<a id="_idIndexMarker254"/> a comprehensive view of how the classifier performs on each class. It is, as a result, useful in imbalanced classification, where we can easily obtain high accuracy by simply classifying every sample as the dominant class, while the precision, recall, and f1 score measurements for the minority class, however, will be significantly low.</p>
    <p class="normal">Precision, recall, and the f1 score are also applicable to <strong class="keyWord">multiclass</strong> classification, where we can simply treat a class we are interested in as a positive case, and any other classes as negative cases.</p>
    <p class="normal">During the process of tweaking a binary classifier (that is, trying out different combinations of hyperparameters, for example, the smoothing factor in our Naïve Bayes classifier), it would be perfect if there was a set of parameters in which the highest averaged and class individual f1 scores are achieved at the same time. It is, however, usually not the case. Sometimes, a model has a higher average f1 score than another model, but a significantly low f1 score for a particular class; sometimes, two models have the same average f1 scores, but one has a higher f1 score for one class and a lower score for another class. In situations<a id="_idIndexMarker255"/> such as these, how can we judge which model works better? The <strong class="keyWord">Area Under the Curve </strong>(<strong class="keyWord">AUC</strong>) of the <strong class="keyWord">Receiver Operating Characteristic</strong> (<strong class="keyWord">ROC</strong>) is a consolidated measurement frequently<a id="_idIndexMarker256"/> used in binary classification.</p>
    <p class="normal">The ROC curve is a plot<a id="_idIndexMarker257"/> of the true positive rate versus the false positive rate at various probability thresholds, ranging from 0 to 1. For a testing sample, if the probability of a positive class is greater than the threshold, then a positive class is assigned; otherwise, we use a negative class. To recap, the true positive rate is equivalent to recall, and the false positive rate is the fraction of negatives that are incorrectly identified as positive. Let’s code and exhibit the ROC curve (under thresholds of <code class="inlineCode">0.0</code>, <code class="inlineCode">0.1</code>, <code class="inlineCode">0.2</code>, …, <code class="inlineCode">1.0</code>) of our model:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">pos_prob = prediction_prob[:, </span><span class="hljs-con-number">1</span><span class="language-python">]</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">thresholds = np.arange(</span><span class="hljs-con-number">0.0</span><span class="language-python">, </span><span class="hljs-con-number">1.1</span><span class="language-python">, </span><span class="hljs-con-number">0.05</span><span class="language-python">)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">true_pos, false_pos = [</span><span class="hljs-con-number">0</span><span class="language-python">]*</span><span class="hljs-con-built_in">len</span><span class="language-python">(thresholds), [</span><span class="hljs-con-number">0</span><span class="language-python">]*</span><span class="hljs-con-built_in">len</span><span class="language-python">(thresholds)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">for</span><span class="language-python"> pred, y </span><span class="hljs-con-keyword">in</span><span class="language-python"> </span><span class="hljs-con-built_in">zip</span><span class="language-python">(pos_prob, Y_test):</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    </span><span class="hljs-con-keyword">for</span><span class="language-python"> i, threshold </span><span class="hljs-con-keyword">in</span><span class="language-python"> </span><span class="hljs-con-built_in">enumerate</span><span class="language-python">(thresholds):</span>
<span class="hljs-con-meta">...</span> <span class="language-python">        </span><span class="hljs-con-keyword">if</span><span class="language-python"> pred &gt;= threshold:</span>
<span class="hljs-con-meta">...</span> <span class="language-python">           </span><span class="hljs-con-comment"># if truth and prediction are both 1</span>
<span class="hljs-con-meta">...</span> <span class="language-python">            </span><span class="hljs-con-keyword">if</span><span class="language-python"> y == </span><span class="hljs-con-number">1</span><span class="language-python">:</span>
<span class="hljs-con-meta">...</span> <span class="language-python">                true_pos[i] += </span><span class="hljs-con-number">1</span>
<span class="hljs-con-meta">...</span> <span class="language-python">           </span><span class="hljs-con-comment"># if truth is 0 while prediction is 1</span>
<span class="hljs-con-meta">...</span> <span class="language-python">            </span><span class="hljs-con-keyword">else</span><span class="language-python">:</span>
<span class="hljs-con-meta">...</span> <span class="language-python">                false_pos[i] += </span><span class="hljs-con-number">1</span>
<span class="hljs-con-meta">...</span> <span class="language-python">        </span><span class="hljs-con-keyword">else</span><span class="language-python">:</span>
<span class="hljs-con-meta">...</span> <span class="language-python">            </span><span class="hljs-con-keyword">break</span>
</code></pre>
    <p class="normal">Then, let’s calculate the true and false positive rates for all threshold settings (remember, there are <code class="inlineCode">516.0</code> positive testing samples and <code class="inlineCode">1191</code> negative ones):</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">n_pos_test = (Y_test == </span><span class="hljs-con-number">1</span><span class="language-python">).</span><span class="hljs-con-built_in">sum</span><span class="language-python">()</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">n_neg_test = (Y_test == </span><span class="hljs-con-number">0</span><span class="language-python">).</span><span class="hljs-con-built_in">sum</span><span class="language-python">()</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">true_pos_rate = [tp / n_pos_test </span><span class="hljs-con-keyword">for</span><span class="language-python"> tp </span><span class="hljs-con-keyword">in</span><span class="language-python"> true_pos]</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">false_pos_rate = [fp / n_neg_test </span><span class="hljs-con-keyword">for</span><span class="language-python"> fp </span><span class="hljs-con-keyword">in</span><span class="language-python"> false_pos]</span>
</code></pre>
    <p class="normal">Now, we can plot the ROC curve with <code class="inlineCode">matplotlib</code>:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">import</span><span class="language-python"> matplotlib.pyplot </span><span class="hljs-con-keyword">as</span><span class="language-python"> plt</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">plt.figure()</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">lw = </span><span class="hljs-con-number">2</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">plt.plot(false_pos_rate, true_pos_rate,</span>
<span class="hljs-con-meta">...</span> <span class="language-python">         color=</span><span class="hljs-con-string">'darkorange'</span><span class="language-python">, lw=lw)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">plt.plot([</span><span class="hljs-con-number">0</span><span class="language-python">, </span><span class="hljs-con-number">1</span><span class="language-python">], [</span><span class="hljs-con-number">0</span><span class="language-python">, </span><span class="hljs-con-number">1</span><span class="language-python">], color=</span><span class="hljs-con-string">'navy'</span><span class="language-python">, lw=lw, linestyle=</span><span class="hljs-con-string">'--'</span><span class="language-python">)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">plt.xlim([</span><span class="hljs-con-number">0.0</span><span class="language-python">, </span><span class="hljs-con-number">1.0</span><span class="language-python">])</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">plt.ylim([</span><span class="hljs-con-number">0.0</span><span class="language-python">, </span><span class="hljs-con-number">1.05</span><span class="language-python">])</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">plt.xlabel(</span><span class="hljs-con-string">'False Positive Rate'</span><span class="language-python">)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">plt.ylabel(</span><span class="hljs-con-string">'True Positive Rate'</span><span class="language-python">)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">plt.title(</span><span class="hljs-con-string">'</span><span class="hljs-con-string">Receiver Operating Characteristic'</span><span class="language-python">)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">plt.legend(loc=</span><span class="hljs-con-string">"lower right"</span><span class="language-python">)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">plt.show()</span>
</code></pre>
    <p class="normal">Refer to <em class="italic">Figure 2.9</em> for the resulting<a id="_idIndexMarker258"/> ROC curve:</p>
    <figure class="mediaobject"><img alt="A picture containing text, line, plot, screenshot  Description automatically generated" src="../Images/B21047_02_09.png"/></figure>
    <p class="packt_figref">Figure 2.9: ROC curve</p>
    <p class="normal">In the graph, the dashed<a id="_idIndexMarker259"/> line is the baseline representing random guessing, where the true positive rate increases linearly with the false positive rate; its AUC is 0.5. The solid line is the ROC plot of our model, and its AUC is somewhat less than 1. In a perfect case, the true positive samples have a probability of 1, so that the ROC starts at the point with 100% true positive and 0% false positive. The AUC of such a perfect curve is 1. To compute the exact AUC of our model, we can resort to the <code class="inlineCode">roc_auc_score</code> function of <code class="inlineCode">scikit-learn</code>:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">from</span><span class="language-python"> sklearn.metrics </span><span class="hljs-con-keyword">import</span><span class="language-python"> roc_auc_score</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">roc_auc_score(Y_test, pos_prob)</span>
0.6857375752586637
</code></pre>
    <div class="note">
      <p class="normal">What AUC value leads to the conclusion that a classifier is good? Unfortunately, there is no such “magic” number. We use the following rule of thumb as general guidelines: classification models achieving an AUC of <code class="inlineCode">0.7</code> to <code class="inlineCode">0.8</code> are considered acceptable, <code class="inlineCode">0.8</code> to <code class="inlineCode">0.9</code> are great, and anything above <code class="inlineCode">0.9</code> are superb. Again, in our case, we are only using the very sparse movie rating data. Hence, an AUC of <code class="inlineCode">0.69</code> is actually acceptable.</p>
    </div>
    <p class="normal">You have learned several classification metrics, and we will explore how to measure them properly and how to fine-tune our models in the next section.</p>
    <h1 class="heading-1" id="_idParaDest-74">Tuning models with cross-validation</h1>
    <p class="normal">Limiting the evaluation<a id="_idIndexMarker260"/> to a single fixed set may be misleading since it’s highly dependent<a id="_idIndexMarker261"/> on the specific data points chosen for that set. We can simply avoid adopting the classification results from one fixed testing set, which we did in experiments previously. Instead, we usually apply the <strong class="keyWord">k-fold cross-validation</strong> technique to assess how a model<a id="_idIndexMarker262"/> will generally perform in practice.</p>
    <p class="normal">In the <em class="italic">k</em>-fold cross-validation setting, the original data is first randomly divided into <em class="italic">k</em> equal-sized subsets, in which class proportion is often preserved. Each of these <em class="italic">k</em> subsets is then successively retained as the testing set for evaluating the model. During each trial, the rest of the <em class="italic">k</em> -1 subsets (excluding the one-fold holdout) form the training set for driving the model. Finally, the average performance across all <em class="italic">k</em> trials is calculated to generate an overall result:</p>
    <figure class="mediaobject"><img alt="" role="presentation" src="../Images/B21047_02_10.png"/></figure>
    <p class="packt_figref">Figure 2.10: Diagram of 3-fold cross-validation</p>
    <p class="normal">Statistically, the average<a id="_idIndexMarker263"/> performance of <em class="italic">k</em>-fold cross-validation is a better estimate<a id="_idIndexMarker264"/> of how a model performs in general. Given different sets of parameters pertaining to a machine learning model and/or data preprocessing algorithms, or even two or more different models, the goal of model tuning and/or model selection is to pick a set of parameters of a classifier so that the best average performance is achieved. With these concepts in mind, we can now start to tweak our Naïve Bayes classifier, incorporating cross-validation and the AUC of ROC measurements.</p>
    <div class="packt_tip">
      <p class="normal">In <em class="italic">k</em>-fold cross-validation, <em class="italic">k</em> is usually<a id="_idIndexMarker265"/> set at 3, 5, or 10. If the training size is small, a large <em class="italic">k</em> (5 or 10) is recommended to ensure sufficient training samples in each fold. If the training size is large, a small value (such as 3 or 4) works fine since a higher <em class="italic">k</em> will lead to an even higher computational cost of training on a large dataset.</p>
    </div>
    <p class="normal">We will use the <code class="inlineCode">split()</code> method from the <code class="inlineCode">StratifiedKFold</code> class of <code class="inlineCode">scikit-learn</code> to divide the data into chunks with preserved class distribution:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">from</span><span class="language-python"> sklearn.model_selection </span><span class="hljs-con-keyword">import</span><span class="language-python"> StratifiedKFold</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">k = </span><span class="hljs-con-number">5</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">k_fold = StratifiedKFold(n_splits=k, random_state=</span><span class="hljs-con-number">42</span><span class="language-python">)</span>
</code></pre>
    <p class="normal">After initializing a 5-fold generator, we choose to explore the following values for the following parameters:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">alpha</code>: This represents the smoothing factor, the initial value for each feature</li>
      <li class="bulletList"><code class="inlineCode">fit_prior</code>: This represents whether to use prior tailored to the training data</li>
    </ul>
    <p class="normal">We start with the following options:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">smoothing_factor_option = [</span><span class="hljs-con-number">1</span><span class="language-python">, </span><span class="hljs-con-number">2</span><span class="language-python">, </span><span class="hljs-con-number">3</span><span class="language-python">, </span><span class="hljs-con-number">4</span><span class="language-python">, </span><span class="hljs-con-number">5</span><span class="language-python">, </span><span class="hljs-con-number">6</span><span class="language-python">]</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">fit_prior_option = [</span><span class="hljs-con-literal">True</span><span class="language-python">, </span><span class="hljs-con-literal">False</span><span class="language-python">]</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">auc_record = {}</span>
</code></pre>
    <p class="normal">Then, for each fold generated<a id="_idIndexMarker266"/> by the <code class="inlineCode">split()</code> method of the <code class="inlineCode">k_fold</code> object, we repeat<a id="_idIndexMarker267"/> the process of classifier initialization, training, and prediction with one of the aforementioned combinations of parameters, and record the resulting AUCs:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">for</span><span class="language-python"> train_indices, test_indices </span><span class="hljs-con-keyword">in</span><span class="language-python"> k_fold.split(X, Y):</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    X_train_k, X_test _k= X[train_indices], X[test_indices]</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    Y_train_k, Y_test_k = Y[train_indices], Y[test_indices]</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    </span><span class="hljs-con-keyword">for</span><span class="language-python"> alpha </span><span class="hljs-con-keyword">in</span><span class="language-python"> smoothing_factor_option:</span>
<span class="hljs-con-meta">...</span> <span class="language-python">        </span><span class="hljs-con-keyword">if</span><span class="language-python"> alpha </span><span class="hljs-con-keyword">not</span><span class="language-python"> </span><span class="hljs-con-keyword">in</span><span class="language-python"> auc_record:</span>
<span class="hljs-con-meta">...</span> <span class="language-python">            auc_record[alpha] = {}</span>
<span class="hljs-con-meta">...</span> <span class="language-python">        </span><span class="hljs-con-keyword">for</span><span class="language-python"> fit_prior </span><span class="hljs-con-keyword">in</span><span class="language-python"> fit_prior_option:</span>
<span class="hljs-con-meta">...</span> <span class="language-python">            clf = MultinomialNB(alpha=alpha,</span>
<span class="hljs-con-meta">...</span> <span class="language-python">                                fit_prior=fit_prior)</span>
<span class="hljs-con-meta">...</span> <span class="language-python">            clf.fit(X_train_k, Y_train_k)</span>
<span class="hljs-con-meta">...</span> <span class="language-python">            prediction_prob = clf.predict_proba(X_test_k)</span>
<span class="hljs-con-meta">...</span> <span class="language-python">            pos_prob = prediction_prob[:, </span><span class="hljs-con-number">1</span><span class="language-python">]</span>
<span class="hljs-con-meta">...</span> <span class="language-python">            auc = roc_auc_score(Y_test_k, pos_prob)</span>
<span class="hljs-con-meta">...</span> <span class="language-python">            auc_record[alpha][fit_prior] = auc +</span>
<span class="hljs-con-meta">...</span> <span class="language-python">                       auc_record[alpha].get(fit_prior, </span><span class="hljs-con-number">0.0</span><span class="language-python">)</span>
</code></pre>
    <p class="normal">Finally, we present the results as follows:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-keyword">for</span><span class="language-python"> smoothing, smoothing_record </span><span class="hljs-con-keyword">in</span><span class="language-python"> auc_record.items():</span>
<span class="hljs-con-meta">...</span> <span class="language-python">    </span><span class="hljs-con-keyword">for</span><span class="language-python"> fit_prior, auc </span><span class="hljs-con-keyword">in</span><span class="language-python"> smoothing_record.items():</span>
<span class="hljs-con-meta">...</span> <span class="language-python">        </span><span class="hljs-con-built_in">print</span><span class="language-python">(</span><span class="hljs-con-string">f'    </span><span class="hljs-con-subst">{smoothing}</span><span class="hljs-con-string">        </span><span class="hljs-con-subst">{fit_prior}</span><span class="hljs-con-string">  </span>
<span class="hljs-con-meta">...</span> <span class="hljs-con-string">              </span><span class="hljs-con-subst">{auc/k:</span><span class="hljs-con-number">.5</span><span class="hljs-con-subst">f}</span><span class="hljs-con-string">'</span><span class="language-python">)</span>
smoothing  fit prior  auc
    1        True    0.65647
    1        False    0.65708
    2        True    0.65795
    2        False    0.65823
    3        True    0.65740
    3        False    0.65801
    4        True    0.65808
    4        False    0.65795
    5        True    0.65814
    5        False    0.65694
    6        True    0.65663
    6        False    0.65719
</code></pre>
    <p class="normal">The (<code class="inlineCode">2</code>, <code class="inlineCode">False</code>) set enables the best averaged AUC, at <code class="inlineCode">0.65823</code>.</p>
    <p class="normal">Finally, we retrain the model with the best set of hyperparameters (<code class="inlineCode">2</code>, <code class="inlineCode">False</code>) and compute the AUC:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">clf = MultinomialNB(alpha=</span><span class="hljs-con-number">2.0</span><span class="language-python">, fit_prior=</span><span class="hljs-con-literal">False</span><span class="language-python">)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">clf.fit(X_train, Y_train)</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="language-python">pos_prob = clf.predict_proba(X_test)[:, </span><span class="hljs-con-number">1</span><span class="language-python">]</span>
<span class="hljs-con-meta">&gt;&gt;&gt;</span> <span class="hljs-con-built_in">print</span><span class="language-python">(</span><span class="hljs-con-string">'AUC with the best model:'</span><span class="language-python">, roc_auc_score(Y_test,</span>
<span class="hljs-con-meta">...</span> <span class="language-python">      pos_prob))</span>
AUC with the best model:  0.6862056720417091
</code></pre>
    <p class="normal">An AUC of <code class="inlineCode">0.686</code> is achieved<a id="_idIndexMarker268"/> with the fine-tuned model. In general, tweaking<a id="_idIndexMarker269"/> model hyperparameters using cross-validation is one of the most effective ways to boost learning performance and reduce overfitting.</p>
    <h1 class="heading-1" id="_idParaDest-75">Summary</h1>
    <p class="normal">In this chapter, you learned about the fundamental concepts of machine learning classification, including types of classification, classification performance evaluation, cross-validation, and model tuning. You also learned about the simple, yet powerful, classifier, Naïve Bayes. We went in depth through the mechanics and implementations of Naïve Bayes with a couple of examples, the most important one being the movie recommendation project.</p>
    <p class="normal">Binary classification using Naïve Bayes was the main talking point of this chapter. In the next chapter, we will solve ad click-through prediction using another binary classification algorithm: a <strong class="keyWord">decision tree</strong>.</p>
    <h1 class="heading-1" id="_idParaDest-76">Exercises</h1>
    <ol>
      <li class="numberedList" value="1">As mentioned earlier, we extracted user-movie relationships only from the movie rating data where most ratings are unknown. Can you also utilize data from the <code class="inlineCode">movies.dat</code> and <code class="inlineCode">users.dat</code> files?</li>
      <li class="numberedList">Practice makes perfect—another great project to deepen your understanding could be heart disease classification. The dataset can be downloaded directly from <a href="https://archive.ics.uci.edu/ml/datasets/Heart+Disease"><span class="url">https://archive.ics.uci.edu/ml/datasets/Heart+Disease</span></a>.</li>
      <li class="numberedList">Don’t forget to fine-tune the model you obtained from Exercise 2 using the techniques you learned in this chapter. What is the best AUC it achieves?</li>
    </ol>
    <h1 class="heading-1" id="_idParaDest-77">References</h1>
    <p class="normal">To acknowledge the use of the MovieLens dataset in this chapter, I would like to cite the following paper:</p>
    <p class="normal">F. Maxwell Harper and Joseph A. Konstan. 2015. <em class="italic">The MovieLens Datasets: History and Context</em>. ACM <strong class="keyWord">Transactions on Interactive Intelligent Systems</strong> (<strong class="keyWord">TiiS</strong>) 5, 4, Article 19 (December 2015), 19 pages. DOI: <a href="http://dx.doi.org/10.1145/2827872"><span class="url">http://dx.doi.org/10.1145/2827872</span></a>.</p>
    <h1 class="heading-1" id="_idParaDest-78">Join our book’s Discord space</h1>
    <p class="normal">Join our community’s Discord space for discussions with the authors and other readers:</p>
    <p class="normal"><a href="https://packt.link/yuxi"><span class="url">https://packt.link/yuxi</span></a></p>
    <p class="normal"><img alt="" role="presentation" src="../Images/QR_Code187846872178698968.png"/></p>
  </div>
</body></html>