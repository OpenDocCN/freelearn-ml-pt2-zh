<html><head></head><body><div class="chapter" title="Chapter&#xA0;7.&#xA0;Black Box Methods &#x2013; Neural Networks and Support Vector Machines"><div class="titlepage"><div><div><h1 class="title"><a id="ch07"/>Chapter 7. Black Box Methods – Neural Networks and Support Vector Machines</h1></div></div></div><p>The late science fiction author Arthur C. Clarke wrote, "any sufficiently advanced technology is indistinguishable from magic."This chapter covers a pair of machine learning methods that may appear at first glance to be magic. Though they are extremely powerful, their inner workings can be difficult to understand.</p><p>In engineering, these are referred to as <a id="id593" class="indexterm"/>
<span class="strong"><strong>black box</strong></span> processes because the mechanism that transforms the input into the output is obfuscated by an imaginary box. For instance, the black box of closed-source software intentionally conceals proprietary algorithms, the black box of political lawmaking is rooted in the bureaucratic processes, and the black box of sausage-making involves a bit of purposeful (but tasty) ignorance. In the case of machine learning, the black box is due to the complex mathematics allowing them to function.</p><p>Although they may not be easy to understand, it is dangerous to apply black box models blindly. Thus, in this chapter, we'll peek inside the box and investigate the statistical sausage-making involved in fitting such models. You'll discover:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Neural networks mimic the structure of animal brains to model arbitrary functions</li><li class="listitem" style="list-style-type: disc">Support vector machines use multidimensional surfaces to define the relationship between features and outcomes</li><li class="listitem" style="list-style-type: disc">Despite their complexity, these can be applied easily to real-world problems</li></ul></div><p>With any luck, you'll realize that you don't need a black belt in statistics to tackle black box machine's learning methods—there's no need to be intimidated!</p><div class="section" title="Understanding neural networks"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec34"/>Understanding neural networks</h1></div></div></div><p>An <span class="strong"><strong>Artificial Neural Network</strong></span> (<span class="strong"><strong>ANN</strong></span>) models<a id="id594" class="indexterm"/> the relationship <a id="id595" class="indexterm"/>between a set of input signals and an output signal using a model derived from our understanding of how a biological brain responds to stimuli from sensory inputs. Just as a brain uses a network of interconnected cells called <a id="id596" class="indexterm"/>
<span class="strong"><strong>neurons</strong></span> to create a massive parallel processor, ANN uses a network of artificial neurons or <span class="strong"><strong>nodes</strong></span><a id="id597" class="indexterm"/> to solve learning problems.</p><p>The human brain is made up of about 85 billion neurons, resulting in a network capable of representing a tremendous amount of knowledge. As you might expect, this dwarfs the brains of other living creatures. For instance, a cat has roughly a billion neurons, a mouse has about 75 million neurons, and a cockroach has only about a million neurons. In contrast, many ANNs contain far fewer neurons, typically only several hundred, so we're in no danger of creating an artificial brain anytime in the near future—even a fruit fly brain with 100,000 neurons far exceeds the current state-of-the-art ANN.</p><p>Though it may be unfeasible to completely model a cockroach's brain, a neural network may still provide an adequate heuristic model of its behavior. Suppose that we develop an algorithm that can mimic how a roach flees when discovered. If the behavior of the robot roach is convincing, does it matter whether its brain is as sophisticated as the living creature's? This question is the basis of the controversial <span class="strong"><strong>Turing test</strong></span>, proposed in 1950 by the pioneering computer scientist Alan Turing, proposed in 1950 by the pioneering computer scientist Alan Turing, which grades a machine as intelligent if a human being cannot distinguish its behavior from a living creature's.</p><p>Rudimentary ANNs<a id="id598" class="indexterm"/> have been used for over 50 years to simulate the brain's approach to problem-solving. At first, this involved learning simple functions like the logical AND function or the logical OR function. These early exercises were used primarily to help scientists understand how biological brains might operate. However, as computers have become increasingly powerful in the recent years, the complexity of ANNs has likewise increased so much that they are now frequently applied to more practical problems including:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Speech and handwriting recognition programs like those used by voicemail transcription services and postal mail sorting machines</li><li class="listitem" style="list-style-type: disc">The automation of smart devices like an office building's environmental controls or self-driving cars and self-piloting drones</li><li class="listitem" style="list-style-type: disc">Sophisticated models of weather and climate patterns, tensile strength, fluid dynamics, and many other scientific, social, or economic phenomena</li></ul></div><p>Broadly speaking, ANNs are versatile learners that can be applied to nearly any learning task: classification, numeric prediction, and even unsupervised pattern recognition.</p><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip84"/>Tip</h3><p>Whether deserving or not, ANN learners are often reported in the media with great fanfare. For instance, an "<span class="emphasis"><em>artificial brain</em></span>" developed by Google was recently touted for its ability to identify cat videos on YouTube. Such hype may have less to do with anything unique to ANNs and more to do with the fact that ANNs are captivating because of their similarities to living minds.</p></div></div><p>ANNs are best applied to problems where the input data and output data are well-defined or at least fairly simple, yet the process that relates the input to output is extremely complex. As a black box method, they work well for these types of black box problems.</p><div class="section" title="From biological to artificial neurons"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec77"/>From biological to artificial neurons</h2></div></div></div><p>Because ANNs <a id="id599" class="indexterm"/>were intentionally designed as conceptual models of human brain activity, it is helpful to first understand how biological neurons function. As illustrated in the following figure, incoming signals are received by the cell's <span class="strong"><strong>dendrites</strong></span> <a id="id600" class="indexterm"/>through a biochemical process. The process allows the impulse to be weighted according to its relative importance or frequency. As the <span class="strong"><strong>cell body</strong></span><a id="id601" class="indexterm"/> begins accumulating the incoming signals, a threshold is reached at which the cell fires and the output signal is transmitted via an electrochemical process down the <a id="id602" class="indexterm"/>
<span class="strong"><strong>axon</strong></span>. At the axon's terminals, the electric signal is again processed as a chemical signal to be passed to the neighboring neurons across a tiny gap known <a id="id603" class="indexterm"/>as a <span class="strong"><strong>synapse</strong></span>.</p><div class="mediaobject"><img src="graphics/3905_07_01.jpg" alt="From biological to artificial neurons"/></div><p>The model of a <a id="id604" class="indexterm"/>single artificial neuron can be understood in terms very similar to the biological model. As depicted in the following figure, a directed network diagram defines a relationship between the input signals received by the dendrites (<span class="emphasis"><em>x</em></span> variables), and the output signal (<span class="emphasis"><em>y</em></span> variable). Just as with the biological neuron, each dendrite's signal is weighted (<span class="emphasis"><em>w</em></span> values) according to its importance—ignore, for now, how these weights are determined. The input signals are summed by the cell body and the signal is passed on according to an <span class="strong"><strong>activation function</strong></span><a id="id605" class="indexterm"/> denoted by <span class="emphasis"><em>f</em></span>:</p><div class="mediaobject"><img src="graphics/3905_07_02.jpg" alt="From biological to artificial neurons"/></div><p>A typical artificial neuron with <span class="emphasis"><em>n</em></span> input dendrites can be represented by the formula that follows. The <span class="emphasis"><em>w</em></span> weights allow each of the <span class="emphasis"><em>n</em></span> inputs (denoted by <span class="emphasis"><em>x<sub>i</sub></em></span>) to contribute a greater or lesser amount to the sum of input signals. The net total is used by the activation function <span class="emphasis"><em>f(x)</em></span>, and the resulting signal, <span class="emphasis"><em>y(x)</em></span>, is the output axon:</p><div class="mediaobject"><img src="graphics/3905_07_03.jpg" alt="From biological to artificial neurons"/></div><p>Neural networks use neurons defined this way as building blocks to construct complex models of data. Although there are numerous variants of neural networks, each can be defined in terms of the following characteristics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">An <span class="strong"><strong>activation function</strong></span>, which<a id="id606" class="indexterm"/> transforms a neuron's <a id="id607" class="indexterm"/>combined input signals into a single output signal to be broadcasted further in the network</li><li class="listitem" style="list-style-type: disc">A <span class="strong"><strong>network topology</strong></span> (or architecture), which <a id="id608" class="indexterm"/>describes the number of neurons in the model as well as the number of layers and manner in which they are connected</li><li class="listitem" style="list-style-type: disc">The <span class="strong"><strong>training algorithm</strong></span> that <a id="id609" class="indexterm"/>specifies how connection weights are set in order to inhibit or excite neurons in proportion to the input signal</li></ul></div><p>Let's take a look at some of the variations within each of these categories to see how they can be used to construct typical neural network models.</p></div><div class="section" title="Activation functions"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec78"/>Activation functions</h2></div></div></div><p>The activation function is <a id="id610" class="indexterm"/>the mechanism by which the artificial neuron processes incoming information and passes it throughout the network. Just as the artificial neuron is modeled after the biological version, so is the activation function modeled after nature's design.</p><p>In the biological case, the activation function could be imagined as a process that involves summing the total input signal and determining whether it meets the firing threshold. If so, the neuron passes on the signal; otherwise, it does nothing. In ANN terms, this is known as a <a id="id611" class="indexterm"/>
<span class="strong"><strong>threshold activation function</strong></span>, as it results in <a id="id612" class="indexterm"/>an output signal only once a specified input threshold has been attained.</p><p>The following figure depicts a typical threshold function; in this case, the neuron fires when the sum of input signals is at<a id="id613" class="indexterm"/> least zero. Because its shape resembles a stair, it is sometimes called a <a id="id614" class="indexterm"/>
<span class="strong"><strong>unit step activation function</strong></span>.</p><div class="mediaobject"><img src="graphics/3905_07_04.jpg" alt="Activation functions"/></div><p>Although the threshold activation function is interesting due to its parallels with biology, it is rarely used in artificial neural networks. Freed from the limitations of biochemistry, the ANN activation functions can be chosen based on their ability to demonstrate desirable mathematical characteristics and accurately model relationships among data.</p><p>Perhaps the most commonly used alternative is the <a id="id615" class="indexterm"/>
<span class="strong"><strong>sigmoid activation function</strong></span> (more specifically, the <span class="emphasis"><em>logistic</em></span> sigmoid) shown in the following figure. Note that in the formula shown, <span class="emphasis"><em>e</em></span> is the base of the natural logarithm (approximately 2.72). Although it shares a similar step or "S" shape with the threshold activation function, the output signal is no longer binary; output values can fall anywhere in the range from 0 to 1. Additionally, the sigmoid is <span class="strong"><strong>differentiable</strong></span>, which means that it is possible to calculate the derivative across the entire range of inputs. As you will learn later, this feature is crucial to create efficient ANN optimization algorithms.</p><div class="mediaobject"><img src="graphics/3905_07_05.jpg" alt="Activation functions"/></div><p>Although sigmoid is <a id="id616" class="indexterm"/>perhaps the most commonly used activation function and is often used by default, some neural network algorithms allow a choice of alternatives. A selection of such activation functions is shown in the following figure:</p><div class="mediaobject"><img src="graphics/3905_07_06.jpg" alt="Activation functions"/></div><p>The primary detail that differentiates these activation functions is the output signal range. Typically, this is one of (0, 1), (-1, +1), or (-inf, +inf). The choice of activation function biases the neural <a id="id617" class="indexterm"/>network such that it may fit certain types of data more appropriately, allowing the construction of specialized neural networks. For instance, a linear activation function results in a neural network very similar to a linear regression model, while a Gaussian activation function results in a model called a <a id="id618" class="indexterm"/>
<span class="strong"><strong>Radial Basis Function</strong></span> (<span class="strong"><strong>RBF</strong></span>) network. Each of these has strengths better suited for certain learning tasks and not others.</p><p>It's important to recognize that for many of the activation functions, the range of input values that affect the output signal is relatively narrow. For example, in the case of sigmoid, the output signal is always nearly 0 or 1 for an input signal below <span class="emphasis"><em>-5</em></span> or above <span class="emphasis"><em>+5</em></span>, respectively. The compression of signal in this way results in a saturated signal at the high and low ends of very dynamic inputs, just as turning a guitar amplifier up too high results in a distorted sound due to clipping of the peaks of sound waves. Because this essentially squeezes the input values into a smaller range of outputs, activation functions like the sigmoid are sometimes called <a id="id619" class="indexterm"/><a id="id620" class="indexterm"/>
<span class="strong"><strong>squashing functions</strong></span>.</p><p>The solution to the squashing problem is to transform all neural network inputs such that the features' values fall within a small range around 0. Typically, this involves standardizing or normalizing the features. By restricting the range of input values, the activation function will have action across the entire range, preventing large-valued features such as household income from dominating small-valued features such as the number of children in the household. A side benefit is that the model may also be faster to train, since the algorithm can iterate more quickly through the actionable range of input values.</p><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip85"/>Tip</h3><p>Although theoretically a neural network can adapt to a very dynamic feature by adjusting its weight over many iterations. In extreme cases, many algorithms will stop iterating long before this occurs. If your model is making predictions that do not make sense, double-check whether you've correctly standardized the input data.</p></div></div></div><div class="section" title="Network topology"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec79"/>Network topology</h2></div></div></div><p>The ability of a <a id="id621" class="indexterm"/>neural network to learn is rooted in its <span class="strong"><strong>topology</strong></span>, or the patterns and structures of interconnected neurons. Although there are countless forms of network architecture, they can be differentiated by three key characteristics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The number of layers</li><li class="listitem" style="list-style-type: disc">Whether information in the network is allowed to travel backward</li><li class="listitem" style="list-style-type: disc">The number of nodes within each layer of the network</li></ul></div><p>The topology <a id="id622" class="indexterm"/>determines the complexity of tasks that can be learned by the network. Generally, larger and more complex networks are capable of identifying more subtle patterns and complex decision boundaries. However, the power of a network is not only a function of the network size, but also the way units are arranged.</p><div class="section" title="The number of layers"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec41"/>The number of layers</h3></div></div></div><p>To define topology, we need <a id="id623" class="indexterm"/>a terminology that distinguishes artificial neurons based on their position in the network. The figure that follows illustrates the topology of a very simple network. A set of neurons called <a id="id624" class="indexterm"/>
<span class="strong"><strong>input nodes</strong></span> receives unprocessed signals directly from the input data. Each input node is responsible for processing a single feature in the dataset; the feature's value will be transformed by the corresponding node's activation function. The signals sent by the input nodes are received by the output node, which uses its own activation function to generate a final prediction (denoted here as <span class="emphasis"><em>p</em></span>).</p><p>The input and output nodes are arranged in groups known as <a id="id625" class="indexterm"/>
<span class="strong"><strong>layers</strong></span>. Because the input nodes process the incoming data exactly as it is received, the network has only one set of connection weights (labeled here as <span class="emphasis"><em>w<sub>1</sub></em></span>, <span class="emphasis"><em>w<sub>2</sub></em></span>, and <span class="emphasis"><em>w<sub>3</sub></em></span>). It is therefore termed a <span class="strong"><strong>single-layer network</strong></span>. Single-layer networks can be used for basic pattern classification, particularly for patterns that are linearly separable, but more sophisticated networks are required for most learning tasks.</p><div class="mediaobject"><img src="graphics/3905_07_07.jpg" alt="The number of layers"/></div><p>As you might expect, an obvious way to create more complex networks is by adding additional layers. As depicted here, a <a id="id626" class="indexterm"/>
<span class="strong"><strong>multilayer network</strong></span> adds one or more <span class="strong"><strong>hidden layers</strong></span> that process the signals from the input nodes prior to it reaching the output node. Most multilayer networks are <span class="strong"><strong>fully connected</strong></span>, which means that every node in one layer is connected to every node in the next layer, but this is not required.</p><div class="mediaobject"><img src="graphics/3905_07_08.jpg" alt="The number of layers"/></div></div><div class="section" title="The direction of information travel"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec42"/>The direction of information travel</h3></div></div></div><p>You may have<a id="id627" class="indexterm"/> noticed that in the prior examples, arrowheads were used to indicate signals traveling in only one direction. Networks in which the input signal is fed continuously in one direction from connection to connection until it reaches the output layer are called <a id="id628" class="indexterm"/>
<span class="strong"><strong>feedforward</strong></span> networks.</p><p>In spite of the restriction on information flow, feedforward networks offer a surprising amount of flexibility. For instance, the number of levels and nodes at each level can be varied, multiple outcomes can be modeled simultaneously, or multiple hidden layers can be applied. A neural network with multiple hidden layers is called a <a id="id629" class="indexterm"/>
<span class="strong"><strong>Deep Neural Network</strong></span> (<span class="strong"><strong>DNN</strong></span>) and the practice of training such network is sometimes referred to as <a id="id630" class="indexterm"/>
<span class="strong"><strong>deep learning</strong></span>.</p><div class="mediaobject"><img src="graphics/B03905_07_09.jpg" alt="The direction of information travel"/></div><p>In contrast, a<a id="id631" class="indexterm"/> <span class="strong"><strong>recurrent network</strong></span> (or <span class="strong"><strong>feedback network</strong></span>) allows signals to travel in both directions using loops. This property, which more closely mirrors how a biological neural network works, allows extremely complex patterns to be learned. The addition of a short-term memory, or <span class="strong"><strong>delay</strong></span>, increases the power of recurrent networks immensely. Notably, this includes the capability to understand the sequences of events over a period of time. This could be used for stock market prediction, speech comprehension, or weather forecasting. A simple recurrent network is depicted as follows:</p><div class="mediaobject"><img src="graphics/3905_07_10.jpg" alt="The direction of information travel"/></div><p>In spite of their potential, recurrent networks are still largely theoretical and are rarely used in practice. On the other hand, feedforward networks have been extensively applied to real-world problems. In fact, the multilayer feedforward network, sometimes called the <a id="id632" class="indexterm"/>
<span class="strong"><strong>Multilayer Perceptron</strong></span> (<span class="strong"><strong>MLP</strong></span>), is the de facto standard ANN topology. If someone mentions that they are fitting a neural network, they are most likely referring to a MLP.</p></div><div class="section" title="The number of nodes in each layer"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec43"/>The number of nodes in each layer</h3></div></div></div><p>In addition<a id="id633" class="indexterm"/> to the variations in the number of layers and the direction of information travel, neural networks can also vary in complexity by the number of nodes in each layer. The number of input nodes is predetermined by the number of features in the input data. Similarly, the number of output nodes is predetermined by the number of outcomes to be modeled or the number of class levels in the outcome. However, the number of hidden nodes is left to the user to decide prior to training the model.</p><p>Unfortunately, there is no reliable rule to determine the number of neurons in the hidden layer. The appropriate number depends on the number of input nodes, the amount of training data, the amount of noisy data, and the complexity of the learning task, among many other factors.</p><p>In general, more complex network topologies with a greater number of network connections allow the learning of more complex problems. A greater number of neurons will result in a model that more closely mirrors the training data, but this runs a risk of overfitting; it may generalize poorly to future data. Large neural networks can also be computationally expensive and slow to train.</p><p>The best practice is <a id="id634" class="indexterm"/>to use the fewest nodes that result in adequate performance in a validation dataset. In most cases, even with only a small number of hidden nodes—often as few as a handful—the neural network can offer a tremendous amount of learning ability.</p><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip86"/>Tip</h3><p>It has been proven that a neural network with at least one hidden layer of sufficient neurons is a <a id="id635" class="indexterm"/>
<span class="strong"><strong>universal function approximator</strong></span>. This means that neural networks can be used to approximate any continuous function to an arbitrary precision over a finite interval.</p></div></div></div></div><div class="section" title="Training neural networks with backpropagation"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec80"/>Training neural networks with backpropagation</h2></div></div></div><p>The <a id="id636" class="indexterm"/>network topology is a blank slate that by itself has not learned anything. Like a newborn child, it must be trained with experience. As the<a id="id637" class="indexterm"/> neural network processes the input data, connections between the neurons are strengthened or weakened, similar to how a baby's brain develops as he or she experiences the environment. The network's connection weights are adjusted to reflect the patterns observed over time.</p><p>Training a neural network by adjusting connection weights is very computationally intensive. Consequently, though they had been studied for decades prior, ANNs were rarely applied to real-world learning tasks until the mid-to-late 1980s, when an efficient method of training an ANN was discovered. The algorithm, which used a strategy of back-propagating errors, is now known simply as <a id="id638" class="indexterm"/>
<span class="strong"><strong>backpropagation</strong></span>.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note25"/>Note</h3><p>Coincidentally, several research teams independently discovered and published the backpropagation algorithm around the same time. Among them, perhaps the most often cited work is: Rumelhart DE, Hinton GE, Williams RJ. Learning representations by back-propagating errors. <span class="emphasis"><em>Nature</em></span>. 1986; 323:533-566.</p></div></div><p>Although still notoriously slow relative to many other machine learning algorithms, the backpropagation method led to a resurgence of interest in ANNs. As a result, multilayer feedforward networks that use the backpropagation algorithm are now common in the field of data mining. Such models offer the following strengths and weaknesses:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Strengths</p>
</th><th style="text-align: left" valign="bottom">
<p>Weaknesses</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Can be adapted to classification or numeric prediction problems</li><li class="listitem" style="list-style-type: disc">Capable of modeling more complex patterns than nearly any algorithm</li><li class="listitem" style="list-style-type: disc">Makes few assumptions about the data's underlying relationships</li></ul></div>
</td><td style="text-align: left" valign="top">
<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Extremely computationally intensive and slow to train, particularly if the network topology is complex</li><li class="listitem" style="list-style-type: disc">Very prone to overfitting training data</li><li class="listitem" style="list-style-type: disc">Results in a complex black box model that is difficult, if not impossible, to interpret</li></ul></div>
</td></tr></tbody></table></div><p>In its most <a id="id639" class="indexterm"/>general form, the backpropagation algorithm iterates through many cycles of two processes. Each cycle is known as an <span class="strong"><strong>epoch</strong></span>. Because<a id="id640" class="indexterm"/> the network contains no <span class="emphasis"><em>a priori</em></span> (existing) knowledge, the starting weights are typically set at random. Then, the algorithm iterates through the processes, until a stopping criterion is reached. Each epoch in the backpropagation algorithm includes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">A <span class="strong"><strong>forward phase</strong></span> in <a id="id641" class="indexterm"/>which the neurons are activated in sequence from the input layer to the output layer, applying each neuron's weights and activation function along the way. Upon reaching the final layer, an output signal is produced.</li><li class="listitem" style="list-style-type: disc">A <span class="strong"><strong>backward phase</strong></span> in<a id="id642" class="indexterm"/> which the network's output signal resulting from the forward phase is compared to the true target value in the training data. The difference between the network's output signal and the true value results in an error that is propagated backwards in the network to modify the connection weights between neurons and reduce future errors.</li></ul></div><p>Over time, the network uses the information sent backward to reduce the total error of the network. Yet one question remains: because the relationship between each neuron's inputs and outputs is complex, how does the algorithm determine how much a weight should be changed? The answer to this question involves a technique called <a id="id643" class="indexterm"/>
<span class="strong"><strong>gradient descent</strong></span>. Conceptually, it works similarly to how an explorer trapped in the jungle might find a path to water. By examining the terrain and continually walking in the direction with the greatest downward slope, the explorer will eventually reach the lowest valley, which is likely to be a riverbed.</p><p>In a similar process, the backpropagation algorithm uses the derivative of each neuron's activation function to identify the gradient in the direction of each of the incoming weights—hence the importance of having a differentiable activation function. The gradient suggests how steeply the error will be reduced or increased for a change in the weight. The algorithm will attempt to change the weights that result in the greatest reduction in error by an amount known as the <a id="id644" class="indexterm"/>
<span class="strong"><strong>learning rate</strong></span>. The greater the learning rate, the faster the <a id="id645" class="indexterm"/>algorithm will attempt to descend down the gradients, which could reduce the training time at the risk of overshooting the valley.</p><div class="mediaobject"><img src="graphics/B03905_07_11.jpg" alt="Training neural networks with backpropagation"/></div><p>Although this process seems complex, it is easy to apply in practice. Let's apply our understanding of multilayer feedforward networks to a real-world problem.</p></div></div></div>
<div class="section" title="Example &#x2013; Modeling the strength of concrete with ANNs"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec35"/>Example – Modeling the strength of concrete with ANNs</h1></div></div></div><p>In the field <a id="id646" class="indexterm"/>of engineering, it is crucial to have accurate estimates of the performance of building materials. These estimates are required in order to develop safety guidelines governing the materials used in the construction of buildings, bridges, and roadways.</p><p>Estimating the strength of concrete is a challenge of particular interest. Although it is used in nearly every construction project, concrete performance varies greatly due to a wide variety of ingredients that interact in complex ways. As a result, it is difficult to accurately predict the strength of the final product. A model that could reliably predict concrete strength given a listing of the composition of the input materials could result in safer construction practices.</p><div class="section" title="Step 1 – collecting data"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec81"/>Step 1 – collecting data</h2></div></div></div><p>For this analysis, we <a id="id647" class="indexterm"/>will utilize data on the compressive strength of concrete donated to the UCI Machine Learning <a id="id648" class="indexterm"/>Data Repository (<a class="ulink" href="http://archive.ics.uci.edu/ml">http://archive.ics.uci.edu/ml</a>) by I-Cheng Yeh. As he found success using neural networks to model these data, we will attempt to replicate his work using a simple neural network model in R.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note26"/>Note</h3><p>For more information on Yeh's approach to this learning task, refer to: Yeh IC. Modeling of strength of high performance concrete using artificial neural networks. <span class="emphasis"><em>Cement and Concrete Research</em></span>. 1998; 28:1797-1808.</p></div></div><p>According to the website, the concrete dataset contains 1,030 examples of concrete with eight features describing the components used in the mixture. These features are thought to be related to the final compressive strength and they include the amount (in kilograms per cubic meter) of cement, slag, ash, water, superplasticizer, coarse aggregate, and fine aggregate used in the product in addition to the aging time (measured in days).</p><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip87"/>Tip</h3><p>To follow along with this example, download the <code class="literal">concrete.csv</code> file from the Packt Publishing website and save it to your R working directory.</p></div></div></div><div class="section" title="Step 2 – exploring and preparing the data"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec82"/>Step 2 – exploring and preparing the data</h2></div></div></div><p>As usual, we'll begin <a id="id649" class="indexterm"/>our analysis by loading the data<a id="id650" class="indexterm"/> into an R object using the <code class="literal">read.csv()</code> function, and confirming that it matches the expected structure: </p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; concrete &lt;- read.csv("concrete.csv")</strong></span>
<span class="strong"><strong>&gt; str(concrete)</strong></span>
<span class="strong"><strong>'data.frame':   1030 obs. of  9 variables:</strong></span>
<span class="strong"><strong> $ cement      : num  141 169 250 266 155 ...</strong></span>
<span class="strong"><strong> $ slag        : num  212 42.2 0 114 183.4 ...</strong></span>
<span class="strong"><strong> $ ash         : num  0 124.3 95.7 0 0 ...</strong></span>
<span class="strong"><strong> $ water       : num  204 158 187 228 193 ...</strong></span>
<span class="strong"><strong> $ superplastic: num  0 10.8 5.5 0 9.1 0 0 6.4 0 9 ...</strong></span>
<span class="strong"><strong> $ coarseagg   : num  972 1081 957 932 1047 ...</strong></span>
<span class="strong"><strong> $ fineagg     : num  748 796 861 670 697 ...</strong></span>
<span class="strong"><strong> $ age         : int  28 14 28 28 28 90 7 56 28 28 ...</strong></span>
<span class="strong"><strong> $ strength    : num  29.9 23.5 29.2 45.9 18.3 ...</strong></span>
</pre></div><p>The nine variables <a id="id651" class="indexterm"/>in the data frame correspond to the eight features and one outcome we expected, although a problem has become apparent. Neural networks work best when the input data are scaled to a narrow range around zero, and here, we see values ranging anywhere from zero up to over a thousand.</p><p>Typically, the <a id="id652" class="indexterm"/>solution to this problem is to rescale the data with a normalizing or standardization function. If the data follow a bell-shaped curve (a normal distribution as described in <a class="link" href="ch02.html" title="Chapter 2. Managing and Understanding Data">Chapter 2</a>, <span class="emphasis"><em>Managing and Understanding Data</em></span>), then it may make sense to use standardization via R's built-in scale() function. On the other hand, if the data follow a uniform distribution or are severely nonnormal, then normalization to a 0-1 range may be more appropriate. In this case, we'll use the latter.</p><p>In <a class="link" href="ch03.html" title="Chapter 3. Lazy Learning – Classification Using Nearest Neighbors">Chapter 3</a>, <span class="emphasis"><em>Lazy Learning – Classification Using Nearest Neighbors</em></span>, we defined our own <code class="literal">normalize()</code> function as:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; normalize &lt;- function(x) {</strong></span>
<span class="strong"><strong>    return((x - min(x)) / (max(x) - min(x)))</strong></span>
<span class="strong"><strong>  }</strong></span>
</pre></div><p>After executing this code, our <code class="literal">normalize()</code> function can be applied to every column in the concrete data frame using the <code class="literal">lapply()</code> function as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; concrete_norm &lt;- as.data.frame(lapply(concrete, normalize))</strong></span>
</pre></div><p>To confirm that the normalization worked, we can see that the minimum and maximum strength are now 0 and 1, respectively:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; summary(concrete_norm$strength)</strong></span>
<span class="strong"><strong>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </strong></span>
<span class="strong"><strong> 0.0000  0.2664  0.4001  0.4172  0.5457  1.0000</strong></span>
</pre></div><p>In comparison, the original minimum and maximum values were 2.33 and 82.60:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; summary(concrete$strength)</strong></span>
<span class="strong"><strong>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </strong></span>
<span class="strong"><strong>   2.33   23.71   34.44   35.82   46.14   82.60</strong></span>
</pre></div><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip88"/>Tip</h3><p>Any transformation applied to the data prior to training the model will have to be applied in reverse later on, in order to convert back to the original units of measurement. To facilitate the rescaling, it is wise to save the original data or at least the summary statistics of the original data.</p></div></div><p>Following Yeh's precedent in the original publication, we will partition the data into a training set with 75 percent of the <a id="id653" class="indexterm"/>examples and a testing set with 25 percent. The CSV file we used was already sorted in random order, so we simply need to divide it into two portions:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; concrete_train &lt;- concrete_norm[1:773, ]</strong></span>
<span class="strong"><strong>&gt; concrete_test &lt;- concrete_norm[774:1030, ]</strong></span>
</pre></div><p>We'll use the training dataset to build the neural network and the testing dataset to evaluate how well the model generalizes to future results. As it is easy to overfit a neural network, this step is very important.</p></div><div class="section" title="Step 3 – training a model on the data"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec83"/>Step 3 – training a model on the data</h2></div></div></div><p>To model the <a id="id654" class="indexterm"/>relationship between the ingredients used in concrete and the strength of the finished product, we will use a multilayer feedforward neural network. The <code class="literal">neuralnet</code> package by Stefan Fritsch and Frauke Guenther provides a standard and easy-to-use implementation of such networks. It also offers a function to plot the network topology. For these reasons, the <code class="literal">neuralnet</code> implementation is a strong choice for learning more about neural networks, though this is not to say that it cannot be used to accomplish real work as well—it's quite a powerful tool, as you will soon see.</p><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip89"/>Tip</h3><p>There are several other commonly used packages to train ANN models in R, each with unique strengths and weaknesses. Because it ships as a part of the standard R installation, the <code class="literal">nnet</code> package is perhaps the most frequently cited ANN implementation. It uses a slightly more sophisticated algorithm than standard backpropagation. Another strong option is the <code class="literal">RSNNS</code> package, which offers a complete suite of neural network functionality with the downside being that it is more difficult to learn.</p></div></div><p>As <code class="literal">neuralnet</code> is not included in base R, you will need to install it by typing <code class="literal">install.packages("neuralnet")</code> and load it with the <code class="literal">library(neuralnet)</code> command. The included <code class="literal">neuralnet()</code> function can be used for training neural networks for numeric prediction<a id="id655" class="indexterm"/> using the following syntax:</p><div class="mediaobject"><img src="graphics/3905_07_12.jpg" alt="Step 3 – training a model on the data"/></div><p>We'll begin by<a id="id656" class="indexterm"/> training the simplest multilayer feedforward network with only a single hidden node:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; concrete_model &lt;- neuralnet(strength ~ cement + slag + ash + water + superplastic + coarseagg + fineagg + age, data = concrete_train)</strong></span>
</pre></div><p>We can then visualize the network topology using the <code class="literal">plot()</code> function on the resulting model object:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; plot(concrete_model)</strong></span>
</pre></div><div class="mediaobject"><img src="graphics/3905_07_13.jpg" alt="Step 3 – training a model on the data"/></div><p>In this simple model, there is one input node for each of the eight features, followed by a single hidden node and a single output node that predicts the concrete strength. The weights for each of the connections are also depicted, as are the <span class="strong"><strong>bias terms</strong></span> (indicated by the nodes labeled with the number <span class="strong"><strong>1</strong></span>). The bias terms are numeric constants that allow the value at the indicated nodes to be shifted upward or downward, much like the intercept in a linear equation.</p><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip910"/>Tip</h3><p>A neural network with a single hidden node can be thought of as a distant cousin of the linear regression models we studied in <a class="link" href="ch06.html" title="Chapter 6. Forecasting Numeric Data – Regression Methods">Chapter 6</a>, <span class="emphasis"><em>Forecasting Numeric Data – Regression Methods</em></span>. The weight between each input node and the hidden node is similar to the regression coefficients, and the weight for the bias term is similar to the intercept.</p></div></div><p>At the bottom of the figure, R reports the number of training steps and an error measure called the <span class="strong"><strong>Sum of Squared Errors</strong></span> (<span class="strong"><strong>SSE</strong></span>), which as you might expect, is the sum of the squared predicted minus actual values. A lower SSE implies better predictive performance. This is helpful for estimating the model's performance on the training data, but tells us little about how it will perform on unseen data.</p></div><div class="section" title="Step 4 – evaluating model performance"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec84"/>Step 4 – evaluating model performance</h2></div></div></div><p>The network topology <a id="id657" class="indexterm"/>diagram gives us a peek into the black box of the ANN, but it doesn't provide much information about how well the model fits future data. To generate predictions on the test dataset, we can use the <code class="literal">compute()</code> as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; model_results &lt;- compute(concrete_model, concrete_test[1:8])</strong></span>
</pre></div><p>The <code class="literal">compute()</code> function works a bit differently from the <code class="literal">predict()</code> functions we've used so far. It returns a list with two components: <code class="literal">$neurons</code>, which stores the neurons for each layer in the network, and <code class="literal">$net.result</code>, which stores the predicted values. We'll want the latter:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; predicted_strength &lt;- model_results$net.result</strong></span>
</pre></div><p>Because this is a numeric prediction problem rather than a classification problem, we cannot use a confusion matrix to examine model accuracy. Instead, we must measure the correlation between our predicted concrete strength and the true value. This provides insight into the strength of the linear association between the two variables.</p><p>Recall that the <code class="literal">cor()</code> function is used to obtain a correlation between two numeric vectors:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; cor(predicted_strength, concrete_test$strength)</strong></span>
<span class="strong"><strong>             [,1]</strong></span>
<span class="strong"><strong>[1,] 0.8064655576</strong></span>
</pre></div><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip90"/>Tip</h3><p>Don't be alarmed if your result differs. Because the neural network begins with random weights, the predictions can vary from model to model. If you'd like to match these results exactly, try using <code class="literal">set.seed(12345)</code> before building the neural network.</p></div></div><p>Correlations close to 1 indicate strong linear relationships between two variables. Therefore, the correlation here of about 0.806 indicates a fairly strong relationship. This implies that our model is doing a fairly good job, even with only a single hidden node.</p><p>Given that we only <a id="id658" class="indexterm"/>used one hidden node, it is likely that we can improve the performance of our model. Let's try to do a bit better.</p></div><div class="section" title="Step 5 – improving model performance"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec85"/>Step 5 – improving model performance</h2></div></div></div><p>As networks with more <a id="id659" class="indexterm"/>complex topologies are capable of learning more difficult concepts, let's see what happens when we increase the number of hidden nodes to five. We use the <code class="literal">neuralnet()</code> function as before, but add the <code class="literal">hidden = 5</code> parameter:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; concrete_model2 &lt;- neuralnet(strength ~ cement + slag +</strong></span>
<span class="strong"><strong>                               ash + water + superplastic +</strong></span>
<span class="strong"><strong>                               coarseagg + fineagg + age,</strong></span>
<span class="strong"><strong>                               data = concrete_train, hidden = 5)</strong></span>
</pre></div><p>Plotting the network again, we see a drastic increase in the number of connections. We can see how this impacted the performance as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; plot(concrete_model2)</strong></span>
</pre></div><div class="mediaobject"><img src="graphics/3905_07_14.jpg" alt="Step 5 – improving model performance"/></div><p>Notice that the <a id="id660" class="indexterm"/>reported error (measured again by SSE) has been reduced from 5.08 in the previous model to 1.63 here. Additionally, the number of training steps rose from 4,882 to 86,849, which should come as no surprise given how much more complex the model has become. More complex networks take many more iterations to find the optimal weights.</p><p>Applying the same steps to compare the predicted values to the true values, we now obtain a correlation around 0.92, which is a considerable improvement over the previous result of 0.80 with a single hidden node:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; model_results2 &lt;- compute(concrete_model2, concrete_test[1:8])</strong></span>
<span class="strong"><strong>&gt; predicted_strength2 &lt;- model_results2$net.result</strong></span>
<span class="strong"><strong>&gt; cor(predicted_strength2, concrete_test$strength)</strong></span>
<span class="strong"><strong>             [,1]</strong></span>
<span class="strong"><strong>[1,] 0.9244533426</strong></span>
</pre></div><p>Interestingly, in the original publication, Yeh reported a mean correlation of 0.885 using a very similar neural network. This means that with relatively little effort, we were able to match the <a id="id661" class="indexterm"/>performance of a subject-matter expert. If you'd like more practice with neural networks, you might try applying the principles learned earlier in this chapter to see how it impacts model performance. Perhaps try using different numbers of hidden nodes, applying different activation functions, and so on. The <code class="literal">?neuralnet</code> help page provides more information on the various parameters that can be adjusted.</p></div></div>
<div class="section" title="Understanding Support Vector Machines"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec36"/>Understanding Support Vector Machines</h1></div></div></div><p>A <span class="strong"><strong>Support Vector Machine</strong></span> (<span class="strong"><strong>SVM</strong></span>) can <a id="id662" class="indexterm"/>be imagined as a surface that creates a boundary between points of data plotted in multidimensional that represent examples and their feature values. The goal of a SVM is to create a flat boundary called a <a id="id663" class="indexterm"/>
<span class="strong"><strong>hyperplane</strong></span>, which divides the space to create fairly homogeneous partitions on either side. In this way, the SVM learning combines aspects of both the instance-based nearest neighbor learning presented in <a class="link" href="ch03.html" title="Chapter 3. Lazy Learning – Classification Using Nearest Neighbors">Chapter 3</a>, <span class="emphasis"><em>Lazy Learning – Classification Using Nearest Neighbors</em></span>, and the linear regression modeling described in <a class="link" href="ch06.html" title="Chapter 6. Forecasting Numeric Data – Regression Methods">Chapter 6</a>, <span class="emphasis"><em>Forecasting Numeric Data – Regression Methods</em></span>. The combination is extremely powerful, allowing SVMs to model highly complex relationships.</p><p>Although the basic mathematics that drive SVMs have been around for decades, they have recently exploded in popularity. This is, of course, rooted in their state-of-the-art performance, but perhaps also due to the fact that award winning SVM algorithms have been implemented in several popular and well-supported libraries across many programming languages, including R. SVMs have thus been adopted by a much wider audience, might have otherwise been unable to apply the somewhat complex math needed to implement a SVM. The good news is that although the math may be difficult, the basic concepts are understandable.</p><p>SVMs can be adapted for use with nearly any type of learning task, including both classification and numeric prediction. Many of the algorithm's key successes have come in pattern recognition. Notable <a id="id664" class="indexterm"/>applications include:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Classification of microarray gene expression data in the field of bioinformatics to identify cancer or other genetic diseases</li><li class="listitem" style="list-style-type: disc">Text categorization such as identification of the language used in a document or the classification of documents by subject matter</li><li class="listitem" style="list-style-type: disc">The detection <a id="id665" class="indexterm"/>of rare yet important events like combustion engine failure, security breaches, or earthquakes</li></ul></div><p>SVMs are most easily understood when used for binary classification, which is how the method has been traditionally applied. Therefore, in the remaining sections, we will focus only on SVM classifiers. Don't worry, however, as the same principles you learn here will apply while adapting SVMs to other learning tasks such as numeric prediction.</p><div class="section" title="Classification with hyperplanes"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec86"/>Classification with hyperplanes</h2></div></div></div><p>As noted previously, SVMs <a id="id666" class="indexterm"/>use a boundary called a hyperplane to partition data into groups of similar class values. For example, the following figure depicts hyperplanes that separate groups of circles and squares in two and three dimensions. Because the circles and squares can be separated perfectly by the straight line or flat surface, they are said to be <span class="strong"><strong>linearly separable</strong></span>. At first, we'll consider only the simple case where this is true, but SVMs can also be extended to problems where the points are not linearly separable.</p><div class="mediaobject"><img src="graphics/3905_07_15.jpg" alt="Classification with hyperplanes"/></div><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip91"/>Tip</h3><p>For convenience, the hyperplane is traditionally depicted as a line in 2D space, but this is simply because it is difficult to illustrate space in greater than two dimensions. In reality, the hyperplane is a flat surface in a high-dimensional space—a concept that can be difficult to get your mind around.</p></div></div><p>In two dimensions, the <a id="id667" class="indexterm"/>task of the SVM algorithm is to identify a line that separates the two classes. As shown in the following figure, there is more than one choice of dividing line between the groups of circles and squares. Three such possibilities are labeled <span class="strong"><strong>a</strong></span>, <span class="strong"><strong>b</strong></span>, and <span class="strong"><strong>c</strong></span>. How does the algorithm choose?</p><div class="mediaobject"><img src="graphics/3905_07_16.jpg" alt="Classification with hyperplanes"/></div><p>The answer to that question involves a search for the <a id="id668" class="indexterm"/>
<span class="strong"><strong>Maximum Margin Hyperplane</strong></span> (<span class="strong"><strong>MMH</strong></span>) that creates the greatest separation between the two classes. Although any of the three lines separating the circles and squares would correctly classify all the data points, it is likely that the line that leads to the greatest separation will generalize the best to the future data. The maximum margin will improve the chance that, in spite of random noise, the points will remain on the correct side of the boundary.</p><p>The <a id="id669" class="indexterm"/>
<span class="strong"><strong>support vectors</strong></span> (indicated by arrows in the figure that follows) are the points from each class that are the closest to the MMH; each class must have at least one support vector, but it is possible to have more than one. Using the support vectors alone, it is possible to define the MMH. This is a key feature of SVMs; the support vectors provide a very compact way to store a classification model, even if the number of features is extremely large.</p><div class="mediaobject"><img src="graphics/3905_07_17.jpg" alt="Classification with hyperplanes"/></div><p>The algorithm to <a id="id670" class="indexterm"/>identify the support vectors relies on vector geometry and involves some fairly tricky math that is outside the scope of this book. However, the basic principles of the process are fairly straightforward.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note27"/>Note</h3><p>More information on the mathematics of SVMs can be found in the classic paper: Cortes C, Vapnik V. Support-vector network. <span class="emphasis"><em>Machine Learning</em></span>. 1995; 20:273-297. A beginner level discussion can be found in: Bennett KP, Campbell C. Support vector machines: hype or hallelujah. SIGKDD Explorations. 2003; 2:1-13. A more in-depth look can be found in: Steinwart I, Christmann A. <span class="emphasis"><em>Support Vector Machines</em></span>. New York: Springer; 2008.</p></div></div><div class="section" title="The case of linearly separable data"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec44"/>The case of linearly separable data</h3></div></div></div><p>It is easiest to<a id="id671" class="indexterm"/> understand how to find the maximum margin under the assumption that the classes are linearly separable. In this case, the MMH is as far away as possible from the outer boundaries of the two groups of data points. These outer boundaries are known as the <a id="id672" class="indexterm"/>
<span class="strong"><strong>convex hull</strong></span>. The MMH is then the perpendicular bisector of the shortest line between the two convex hulls. Sophisticated computer algorithms that use a technique known as <a id="id673" class="indexterm"/>
<span class="strong"><strong>quadratic optimization</strong></span> are capable of finding the maximum margin in this way.</p><div class="mediaobject"><img src="graphics/3905_07_18.jpg" alt="The case of linearly separable data"/></div><p>An <a id="id674" class="indexterm"/>alternative (but equivalent) approach involves a search through the space of every possible hyperplane in order to find a set of two parallel planes that divide the points into homogeneous groups yet themselves are as far apart as possible. To use a metaphor, one can imagine this process as similar to trying to find the thickest mattress that can fit up a stairwell to your bedroom.</p><p>To understand this search process, we'll need to define exactly what we mean by a hyperplane. In <span class="emphasis"><em>n</em></span>-dimensional space, the following equation is used:</p><div class="mediaobject"><img src="graphics/3905_07_19.jpg" alt="The case of linearly separable data"/></div><p>If you aren't familiar with this notation, the arrows above the letters indicate that they are vectors rather than single numbers. In particular, <span class="emphasis"><em>w</em></span> is a vector of <span class="emphasis"><em>n</em></span> weights, that is, <span class="emphasis"><em>{w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>}</em></span>, and <span class="emphasis"><em>b</em></span> is a single number known as the <a id="id675" class="indexterm"/>
<span class="strong"><strong>bias</strong></span>. The bias is conceptually equivalent to the intercept term in the slope-intercept form discussed in <a class="link" href="ch06.html" title="Chapter 6. Forecasting Numeric Data – Regression Methods">Chapter 6</a>, <span class="emphasis"><em>Forecasting Numeric Data – Regression Methods</em></span>.</p><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip92"/>Tip</h3><p>If you're having trouble imagining the plane, don't worry about the details. Simply think of the equation as a way to specify a surface, much like when the slope-intercept form (<span class="emphasis"><em>y = mx + b</em></span>) is used to specify lines in 2D space.</p></div></div><p>Using this formula, the goal of the process is to find a set of weights that specify two hyperplanes, as follows:</p><div class="mediaobject"><img src="graphics/3905_07_20.jpg" alt="The case of linearly separable data"/></div><p>We will also require that these hyperplanes are specified such that all the points of one class fall above the <a id="id676" class="indexterm"/>first hyperplane and all the points of the other class fall beneath the second hyperplane. This is possible so long as the data are linearly separable.</p><p>Vector geometry defines the distance between these two planes as:</p><div class="mediaobject"><img src="graphics/3905_07_21.jpg" alt="The case of linearly separable data"/></div><p>Here, <span class="emphasis"><em>||w||</em></span> indicates the <a id="id677" class="indexterm"/>
<span class="strong"><strong>Euclidean norm</strong></span> (the distance from the origin to vector <span class="emphasis"><em>w</em></span>). Because <span class="emphasis"><em>||w||</em></span> is in the denominator, to maximize distance, we need to minimize <span class="emphasis"><em>||w||</em></span>. The task is typically reexpressed as a set of constraints, as follows:</p><div class="mediaobject"><img src="graphics/3905_07_22.jpg" alt="The case of linearly separable data"/></div><p>Although this looks messy, it's really not too complicated to understand conceptually. Basically, the first line implies that we need to minimize the Euclidean norm (squared and divided by two to make the calculation easier). The second line notes that this is subject to (<span class="emphasis"><em>s.t.</em></span>), the condition that each of the <span class="emphasis"><em>y<sub>i</sub></em></span> data points is correctly classified. Note that <span class="emphasis"><em>y</em></span> indicates the class value (transformed to either +1 or -1) and the upside down "A" is shorthand for "for all."</p><p>As with the other method for finding the maximum margin, finding a solution to this problem is a task best left for quadratic optimization software. Although it can be processor-intensive, specialized algorithms are capable of solving these problems quickly even on fairly large datasets.</p></div><div class="section" title="The case of nonlinearly separable data"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec45"/>The case of nonlinearly separable data</h3></div></div></div><p>As we've <a id="id678" class="indexterm"/>worked through the theory behind SVMs, you may be wondering about the elephant in the room: what happens if the data are not linearly separable? The solution to this problem is the use of a <a id="id679" class="indexterm"/>
<span class="strong"><strong>slack variable</strong></span>, which creates a soft margin that allows some points to fall on the incorrect side of the margin. The figure that follows illustrates two points falling on the wrong side of the line with the corresponding slack terms (denoted with the Greek letter Xi):</p><div class="mediaobject"><img src="graphics/3905_07_23.jpg" alt="The case of nonlinearly separable data"/></div><p>A cost value (denoted as <span class="emphasis"><em>C</em></span>) is applied to all points that violate the constraints, and rather than finding the maximum margin, the algorithm attempts to minimize the total cost. We can therefore revise the optimization problem to:</p><div class="mediaobject"><img src="graphics/3905_07_24.jpg" alt="The case of nonlinearly separable data"/></div><p>If you're still confused, don't worry, you're not alone. Luckily, SVM packages will happily optimize this for you without you having to understand the technical details. The important piece to understand is the addition of the cost parameter <span class="emphasis"><em>C</em></span>. Modifying this value will adjust the penalty, for example, the fall on the wrong side of the hyperplane. The greater the<a id="id680" class="indexterm"/> cost parameter, the harder the optimization will try to achieve 100 percent separation. On the other hand, a lower cost parameter will place the emphasis on a wider overall margin. It is important to strike a balance between these two in order to create a model that generalizes well to future data.</p></div></div><div class="section" title="Using kernels for non-linear spaces"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec87"/>Using kernels for non-linear spaces</h2></div></div></div><p>In many real-world applications, the <a id="id681" class="indexterm"/>relationships between variables are nonlinear. As we just discovered, a SVM can still be trained on such data<a id="id682" class="indexterm"/> through the addition of a slack variable, which allows some examples to be misclassified. However, this is not the only way to approach the problem of nonlinearity. A key feature of SVMs is their ability to map the problem into a higher dimension space using a process known as the <span class="strong"><strong>kernel trick</strong></span>. In <a id="id683" class="indexterm"/>doing so, a nonlinear relationship may suddenly appear to be quite linear.</p><p>Though this seems like nonsense, it is actually quite easy to illustrate by example. In the following figure, the scatterplot on the left depicts a nonlinear relationship between a weather class (sunny or snowy) and two features: latitude <a id="id684" class="indexterm"/>and <a id="id685" class="indexterm"/>longitude. The points at the center of the plot are members of the snowy class, while the points at the margins are all sunny. Such data could have been generated from a set of weather reports, some of which were obtained from stations near the top of a mountain, while others were obtained from stations around the base of the mountain.</p><div class="mediaobject"><img src="graphics/3905_07_25.jpg" alt="Using kernels for non-linear spaces"/></div><p>On the right side of the figure, after the kernel trick has been applied, we look at the data through the lens of a new dimension: altitude. With the addition of this feature, the classes are now <a id="id686" class="indexterm"/>perfectly linearly separable. This is possible because we have obtained a new perspective on the data. In the left figure, we are viewing the mountain from a bird's eye view, while in the right one, we are viewing the mountain from a distance at the ground level. Here, the trend is obvious: snowy weather is found at higher altitudes.</p><p>SVMs with nonlinear <a id="id687" class="indexterm"/>kernels add additional dimensions to the data in order to create separation in this way. Essentially, the kernel trick involves a process of constructing new features that express mathematical relationships between measured characteristics. For instance, the altitude feature can be expressed mathematically as an interaction between latitude and longitude—the closer the point is to the center of each of these scales, the greater the altitude. This allows SVM to learn concepts that were not explicitly measured in the original data.</p><p>SVMs with nonlinear kernels are extremely powerful classifiers, although they do have some downsides, as shown in the following table:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Strengths</p>
</th><th style="text-align: left" valign="bottom">
<p>Weaknesses</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Can be used for classification or numeric prediction problems</li><li class="listitem" style="list-style-type: disc">Not overly influenced by noisy data and not very prone to overfitting</li><li class="listitem" style="list-style-type: disc">May be easier to use than neural networks, particularly due to the existence of several well-supported SVM algorithms</li><li class="listitem" style="list-style-type: disc">Gaining popularity due to its high accuracy and high-profile wins in data mining competitions</li></ul></div>
</td><td style="text-align: left" valign="top">
<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Finding the best model requires testing of various combinations of kernels and model parameters</li><li class="listitem" style="list-style-type: disc">Can be slow to train, particularly if the input dataset has a large number of features or examples</li><li class="listitem" style="list-style-type: disc">Results in a complex black box model that is difficult, if not impossible, to interpret</li></ul></div>
</td></tr></tbody></table></div><p>Kernel functions, in general, are of the following form. The function denoted by the Greek letter phi, that is, ϕ(x), is a mapping of the data into another space. Therefore, the general kernel function applies some transformation to the feature vectors <span class="emphasis"><em>x<sub>i</sub></em></span> and <span class="emphasis"><em>x<sub>j</sub></em></span> and combines them using the <span class="strong"><strong>dot product</strong></span>, which takes two vectors and returns a single number.</p><div class="mediaobject"><img src="graphics/3905_07_26.jpg" alt="Using kernels for non-linear spaces"/></div><p>Using this form, kernel functions have been developed for many different domains of data. A few of the most commonly used kernel functions are listed as follows. Nearly all SVM software <a id="id688" class="indexterm"/>packages will include these kernels, among many others.</p><p>The <span class="strong"><strong>linear kernel</strong></span><a id="id689" class="indexterm"/> does <a id="id690" class="indexterm"/>not transform the data at all. Therefore, it can be expressed simply as the dot product of the features:</p><div class="mediaobject"><img src="graphics/3905_07_27.jpg" alt="Using kernels for non-linear spaces"/></div><p>The <a id="id691" class="indexterm"/>
<span class="strong"><strong>polynomial kernel</strong></span> of degree <span class="emphasis"><em>d</em></span> adds a simple nonlinear transformation of the data:</p><div class="mediaobject"><img src="graphics/3905_07_28.jpg" alt="Using kernels for non-linear spaces"/></div><p>The <span class="strong"><strong>sigmoid kernel</strong></span><a id="id692" class="indexterm"/> results in a SVM model somewhat analogous to a neural network using a sigmoid activation function. The Greek letters kappa and delta are used as kernel parameters:</p><div class="mediaobject"><img src="graphics/3905_07_29.jpg" alt="Using kernels for non-linear spaces"/></div><p>The <span class="strong"><strong>Gaussian RBF kernel</strong></span><a id="id693" class="indexterm"/> is similar to a RBF neural network. The RBF kernel performs well on many types of data and is thought to be a reasonable starting point for many learning tasks:</p><div class="mediaobject"><img src="graphics/3905_07_30.jpg" alt="Using kernels for non-linear spaces"/></div><p>There is no reliable rule to match a kernel to a particular learning task. The fit depends heavily on the concept to be learned as well as the amount of training data and the relationships among the features. Often, a bit of trial and error is required by training and evaluating several SVMs on a validation dataset. This said, in many cases, the choice of kernel is arbitrary, as the <a id="id694" class="indexterm"/>performance may vary slightly. To see how<a id="id695" class="indexterm"/> this works in practice, let's apply our understanding of SVM classification to a real-world problem.</p></div></div>
<div class="section" title="Example &#x2013; performing OCR with SVMs"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec37"/>Example – performing OCR with SVMs</h1></div></div></div><p>Image processing is <a id="id696" class="indexterm"/>a difficult task for many types of machine learning algorithms. The relationships linking patterns of pixels to higher concepts <a id="id697" class="indexterm"/>are extremely complex and hard to define. For instance, it's easy for a human being to recognize a face, a cat, or the letter "A", but defining these patterns in strict rules is difficult. Furthermore, image data is often noisy. There can be many slight variations in how the image was captured, depending on the lighting, orientation, and positioning of the subject.</p><p>SVMs are well-suited to tackle the challenges of image data. Capable of learning complex patterns without being overly sensitive to noise, they are able to recognize visual patterns with a high degree of accuracy. Moreover, the key weakness of SVMs—the black box model representation—is less critical for image processing. If an SVM can differentiate a cat from a dog, it does not matter much how it is doing so.</p><p>In this section, we will develop a model similar to those used at the core of the <span class="strong"><strong>Optical Character Recognition</strong></span> (<span class="strong"><strong>OCR</strong></span>) software often bundled with desktop document scanners. The purpose of such software is to process paper-based documents by converting printed or handwritten text into an electronic form to be saved in a database. Of course, this is a difficult problem due to the many variants in handwritten style and printed fonts. Even so, software users expect perfection, as errors or typos can result in embarrassing or costly mistakes in a business environment. Let's see whether our SVM is up to the task.</p><div class="section" title="Step 1 – collecting data"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec88"/>Step 1 – collecting data</h2></div></div></div><p>When OCR software first <a id="id698" class="indexterm"/>processes a document, it divides the paper into a matrix such that each cell in the grid contains a single <a id="id699" class="indexterm"/>
<span class="strong"><strong>glyph</strong></span>, which is just a term referring to a letter, symbol, or number. Next, for each cell, the software will attempt to match the glyph to a set of all characters it recognizes. Finally, the individual characters would be combined back together into words, which optionally could be spell-checked against a dictionary in the document's language.</p><p>In this exercise, we'll <a id="id700" class="indexterm"/>assume that we have already developed the algorithm to partition the document into rectangular regions each consisting of a single character. We will also assume the document contains only alphabetic characters in English. Therefore, we'll simulate a process that involves matching glyphs to one of the 26 letters, A through Z.</p><p>To this end, we'll use a dataset donated to the<a id="id701" class="indexterm"/> UCI Machine Learning Data Repository (<a class="ulink" href="http://archive.ics.uci.edu/ml">http://archive.ics.uci.edu/ml</a>) by W. Frey and D. J. Slate. The dataset contains 20,000 examples of 26 English alphabet capital letters as printed using 20 different randomly reshaped and distorted black and white fonts.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note28"/>Note</h3><p>For more information on this dataset, refer to Slate DJ, Frey W. Letter recognition using Holland-style adaptive classifiers<span class="emphasis"><em>. Machine Learning. </em></span>1991; 6:161-182.</p></div></div><p>The following figure, published by Frey and Slate, provides an example of some of the printed glyphs. Distorted in this way, the letters are challenging for a computer to identify, yet are easily recognized by a human being:</p><div class="mediaobject"><img src="graphics/3905_07_31.jpg" alt="Step 1 – collecting data"/></div></div><div class="section" title="Step 2 – exploring and preparing the data"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec89"/>Step 2 – exploring and preparing the data</h2></div></div></div><p>According to the <a id="id702" class="indexterm"/>documentation provided by Frey and Slate, when<a id="id703" class="indexterm"/> the glyphs are scanned into the computer, they are converted into pixels and 16 statistical attributes are recorded.</p><p>The attributes measure such characteristics as the horizontal and vertical dimensions of the glyph, the proportion of black (versus white) pixels, and the average horizontal and vertical position of the pixels. Presumably, differences in the concentration of black pixels across various areas of the box should provide a way to differentiate among the 26 letters of the alphabet.</p><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip93"/>Tip</h3><p>To follow along with this example, download the <code class="literal">letterdata.csv</code> file from the Packt Publishing website, and save it to your R working directory.</p></div></div><p>Reading the data into R, we confirm that we have received the data with the 16 features that define each example of the letter class. As expected, letter has 26 levels:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; letters &lt;- read.csv("letterdata.csv")</strong></span>
<span class="strong"><strong>&gt; str(letters)</strong></span>
<span class="strong"><strong>'data.frame':  20000 obs. of 17 variables:</strong></span>
<span class="strong"><strong> $ letter: Factor w/ 26 levels "A","B","C","D",..</strong></span>
<span class="strong"><strong> $ xbox  : int  2 5 4 7 2 4 4 1 2 11 ...</strong></span>
<span class="strong"><strong> $ ybox  : int  8 12 11 11 1 11 2 1 2 15 ...</strong></span>
<span class="strong"><strong> $ width : int  3 3 6 6 3 5 5 3 4 13 ...</strong></span>
<span class="strong"><strong> $ height: int  5 7 8 6 1 8 4 2 4 9 ...</strong></span>
<span class="strong"><strong> $ onpix : int  1 2 6 3 1 3 4 1 2 7 ...</strong></span>
<span class="strong"><strong> $ xbar  : int  8 10 10 5 8 8 8 8 10 13 ...</strong></span>
<span class="strong"><strong> $ ybar  : int  13 5 6 9 6 8 7 2 6 2 ...</strong></span>
<span class="strong"><strong> $ x2bar : int  0 5 2 4 6 6 6 2 2 6 ...</strong></span>
<span class="strong"><strong> $ y2bar : int  6 4 6 6 6 9 6 2 6 2 ...</strong></span>
<span class="strong"><strong> $ xybar : int  6 13 10 4 6 5 7 8 12 12 ...</strong></span>
<span class="strong"><strong> $ x2ybar: int  10 3 3 4 5 6 6 2 4 1 ...</strong></span>
<span class="strong"><strong> $ xy2bar: int  8 9 7 10 9 6 6 8 8 9 ...</strong></span>
<span class="strong"><strong> $ xedge : int  0 2 3 6 1 0 2 1 1 8 ...</strong></span>
<span class="strong"><strong> $ xedgey: int  8 8 7 10 7 8 8 6 6 1 ...</strong></span>
<span class="strong"><strong> $ yedge : int  0 4 3 2 5 9 7 2 1 1 ...</strong></span>
<span class="strong"><strong> $ yedgex: int  8 10 9 8 10 7 10 7 7 8 ...</strong></span>
</pre></div><p>Recall that SVM learners require all features to be numeric, and moreover, that each feature is scaled to a fairly small interval. In this case, every feature is an integer, so we do not need to convert any factors into numbers. On the other hand, some of the ranges for these integer variables appear fairly wide. This indicates that we need to normalize or standardize the data. However, we can skip this step for now, because the R package that we will use for fitting the SVM model will perform the rescaling  automatically.</p><p>Given that the <a id="id704" class="indexterm"/>data <a id="id705" class="indexterm"/>preparation has been largely done for us, we can move directly to the training and testing phases of the machine learning process. In the previous analyses, we randomly divided the data between the training and testing sets. Although we could do so here, Frey and Slate have already randomized the data, and therefore suggest using the first 16,000 records (80 percent) to build the model and the next 4,000 records (20 percent) to test. Following their advice, we can create training and testing data frames as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; letters_train &lt;- letters[1:16000, ]</strong></span>
<span class="strong"><strong>&gt; letters_test  &lt;- letters[16001:20000, ]</strong></span>
</pre></div><p>With our data ready to go, let's start building our classifier.</p></div><div class="section" title="Step 3 – training a model on the data"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec90"/>Step 3 – training a model on the data</h2></div></div></div><p>When it comes <a id="id706" class="indexterm"/>to fitting an SVM model in R, there are several outstanding packages to choose from. The <code class="literal">e1071</code> package from the Department of Statistics at the Vienna University of Technology (TU Wien) provides an R interface to the award winning LIBSVM library, a widely used open source SVM program written in C++. If you are already familiar with LIBSVM, you may want to start here.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note29"/>Note</h3><p>For more information on<a id="id707" class="indexterm"/> LIBSVM, refer to the authors' website at <a class="ulink" href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/">http://www.csie.ntu.edu.tw/~cjlin/libsvm/</a>.</p></div></div><p>Similarly, if you're already invested in the <a id="id708" class="indexterm"/>SVMlight algorithm, the <code class="literal">klaR</code> package from the Department of Statistics at the Dortmund University of Technology (TU Dortmund) provides functions to work with this SVM implementation directly within R.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note30"/>Note</h3><p>For information<a id="id709" class="indexterm"/> on SVMlight, have a look at <a class="ulink" href="http://svmlight.joachims.org/">http://svmlight.joachims.org/</a>.</p></div></div><p>Finally, if you are starting from scratch, it is perhaps best to begin with the SVM functions in the <code class="literal">kernlab</code> package. An interesting advantage of this package is that it was developed natively in R rather than C or C++, which allows it to be easily customized; none of the internals are hidden behind the scenes. Perhaps even more importantly, unlike the other options, <code class="literal">kernlab</code> can be used with the <code class="literal">caret</code> package, which allows SVM models to be trained and evaluated using a variety of automated methods (covered in <a class="link" href="ch11.html" title="Chapter 11. Improving Model Performance">Chapter 11</a>, <span class="emphasis"><em>Improving Model Performance</em></span>).</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note31"/>Note</h3><p>For a more thorough introduction to <a id="id710" class="indexterm"/>
<code class="literal">kernlab</code>, please refer to the authors' paper at <a class="ulink" href="http://www.jstatsoft.org/v11/i09/">http://www.jstatsoft.org/v11/i09/</a>.</p></div></div><p>The syntax for <a id="id711" class="indexterm"/>training SVM classifiers with <code class="literal">kernlab</code> is as follows. If you do happen to be using one of the other packages, the commands are largely similar. By default, the <code class="literal">ksvm()</code> function uses the Gaussian RBF kernel, but a number of other options are provided.</p><div class="mediaobject"><img src="graphics/3905_07_32.jpg" alt="Step 3 – training a model on the data"/></div><p>To provide a baseline measure of SVM performance, let's begin by training a simple linear SVM classifier. If <a id="id712" class="indexterm"/>you haven't already, install the <code class="literal">kernlab</code> package to your library, using the <code class="literal">install.packages("kernlab")</code> command. Then, we can call the <code class="literal">ksvm()</code> function on the training data and specify the linear (that is, vanilla) kernel using the <code class="literal">vanilladot</code> option, as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; library(kernlab)</strong></span>
<span class="strong"><strong>&gt; letter_classifier &lt;- ksvm(letter ~ ., data = letters_train,</strong></span>
<span class="strong"><strong>                            kernel = "vanilladot")</strong></span>
</pre></div><p>Depending on the performance of your computer, this operation may take some time to complete. When it finishes, type the name of the stored model to see some basic information about the training parameters and the fit of the model.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; letter_classifier</strong></span>
<span class="strong"><strong>Support Vector Machine object of class "ksvm" </strong></span>

<span class="strong"><strong>SV type: C-svc  (classification) </strong></span>
<span class="strong"><strong> parameter : cost C = 1 </strong></span>

<span class="strong"><strong>Linear (vanilla) kernel function. </strong></span>

<span class="strong"><strong>Number of Support Vectors : 7037 </strong></span>

<span class="strong"><strong>Objective Function Value : -14.1746 -20.0072 -23.5628 -6.2009 -7.5524 -32.7694 -49.9786 -18.1824 -62.1111 -32.7284 -16.2209...</strong></span>

<span class="strong"><strong>Training error : 0.130062</strong></span>
</pre></div><p>This information tells us very little about how well the model will perform in the real world. We'll need to examine its performance on the testing dataset to know whether it generalizes well to unseen data.</p></div><div class="section" title="Step 4 – evaluating model performance"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec91"/>Step 4 – evaluating model performance</h2></div></div></div><p>The <code class="literal">predict()</code> function <a id="id713" class="indexterm"/>allows us to use the letter classification model to make predictions on the testing dataset:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; letter_predictions &lt;- predict(letter_classifier, letters_test)</strong></span>
</pre></div><p>Because we didn't specify the type parameter, the <code class="literal">type = "response"</code> default was used. This returns a vector containing a predicted letter for each row of values in the test data. Using the <code class="literal">head()</code> function, we can see that the first six predicted letters were <code class="literal">U</code>, <code class="literal">N</code>, <code class="literal">V</code>, <code class="literal">X</code>, <code class="literal">N</code>, and <code class="literal">H</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; head(letter_predictions)</strong></span>
<span class="strong"><strong>[1] U N V X N H</strong></span>
<span class="strong"><strong>Levels: A B C D E F G H I J K L M N O P Q R S T U V W X Y Z</strong></span>
</pre></div><p>To examine how <a id="id714" class="indexterm"/>well our classifier performed, we need to compare the predicted letter to the true letter in the testing dataset. We'll use the <code class="literal">table()</code> function for this purpose (only a portion of the full table is shown here):</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; table(letter_predictions, letters_test$letter)</strong></span>
<span class="strong"><strong>letter_predictions   A   B   C   D   E</strong></span>
<span class="strong"><strong>                 A 144   0   0   0   0</strong></span>
<span class="strong"><strong>                 B   0 121   0   5   2</strong></span>
<span class="strong"><strong>                 C   0   0 120   0   4</strong></span>
<span class="strong"><strong>                 D   2   2   0 156   0</strong></span>
<span class="strong"><strong>                 E   0   0   5   0 127</strong></span>
</pre></div><p>The diagonal values of <code class="literal">144</code>, <code class="literal">121</code>, <code class="literal">120</code>, <code class="literal">156</code>, and <code class="literal">127</code> indicate the total number of records where the predicted letter matches the true value. Similarly, the number of mistakes is also listed. For example, the value of <code class="literal">5</code> in row <code class="literal">B</code> and column <code class="literal">D</code> indicates that there were five cases where the letter <code class="literal">D</code> was misidentified as a <code class="literal">B</code>.</p><p>Looking at each type of mistake individually may reveal some interesting patterns about the specific types of letters the model has trouble with, but this is time consuming. We can simplify our evaluation instead by calculating the overall accuracy. This considers only whether the prediction was correct or incorrect, and ignores the type of error.</p><p>The following command returns a vector of <code class="literal">TRUE</code> or <code class="literal">FALSE</code> values, indicating whether the model's predicted letter agrees with (that is, matches) the actual letter in the test dataset:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; agreement &lt;- letter_predictions == letters_test$letter</strong></span>
</pre></div><p>Using the <code class="literal">table()</code> function, we see that the classifier correctly identified the letter in 3,357 out of the 4,000 test records:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; table(agreement)</strong></span>
<span class="strong"><strong>agreement</strong></span>
<span class="strong"><strong>FALSE  TRUE</strong></span>
<span class="strong"><strong>643 3357</strong></span>
</pre></div><p>In percentage terms, the accuracy is about 84 percent:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; prop.table(table(agreement))</strong></span>
<span class="strong"><strong>agreement</strong></span>
<span class="strong"><strong>  FALSE    TRUE</strong></span>
<span class="strong"><strong>0.16075 0.83925</strong></span>
</pre></div><p>Note that when <a id="id715" class="indexterm"/>Frey and Slate published the dataset in 1991, they reported a recognition accuracy of about 80 percent. Using just a few lines of R code, we were able to surpass their result, although we also have the benefit of over two decades of additional machine learning research. With this in mind, it is likely that we are able to do even better.</p></div><div class="section" title="Step 5 – improving model performance"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec92"/>Step 5 – improving model performance</h2></div></div></div><p>Our previous SVM model <a id="id716" class="indexterm"/>used the simple linear kernel function. By using a more complex kernel function, we can map the data into a higher dimensional space, and potentially obtain a better model fit.</p><p>It can be challenging, however, to choose from the many different kernel functions. A popular convention is to begin with the Gaussian RBF kernel, which has been shown to perform well for many types of data. We can train an RBF-based SVM, using the <code class="literal">ksvm()</code> function as shown here:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; letter_classifier_rbf &lt;- ksvm(letter ~ ., data = letters_train,</strong></span>
<span class="strong"><strong>                                kernel = "rbfdot")</strong></span>
</pre></div><p>Next, we make predictions as done earlier:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; letter_predictions_rbf &lt;- predict(letter_classifier_rbf,</strong></span>
<span class="strong"><strong>                                    letters_test)</strong></span>
</pre></div><p>Finally, we'll compare the accuracy to our linear SVM:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; agreement_rbf &lt;- letter_predictions_rbf == letters_test$letter</strong></span>
<span class="strong"><strong>&gt; table(agreement_rbf)</strong></span>
<span class="strong"><strong>agreement_rbf
FALSE  TRUE 
  275  3725</strong></span>
<span class="strong"><strong>&gt; prop.table(table(agreement_rbf))</strong></span>
<span class="strong"><strong>agreement_rbf</strong></span>
<span class="strong"><strong>  FALSE    TRUE</strong></span>
<span class="strong"><strong>0.06875 0.93125</strong></span>
</pre></div><div class="tip" title="Tip" style=""><div class="inner"><h3 class="title"><a id="tip94"/>Tip</h3><p>Your results may differ from those shown here due to randomness in the <code class="literal">ksvm</code> RBF kernel. If you'd like them to match exactly, use <code class="literal">set.seed(12345)</code> prior to running the ksvm() function.</p></div></div><p>By simply changing the kernel function, we were able to increase the accuracy of our character recognition model from 84 percent to 93 percent. If this level of performance is still unsatisfactory for <a id="id717" class="indexterm"/>the OCR program, other kernels could be tested, or the cost of constraints parameter C could be varied to modify the width of the decision boundary. As an exercise, you should experiment with these parameters to see how they impact the success of the final model.</p></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec92"/>Summary</h1></div></div></div><p>In this chapter, we examined two machine learning methods that offer a great deal of potential, but are often overlooked due to their complexity. Hopefully, you now see that this reputation is at least somewhat undeserved. The basic concepts that drive ANNs and SVMs are fairly easy to understand.</p><p>On the other hand, because ANNs and SVMs have been around for many decades, each of them has numerous variations. This chapter just scratches the surface of what is possible with these methods. By utilizing the terminology you learned here, you should be capable of picking up the nuances that distinguish the many advancements that are being developed every day.</p><p>Now that we have spent some time learning about many different types of predictive models from simple to sophisticated; in the next chapter, we will begin to consider methods for other types of learning tasks. These unsupervised learning techniques will bring to light fascinating patterns within the data.</p></div></body></html>