<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Preface</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span>Ensembling is a technique for combining two or more similar or dissimilar machine learning algorithms to create a model that delivers superior predictive power. This book will demonstrate how you can use a variety of weak algorithms to make a strong predictive model.</span><br/>
<br/>
<span>With its hands-on approach, you'll not only get up to speed on the basic theory, but also the application of various ensemble learning techniques. Using examples and real-world datasets, you'll be able to produce better machine learning models to solve supervised learning problems such as classification and regression. Later in the book, you'll go on to leverage ensemble learning techniques such as clustering to produce unsupervised machine learning models. As you progress, the chapters will cover different machine learning algorithms that are widely used in the practical world to make predictions and classifications. You'll even get to grips with using Python libraries such as scikit-learn and Keras to implement different ensemble models.</span><br/>
<br/>
<span>By the end of this book, you will be well versed in ensemble learning and have the skills you need to understand which ensemble method is required for which problem, in order to successfully implement them in real-world scenarios.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Who this book is for</h1>
                </header>
            
            <article>
                
<p>This book is for data analysts, data scientists, machine learning engineers, and other professionals who are looking to generate advanced models using ensemble techniques.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What this book covers</h1>
                </header>
            
            <article>
                
<p><a href="57f23be7-7e0d-4fa5-b7a5-08e0caf8e704.xhtml">Chapter 1</a>, <em>A Machine Learning Refresher</em>, <span>presents an overview of machine learning, including basic concepts such as training/test sets, performance measures, supervised and unsupervised learning, machine learning algorithms, and benchmark datasets.</span></p>
<p><a href="d7921006-351e-4c21-ab54-f1dc834557dc.xhtml">Chapter 2</a>, <em>Getting Started with Ensemble Learning</em>, <span>introduces the concept of ensemble learning, highlighting the problems that it solves as well as the problems that it poses.</span></p>
<p><a href="ad9aa66b-7b30-4779-8914-0ff58140b3e8.xhtml">Chapter 3</a>, <em>Voting</em>, introduces<span> the most simple ensemble learning technique, voting, while explaining the difference between hard and soft voting. You will learn how to implement a custom classifier, as well as use scikit-learn's implementation of hard/soft voting.</span></p>
<p><a href="49a05219-d6cb-4893-aaac-49280842b647.xhtml">Chapter 4</a>, <em>Stacking</em>, covers<span> meta learning (stacking) a more advanced ensemble learning method. After reading this chapter, you will be able to implement a stacking classifier in Python to use with scikit-learn classifiers.</span></p>
<p><a href="a0e9eea5-bc95-4d15-9679-fafce5718525.xhtml">Chapter 5</a>, <em>Bagging</em>,<span> introduces bootstrap resampling and the first generative ensemble learning technique, bagging. Furthermore, this chapter guides you through the process of implementing the technique in Python, as well as how to use the scikit-learn implementation.</span></p>
<p><a href="a1a92022-31ce-4c9b-9712-6b8282fac1af.xhtml">Chapter 6</a>, <em>Boosting</em>,<span> touches on more advanced subjects in ensemble learning. This chapter explains how popular boosting algorithms work and are implemented. Furthermore, it presents XGBoost, a highly successful distributed boosting library.</span></p>
<p><a href="0ef15819-a43a-46ca-bbfa-9457481b3311.xhtml">Chapter 7</a>, <em>Random Forests</em>,<span> goes through the process of creating random decision trees by subsampling the instances and features of a dataset. Moreover, this chapter explains how to utilize an ensemble of random trees to create a random forest. Finally, this chapter presents scikit-learn's implementations and how to use them.</span></p>
<p><a href="f6899a7f-8345-4d8f-8b74-f88ede323e5e.xhtml">Chapter 8</a>, <em>Clustering</em>, <span>introduces to the possibility of using ensembles for unsupervised learning tasks, such as clustering. Furthermore, the OpenEnsembles Python library is introduced, along with guidance on using it.</span></p>
<p><a href="b27e310c-a779-4c2a-85e1-eac25d9d17af.xhtml">Chapter 9</a>, <em>Classifying Fraudulent Transactions</em>, <span>presents an application for the classification of a real-world dataset, using ensemble learning techniques presented in earlier chapters. The dataset concerns fraudulent credit card transactions.</span></p>
<p><a href="d54eda3a-3681-4517-882a-0cb4575419e1.xhtml">Chapter 10</a>, <em>Predicting Bitcoin Prices</em>, <span>presents an application for the regression of a real-world dataset, using ensemble learning techniques presented in earlier chapters. The dataset concerns the price of the popular cryptocurrency Bitcoin.</span></p>
<p><a href="8278ebda-a6f3-426a-a2c8-076616701c95.xhtml">Chapter 11</a>, <em>Evaluating Sentiment on Twitter</em>,<span> presents an application for evaluating the sentiment of various tweets using a real-world dataset.</span></p>
<p><a href="52e04074-a76b-404f-b930-35f664b3a6c1.xhtml">Chapter 12</a>, <em>Recommending Movies with Keras</em>,<span> presents the process of creating a recommender system using ensembles of neural networks.</span></p>
<p><a href="22ce31ed-8650-48a7-9ddd-a2312e95ac32.xhtml"/><a href="22ce31ed-8650-48a7-9ddd-a2312e95ac32.xhtml">Chapter 13</a>, <em>Clustering World Happiness</em>, <span>presents the process of using an ensemble learning approach to cluster data from the World Happiness Report 2018.</span></p>
<p> </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">To get the most out of this book</h1>
                </header>
            
            <article>
                
<p>This book is aimed at analysts, data scientists, engineers, and other professionals who have an interest in generating advanced models that describe and generalize datasets of interest to them. It is assumed that the reader has basic experience of programming in Python and is familiar with elementary machine learning models. Furthermore, a basic understanding of statistics is assumed, although key points and more advanced concepts are briefly presented. Familiarity with Python's scikit-learn module would be greatly beneficial, although it is not strictly required. A standard Python installation is required. Anaconda Distribution (<a href="https://www.anaconda.com/distribution/">https://www.anaconda.com/distribution/</a>) greatly simplifies the task of installing and managing the various Python packages, although it is not necessary. Finally, a good <strong>Integrated Development Environment</strong> (<strong>IDE</strong>) is extremely useful for managing your code and debugging. In our examples, we usually utilize the Spyder IDE, which can be easily installed through Anaconda.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Download the example code files</h1>
                </header>
            
            <article>
                
<p>You can download the example code files for this book from your account at <a href="http://www.packt.com" target="_blank">www.packt.com</a>. If you purchased this book elsewhere, you can visit <a href="http://www.packt.com/support" target="_blank">www.packt.com/support</a> and register to have the files emailed directly to you.</p>
<p>You can download the code files by following these steps:</p>
<ol>
<li>Log in or register at <a href="http://www.packt.com" target="_blank">www.packt.com</a>.</li>
<li>Select the <span class="packt_screen">SUPPORT</span> tab.</li>
<li>Click on <span class="packt_screen">Code Downloads &amp; Errata</span>.</li>
<li>Enter the name of the book in the <span class="packt_screen">Search</span> box and follow the onscreen instructions.</li>
</ol>
<p>Once the file is downloaded, please make sure that you unzip or extract the folder using the latest versions of the following:</p>
<ul>
<li>WinRAR/7-Zip for Windows</li>
<li>Zipeg/iZip/UnRarX for macOS</li>
<li>7-Zip/PeaZip for Linux</li>
</ul>
<p><span>The code bundle for the book is also hosted on GitHub at</span><span> <a href="https://github.com/PacktPublishing/Hands-On-Ensemble-Learning-with-Python">https://github.com/PacktPublishing/Hands-On-Ensemble-Learning-with-Python</a></span><span>. </span><span>In case there's an update to the code, it will be updated on the existing GitHub repository.</span></p>
<p><span>We also have other code bundles from our rich catalog of books and videos available at</span><span> </span><strong><span class="Object"><a href="https://github.com/PacktPublishing/" target="_blank">https://github.com/PacktPublishing/</a></span></strong><span>. Check them out!</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Download the color images</h1>
                </header>
            
            <article>
                
<p>We also provide a PDF file that has color images of the screenshots/diagrams used in this book. You can download it here: <a href="https://static.packt-cdn.com/downloads/9781789612851_ColorImages.pdf">https://static.packt-cdn.com/downloads/9781789612851_ColorImages.pdf</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Code in action</h1>
                </header>
            
            <article>
                
<p><span class="fontstyle0">Visit the following link to check out videos of the code being run: <a href="http://bit.ly/2GfnRrv">http://bit.ly/2GfnRrv</a>. </span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Conventions used</h1>
                </header>
            
            <article>
                
<p>There are a number of text conventions used throughout this book.</p>
<p><kbd>CodeInText</kbd>: <span>Indicates c</span>ode words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles. <span>Here is an example:</span> "Mount the downloaded <kbd>WebStorm-10*.dmg</kbd> disk image file as another disk in your system."</p>
<p>A block of code is set as follows:</p>
<pre># --- SECTION 6 ---<br/># Accuracy of hard voting<br/>print('-'*30)<br/>print('Hard Voting:', accuracy_score(y_test, hard_predictions))</pre>
<p><strong>Bold</strong>: Indicates a new term, an important word, or w<span>ords that you see onscreen. For example, words in menus or dialog boxes appear in the text like this. Here is an example: "Thus, the preferred approach is to utilize <strong>K-fold cross validation</strong>.</span><span>"</span></p>
<div class="packt_infobox">Warnings or important notes appear like this.</div>
<div class="packt_tip">Tips and tricks appear like this.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Get in touch</h1>
                </header>
            
            <article>
                
<p>Feedback from our readers is always welcome.</p>
<p class="mce-root"><strong>General feedback</strong>: If you have questions about any aspect of this book, <span>mention the book title in the subject of your message and</span> email us at <kbd><span>customercare@packtpub.com</span></kbd>.</p>
<p><strong>Errata</strong>: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you have found a mistake in this book, we would be grateful if you would report this to us. Please visit <a href="http://www.packt.com/submit-errata" target="_blank">www.packt.com/submit-errata</a>, selecting your book, clicking on the Errata Submission Form link, and entering the details.</p>
<p><strong>Piracy</strong>: If you come across any illegal copies of our works in any form on the Internet, we would be grateful if you would provide us with the location address or website name. Please contact us at <kbd>copyright@packt.com</kbd> with a link to the material.</p>
<p class="mce-root"><strong>If you are interested in becoming an author</strong>: If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, please visit <a href="http://authors.packtpub.com/" target="_blank">authors.packtpub.com</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Reviews</h1>
                </header>
            
            <article>
                
<p>Please leave a review. Once you have read and used this book, why not leave a review on the site that you purchased it from? Potential readers can then see and use your unbiased opinion to make purchase decisions, we at Packt can understand what you think about our products, and our authors can see your feedback on their book. Thank you!</p>
<p>For more information about Packt, please visit <a href="http://www.packt.com/" target="_blank">packt.com</a>.<a href="https://www.packtpub.com/" target="_blank"/></p>


            </article>

            
        </section>
    </body></html>