["```py\nimport pandas as pd\n\n# Reading in the dataset \n\ndf = pd.read_csv('fraud_prediction.csv')\n```", "```py\nfrom sklearn.model_selection import train_test_split\n\n#Creating the features and target\n\nfeatures = df.drop('isFraud', axis = 1).values\ntarget = df['isFraud'].values\n\n#Creating the training and testing data\n\nX_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42, stratify = target)\n```", "```py\nfrom sklearn import linear_model\n\n#Initializing an logistic regression object\n\nlogistic_regression = linear_model.LogisticRegression()\n\n#Fitting the model to the training and test sets\n\nlogistic_regression.fit(X_train, y_train)\n```", "```py\n#Accuracy score of the logistic regression model\n\nlogistic_regression.score(X_test, y_test)\n```", "```py\n#Building the model with L1 penality \n\nlogistic_regression = linear_model.LogisticRegression(penalty='l1')\n\n#Using GridSearchCV to search for the best parameter\n\ngrid = GridSearchCV(logistic_regression, {'C':[0.0001, 0.001, 0.01, 0.1, 10]})\ngrid.fit(X_train, y_train)\n\n# Print out the best parameter\n\nprint(\"The most optimal inverse regularization strength is:\", grid.best_params_)\n```", "```py\n#Initializing an logistic regression object\n\nlogistic_regression = linear_model.LogisticRegression(C = 10, penalty = 'l1')\n\n#Fitting the model to the training and test sets\n\nlogistic_regression.fit(X_train, y_train)\n```", "```py\n#Accuracy score of the logistic regression model\n\nlogistic_regression.score(X_test, y_test)\n```", "```py\ntrain_errors = []\ntest_errors = []\n\nC_list = [0.0001, 0.001, 0.01, 0.1, 10, 100, 1000]\n\n# Evaluate the training and test classification errors for each value of C\n\nfor value in C_list:\n\n # Create LogisticRegression object and fit\n logistic_regression = linear_model.LogisticRegression(C= value, penalty = 'l1')\n logistic_regression.fit(X_train, y_train)\n\n # Evaluate error rates and append to lists\n train_errors.append(logistic_regression.score(X_train, y_train) )\n test_errors.append(logistic_regression.score(X_test, y_test))\n\n# Plot results\nplt.semilogx(C_list, train_errors, C_list, test_errors)\nplt.legend((\"train\", \"test\"))\nplt.ylabel('Accuracy Score')\nplt.xlabel('C (Inverse regularization strength)')\nplt.show()\n```", "```py\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\n#Setting up the scaling pipeline \n\npipeline_order = [('scaler', StandardScaler()), ('logistic_reg', linear_model.LogisticRegression(C = 10, penalty = 'l1'))]\n\npipeline = Pipeline(pipeline_order)\n\n#Fitting the classfier to the scaled dataset \n\nlogistic_regression_scaled = pipeline.fit(X_train, y_train)\n\n#Extracting the score \n\nlogistic_regression_scaled.score(X_test, y_test)\n```", "```py\n#Printing out the coefficients of each variable \n\nprint(logistic_regression.coef_)\n```", "```py\n#Printing out the intercept of the model\n\nprint(logistic_regression.intercept_)\n```"]