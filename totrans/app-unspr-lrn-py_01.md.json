["```py\n    import math\n    import numpy as np\n    def dist(a, b):\n        return math.sqrt(math.pow(a[0]-b[0],2) + math.pow(a[1]-b[1],2))\n    ```", "```py\n    centroids = [ (2, 5), (8, 3), (4,5) ]\n    x = (0, 8)\n    ```", "```py\n    centroid_distances =[]\n    for centroid in centroids:\n        centroid_distances.append(dist(x,centroid))\n    print(centroid_distances)\n    print(np.argmin(centroid_distances))\n    ```", "```py\n    [3.605551275463989, 9.433981132056603, 5.0]\n    0\n    ```", "```py\n    cluster_1_points =[ (0,8), (3,8), (3,4) ]\n    ```", "```py\n    mean =[ (0+3+3)/3, (8+8+4)/3 ]\n    print(mean)\n    ```", "```py\n    [2.0, 6.666666666666667]\n    ```", "```py\n    from sklearn.datasets import make_blobs\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import math\n    %matplotlib inline\n    ```", "```py\n    X, y = make_blobs(n_samples=1500, centers=3, \n                      n_features=2, random_state=800)\n    centroids = [[-6,2],[3,-4],[-5,10]]\n    ```", "```py\n    X\n    ```", "```py\n    array([[-3.83458347,  6.09210705],\n           [-4.62571831,  5.54296865],\n           [-2.87807159, -7.48754592],\n           ...,\n            [-3.709726  , -7.77993633],\n            [-8.44553266, -1.83519866],\n            [-4.68308431,  6.91780744]])\n    ```", "```py\n    plt.scatter(X[:, 0], X[:, 1], s=50, cmap='tab20b')\n    plt.show()\n    ```", "```py\n    y\n    ```", "```py\n    array([2, 2, 1, ..., 1, 0, 2])\n    ```", "```py\n    plt.scatter(X[:, 0], X[:, 1], c=y,s=50, cmap='tab20b')\n    plt.show()\n    ```", "```py\n    def dist(a, b):\n        return math.sqrt(math.pow(a[0]-b[0],2) + math.pow(a[1]-b[1],2))\n    ```", "```py\n    from scipy.spatial.distance import cdist\n    ```", "```py\n    X[105:110]\n    ```", "```py\n    array([[-3.09897933,  4.79407445],\n           [-3.37295914, -7.36901393],\n            [-3.372895  ,  5.10433846],\n            [-5.90267987, -3.28352194],\n            [-3.52067739,  7.7841276 ]])\n    ```", "```py\n    for x in X[105:110]:\n        calcs = []\n        for c in centroids:\n            calcs.append(dist(x, c))\n        print(calcs, \"Cluster Membership: \", np.argmin(calcs, axis=0))\n    ```", "```py\n    def k_means(X, K):\n        # Keep track of history so you can see k-means in action\n        centroids_history = []\n        labels_history = []\n        rand_index = np.random.choice(X.shape[0], K)  \n        centroids = X[rand_index]\n        centroids_history.append(centroids)\n        while True:\n    # Euclidean distances are calculated for each point relative to\n    # centroids, and then np.argmin returns the index location of the\n    # minimal distance - which cluster a point is assigned to\n            labels = np.argmin(cdist(X, centroids), axis=1)\n            labels_history.append(labels)\n        # Take mean of points within clusters to find new centroids\n            new_centroids = np.array([X[labels == i].mean(axis=0) \n                                      for i in range(K)])\n            centroids_history.append(new_centroids)\n\n    # If old centroids and new centroids no longer change, k-means is\n    # complete and end. Otherwise continue\n            if np.all(centroids == new_centroids):\n                break\n            centroids = new_centroids\n\n        return centroids, labels, centroids_history, labels_history\n    centers, labels, centers_hist, labels_hist = k_means(X, 3)\n    ```", "```py\n    for x, y in history:\n        plt.figure(figsize=(4,3))\n        plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='tab20b');\n        plt.scatter(x[:, 0], x[:, 1], c='red')\n        plt.show()\n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    import matplotlib.pyplot as plt\n    from sklearn.metrics import silhouette_score\n    from scipy.spatial.distance import cdist\n    iris = pd.read_csv('iris_data.csv', header=None)\n    iris.columns = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'species']\n    ```", "```py\n    X = iris[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n    ```", "```py\n    def k_means(X, K):\n    #Keep track of history so you can see k-means in action\n        centroids_history = []\n        labels_history = []\n        rand_index = np.random.choice(X.shape[0], K)\n        centroids = X[rand_index]\n        centroids_history.append(centroids)\n        while True:\n    # Euclidean distances are calculated for each point relative to\n    # centroids, #and then np.argmin returns\n    # the index location of the minimal distance - which cluster a point\n    # is #assigned to\n            labels = np.argmin(cdist(X, centroids), axis=1)\n            labels_history.append(labels)\n    #Take mean of points within clusters to find new centroids:\n            new_centroids = np.array([X[labels == i].mean(axis=0)\n                                      for i in range(K)])\n            centroids_history.append(new_centroids)\n\n    # If old centroids and new centroids no longer change, k-means is\n    # complete and end. Otherwise continue\n            if np.all(centroids == new_centroids):\n                break\n            centroids = new_centroids\n\n        return centroids, labels, centroids_history, labels_history\n    ```", "```py\n    X_mat = X.values\n    ```", "```py\n    centroids, labels, centroids_history, labels_history = k_means(X_mat, 3)\n    ```", "```py\n    silhouette_score(X[['PetalLengthCm','PetalWidthCm']], labels)\n    ```", "```py\n    0.6214938502379446\n    ```", "```py\n['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'species']\n```"]