- en: Voting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The most intuitive of all ensemble learning methods is **majority voting**.
    It is intuitive, as the aim is to output the most popular (or most voted for)
    of the base learner''s predictions. This chapter covers the basic theory as well
    as practical implementations concerning majority voting. By the end of this chapter,
    you will be able to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Understand majority voting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand the difference between hard and soft majority voting and their respective
    strengths and weaknesses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement both versions in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Utilize the voting technique to improve the performance of classifiers on the
    breast cancer dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will require basic knowledge of machine learning techniques and algorithms.
    Furthermore, a knowledge of python conventions and syntax is required. Finally,
    familiarity with the NumPy library will greatly help the reader to understand
    some custom algorithm implementations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code files of this chapter can be found on GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Hands-On-Ensemble-Learning-with-Python/tree/master/Chapter03](https://github.com/PacktPublishing/Hands-On-Ensemble-Learning-with-Python/tree/master/Chapter03)'
  prefs: []
  type: TYPE_NORMAL
- en: Check out the following video to see the Code in Action: [http://bit.ly/2M52VY7](http://bit.ly/2M52VY7).
  prefs: []
  type: TYPE_NORMAL
- en: Hard and soft voting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Majority voting is the simplest ensemble learning technique that allows the
    combination of multiple base learner''s predictions. Similar to how elections
    work, the algorithm assumes that each base learner is a voter and each class is
    a contender. The algorithm takes votes into consideration in order to elect a
    contender as the winner. There are two main approaches to combining multiple predictions
    with voting: one is hard voting and the other is soft voting. We present both
    approaches here.'
  prefs: []
  type: TYPE_NORMAL
- en: Hard voting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Hard voting combines a number of predictions by assuming that the most voted
    class is the winner. In a simple case of two classes and three base learners,
    if a target class has at least two votes, it becomes the ensemble''s output, as
    shown in the following diagram. Implementing a hard voting classifier is as simple
    as counting the votes for each target class:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cf089773-85dd-4f2a-84de-a4c10f12254f.png)'
  prefs: []
  type: TYPE_IMG
- en: Voting with two classes and three base learners
  prefs: []
  type: TYPE_NORMAL
- en: For example, let's say that there are three different base learners, who are predicting
    whether a sample belongs to one of three classes with a certain probability (*Table
    1*).
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following table, each learner predicts the probability that the instance
    belongs to a certain class:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Class A** | **Class B** | **Class C** |'
  prefs: []
  type: TYPE_TB
- en: '| **Learner 1** | 0.5 | 0.3 | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| **Learner 2** | 0 | 0.48 | 0.52 |'
  prefs: []
  type: TYPE_TB
- en: '| **Learner 3** | 0.4 | 0.3 | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: Assigned class probabilities
  prefs: []
  type: TYPE_NORMAL
- en: In this example, class A has two votes, while class C has only one. According
    to hard voting, class A will be the prediction of the ensemble. It's a fairly
    robust method of combining many base learners, although it doesn't take into account
    that some classes may be chosen by a base learner only because they are marginally
    better than the others.
  prefs: []
  type: TYPE_NORMAL
- en: Soft voting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Soft voting takes into account the probability of the predicted classes. In
    order to combine the predictions, soft voting calculates the average probability
    of each class and assumes that the winner is the class with the highest average
    probability.In the simple case of three base learners and two classes, we must
    take into consideration the predicted probability for each class and average them
    across the three learners:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9a69ad7d-0f1d-4116-abd2-572423922f69.png)'
  prefs: []
  type: TYPE_IMG
- en: Soft voting with two classes and three base learners
  prefs: []
  type: TYPE_NORMAL
- en: Using our previous example, and by taking the average of each column for *Table
    1*, we can expand it, adding a row for the average probability.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table shows the predicted probabilities for each class by each
    learner, as well as the average probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Class A** | **Class B** | **Class C** |'
  prefs: []
  type: TYPE_TB
- en: '| **Learner 1** | 0.5 | 0.3 | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| **Learner 2** | 0 | 0.48 | 0.52 |'
  prefs: []
  type: TYPE_TB
- en: '| **Learner 3** | 0.4 | 0.3 | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| **Average** | 0.3 | 0.36 | 0.34 |'
  prefs: []
  type: TYPE_TB
- en: Predicted probabilities for each class by each learner, as well as the average
    probability
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, class A has an average probability of 0.3, class B has an average
    probability of 0.36, and class C has an average probability of 0.34, making class
    B the winner. Note that class B is not selected by any base learner as the predicted
    class, but by combining the predicted probabilities, class B arises as the best
    compromise between the predictions.
  prefs: []
  type: TYPE_NORMAL
- en: In order for soft voting to be more effective than hard voting, the base classifiers
    must produce good estimates regarding the probability that a sample belongs to
    a specific class. If the probabilities are meaningless (for example, if they are
    always 100% for one class and 0% for all others), soft voting could be even worse
    than hard voting.
  prefs: []
  type: TYPE_NORMAL
- en: 'A note on voting: it is impossible to have a perfect voting system, as has
    been proved by Dr. Kenneth Arrow with his impossibility theorem. Nonetheless,
    certain types of voting systems can better reflect the preferences of a population.
    Soft voting better reflects the individual learner''s preferences, as it takes
    into account the rating (probabilities) instead of the ranking (predicted class).'
  prefs: []
  type: TYPE_NORMAL
- en: For more on the impossibility theorem, see A difficulty in the concept of social
    welfare. *Arrow, K.J., 1950*. *Journal of political economy*, 58(4), pp.328-346.
  prefs: []
  type: TYPE_NORMAL
- en: ​Python implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The simplest way to implement hard voting in Python is to use scikit-learn to
    create base learners, train them on some data, and combine their predictions on
    test data. In order to do so, we will go through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Load the data and split it into train and test sets
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create some base learners
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train them on the train data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Produce predictions for the test data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Combine predictions using hard voting
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare the individual learner's predictions as well as the combined predictions
    with the ground truth (actual correct classes)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Although scikit-learn has implementations for voting, by creating a custom implementation,
    it will be easier to understand how the algorithm works. Furthermore, it will
    enable us to better understand how to process and analyze a base learner's outputs.
  prefs: []
  type: TYPE_NORMAL
- en: Custom hard voting implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to implement a custom hard voting solution, we will use three base
    learners: a **Perceptron** (a neural network with a single neuron), a **Support
    Vector Machine** (**SVM**), and a **Nearest Neighbor**. These are contained in
    the `sklearn.linear_model`, `sklearn.svm`, and `sklearn.neighbors` packages. Furthermore,
    we will use the `argmax` function from NumPy. This function returns the index
    of an array''s (or array-like data structure) element with the highest value.
    Finally, `accuracy_score` will calculate the accuracy of each classifier on our
    test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We then instantiate our base learners. We hand-picked their hyperparameters
    to ensure that they are diverse in order to produce a well-performing ensemble.
    As `breast_cancer` is a classification dataset, we use `SVC`, the classification
    version of SVM, along with `KNeighborsClassifier` and `Perceptron`. Furthermore,
    we set the random state of `Perceptron` to 0 in order to ensure the reproducibility
    of our example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We split the data into train and test sets, using 100 instances for our test
    set and train our base learners on the train set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'By storing each base learner''s prediction in `predictions_1`, `predictions_2`,
    and `predictions_3`, we can further analyze and combine them into our ensemble.
    Note that we trained each classifier individually; additionally, as well as that
    each classifier produces predictions for the test data autonomously. As mentioned
    in [Chapter 2](d7921006-351e-4c21-ab54-f1dc834557dc.xhtml), *Getting Started with
    Ensemble Learning*, this is the main characteristic of non-generative ensemble
    methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Following the predictions, we combine the predictions of each base learner
    for each test instance. The `hard_predictions` list will contain the ensemble''s
    predictions (output). By iterating over every test sample with `for i in range(test_samples)`,
    we count the total number of votes that each class has received from the three
    base learners. As the dataset contains only two classes, we need a list of two
    elements: `counts = [0 for _ in range(2)]`. In `# --- SECTION 3 ---`, we stored
    each base learner''s predictions in an array. Each one of those array''s elements
    contains the index of the instance''s predicted class (in our case, 0 and 1).
    Thus, we increase the corresponding element''s value in `counts[predictions_1[i]]` by
    one to count the base learner''s vote. Then, `argmax(counts)` returns the element
    (class) with the highest number of votes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we calculate the accuracy of the individual base learners as well
    as the ensemble with `accuracy_score`, and print them on screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The final output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Analyzing our results using Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The final accuracy achieved is 1% better than the best of the three classifiers
    (the **k-Nearest Neighbors** (**k-NN**) classifier). We can visualize the learner's
    errors in order to examine why the ensemble performs in this specific way.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we `import matplotlib` and use a specific `seaborn-paper` plotting style
    with `mpl.style.use(''seaborn-paper'')`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we calculate the errors by subtracting our prediction from the actual
    target. Thus, we get a -1 each time the learner predicts a positive (1) when the
    true class is negative (0), and a 1 when it predicts a negative (0) while the
    true class is positive (1). If the prediction is correct, we get a zero (0):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: For each base learner, we plot the instances where they have predicted the wrong
    class. Our aim is to scatter plot the `x` and `y` lists. These lists will contain
    the instance number (the `x` list) and the type of error (the `y` list). With `plt.scatter`,
    we can specify the coordinates of our points using the aforementioned lists, as
    well as specify how these points are depicted. This is important in order to ensure
    that we can simultaneously visualize all the errors of the classifiers as well
    as the relationship between them.
  prefs: []
  type: TYPE_NORMAL
- en: 'The default shape for each point is a circle. By specifying the `marker` parameter,
    we can alter this shape. Furthermore, with the `s` parameter, we can specify the
    marker''s size. Thus, the first learner (k-NN) will have a round shape of size
    120, the second learner (Perceptron) will have an `x` shape of size 60, and the
    third learner (SVM) will have a round shape of size 20\. The `if not errors_*[i]
    == 0` guard ensures that we will not store correctly classified instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we specify the figure''s title and labels, and plot the legend:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'As the following shows, there are five samples where at least two learners
    predict the wrong class. These are the 5 cases out of the 100 that the ensemble
    predicts wrong, as the most voted class is wrong, thus producing a 95% accuracy.
    In all other cases, two out of three learners predict the correct class, thus
    the ensemble predicts the correct class as it is the most voted:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0ba4d397-fc7a-43f0-8009-ef44003bcf9a.png)'
  prefs: []
  type: TYPE_IMG
- en: Learner errors on the test set
  prefs: []
  type: TYPE_NORMAL
- en: Using scikit-learn
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The scikit-learn library includes many ensemble learning algorithms, including
    voting. In order to implement hard voting, we will follow the same procedure as
    we did previously, except this time, we will not implement the individual fitting,
    predicting, and voting ourselves. Instead, we will use the provided implementation,
    which enables quick and easy training and testing.
  prefs: []
  type: TYPE_NORMAL
- en: Hard voting implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Similarly to our custom implementation, we import the required libraries, split
    our train and test data, and instantiate our base learners. Furthermore, we import
    scikit-learn''s `VotingClassifier` voting implementation from the `sklearn.ensemble` package,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Following the above code, we instantiate the `VotingClassifier` class, passing
    as a parameter a list of tuples with the names and objects of our base classifiers.
    Note that passing the parameters outside of a list will result in an error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, having instantiated the classifier, we can use it in the same way as any
    other classifier, without having to tend to each base learner individually. The
    following two sections execute the fitting and prediction for all base learners
    as well as the calculation of the most voted class for each test instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can print the accuracy of the ensemble:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the same as our custom implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Note that `VotingClassifier` will not fit the objects that you pass as parameters,
    but will, instead, clone them and fit the cloned objects. Thus, if you try to
    print the accuracy of each individual base learner on the test set, you will get `NotFittedError`,
    as the objects that you have access to are, in fact, not fitted. This is the only
    drawback of using scikit-learn's implementation over a custom one.
  prefs: []
  type: TYPE_NORMAL
- en: Soft voting implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Scikit-learn's implementation allows for soft voting as well. The only requirement
    is that the base learners implement the `predict_proba` function. In our example,
    `Perceptron` does not implement the function at all, while `SVC` only produces
    probabilities when it is passed the `probability=True` argument. Having these
    limitations in mind, we swap our `Perceptron` with a Naive Bayes classifier implemented
    in the `sklearn.naive_bayes` package.
  prefs: []
  type: TYPE_NORMAL
- en: 'To actually use soft voting, the `VotingClassifier` object must be initialized
    with the `voting=''soft''` argument. Except for the changes mentioned here, the
    majority of the code remains the same. Load the libraries and datasets, and produce
    a train/test split as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Instantiate the base learners and voting classifier. We use a Gaussian Naive
    Bayes implemented as `GaussianNB`. Note that we use `probability=True` in order
    for the `GaussianNB` object to be able to produce probabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We fit both `VotingClassifier` and the individual learners. We want to analyze
    our results, and, as mentioned earlier, the classifier will not fit the objects
    that we pass as arguments, but will instead clone them. Thus, we have to manually
    fit our learners as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We predict the test set''s targets using both the voting ensemble and the individual
    learners:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we print the accuracy of each base learner and the soft voting ensemble''s
    accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The final output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Analyzing our results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As is evident, the accuracy achieved by soft voting is 2% worse than the best
    learner and on par with the second-best learner. We would like to analyze our
    results similarly to how we analyzed the performance of our hard voting custom
    implementation. But as soft voting takes into account the predicted class probabilities,
    we cannot use the same approach. Instead, we will plot the predicted probability
    for each instance to be classified as positive by each base learner as well as
    the average probability of the ensemble.
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, we `import matplotlib` and set the plotting style:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'We calculate the ensemble''s errors with `errors = y_test-hard_predictions`
    and get the predicted probabilities of each base learner with the `predict_proba(x_test)` function.
    All base learners implement this function, as it is a requirement for utilizing
    them in a soft voting ensemble:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Following this, for each wrongly classified instance, we store the predicted
    probability that the instance belongs to in class 0\. We also implement this for
    each base learner, as well as their average. Each `probabilities_*` array,  is
    a two-dimensional array. Each row contains the predicted probability that the
    corresponding instance belongs to class 0 or class 1\. Thus, storing one of the
    two is sufficient. In the case of a dataset with *N* classes, we would have to
    store at least *N*-1 probabilities in order to get a clear picture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we plot the probabilities as bars of different widths with `plt.bar`.
    This ensures that any overlapping bars will still be visible. The third `plt.bar`
    argument dictates the bar''s width. We scatter plot the average probability as
    a black ''X'' and ensure that it will be plotted over any bar with `zorder=10`.
    Finally, we plot a threshold line at 0.5 probability with `plt.plot(y, c=''k'',
    linestyle=''--'')`, ensuring that it will be a black dotted line with `c=''k'',
    linestyle=''--''`. If the average probability is above the line, the sample is
    classified as positive, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code outputs the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/557d63bc-fadb-42d6-bdea-ace7257b02da.png)'
  prefs: []
  type: TYPE_IMG
- en: Predicted and average probabilities for the test set
  prefs: []
  type: TYPE_NORMAL
- en: 'As we can see, only two samples have an extreme average probability (sample
    22 with p = 0.98 and 67 with p = 0.001). The other four are quite close to 50%.
    For three out of these four samples, SVM seems to assign a very high probability
    to the wrong class, thus greatly affecting the average probability. If SVM did
    not overestimate the probability of these samples as much, the ensemble could
    well out perform each individual learner. For the two extreme cases, nothing can
    be done, as all three learners agree on the miss classification. We can try to
    swap our SVM for another k-NN with a significantly higher number of neighbors.
    In this case, `(learner_3 = neighbors.KNeighborsClassifier(n_neighbors=50) )`,
    we can see that the ensemble''s accuracy is greatly increased. The ensemble''s
    accuracies and errors are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Take a look at the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f7a6f54d-3272-4c1a-bfc4-430a293f2a76.png)'
  prefs: []
  type: TYPE_IMG
- en: Predicted and average probabilities for the test set with two k-NNs
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we presented the most basic ensemble learning method: voting.
    Although it is quite simple, it can prove to be effective and an easy way to combine
    many machine learning models. We presented hard and soft voting, a custom implementation
    for hard voting, and scikit-learn implementations for both hard and soft voting.
    Finally, we presented a way to analyze the ensemble''s performance by plotting
    each base learner''s errors using `matplotlib`. The chapter''s key points are
    summarized below.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Hard voting** assumes that the most voted class is the winner. **Soft voting**
    assumes that the class with the highest average probability is the winner. **Soft
    voting** requires that the base classifiers predict the **probability** of each
    class for every instance with a relatively high accuracy. Scikit-learn implements
    voting ensembles using the `VotingClassifier` class. An array of tuples in the
    form of `[(learner_name, learner_object),…]` is passed to `VotingClassifier`.
    The `VotingClassifier` does not train the objects passed as arguments. Instead,
    a copy is generated and trained. The default mode of `VotingClassifier `implements
    hard voting. To use soft voting, pass the `voting=''soft''` argument to the constructor. Soft
    voting requires that the base learners return probabilities for each prediction. If
    a base learner greatly takes over or underestimates the probabilities, the ensemble''s
    predictive ability will suffer.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss about another non-generative method, Stacking,
    and how it can be utilized in both regression and classification problems.
  prefs: []
  type: TYPE_NORMAL
