<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Use Machine Learning to Forecast the Stock Market</h1>
                </header>
            
            <article>
                
<p>Just recently, I was reading an article that described the tremendous success of a particular treatment in combating the <strong><span>Methicillin-resistant Staphylococcus aureus</span></strong><span> </span>(<strong>MRSA</strong>) <span>superbug</span>. If you haven't heard of MRSA directly, it is likely you've heard something about current concerns that we are headed toward a time when our antibiotics will no longer be effective. This is largely an inevitable phenomenon that occurs because some bugs in the population are genetically more resistant to the relevant drug. When bugs that are susceptible to the drug are wiped out during treatment, the remaining drug-resistant bugs then reproduce and become the dominant variant in the population. To combat this, scientists are constantly pushing the boundaries of science to find new ways to combat these bugs.</p>
<p>In biology, this situation is called a <strong>Red Queen's race</strong>: the term comes from a quote in Lewis Carol's <em>Through the Looking Glass:</em></p>
<div class="packt_quote">"Now, here, you see, it takes all the running you can do, to keep in the same place."</div>
<p>This effectively describes the situation we're in with antibiotics, but perhaps the answer is not to be found in moving on to new, ever-more advanced drugs. Perhaps the answer might be found in understanding the larger cycle at play and using it to our advantage.</p>
<p>That new treatment for MRSA I was discussing earlier? That was actually from a 10<sup>th</sup> century book of medical potions called <strong>Bald's Leechbook</strong>. Among the listed ingredients were garlic, wine, and onions. This combination was found to have surpassed the results for our current treatment-of-last-resort, <strong>vancomycin</strong>.</p>
<p>But what does any of this have to do with forecasting the stock market? I would like to suggest that the very same phenomenon is at play in both scenarios. For example, every so often, a paper is published that alerts the financial world to the existence of a phenomenon that is a profitable anomaly. Most likely, this phenomenon is the downstream effect of some externally imposed, real-world constraint.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Take, for example, year-end tax loss sales. Because of the nature of tax laws, it makes sense for traders to sell their losses at the end of the year. This imposes downward price pressure on losing stocks toward year end. The falling prices then mean the stocks can be discounted beyond their fair value. This also means that, in January, the downward pressure is gone, replaced by upward pressure as new money is put to work in these undervalued assets. But once that phenomenon has been broadcast, it only makes sense for traders to attempt to get ahead of it and begin buying those stocks in late December and selling to those other traders who are expected to be buyers in January. These new traders, by entering the market, have now diluted the effect. They are relieving the year-end selling pressure and decreasing the January buying pressure. The effect is essentially arbitraged away right along with the profitability. What once worked no longer works and traders will begin to abandon the strategy and move on to the next new thing.</p>
<p>By now, I hope you are beginning to see the parallels. It is likely that the garlic, wine, and onions combination was once a very effective cure for bacterial infections that gradually lost its effectiveness as the bacteria adapted. Having been abandoned long ago as a cure, the bacteria had no reason to avoid the original genes that made them susceptible to this treatment. There are real-world constraints that make it nearly inevitable that these types of cycles will occur—both in living organisms and in markets. The key is to use this to our advantage.</p>
<p>In this chapter, we'll spend some time discussing how to build and test a trading strategy. We'll spend even more time, however, on how <em>not</em> to do it. There are countless pitfalls to avoid when trying to devise you own system, and it is nearly an impossible task, but it can be a lot of fun, and sometimes it can even be profitable. With that said, don't do dumb things such as risking money you can't afford to lose.</p>
<div class="packt_infobox">If you do decide to use anything you learned here to trade, you're on your own. This shouldn't be deemed investment advice of any kind, and I accept no responsibility for your actions.</div>
<p><span class="HeaderFooterPACKT">In this chapter, we will cover the following topics:</span></p>
<ul>
<li>Types of market analysis</li>
<li>What does research tell us about the stock market?</li>
<li>How to develop a trading system</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Types of market analysis</h1>
                </header>
            
            <article>
                
<p>Let's begin with a discussion of some key terms and methods of analysis when dealing with financial markets. Though there are countless financial instruments, including stocks, bonds, ETFs, currencies, and swaps, we'll limit our discussion to stocks and the stock market. A stock is simply a fractional share of ownership in a public company. The price of a stock is expected to increase when future prospects for the company rise, and decrease as these prospects decline.</p>
<p>There are generally two camps that investors fall into. The first are the fundamental analysts. These analysts pore through company financials looking for information that indicates that, somehow, the market is undervaluing the shares of the company. These investors look at various factors, such as revenue, earnings, and cash flow, and various ratios of the values. This frequently involves looking at how one company's financials compare to another's.</p>
<p>The second camp of investors is the technical analysts. Technical analysts believe that share prices already reflect all publicly available information and that looking through the fundamentals is largely a waste of time. They believe that by looking at historical prices—stock charts—you can see areas where prices are likely to rise, fall, or stagnate. Generally, they feel that these charts reveal clues to investor psychology.</p>
<p>What both groups have in common is an underlying belief that the right analysis can lead to profits. But is that true?</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What does research tell us about the stock market?</h1>
                </header>
            
            <article>
                
<p>Perhaps the most influential theory of the stock market over the last 50 years is that of the efficient market hypothesis. This theory, developed by Eugene Fama, stipulates that markets are rational and that all the available information is appropriately reflected in stock prices. As such, it is impossible for an investor to consistently <em>beat the market</em> on a risk-adjusted basis. The efficient market hypothesis is often discussed as having three forms: a weak form, a semi-strong form, and a strong form:</p>
<ol>
<li>In the weak<span> </span><span>form, the market is efficient in the sense that you cannot use past information from prices to predict future prices. Information is reflected in stocks relatively quickly, and while technical</span><span> </span><span>analysis would be ineffective, in some scenarios, fundamental analysis could be effective.</span></li>
</ol>
<ol start="2">
<li>In the semi-strong form, prices immediately reflect all relevant new public information in an unbiased manner. Here, neither technical nor fundamental analysis would be effective.</li>
<li>And finally, in the strong form, stock prices reflect all public and private information.</li>
</ol>
<p>Based on these theories, there isn't much hope of making money by exploiting patterns in the market. But fortunately, while the market operates in a largely efficient manner on the whole, distinct pockets of inefficiency have been uncovered. Most of these tend to be ephemeral, but some have been documented as persisting. One of the most noteworthy—even according to Fama—is the outperformance of momentum strategies.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">So, what exactly is a momentum strategy?</h1>
                </header>
            
            <article>
                
<p>There are a number of variations on the theme, but the basic idea is that stocks are ranked from the highest to lowest according to their return over a prior period. The top-ranked performers are bought and held for a period of time, and then the process is repeated after a fixed holding period. A typical long-only momentum strategy might involve buying the top 25 performing stocks in the S&amp;P 500 over the past year, holding them for a year, selling them, and then repeating the process.</p>
<p>This may sound like an absurdly simple strategy, and it is, but it has consistently returned results that defy expectation. But why? As you can imagine, a lot of research has examined this effect, and the hypothesis is that there is something inherently systemically biased about how humans deal with new information. The research suggests they underreact to news in the short term and then overreact to news in the long term. This means that, when stocks begin to rise on exceptionally good news, investors don't fully elevate the share price to the level that would fully reflect this news; it takes time for them to come around to incorporating this rosy outlook.</p>
<div class="packt_infobox">This tendency of investors to fail to adequately reprice shares in the face of exceedingly good news may be the result of a well-documented bias called the <strong><span class="KeyPACKT">anchoring effect</span></strong>. Essentially, when presented with a number, even a random number, and then asked to estimate a real-world value, such as the number of countries in Africa, for instance, our answer will be mentally tethered to that number we were primed with. Remarkably, this happens even if we know the number is randomly generated and unrelated to the question.</div>
<p>So, will momentum strategies be arbitraged away as more traders learn of it and pile in? There has been some evidence of this in recent years, but it remains unclear. Regardless, the effect was demonstrably real and persisted far longer than can currently be accounted for by the efficient market hypothesis. So, there at least appears to be some hope for market prediction. With that in mind, let's now move on to exploring how we might go about unearthing our own market anomalies.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to develop a trading strategy</h1>
                </header>
            
            <article>
                
<p>We'll begin our strategy development by focusing on the technical aspects. Let's take a look at the S&amp;P 500 over the last few  years. We'll use <kbd>pandas</kbd> to import our data. This will give us access to several sources of stock data, including Yahoo! And Google.</p>
<ol>
<li>First, you'll need to install the data reader:</li>
</ol>
<pre style="padding-left: 60px"><strong>!pip install pandas_datareader </strong></pre>
<ol start="2">
<li>Then, go ahead and incorporate your imports:</li>
</ol>
<pre style="padding-left: 60px"><strong>import pandas as pd 
from pandas_datareader import data, wb 
import matplotlib.pyplot as plt 
 
%matplotlib inline 
pd.set_option('display.max_colwidth', 200)</strong> </pre>
<ol start="3">
<li>Now, we'll get our data for the <kbd>SPY</kbd> ETF, which represents the stocks of the S&amp;P 500. We'll pull data from the start of 2010 through December 2018:</li>
</ol>
<pre style="padding-left: 60px"><strong>import pandas_datareader as pdr 
 
start_date = pd.to_datetime('2010-01-01') 
stop_date = pd.to_datetime('2018-12-01') 
 
spy = pdr.data.get_data_yahoo</strong><strong>('SPY', start_date, stop_date)</strong> </pre>
<p style="padding-left: 60px"><span class="fontstyle0">This code generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-472 image-border" src="assets/b39cf97d-19e3-4d93-be27-7a5b19574069.png" style="width:40.42em;height:22.67em;"/></p>
<ol start="4">
<li>We can now plot our data. We'll select only the closing price:</li>
</ol>
<pre style="padding-left: 60px"><strong>spy_c = spy['Close'] 
 
fig, ax = plt.subplots(figsize=(15,10)) 
spy_c.plot(color='k') 
plt.title("SPY", fontsize=20);</strong> </pre>
<ol start="5">
<li>This <span>generates the following output:</span></li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-473 image-border" src="assets/76555344-12fd-4691-b889-c67fdfd4552d.png" style="width:147.50em;height:94.33em;"/></p>
<p style="padding-left: 60px">In the preceding diagram, we see the price chart of the daily closing price of the S&amp;P 500 for the period we selected.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Analysis of the data</h1>
                </header>
            
            <article>
                
<p>Let's run some analysis to see what the returns over this period might have been had we invested in this ETF:</p>
<ol>
<li>We'll pull data for the <kbd>first_open</kbd> first:</li>
</ol>
<pre style="padding-left: 60px"><strong>first_open = spy['Open'].iloc[0] 
first_open</strong> </pre>
<p style="padding-left: 60px">This <span>generates the following output</span>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-474 image-border" src="assets/1277486c-c70d-42a2-a87d-2b30b3bd9951.png" style="width:11.83em;height:1.42em;"/></p>
<p class="mce-root"/>
<ol start="2">
<li>Next, let's get the closing price on the final day of the period:</li>
</ol>
<pre style="padding-left: 60px"><strong>last_close = spy['Close'].iloc[-1] 
last_close</strong> </pre>
<p style="padding-left: 60px">This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-477 image-border" src="assets/9aaea445-e5d0-4e72-be77-f3a6bef10c31.png" style="width:11.00em;height:1.83em;"/></p>
<ol start="3">
<li>And finally, let's see the change over the full period:</li>
</ol>
<pre style="padding-left: 60px"><strong>last_close - first_open</strong> </pre>
<p style="padding-left: 60px">This <span>generates the following output</span>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-478 image-border" src="assets/1204d125-c15f-4c58-874d-6289f01b0788.png" style="width:11.42em;height:2.00em;"/></p>
<p>So, it appears that a purchase of 100 shares at the start of the period would have cost us approximately $11,237 and, at the end of the period, those same 100 shares would have been valued at roughly $27,564. This transaction would have given us a gain of just a bit over 145% over the period. Not too bad at all.</p>
<p>Let's now take a look at the return over the same period for just the intraday gains. This assumes we buy the stock at the opening of each day and sell it at the close of that same day:</p>
<pre><strong>spy['Daily Change'] = pd.Series(spy['Close'] - spy['Open'])</strong> </pre>
<p>That will give us the change from the open to the close each day. Let's take a look at that:</p>
<pre><strong>spy['Daily Change']</strong> </pre>
<p class="mce-root"/>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-479 image-border" src="assets/116b452a-c510-476b-b667-ef75bd3ce10c.png" style="width:14.83em;height:24.67em;"/></p>
<p>Let's now total those changes over the period:</p>
<pre><strong>spy['Daily Change'].sum()</strong> </pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-480 image-border" src="assets/1229a31b-75bc-4423-bf64-8205cb5f9717.png" style="width:12.58em;height:1.75em;"/></p>
<p>So, as you can see, we have gone from a gain of over 163 points to one of just over 53 points. Ouch! More than half the market's gains came from holding overnight during the period.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Volatility of the returns</h1>
                </header>
            
            <article>
                
<p>The overnight returns were better than the intraday returns, but how about the volatility? Returns are always judged on a risk-adjusted basis, so let's see how the overnight trades compared to the intraday trades on the basis of their standard deviation.</p>
<p class="mce-root"/>
<p>We can use NumPy to calculate this for us as follows:</p>
<pre><strong>np.std(spy['Daily Change'])</strong> </pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-481 image-border" src="assets/7d3e5a44-e468-4842-8627-f88be8b32948.png" style="width:12.75em;height:2.17em;"/></p>
<pre><strong>spy['Overnight Change'] = pd.Series(spy['Open'] - spy['Close'].shift(1)) 
 
np.std(spy['Overnight Change'])</strong> </pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-484 image-border" src="assets/86c5b999-7f02-4c8f-b68d-f8570bafe99e.png" style="width:12.92em;height:2.42em;"/></p>
<p>So our overnight trading not only had higher gains, but lower volatility as well, compared to the intraday trading. But not all volatility is created equal. Let's compare the mean change on downside days versus upside days for both strategies:</p>
<pre><strong> spy[spy['Daily Change']&lt;0]['Daily Change'].mean()</strong> </pre>
<p><span class="fontstyle0">This code generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-485 image-border" src="assets/60138527-ec0f-442c-8324-6ee83becb90c.png" style="width:13.50em;height:1.83em;"/></p>
<p>Run this code for upside days:</p>
<pre><strong> spy[spy['Overnight Change']&lt;0]['Overnight Change'].mean()</strong> </pre>
<p>We get the output as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-486 image-border" src="assets/5b756271-fdf5-4539-a02c-1031411b122e.png" style="width:12.75em;height:2.08em;"/></p>
<p>Again, we see that the average downside volatility is far less for our overnight trading strategy than our intraday trading strategy.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Daily returns</h1>
                </header>
            
            <article>
                
<p>So far, we have looked at everything in terms of points, but let's now look at daily returns. This will help put our gains and losses into a more realistic context. Let's create a pandas series for each scenario: daily returns (close to close change), intraday returns, and overnight returns:</p>
<pre><strong>daily_rtn = ((spy['Close'] - spy['Close'].shift(1))/spy['Close'].shift(1))*100 
 
id_rtn = ((spy['Close'] - spy['Open'])/spy['Open'])*100 
  
on_rtn = ((spy['Open'] - spy['Close'].shift(1))/spy['Close'].shift(1))*100</strong> </pre>
<p>What we've done is use the pandas <kbd>.shift()</kbd> method to subtract each series from the prior day's series. For example, for the preceding first series, we are subtracting the close from the close one day before for each day. This will result in one less data point. If you print out the new series, you can see this as follows:</p>
<pre><strong>Daily_rtn</strong> </pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-487 image-border" src="assets/a77a8d8c-ee34-42c9-b747-b6c9734d1b2e.png" style="width:14.25em;height:23.50em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Statistics for the strategies</h1>
                </header>
            
            <article>
                
<p>Let's now take a look at the statistics for all three strategies. We'll create a function that can take in each series of returns, and will print out the summary results. We're going to get statistics for each of our winning, losing, and break-even trades, and something called the <strong>Sharpe ratio</strong>. I said earlier that returns are judged on a risk-adjusted basis; this is exactly what the Sharpe ratio provides us with; it is a method of comparing returns by accounting for the volatility of those returns. Here, we use the Sharpe ratio with an adjustment to annualize the ratio:</p>
<pre><strong>def get_stats(s, n=252): 
    s = s.dropna() 
    wins = len(s[s&gt;0]) 
    losses = len(s[s&lt;0]) 
    evens = len(s[s==0]) 
    mean_w = round(s[s&gt;0].mean(), 3) 
    mean_l = round(s[s&lt;0].mean(), 3) 
    win_r = round(wins/losses, 3) 
    mean_trd = round(s.mean(), 3) 
    sd = round(np.std(s), 3) 
    max_l = round(s.min(), 3) 
    max_w = round(s.max(), 3) 
    sharpe_r = round((s.mean()/np.std(s))*np.sqrt(n), 4) 
    cnt = len(s) 
    print('Trades:', cnt,\ 
          '\nWins:', wins,\ 
          '\nLosses:', losses,\ 
          '\nBreakeven:', evens,\ 
          '\nWin/Loss Ratio', win_r,\ 
          '\nMean Win:', mean_w,\ 
          '\nMean Loss:', mean_l,\ 
          '\nMean', mean_trd,\ 
          '\nStd Dev:', sd,\ 
          '\nMax Loss:', max_l,\ 
          '\nMax Win:', max_w,\ 
          '\nSharpe Ratio:', sharpe_r)</strong> </pre>
<p>Let's now run each strategy to see the stats. We'll start with the buy-and-hold strategy (daily returns) and then move onto the other two, as follows:</p>
<pre><strong>get_stats(daily_rtn)</strong> </pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-488 image-border" src="assets/59e1a71f-db90-4408-a1e7-7e2ca4c92eae.png" style="width:16.17em;height:18.42em;"/></p>
<p><span>Run the following code for intraday returns:</span></p>
<pre><strong>get_stats(id_rtn)</strong> </pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-489 image-border" src="assets/3ba22f6f-3a6c-42ba-8c18-ccf0be85d6f1.png" style="width:15.58em;height:17.25em;"/></p>
<p><span>Run the following code for overnight returns:</span></p>
<pre><strong>get_stats(on_rtn)</strong> </pre>
<p class="mce-root"/>
<p>This <span>generates the following output</span>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-490 image-border" src="assets/a0460c44-deb4-4ac1-a148-e9b3bb4199f3.png" style="width:16.33em;height:16.25em;"/></p>
<p>As you can see, the buy-and-hold strategy has the highest mean return, as well as the highest standard deviation, of the three. It also has the largest daily drawdown (loss). You will also notice that, even though the overnight-only strategy has a higher mean return than the intraday strategy, it also has substantially less volatility. This, in turn, gives it a Sharpe ratio that is higher than the intraday strategy.</p>
<p>At this point, we have a solid baseline for comparing our future strategies. Now, I am going to tell you about a strategy that blows all three of these strategies out of the water.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The mystery strategy</h1>
                </header>
            
            <article>
                
<p>Let's take a look at the statistics for this new mystery strategy:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-491 image-border" src="assets/38ea8574-ea3e-4a32-9c5d-098b404b7137.png" style="width:15.25em;height:16.33em;"/></p>
<p>With this strategy, I have essentially doubled the Sharpe ratio over buy-and-hold, lowered the volatility substantially, increased the max win, and reduced the max loss by a significant level.</p>
<p>And how is it that I devised this market-trouncing strategy? Wait for it... I did it by generating 5,000 random overnight signals and picked the best one.</p>
<p>This is obviously not the way to beat the market. So why then did I do it? To demonstrate that, if you test enough strategies, just by random chance you will come across a number that appears to be amazing. This is the called the <strong>data mining fallacy</strong>, and it is a real risk in trading strategy development. That is why it is so important to find a strategy that is anchored to real-world investor biases and behaviors. If you want an edge in trading, you don't trade the markets; you the trade people who trade markets<em>.</em></p>
<p>An edge then comes from thoughtfully understanding how people might react incorrectly to certain situations.</p>
<p>Let's now extend our analysis. First, we'll pull data for the index beginning with the year 2000:</p>
<pre><strong>start_date = pd.to_datetime('2000-01-01') 
stop_date = pd.to_datetime('2018-12-01') 
 
sp = pdr.data.get_data_yahoo('SPY', start_date, stop_date)</strong> </pre>
<p>Let's now take a look at our chart:</p>
<pre><strong>fig, ax = plt.subplots(figsize=(15,10)) 
sp['Close'].plot(color='k') 
plt.title("SPY", fontsize=20)</strong> </pre>
<p class="mce-root"/>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-492 image-border" src="assets/bb069f0f-193a-4920-8620-937b8f1cc537.png" style="width:148.33em;height:94.83em;"/></p>
<p>Here, we see the price action for the <kbd>SPY</kbd> from the start of 2000 until December 1, 2018. There has certainly been a lot of movement during that period as the market has experienced both highly positive and highly negative regimes.</p>
<p>Let's get our baseline for our new expanded period for our three base strategies.</p>
<p>First, let's set up our variables for each:</p>
<pre><strong>long_day_rtn = ((sp['Close'] - sp['Close'].shift(1))/sp['Close'].shift(1))*100 
 
long_id_rtn = ((sp['Close'] - sp['Open'])/sp['Open'])*100 
 
long_on_rtn = ((sp['Open'] - sp['Close'].shift(1))/sp['Close'].shift(1))*100</strong> </pre>
<p>Now, let's see what the point totals are for each:</p>
<pre><strong>(sp['Close'] - sp['Close'].shift(1)).sum()</strong> </pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-493 image-border" src="assets/129ee241-4113-4bc8-8b58-87ea6ccf0b28.png" style="width:12.00em;height:2.17em;"/></p>
<p>Now, let's see what the point totals are for open to close:</p>
<pre><strong>(sp['Close'] - sp['Open']).sum()</strong> </pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-494 image-border" src="assets/2438ea4d-8fec-4a91-9b05-0f2346bc764a.png" style="width:12.17em;height:2.00em;"/></p>
<p><span>Now, let's see what the point totals are for close</span><span> to open:</span></p>
<pre><strong>(sp['Open'] - sp['Close'].shift(1)).sum()</strong> </pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-495 image-border" src="assets/d811fd81-8908-48a0-a292-f6431690e395.png" style="width:12.75em;height:2.00em;"/></p>
<p>And now let's look at the statistics for each:</p>
<pre><strong>get_stats(long_day_rtn)</strong> </pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-496 image-border" src="assets/84fd8395-a52a-4816-8440-eed87a9ab176.png" style="width:15.42em;height:16.75em;"/></p>
<p><span>Now, let's look at the statistics for intraday returns:</span></p>
<pre><strong>get_stats(long_id_rtn)</strong> </pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-497 image-border" src="assets/91666e3b-4eb1-4853-ae95-02e00536b7ef.png" style="width:13.92em;height:15.92em;"/></p>
<p><span>Now, let's look at the statistics for overnight returns:</span></p>
<pre><strong>get_stats(long_on_rtn) </strong></pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-498 image-border" src="assets/df97c14f-abb1-43c8-a337-08bb4064adba.png" style="width:14.08em;height:15.67em;"/></p>
<p>We can see that the differences between the three are even more pronounced over the longer period. Had you only held during the day over the past 18 years, you would have lost money in this S&amp;P ETF. Had you held only overnight, you would have improved your total point returns by over 18%! Obviously, this presumes no trading costs and no taxes along with perfect fills but, regardless, this is a remarkable finding.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building the regression model</h1>
                </header>
            
            <article>
                
<p>Now that we have a baseline to compare with, let's build our first regression model. We're going to start with a very basic model using only the stock's prior closing values to predict the next day's close, and we're going to build it using a support vector regression. With that, let's set up our model:</p>
<ol>
<li>The first step is to set up a DataFrame that contains a price history for each day. We're going to include the past 20 closes in our model:</li>
</ol>
<pre style="padding-left: 60px"><strong>for i in range(1, 21, 1): 
    sp.loc[:,'Close Minus ' + str(i)] = sp['Close'].shift(i) 
 
sp20 = sp[[x for x in sp.columns if 'Close Minus' in x or x == 'Close']].iloc[20:,] 
 
sp20</strong> </pre>
<ol start="2">
<li>This code gives us each day's closing price, along with the previous 20, all on the same line. The result of our code is seen in the following output:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-499 image-border" src="assets/e6d615df-bb9c-44ef-85dd-a55d2b53c7a1.png" style="width:134.50em;height:48.00em;"/></p>
<ol start="3">
<li>This will form the basis of the <em>X</em> array we will feed our model. But before we're ready for that, there are a few additional steps.</li>
<li>First, we'll reverse our columns so that time runs from left to right:</li>
</ol>
<pre style="padding-left: 60px"><strong>sp20 = sp20.iloc[:,::-1] 
 
sp20</strong> </pre>
<p style="padding-left: 60px">This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-500 image-border" src="assets/dfea1f30-2143-401b-b300-e614f46889b5.png" style="width:134.00em;height:47.33em;"/></p>
<ol start="5">
<li>Now, let's import our support vector machine and set our our training and test matrices and vectors:</li>
</ol>
<pre style="padding-left: 60px"><strong>from sklearn.svm import SVR 
clf = SVR(kernel='linear') 
 
X_train = sp20[:-2000] 
y_train = sp20['Close'].shift(-1)[:-2000] 
 
X_test = sp20[-2000:] 
y_test = sp20['Close'].shift(-1)[-2000:]</strong> </pre>
<ol start="6">
<li>We had just 5,000 data points to work with, so I chose to use the last 2,000 for testing. Let's now fit our model and use it to check out-of-sample data:</li>
</ol>
<pre style="padding-left: 60px"><strong>model = clf.fit(X_train, y_train) 
 
preds = model.predict(X_test)</strong> </pre>
<ol start="7">
<li>Now that we have our predictions, let's compare them to our actual data:</li>
</ol>
<pre style="padding-left: 60px"><strong>tf = pd.DataFrame(list(zip(y_test, preds)), columns=['Next Day Close', 'Predicted Next Close'], index=y_test.index) 
 
tf </strong></pre>
<p style="padding-left: 60px">The preceding code <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-501 image-border" src="assets/ba8c2a4d-b07e-4a05-923e-24aed37b002f.png" style="width:22.42em;height:21.25em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Performance of the model</h1>
                </header>
            
            <article>
                
<p>Let's now look at the performance of our model. We're going to buy the next day's open if the close is predicted to be higher than the open. We'll then sell at the close that same day. We'll need to add a few extra data points to our DataFrame to calculate our results, as follows:</p>
<pre><strong>cdc = sp[['Close']].iloc[-1000:] 
ndo = sp[['Open']].iloc[-1000:].shift(-1) 
 
tf1 = pd.merge(tf, cdc, left_index=True, right_index=True) 
tf2 = pd.merge(tf1, ndo, left_index=True, right_index=True) 
tf2.columns = ['Next Day Close', 'Predicted Next Close', 'Current Day Close', 'Next Day Open'] 
 
tf2</strong> </pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-502 image-border" src="assets/727e9625-5aec-43c9-b321-15f1735c90f5.png" style="width:35.00em;height:20.00em;"/></p>
<p>Here we'll add the following code to get our signal and our profit and loss for the signal:</p>
<pre><strong>def get_signal(r): 
    if r['Predicted Next Close'] &gt; r['Next Day Open']: 
        return 1 
    else: 
        return 0 
 
def get_ret(r): 
    if r['Signal'] == 1: 
        return ((r['Next Day Close'] - r['Next Day Open'])/r['Next Day Open']) * 100 
    else: 
        return 0 
 
tf2 = tf2.assign(Signal = tf2.apply(get_signal, axis=1)) 
tf2 = tf2.assign(PnL = tf2.apply(get_ret, axis=1)) 
 
tf2</strong> </pre>
<p class="mce-root"/>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-503 image-border" src="assets/a78fa97e-2bad-40c5-ae25-393a9c2a1750.png" style="width:107.00em;height:50.17em;"/></p>
<p>Let's now see whether, using just the price history, we were able to successfully predict the next day's price. We'll start by calculating the points gained:</p>
<pre><strong>(tf2[tf2['Signal']==1]['Next Day Close'] - tf2[tf2['Signal']==1]['Next Day Open']).sum()</strong> </pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-504 image-border" src="assets/702d59f5-f189-42a5-ba32-ff24dce34385.png" style="width:12.58em;height:2.08em;"/></p>
<p>Ouch! This looks bad. But what about the period we tested? We never evaluated it in isolation. How many points would our basic intraday strategy have generated during the last 2,000 days:</p>
<pre><strong>(sp['Close'].iloc[-2000:] - sp['Open'].iloc[-2000:]).sum()</strong> </pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-505 image-border" src="assets/35a29a4d-e1f5-4982-bfcb-a4f60c72d301.png" style="width:12.25em;height:2.08em;"/></p>
<p class="mce-root"/>
<p>So it looks as if our strategy is abysmal. Let's compare the two.</p>
<p>First, the basic intraday strategy for the period:</p>
<pre><strong>get_stats((sp['Close'].iloc[-2000:] - sp['Open'].iloc[-2000:])/sp['Open'].iloc[-2000:] * 100)</strong> </pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-506 image-border" src="assets/083afef5-1f88-4d56-ba45-eeb098380cb6.png" style="width:14.50em;height:16.67em;"/></p>
<p>And now the results for our model:</p>
<pre><strong>get_stats(tf2['PnL'])</strong> </pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-507 image-border" src="assets/42649d66-83a0-4f34-a788-fa06e81ac148.png" style="width:14.58em;height:16.75em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p>It's clear our strategy is not one we would want to implement. How might we improve what we have here? What if we modified our trading strategy? What if we only took trades that, instead of just being any amount greater than the open, were expected to be greater by a point or more. Would that help? Let's try it. We'll re-run our strategy with a modified signal, as demonstrated in the following code block:</p>
<pre><strong>def get_signal(r): 
    if r['Predicted Next Close'] &gt; r['Next Day Open'] + 1: 
        return 1 
    else: 
        return 0 
</strong> 
<strong>def get_ret(r): 
    if r['Signal'] == 1: 
        return ((r['Next Day Close'] - r['Next Day Open'])/r['Next Day Open']) * 100 
    else: 
        return 0 
 
tf2 = tf2.assign(Signal = tf2.apply(get_signal, axis=1)) 
tf2 = tf2.assign(PnL = tf2.apply(get_ret, axis=1)) 
 
(tf2[tf2['Signal']==1]['Next Day Close'] - tf2[tf2['Signal']==1]['Next Day Open']).sum()</strong> </pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-508 image-border" src="assets/55e4a7ef-13b6-4629-94be-90c3774c9fad.png" style="width:13.17em;height:2.08em;"/></p>
<p>And now the stats:</p>
<pre><strong>get_stats(tf2['PnL'])</strong> </pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-509 image-border" src="assets/59060bd5-2563-4c21-9c50-466a05f2eced.png" style="width:15.25em;height:16.83em;"/></p>
<p>We have gone from bad to worse. It appears that, if past price history suggests good things to come, you can expect precisely the opposite. We seem to have developed a contrarian indicator with our model. What if we explore that? Let's see what our gains would look like if we flipped our model so that, when we predict strong gains, we don't trade, but otherwise we do:</p>
<pre><strong>def get_signal(r): 
    if r['Predicted Next Close'] &gt; r['Next Day Open'] + 1: 
        return 0 
    else: 
        return 1 
 
def get_ret(r): 
    if r['Signal'] == 1: 
        return ((r['Next Day Close'] - r['Next Day Open'])/r['Next Day Open']) * 100 
    else: 
        return 0 
 
tf2 = tf2.assign(Signal = tf2.apply(get_signal, axis=1)) 
tf2 = tf2.assign(PnL = tf2.apply(get_ret, axis=1)) 
 
(tf2[tf2['Signal']==1]['Next Day Close'] - tf2[tf2['Signal']==1]['Next Day Open']).sum()</strong> </pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-510 image-border" src="assets/eb79b57d-2e6c-4cfe-ad90-11e23c8aec11.png" style="width:11.25em;height:2.08em;"/></p>
<p>Let's get our stats:</p>
<pre><strong>get_stats(tf2['PnL'])</strong> </pre>
<p>This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-511 image-border" src="assets/7d8ec085-d251-4432-9ca5-5c8371dc6ad3.png" style="width:14.83em;height:16.67em;"/></p>
<p>It looks like we do have a contrarian indicator here. When our model predicts strong next-day gains, the market significantly underperforms, at least during our test period. Would this hold in most scenarios? Unlikely. Markets tend to flip from regimes of mean reversion to regimes of trend persistence.</p>
<p>At this point, there are a number of extensions we could make to this model. We haven't even touched on using technical indicators or fundamental data in our model, and we have limited our trades to one day. All of this could be tweaked and extended upon, but there is one important point we have not addressed that must be mentioned.</p>
<p>The data we are working with is of a special type called <strong>time series data</strong>. Time series data requires special treatment to properly model it, as it typically violates the assumptions required for statistical modeling, such as a constant mean and variance.</p>
<p>One consequence of improperly handling time series data is that error metrics give wildly inaccurate measures. Because of significant autocorrelation, in other words, the data in the next period is highly correlated with data in the current period, it appears that we have achieved much better predictions than we actually have.</p>
<p>To address these issues, time series data is often <strong>differenced</strong> (in the case of stock data, this would mean we look at the daily change, not the absolute level of the index) to render it as what we call <strong>stationary</strong>; that is, it has a constant mean and variance and lacks significant autocorrelation.</p>
<p>If you intend to pursue working with time series data, I implore you to research these concepts in more detail.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dynamic time warping</h1>
                </header>
            
            <article>
                
<p>Next, however, I want to introduce another model, which uses a completely different algorithm. This algorithm is called <strong>dynamic time warping</strong>. What it does is give you a metric that represents the similarity between two time series:</p>
<ol>
<li>To get started, we'll need to <kbd>pip install</kbd> the <kbd>fastdtw</kbd> library:</li>
</ol>
<pre style="padding-left: 60px"><strong>!pip install fastdtw</strong> </pre>
<ol start="2">
<li>Once that is installed, we'll import the additional libraries we'll need:</li>
</ol>
<pre style="padding-left: 60px"><strong>from scipy.spatial.distance import euclidean 
from fastdtw import fastdtw</strong> </pre>
<ol start="3">
<li>Next, we'll create the function that will take in two series and return the distance between them:</li>
</ol>
<pre style="padding-left: 60px"><strong>def dtw_dist(x, y): 
    distance, path = fastdtw(x, y, dist=euclidean) 
    return distance</strong> </pre>
<ol start="4">
<li>Now, we'll split our 18 years' worth of time series data into distinct five-day periods. We'll pair together each period with one additional point. This will serve to create our <em>x</em> and <em>y</em> data, as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>tseries = [] 
tlen = 5 
for i in range(tlen, len(sp), tlen): 
    pctc = sp['Close'].iloc[i-tlen:i].pct_change()[1:].values * 100 
    res = sp['Close'].iloc[i-tlen:i+1].pct_change()[-1] * 100 
    tseries.append((pctc, res))</strong> </pre>
<ol start="5">
<li>We can take a look at our first series to get an idea of what the data looks like:</li>
</ol>
<pre style="padding-left: 60px"><strong>tseries[0]</strong> </pre>
<p style="padding-left: 60px">This <span>generates the following output:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-512 image-border" src="assets/60f02d5a-6428-4761-8f83-d88401d360e5.png" style="width:41.50em;height:3.58em;"/></p>
<ol start="6">
<li>Now that we have each series, we can run them all through our algorithm to get the distance metric for each series against every other series:</li>
</ol>
<pre style="padding-left: 60px"><strong>dist_pairs = [] 
for i in range(len(tseries)): 
    for j in range(len(tseries)): 
        dist = dtw_dist(tseries[i][0], tseries[j][0]) 
        dist_pairs.append((i,j,dist,tseries[i][1], tseries[j][1]))</strong> </pre>
<p>Once we have that, we can place it into a <kbd>DataFrame</kbd>. We'll drop series that have <kbd>0</kbd> distance, as they represent the same series. We'll also sort according to the date of the series and look only at those where the first series is before the second, <span>chronologically speaking:</span></p>
<pre><strong>dist_frame = pd.DataFrame(dist_pairs, columns=['A','B','Dist', 'A Ret', 'B Ret']) 
 
sf = dist_frame[dist_frame['Dist']&gt;0].sort_values(['A','B']).reset_index(drop=1) 
 
sfe = sf[sf['A']&lt;sf['B']]</strong> </pre>
<p>And finally, we'll limit our trades where the distance is less than <kbd>1</kbd> and the first series has a positive return:</p>
<pre><strong>winf = sfe[(sfe['Dist']&lt;=1)&amp;(sfe['A Ret']&gt;0)] 
 
winf</strong> </pre>
<p class="mce-root"/>
<p>This generates the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-513 image-border" src="assets/adb82c6f-6a3a-44f6-b76b-559fb4fc0f63.png" style="width:24.33em;height:23.67em;"/></p>
<p>Let's see what one of our top patterns (A:6 and B:598) looks like when plotted:</p>
<pre><strong>plt.plot(np.arange(4), tseries[6][0]);</strong> </pre>
<p>The preceding code generates the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-514 image-border" src="assets/5e0fe1c2-0cd7-4bb7-b3e6-2dc607a7542a.png" style="width:31.67em;height:19.75em;"/></p>
<p class="mce-root"/>
<p>Now, we'll plot the second one:</p>
<pre><strong>plt.plot(np.arange(4), tseries[598][0])</strong> </pre>
<p>The preceding code generates the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-515 image-border" src="assets/3d57a1f6-daa1-4a21-8049-accc007be82e.png" style="width:30.58em;height:19.83em;"/></p>
<p>As you can see, the curves are nearly identical, which is exactly what we want. We're going to try to find all curves that have positive next-day gains and then, once we have a curve that is highly similar to one of these profitable curves, we'll buy it in anticipation of another gain.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Evaluating our trades</h1>
                </header>
            
            <article>
                
<p>Let's now construct a function to evaluate our trades. We'll buy similar curves unless they fail to return a positive result. If that happens, we'll eliminate them, as follows:</p>
<pre><strong>excluded = {} 
return_list = [] 
def get_returns(r): 
    if excluded.get(r['A']) is None: 
        return_list.append(r['B Ret']) 
        if r['B Ret'] &lt; 0: 
            excluded.update({r['A']:1}) 
 
winf.apply(get_returns, axis=1);</strong> </pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Now that we have all the returns from our trades stored in <kbd>return_list</kbd>, let's evaluate the results:</p>
<pre><strong>get_stats(pd.Series(return_list))</strong> </pre>
<p>This generates the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-516 image-border" src="assets/c30f2649-f010-49bf-8967-c431a1f1b4ee.png" style="width:13.50em;height:14.58em;"/></p>
<p>These results are by far the best we've seen. The win/loss ratio and the mean are far above our other models. It appears we may be on to something with this new model, especially compared to the others we've seen.</p>
<p>At this point, to vet our model <span>further</span>, we should explore its robustness by examining other time periods for our matches. Does extending beyond the four days improve the model? Should we always exclude the patterns that generate a loss? There are an enormous number of questions to explore at this point, but I'll leave this as an exercise for the reader.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we've looked at the inner workings of the stock market and explored a number of ways to approach utilizing machine learning in a trading strategy. There is no doubt the material in this chapter could fill a book itself. We even failed to cover some of the most important aspects of trading, such as portfolio construction, risk mitigation, and money management. These are critical components to any strategy, perhaps even more important than trade signals.</p>
<p>Hopefully, this will serve as a jumping-off point for your own explorations, but again, I caution you that <em>beating the market</em> is a nearly impossible game—one in which you are competing against the brightest minds in the world. If you do decide to try, I wish you the best of luck. Just remember that I warned you if it doesn't turn out like you hoped!</p>


            </article>

            
        </section>
    </body></html>