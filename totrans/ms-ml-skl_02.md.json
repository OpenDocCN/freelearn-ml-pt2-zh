["```py\n>>> import matplotlib.pyplot as plt\n>>> X = [[6], [8], [10], [14],   [18]]\n>>> y = [[7], [9], [13], [17.5], [18]]\n>>> plt.figure()\n>>> plt.title('Pizza price plotted against diameter')\n>>> plt.xlabel('Diameter in inches')\n>>> plt.ylabel('Price in dollars')\n>>> plt.plot(X, y, 'k.')\n>>> plt.axis([0, 25, 0, 25])\n>>> plt.grid(True)\n>>> plt.show()\n```", "```py\n>>> from sklearn.linear_model import LinearRegression\n>>> # Training data\n>>> X = [[6], [8], [10], [14],   [18]]\n>>> y = [[7], [9], [13], [17.5], [18]]\n>>> # Create and fit the model\n>>> model = LinearRegression()\n>>> model.fit(X, y)\n>>> print 'A 12\" pizza should cost: $%.2f' % model.predict([12])[0]\nA 12\" pizza should cost: $13.68\n```", "```py\n>>> import numpy as np\n>>> print 'Residual sum of squares: %.2f' % np.mean((model.predict(X) - y) ** 2)\nResidual sum of squares: 1.75\n```", "```py\n>>> from __future__ import division\n>>> xbar = (6 + 8 + 10 + 14 + 18) / 5\n>>> variance = ((6 - xbar)**2 + (8 - xbar)**2 + (10 - xbar)**2 + (14 - xbar)**2 + (18 - xbar)**2) / 4\n>>> print variance\n23.2\n```", "```py\n>>> import numpy as np\n>>> print np.var([6, 8, 10, 14, 18], ddof=1)\n23.2\n```", "```py\n>>> xbar = (6 + 8 + 10 + 14 + 18) / 5\n>>> ybar = (7 + 9 + 13 + 17.5 + 18) / 5\n>>> cov = ((6 - xbar) * (7 - ybar) + (8 - xbar) * (9 - ybar) + (10 - xbar) * (13 - ybar) +\n>>>        (14 - xbar) * (17.5 - ybar) + (18 - xbar) * (18 - ybar)) / 4\n>>> print cov\n>>> import numpy as np\n>>> print np.cov([6, 8, 10, 14, 18], [7, 9, 13, 17.5, 18])[0][1]\n22.65\n22.65\n```", "```py\n>>> from sklearn.linear_model import LinearRegression\n>>> X = [[6], [8], [10], [14],   [18]]\n>>> y = [[7], [9], [13], [17.5], [18]]\n>>> X_test = [[8],  [9],   [11], [16], [12]]\n>>> y_test = [[11], [8.5], [15], [18], [11]]\n>>> model = LinearRegression()\n>>> model.fit(X, y)\n>>> print 'R-squared: %.4f' % model.score(X_test, y_test)\nR-squared: 0.6620\n```", "```py\n>>> from numpy.linalg import inv\n>>> from numpy import dot, transpose\n>>> X = [[1, 6, 2], [1, 8, 1], [1, 10, 0], [1, 14, 2], [1, 18, 0]]\n>>> y = [[7], [9], [13], [17.5], [18]]\n>>> print dot(inv(dot(transpose(X), X)), dot(transpose(X), y))\n[[ 1.1875    ]\n [ 1.01041667]\n [ 0.39583333]]\n```", "```py\n>>> from numpy.linalg import lstsq\n>>> X = [[1, 6, 2], [1, 8, 1], [1, 10, 0], [1, 14, 2], [1, 18, 0]]\n>>> y = [[7],    [9],    [13],    [17.5],  [18]]\n>>> print lstsq(X, y)[0]\n[[ 1.1875    ]\n [ 1.01041667]\n [ 0.39583333]]\n```", "```py\n>>> from sklearn.linear_model import LinearRegression\n>>> X = [[6, 2], [8, 1], [10, 0], [14, 2], [18, 0]]\n>>> y = [[7],    [9],    [13],    [17.5],  [18]]\n>>> model = LinearRegression()\n>>> model.fit(X, y)\n>>> X_test = [[8, 2], [9, 0], [11, 2], [16, 2], [12, 0]]\n>>> y_test = [[11],   [8.5],  [15],    [18],    [11]]\n>>> predictions = model.predict(X_test)\n>>> for i, prediction in enumerate(predictions):\n>>>     print 'Predicted: %s, Target: %s' % (prediction, y_test[i])\n>>> print 'R-squared: %.2f' % model.score(X_test, y_test)\nPredicted: [ 10.0625], Target: [11]\nPredicted: [ 10.28125], Target: [8.5]\nPredicted: [ 13.09375], Target: [15]\nPredicted: [ 18.14583333], Target: [18]\nPredicted: [ 13.3125], Target: [11]\nR-squared: 0.77\n```", "```py\n>>> import numpy as np\n>>> import matplotlib.pyplot as plt\n>>> from sklearn.linear_model import LinearRegression\n>>> from sklearn.preprocessing import PolynomialFeatures\n\n>>> X_train = [[6], [8], [10], [14],   [18]]\n>>> y_train = [[7], [9], [13], [17.5], [18]]\n>>> X_test = [[6],  [8],   [11], [16]]\n>>> y_test = [[8], [12], [15], [18]]\n\n>>> regressor = LinearRegression()\n>>> regressor.fit(X_train, y_train)\n>>> xx = np.linspace(0, 26, 100)\n>>> yy = regressor.predict(xx.reshape(xx.shape[0], 1))\n>>> plt.plot(xx, yy)\n\n>>> quadratic_featurizer = PolynomialFeatures(degree=2)\n>>> X_train_quadratic = quadratic_featurizer.fit_transform(X_train)\n>>> X_test_quadratic = quadratic_featurizer.transform(X_test)\n\n>>> regressor_quadratic = LinearRegression()\n>>> regressor_quadratic.fit(X_train_quadratic, y_train)\n>>> xx_quadratic = quadratic_featurizer.transform(xx.reshape(xx.shape[0], 1))\n\n>>> plt.plot(xx, regressor_quadratic.predict(xx_quadratic), c='r', linestyle='--')\n>>> plt.title('Pizza price regressed on diameter')\n>>> plt.xlabel('Diameter in inches')\n>>> plt.ylabel('Price in dollars')\n>>> plt.axis([0, 25, 0, 25])\n>>> plt.grid(True)\n>>> plt.scatter(X_train, y_train)\n>>> plt.show()\n\n>>> print X_train\n>>> print X_train_quadratic\n>>> print X_test\n>>> print X_test_quadratic\n>>> print 'Simple linear regression r-squared', regressor.score(X_test, y_test)\n>>> print 'Quadratic regression r-squared', regressor_quadratic.score(X_test_quadratic, y_test)\n```", "```py\n[[6], [8], [10], [14], [18]]\n[[  1   6  36]\n [  1   8  64]\n [  1  10 100]\n [  1  14 196]\n [  1  18 324]]\n[[6], [8], [11], [16]]\n[[  1   6  36]\n [  1   8  64]\n [  1  11 121]\n [  1  16 256]]\nSimple linear regression r-squared 0.809726797708\nQuadratic regression r-squared 0.867544365635\n```", "```py\n>>> import pandas as pd\n>>> df = pd.read_csv('winequality-red.csv', sep=';')\n>>> df.describe()\n\n                pH    sulphates      alcohol      quality\ncount  1599.000000  1599.000000  1599.000000  1599.000000\nmean      3.311113     0.658149    10.422983     5.636023\nstd       0.154386     0.169507     1.065668     0.807569\nmin       2.740000     0.330000     8.400000     3.000000\n25%       3.210000     0.550000     9.500000     5.000000\n50%       3.310000     0.620000    10.200000     6.000000\n75%       3.400000     0.730000    11.100000     6.000000\nmax       4.010000     2.000000    14.900000     8.000000\n```", "```py\n>>> import matplotlib.pylab as plt\n>>> plt.scatter(df['alcohol'], df['quality'])\n>>> plt.xlabel('Alcohol')\n>>> plt.ylabel('Quality')\n>>> plt.title('Alcohol Against Quality')\n>>> plt.show()\n```", "```py\n>>> from sklearn.linear_model import LinearRegression\n>>> import pandas as pd\n>>> import matplotlib.pylab as plt\n>>> from sklearn.cross_validation import train_test_split\n\n>>> df = pd.read_csv('wine/winequality-red.csv', sep=';')\n>>> X = df[list(df.columns)[:-1]]\n>>> y = df['quality']\n>>> X_train, X_test, y_train, y_test = train_test_split(X, y)\n\n>>> regressor = LinearRegression()\n>>> regressor.fit(X_train, y_train)\n>>> y_predictions = regressor.predict(X_test)\n>>> print 'R-squared:', regressor.score(X_test, y_test)\n0.345622479617\n```", "```py\n>>> import pandas as pd\n>>> from sklearn. cross_validation import cross_val_score\n>>> from sklearn.linear_model import LinearRegression\n>>> df = pd.read_csv('data/winequality-red.csv', sep=';')\n>>> X = df[list(df.columns)[:-1]]\n>>> y = df['quality']\n>>> regressor = LinearRegression()\n>>> scores = cross_val_score(regressor, X, y, cv=5)\n>>> print scores.mean(), scores\n0.290041628842 [ 0.13200871  0.31858135  0.34955348  0.369145    0.2809196 ]\n```", "```py\nPredicted: 4.89907499467 True: 4\nPredicted: 5.60701048317 True: 6\nPredicted: 5.92154439575 True: 6\nPredicted: 5.54405696963 True: 5\nPredicted: 6.07869910663 True: 7\nPredicted: 6.036656327 True: 6\nPredicted: 6.43923020473 True: 7\nPredicted: 5.80270760407 True: 6\nPredicted: 5.92425033278 True: 5\nPredicted: 5.31809822449 True: 6\nPredicted: 6.34837585295 True: 6\n```", "```py\n>>> import numpy as np\n>>> from sklearn.datasets import load_boston\n>>> from sklearn.linear_model import SGDRegressor\n>>> from sklearn.cross_validation import cross_val_score\n>>> from sklearn.preprocessing import StandardScaler\n>>> from sklearn.cross_validation import train_test_split\n>>> data = load_boston()\n>>> X_train, X_test, y_train, y_test = train_test_split(data.data, data.target)\n```", "```py\n>>> X_scaler = StandardScaler()\n>>> y_scaler = StandardScaler()\n>>> X_train = X_scaler.fit_transform(X_train)\n>>> y_train = y_scaler.fit_transform(y_train)\n>>> X_test = X_scaler.transform(X_test)\n>>> y_test = y_scaler.transform(y_test)\n```", "```py\n>>> regressor = SGDRegressor(loss='squared_loss')\n>>> scores = cross_val_score(regressor, X_train, y_train, cv=5)\n>>> print 'Cross validation r-squared scores:', scores\n>>> print 'Average cross validation r-squared score:', np.mean(scores)\n>>> regressor.fit_transform(X_train, y_train)\n>>> print 'Test set r-squared score', regressor.score(X_test, y_test)\n```", "```py\nCross validation r-squared scores: [ 0.73428974  0.80517755  0.58608421  0.83274059  0.69279604]\nAverage cross validation r-squared score: 0.730217627242\nTest set r-squared score 0.653188093125\n```"]