["```py\n    import pandas as pd\n    df = pd.read_csv('titanic.csv')\n    ```", "```py\n    # Have a look at the first 5 sample of the data\n    df.head()\n    ```", "```py\n    df.describe(include='all')\n    ```", "```py\n    df = df[df.columns[1:]] # Use the columns\n    df.head()\n    ```", "```py\n    df.mean()\n    Fare        33.295479\n    Pclass       2.294882\n    Age         29.881138\n    Parch        0.385027\n    SibSp        0.498854\n    Survived     0.383838\n    dtype: float64\n    df.std()\n    Fare        51.758668\n    Pclass       0.837836\n    Age         14.413493\n    Parch        0.865560\n    SibSp        1.041658\n    Survived     0.486592\n    dtype: float64\n    df.min()\n    Fare        0.00\n    Pclass      1.00\n    Age         0.17\n    Parch       0.00\n    SibSp       0.00\n    Survived    0.00\n    dtype: float64\n    df.max()\n    Fare        512.3292\n    Pclass        3.0000\n    Age          80.0000\n    Parch         9.0000\n    SibSp         8.0000\n    Survived      1.0000\n    dtype: float64\n    ```", "```py\n    df.quantile(0.33)\n    Fare         8.559325\n    Pclass       2.000000\n    Age         23.000000\n    Parch        0.000000\n    SibSp        0.000000\n    Survived     0.000000\n    Name: 0.33, dtype: float64\n    df.quantile(0.66)\n    Fare        26.0\n    Pclass       3.0\n    Age         34.0\n    Parch        0.0\n    SibSp        0.0\n    Survived     1.0\n    Name: 0.66, dtype: float64\n    df.quantile(0.99)\n    Fare        262.375\n    Pclass        3.000\n    Age          65.000\n    Parch         4.000\n    SibSp         5.000\n    Survived      1.000\n    Name: 0.99, dtype: float64\n    ```", "```py\n    class_groups = df.groupby('Pclass')\n    for name, index in class_groups:\n        print(f'Class: {name}: {len(index)}')\n    Class: 1: 323\n    Class: 2: 277\n    Class: 3: 709\n    ```", "```py\n    for clsGrp in df.Pclass.unique():\n        num_class = len(df[df.Pclass == clsGrp])\n        print(f'Class {clsGrp}: {num_class}')\n    Class 3: 709\n    Class 1: 323\n    Class 2: 277\n    ```", "```py\n    third_class = df.loc[(df.Pclass == 3)]\n    third_class.loc[(third_class.Age == third_class.Age.max())]\n    ```", "```py\n    fare_max = df.Fare.max()\n    age_max = df.Age.max()\n    df.agg({\n        'Fare': lambda x: x / fare_max, \n        'Age': lambda x: x / age_max,\n    }).head()\n    ```", "```py\n    df_nan_fare = df.loc[(df.Fare.isna())]\n    df_nan_fare\n    ```", "```py\nembarked_class_groups = df.groupby(['Embarked', 'Pclass'])\nindices = embarked_class_groups.groups[(df_nan_fare.Embarked.values[0], df_nan_fare.Pclass.values[0])]\nmean_fare = df.iloc[indices].Fare.mean()\ndf.loc[(df.index == 1043), 'Fare'] = mean_fare\ndf.iloc[1043]\n```", "```py\nCabin                      NaN\nEmbarked                     S\nFare                   14.4354\nPclass                       3\nTicket                    3701\nAge                       60.5\nName        Storey, Mr. Thomas\nParch                        0\nSex                       male\nSibSp                        0\nSurvived                   NaN\nName: 1043, dtype: object\n```", "```py\n    data = pd.read_csv('house_prices.csv')\n    ```", "```py\n    data.info()\n    data.describe().T\n    ```", "```py\n    mask = data.isnull()\n    total = mask.sum()\n    percent = 100*mask.mean()\n    missing_data = pd.concat([total, percent], axis=1,join='outer',\n                   keys=['count_missing', 'perc_missing'])\n    missing_data.sort_values(by='perc_missing', ascending=False, inplace=True)\n    missing_data[missing_data.count_missing > 0]\n    ```", "```py\n    nullable_columns = data.columns[mask.any()].tolist()\n    msno.matrix(data[nullable_columns].sample(500))\n    plt.show()\n    msno.heatmap(data[nullable_columns], figsize=(18,18))\n    plt.show()\n    ```", "```py\n    data = data.loc[:,missing_data[missing_data.perc_missing < 80].index]\n    ```", "```py\n    data['FireplaceQu'] = data['FireplaceQu'].fillna('NA')\n    ```", "```py\n    plt.figure(figsize=(8,6))\n    plt.hist(data.SalePrice, bins=range(0,800000,50000))\n    plt.ylabel('Number of data points')\n    plt.xlabel('SalePrice')\n    plt.show()\n    ```", "```py\n    object_variables = data.select_dtypes(include=[np.object])\n    object_variables.nunique().sort_values()\n    ```", "```py\n    counts = data.HouseStyle.value_counts(dropna=False)\n    counts.reset_index().sort_values(by='index')\n    ```", "```py\n    plt.figure(figsize=(10,10))\n    plt.pie(counts, labels=counts.index)\n    plt.title('Pie chart showing counts for\\nHouseStyle categories')\n    plt.show()\n    ```", "```py\n    numeric_variables = data.select_dtypes(include=[np.number])\n    numeric_variables.nunique().sort_values(ascending=False)\n    ```", "```py\n    plt.figure(figsize=(10,7))\n    sns.distplot(data.LotArea.dropna(), , bins=range(0,100000,1000))\n    plt.xlim(0,100000)\n    plt.show()\n    ```", "```py\n    data.skew().sort_values()\n    data.kurt()\n    ```", "```py\n    plt.figure(figsize = (12,10))\n    sns.heatmap(data.corr(), square=True, cmap=\"RdBu\", vmin=-1, vmax=1)\n    plt.show()\n    ```", "```py\n    feature_subset = [\n        'GarageArea', 'GarageCars','GarageCond','GarageFinish','GarageQual','GarageType',\n        'GarageYrBlt','GrLivArea','LotArea','MasVnrArea','SalePrice'\n    ]\n    ```", "```py\n    plt.figure(figsize = (12,10))\n    sns.heatmap(data[feature_subset].corr(), square=True, annot=True, cmap=\"RdBu\", vmin=-1, vmax=1)\n    plt.show()\n    ```", "```py\n    sns.pairplot(data[feature_subset].dropna(), kind ='scatter', diag_kind='kde')\n    plt.show()\n    ```", "```py\n    plt.figure(figsize=(10, 10))\n    sns.boxplot(x='GarageCars', y=\"SalePrice\", data=data)\n    plt.show()\n    ```", "```py\n    plt.figure(figsize=(10,7))\n    sns.lineplot(x=data.YearBuilt, y=data.SalePrice, ci=None)\n    plt.show()\n    ```", "```py\n    df = pd.read_csv('austin_weather.csv')\n    df.head()\n    ```", "```py\n    df = df[['Date', 'TempAvgF']]\n    df.head()\n    ```", "```py\n    df['Year'] = [int(dt[:4]) for dt in df.Date]\n    df.head()\n    ```", "```py\n    df['Month'] = [int(dt[5:7]) for dt in df.Date]\n    df.head()\n    ```", "```py\n    df_first_year = df[:365]\n    df_first_year.head()\n    ```", "```py\n    window = 20\n    rolling = df_first_year.TempAvgF.rolling(window).mean();\n    rolling.head(n=20)\n    ```", "```py\n    0       NaN\n    1       NaN\n    2       NaN\n    3       NaN\n    4       NaN\n    5       NaN\n    6       NaN\n    7       NaN\n    8       NaN\n    9       NaN\n    10      NaN\n    11      NaN\n    12      NaN\n    13      NaN\n    14      NaN\n    15      NaN\n    16      NaN\n    17      NaN\n    18      NaN\n    19    47.75\n    Name: TempAvgF, dtype: float64\n    ```", "```py\n    fig = plt.figure(figsize=(10, 7))\n    ax = fig.add_axes([1, 1, 1, 1]);\n    # Temp measurements\n    ax.scatter(range(1, 366), df_first_year.TempAvgF, label='Raw Data');\n    ax.plot(range(1, 366), rolling, c='r', label=f'{window} day moving average');\n    ax.set_title('Daily Mean Temperature Measurements')\n    ax.set_xlabel('Day')\n    ax.set_ylabel('Temperature (degF)')\n    ax.set_xticks(range(1, 366), 10)\n    ax.legend();\n    ```", "```py\n    df.head()\n    ```", "```py\n    rolling.head(n=30)\n    ```", "```py\n    model = LinearRegression()\n    model\n    ```", "```py\n    LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n             normalize=False)\n    ```", "```py\n    df_first_year.loc[:,'DayOfYear'] = [i + 1 for i in df_first_year.index]\n    df_first_year.head()\n    ```", "```py\n    # Note the year values need to be provided as an N x 1 array\n    model.fit(df_first_year.DayOfYear.values.reshape((-1, 1)), df_first_year.TempAvgF)\n    ```", "```py\n    LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n             normalize=False)\n    ```", "```py\n    print(f'm = {model.coef_[0]}')\n    print(f'c = {model.intercept_}')\n    print('\\nModel Definition')\n    print(f'y = {model.coef_[0]:0.4}x + {model.intercept_:0.4f}')\n    ```", "```py\n    m = 0.04909173467448788\n    c = 60.28196597922625\n    Model Definition\n    y = 0.04909x + 60.2820\n    ```", "```py\n    trend_x = np.array([\n        1,\n        182.5,\n        365\n    ])\n    trend_y = model.predict(trend_x.reshape((-1, 1)))\n    trend_y\n    ```", "```py\n    array([60.33105771, 69.24120756, 78.20044914])\n    ```", "```py\n    fig = plt.figure(figsize=(10, 7))\n    ax = fig.add_axes([1, 1, 1, 1]);\n    # Temp measurements\n    ax.scatter(df_first_year.DayOfYear, df_first_year.TempAvgF, label='Raw Data');\n    ax.plot(df_first_year.DayOfYear, rolling, c='r', label=f'{window} day moving average');\n    ax.plot(trend_x, trend_y, c='k', label='Model: Predicted trendline')\n    ax.set_title('Daily Mean Temperature Measurements')\n    ax.set_xlabel('Day')\n    ax.set_ylabel('Temperature (degF)')\n    ax.set_xticks(range(1, 366), 10)\n    ax.legend();\n    ```", "```py\n    # Note the year values need to be provided as an N x 1 array\n    r2 = model.score(df_first_year.DayOfYear.values.reshape((-1, 1)), df_first_year.TempAvgF)\n    print(f'r2 score = {r2:0.4f}')\n    ```", "```py\n    r2 score = 0.1222\n    ```", "```py\n    fig = plt.figure(figsize=(10, 7))\n    ax = fig.add_axes([1, 1, 1, 1]);\n    # Temp measurements\n    ax.scatter(df_first_year.DayOfYear, df_first_year.TempAvgF, label='Raw Data');\n    ax.plot(df_first_year.DayOfYear, rolling, c='r', label=f'{window} day moving average');\n    ax.set_title('Daily Mean Temperature Measurements')\n    ax.set_xlabel('Day')\n    ax.set_ylabel('Temperature (degF)')\n    ax.set_xticks(range(1, 366), 10)\n    ax.legend();\n    ```", "```py\n    df_first_year.loc[:,'inflection'] = [1 * int(i < 250) for i in df_first_year.DayOfYear]\n    ```", "```py\n    df_first_year.head()\n    ```", "```py\n    df_first_year.tail()\n    ```", "```py\n    # Note the year values need to be provided as an N x 1 array\n    model = LinearRegression()\n    model.fit(df_first_year[['DayOfYear', 'inflection']], df_first_year.TempAvgF)\n    ```", "```py\n    LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n             normalize=False)\n    ```", "```py\n    # Note the year values need to be provided as an N x 1 array\n    r2 = model.score(df_first_year[['DayOfYear', 'inflection']], df_first_year.TempAvgF)\n    print(f'r2 score = {r2:0.4f}')\n    ```", "```py\n    r2 score = 0.3631\n    ```", "```py\n    trend_y = model.predict(df_first_year[['DayOfYear', 'inflection']].values)\n    trend_y\n    ```", "```py\n    array([51.60311133, 51.74622654, 51.88934175, 52.03245696, 52.17557217,\n           52.31868739, 52.4618026 , 52.60491781, 52.74803302, 52.89114823,\n           53.03426345, 53.17737866, 53.32049387, 53.46360908, 53.60672429,\n           53.7498395 , 53.89295472, 54.03606993, 54.17918514, 54.32230035,\n           54.46541556, 54.60853078, 54.75164599, 54.8947612 , 55.03787641,\n    …\n    …\n           73.88056649, 74.0236817 , 74.16679692, 74.30991213, 74.45302734,\n           74.59614255, 74.73925776, 74.88237297, 75.02548819, 75.1686034 ,\n           75.31171861, 75.45483382, 75.59794903, 75.74106425, 75.88417946,\n           76.02729467, 76.17040988, 76.31352509, 76.4566403 , 76.59975552,\n           76.74287073, 76.88598594, 77.02910115, 77.17221636, 77.31533157])\n    ```", "```py\n    fig = plt.figure(figsize=(10, 7))\n    ax = fig.add_axes([1, 1, 1, 1]);\n    # Temp measurements\n    ax.scatter(df_first_year.DayOfYear, df_first_year.TempAvgF, label='Raw Data');\n    ax.plot(df_first_year.DayOfYear, rolling, c='r', label=f'{window} day moving average');\n    ax.plot(df_first_year.DayOfYear, trend_y, c='k', label='Model: Predicted trendline')\n    ax.set_title('Daily Mean Temperature Measurements')\n    ax.set_xlabel('Day')\n    ax.set_ylabel('Temperature (degF)')\n    ax.set_xticks(range(1, 366), 10)\n    ax.legend();\n    ```", "```py\n    # Using a sine curve\n    df_first_year['DayOfYear2'] = np.sin(df_first_year['DayOfYear'] / df_first_year['DayOfYear'].max())\n    df_first_year.head()\n    ```", "```py\n    # Note the year values need to be provided as an N x 1 array\n    model = LinearRegression()\n    model.fit(df_first_year[['DayOfYear2', 'DayOfYear']], df_first_year.TempAvgF)\n    ```", "```py\n    LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n             normalize=False)\n    ```", "```py\n    print(f'a = {model.coef_[0]}')\n    print(f'm = {model.coef_[1]}')\n    print(f'c = {model.intercept_}')\n    print('\\nModel Definition')\n    print(f'y = {model.coef_[0]:0.4}x^2 + {model.coef_[1]:0.4}x + {model.intercept_:0.4f}')\n    ```", "```py\n    a = 634.322313570282\n    m = -1.4371290614190075\n    c = 39.93286585807408\n    Model Definition\n    y = 634.3x^2 + -1.437x + 39.9329\n    ```", "```py\n    # Note the year values need to be provided as an N x 1 array\n    r2 = model.score(df_first_year[['DayOfYear2', 'DayOfYear']], df_first_year.TempAvgF)\n    print(f'r2 score = {r2:0.4f}')\n    ```", "```py\n    r2 score = 0.7047\n    ```", "```py\n    trend_y = model.predict(df_first_year[['DayOfYear2', 'DayOfYear']].values)\n    trend_y\n    ```", "```py\n    array([40.23360397, 40.53432905, 40.83502803, 41.13568788, 41.43629555,\n           41.736838  , 42.03730219, 42.33767507, 42.6379436 , 42.93809474,\n           43.23811546, 43.5379927 , 43.83771344, 44.13726463, 44.43663324,\n           44.73580624, 45.03477059, 45.33351327, 45.63202123, 45.93028146,\n           46.22828093, 46.52600661, 46.82344549, 47.12058453, 47.41741073,\n    …\n    …\n           59.96306563, 59.55705293, 59.14720371, 58.73351024, 58.31596484,\n           57.89455987, 57.46928769, 57.04014072, 56.60711138, 56.17019215,\n           55.7293755 , 55.28465397, 54.83602011, 54.38346649, 53.92698572,\n           53.46657045, 53.00221334, 52.53390709, 52.06164442, 51.58541811,\n           51.10522093, 50.62104569, 50.13288526, 49.6407325 , 49.14458033])\n    ```", "```py\n    fig = plt.figure(figsize=(10, 7))\n    ax = fig.add_axes([1, 1, 1, 1]);\n    # Temp measurements\n    ax.scatter(df_first_year.DayOfYear, df_first_year.TempAvgF, label='Raw Data');\n    ax.plot(df_first_year.DayOfYear, rolling, c='r', label=f'{window} day moving average');\n    ax.plot(df_first_year.DayOfYear, trend_y, c='k', label='Model: Predicted trendline')\n    ax.set_title('Daily Mean Temperature Measurements')\n    ax.set_xlabel('Day')\n    ax.set_ylabel('Temperature (degF)')\n    ax.set_xticks(range(1, 366), 10)\n    ax.legend();\n    ```", "```py\n    grad_model = SGDRegressor(max_iter=None, tol=1e-3)\n    _x = df_first_year.DayOfYear / df_first_year.DayOfYear.max()\n    ```", "```py\n    grad_model.fit(_x.values.reshape((-1, 1)), df_first_year.TempAvgF)\n    ```", "```py\n    SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n           eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n           learning_rate='invscaling', loss='squared_loss', max_iter=None,\n           n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n           random_state=None, shuffle=True, tol=None, validation_fraction=0.1,\n           verbose=0, warm_start=False)\n    ```", "```py\n    print(f'm = {grad_model.coef_[0]}')\n    print(f'c = {grad_model.intercept_[0]}')\n    print('\\nModel Definition')\n    print(f'y = {grad_model.coef_[0]:0.4}x + {grad_model.intercept_[0]:0.4f}')\n    ```", "```py\n    m = 26.406162532140563\n    c = 55.07470859678077\n    Model Definition\n    y = 26.41x + 55.0747\n    ```", "```py\n    _trend_x = trend_x / trend_x.max()\n    trend_y = grad_model.predict(_trend_x.reshape((-1, 1)))\n    trend_y\n    ```", "```py\n    array([55.14705425, 68.27778986, 81.48087113])\n    ```", "```py\n    fig = plt.figure(figsize=(10, 7))\n    ax = fig.add_axes([1, 1, 1, 1]);\n    # Temp measurements\n    ax.scatter(df_first_year.DayOfYear, df_first_year.TempAvgF, label='Raw Data');\n    ax.plot(df_first_year.DayOfYear, rolling, c='r', label=f'{window} day moving average');\n    ax.plot(trend_x, trend_y, c='k', linestyle='--', label='Model: Predicted trendline')\n    ax.set_title('Daily Mean Temperature Measurements')\n    ax.set_xlabel('Day')\n    ax.set_ylabel('Temperature (degF)')\n    ax.set_xticks(range(1, 366), 10)\n    ax.legend();\n    ```", "```py\n    plt.figure(figsize=(10, 7))\n    plt.plot(df.TempAvgF.values);\n    yrs = [yr for yr in df.Year.unique()]\n    plt.xticks(np.arange(0, len(df), len(df) // len(yrs)), yrs);\n    plt.title('Austin Texas Average Daily Temperature');\n    plt.xlabel('Year');\n    plt.ylabel('Temperature (F)');\n    ```", "```py\n    plt.figure(figsize=(10, 7))\n    plt.plot(df.TempAvgF.values, label='Original Dataset');\n    plt.plot(df.TempAvgF.shift(20), c='r', linestyle='--',\n        label='Lag 20');\n    yrs = [yr for yr in df.Year.unique()]\n    plt.xticks(np.arange(0, len(df), len(df) // len(yrs)), yrs);\n    plt.title('Austin Texas Average Daily Temperature');\n    plt.xlabel('Year');\n    plt.ylabel('Temperature (F)');\n    plt.legend();\n    ```", "```py\n    plt.figure(figsize=(10, 7))\n    pd.plotting.autocorrelation_plot(df.TempAvgF);\n    ```", "```py\n    plt.figure(figsize=(10,7))\n    ax = pd.plotting.lag_plot(df.TempAvgF, lag=5);\n    ```", "```py\n    plt.figure(figsize=(10,7))\n    ax = pd.plotting.lag_plot(df.TempAvgF, lag=1000);\n    ```", "```py\n    from statsmodels.tsa.ar_model import AR\n    model = AR(df.TempAvgF)\n    ```", "```py\n    model_fit = model.fit()\n    print('Lag: %s' % model_fit.k_ar)\n    print('Coefficients: %s' % model_fit.params)\n    ```", "```py\n    Lag: 23\n    Coefficients: const           1.909395\n    L1.TempAvgF     0.912076\n    L2.TempAvgF    -0.334043\n    L3.TempAvgF     0.157353\n    L4.TempAvgF     0.025721\n    L5.TempAvgF     0.041342\n    L6.TempAvgF     0.030831\n    L7.TempAvgF    -0.021230\n    L8.TempAvgF     0.020324\n    L9.TempAvgF     0.025147\n    L10.TempAvgF    0.059739\n    L11.TempAvgF   -0.017337\n    L12.TempAvgF    0.043553\n    L13.TempAvgF   -0.027795\n    L14.TempAvgF    0.053547\n    L15.TempAvgF    0.013070\n    L16.TempAvgF   -0.033157\n    L17.TempAvgF   -0.000072\n    L18.TempAvgF   -0.026307\n    L19.TempAvgF    0.025258\n    L20.TempAvgF    0.038341\n    L21.TempAvgF    0.007885\n    L22.TempAvgF   -0.008889\n    L23.TempAvgF   -0.011080\n    dtype: float64\n    ```", "```py\n    predictions = model_fit.predict(start=model_fit.k_ar, end=len(df) + 1000)\n    predictions[:10].values\n    ```", "```py\n    array([54.81171857, 56.89097085, 56.41891585, 50.98627626, 56.11843512,\n           53.20665111, 55.13941554, 58.4679288 , 61.92497136, 49.46049801])\n    ```", "```py\n    plt.figure(figsize=(10, 7))\n    plt.plot(df.TempAvgF.values, label='Original Dataset');\n    plt.plot(predictions, c='g', linestyle=':', label='Predictions');\n    yrs = [yr for yr in df.Year.unique()]\n    plt.xticks(np.arange(0, len(df), len(df) // len(yrs)), yrs);\n    plt.title('Austin Texas Average Daily Temperature');\n    plt.xlabel('Year');\n    plt.ylabel('Temperature (F)');\n    plt.legend();\n    ```", "```py\n    plt.figure(figsize=(10, 7))\n    plt.plot(df.TempAvgF.values, label='Original Dataset');\n    plt.plot(predictions, c='g', linestyle=':', label='Predictions');\n    yrs = [yr for yr in df.Year.unique()]\n    plt.xticks(np.arange(0, len(df), len(df) // len(yrs)), yrs);\n    plt.title('Austin Texas Average Daily Temperature');\n    plt.xlabel('Year');\n    plt.ylabel('Temperature (F)');\n    plt.xlim([100, 200])\n    plt.legend();\n    ```", "```py\n    import struct\n    import numpy as np\n    import gzip\n    import urllib.request\n    import matplotlib.pyplot as plt\n    from array import array\n    from sklearn.linear_model import LinearRegression\n    ```", "```py\n    with gzip.open('train-images-idx3-ubyte.gz', 'rb') as f:\n        magic, size, rows, cols = struct.unpack(\">IIII\", f.read(16))\n        img = np.array(array(\"B\", f.read())).reshape((size, rows, cols))\n    with gzip.open('train-labels-idx1-ubyte.gz', 'rb') as f:\n        magic, size = struct.unpack(\">II\", f.read(8))\n        labels = np.array(array(\"B\", f.read()))\n    with gzip.open('t10k-images-idx3-ubyte.gz', 'rb') as f:\n        magic, size, rows, cols = struct.unpack(\">IIII\", f.read(16))\n        img_test = np.array(array(\"B\", f.read())).reshape((size, rows, cols))\n    with gzip.open('t10k-labels-idx1-ubyte.gz', 'rb') as f:\n        magic, size = struct.unpack(\">II\", f.read(8))\n        labels_test = np.array(array(\"B\", f.read()))\n    ```", "```py\n    for i in range(10):\n        plt.subplot(2, 5, i + 1)\n        plt.imshow(img[i], cmap='gray');\n        plt.title(f'{labels[i]}');\n        plt.axis('off')\n    ```", "```py\n    samples_0_1 = np.where((labels == 0) | (labels == 1))[0]\n    images_0_1 = img[samples_0_1]\n    labels_0_1 = labels[samples_0_1]\n    samples_0_1_test = np.where((labels_test == 0) | (labels_test == 1))\n    images_0_1_test = img_test[samples_0_1_test].reshape((-1, rows * cols))\n    labels_0_1_test = labels_test[samples_0_1_test]\n    ```", "```py\n    sample_0 = np.where((labels == 0))[0][0]\n    plt.imshow(img[sample_0], cmap='gray');\n    ```", "```py\n    sample_1 = np.where((labels == 1))[0][0]\n    plt.imshow(img[sample_1], cmap='gray');\n    ```", "```py\n    images_0_1 = images_0_1.reshape((-1, rows * cols))\n    images_0_1.shape\n    ```", "```py\n    (12665, 784)\n    ```", "```py\n    model = LinearRegression()\n    model.fit(X=images_0_1, y=labels_0_1)\n    ```", "```py\n    LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n             normalize=False)\n    ```", "```py\n    model.score(X=images_0_1, y=labels_0_1)\n    ```", "```py\n    0.9705320567708795\n    ```", "```py\n    y_pred = model.predict(images_0_1) > 0.5\n    y_pred = y_pred.astype(int)\n    y_pred\n    ```", "```py\n    array([0, 1, 1, ..., 1, 0, 1])\n    ```", "```py\n    np.sum(y_pred == labels_0_1) / len(labels_0_1)\n    ```", "```py\n    0.9947887879984209\n    ```", "```py\n    y_pred = model.predict(images_0_1_test) > 0.5\n    y_pred = y_pred.astype(int)\n    np.sum(y_pred == labels_0_1_test) / len(labels_0_1_test)\n    ```", "```py\n    0.9938534278959811\n    ```", "```py\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    from sklearn.linear_model import LogisticRegression\n    ```", "```py\n    df = pd.read_csv('iris-data.csv')\n    df.head()\n    ```", "```py\n    markers = {\n        'Iris-setosa': {'marker': 'x'},\n        'Iris-versicolor': {'marker': '*'},\n        'Iris-virginica': {'marker': 'o'},\n    }\n    plt.figure(figsize=(10, 7))\n    for name, group in df.groupby('Species'):\n        plt.scatter(group['Sepal Width'], group['Petal Length'], \n                    label=name,\n                    marker=markers[name]['marker'],\n                   )\n\n    plt.title('Species Classification Sepal Width vs Petal Length');\n    plt.xlabel('Sepal Width (mm)');\n    plt.ylabel('Petal Length (mm)');\n    plt.legend();\n    ```", "```py\n    selected_features = [\n        'Sepal Width', # List features here\n        'Petal Length'\n    ]\n    ```", "```py\n    species = [\n        'Iris-setosa', # 0\n        'Iris-versicolor', # 1\n        'Iris-virginica', # 2\n    ]\n    output = [species.index(spec) for spec in df.Species]\n    ```", "```py\n    model = LogisticRegression(multi_class='auto', solver='lbfgs')\n    model.fit(df[selected_features], output)\n    ```", "```py\n    LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n              intercept_scaling=1, max_iter=100, multi_class='auto',\n              n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n              tol=0.0001, verbose=0, warm_start=False)\n    ```", "```py\n    model.score(df[selected_features], output)\n    ```", "```py\n    0.9533333333333334\n    ```", "```py\n    selected_features = [\n        'Sepal Length', # List features here\n        'Petal Width'\n    ]\n    model.fit(df[selected_features], output)\n    model.score(df[selected_features], output)\n    ```", "```py\n    0.96\n    ```", "```py\n    selected_features = [\n        'Sepal Length', # List features here\n        'Sepal Width'\n    ]\n    model.fit(df[selected_features], output)\n    model.score(df[selected_features], output)\n    ```", "```py\n    0.82\n    ```", "```py\n    import struct\n    import numpy as np\n    import gzip\n    import urllib.request\n    import matplotlib.pyplot as plt\n    from array import array\n    from sklearn.neighbors import KNeighborsClassifier as KNN\n    ```", "```py\n    with gzip.open('train-images-idx3-ubyte.gz', 'rb') as f:\n        magic, size, rows, cols = struct.unpack(\">IIII\", f.read(16))\n        img = np.array(array(\"B\", f.read())).reshape((size, rows, cols))\n    ```", "```py\n    with gzip.open('train-labels-idx1-ubyte.gz', 'rb') as f:\n        magic, size = struct.unpack(\">II\", f.read(8))\n        labels = np.array(array(\"B\", f.read()))\n    ```", "```py\n    with gzip.open('t10k-images-idx3-ubyte.gz', 'rb') as f:\n        magic, size, rows, cols = struct.unpack(\">IIII\", f.read(16))\n        img_test = np.array(array(\"B\", f.read())).reshape((size, rows, cols))\n    ```", "```py\n    with gzip.open('t10k-labels-idx1-ubyte.gz', 'rb') as f:\n        magic, size = struct.unpack(\">II\", f.read(8))\n        labels_test = np.array(array(\"B\", f.read()))\n    ```", "```py\n    for i in range(10):\n        plt.subplot(2, 5, i + 1)\n        plt.imshow(img[i], cmap='gray');\n        plt.title(f'{labels[i]}');\n        plt.axis('off')\n    ```", "```py\n    selection = np.random.choice(len(img), 5000)\n    selected_images = img[selection]\n    selected_labels = labels[selection]\n    ```", "```py\n    selected_images = selected_images.reshape((-1, rows * cols))\n    selected_images.shape\n    ```", "```py\n    (5000, 784)\n    ```", "```py\n    model = KNN(n_neighbors=3)\n    model.fit(X=selected_images, y=selected_labels)\n    ```", "```py\n    KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n               metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n               weights='uniform')\n    ```", "```py\n    model.score(X=selected_images, y=selected_labels)\n    ```", "```py\n    0.9692\n    ```", "```py\n    model.predict(selected_images)[:2]\n    plt.subplot(1, 2, 1)\n    plt.imshow(selected_images[0].reshape((28, 28)), cmap='gray');\n    plt.axis('off');\n    plt.subplot(1, 2, 2)\n    plt.imshow(selected_images[1].reshape((28, 28)), cmap='gray');\n    plt.axis('off');\n    ```", "```py\n    model.score(X=img_test.reshape((-1, rows * cols)), y=labels_test)\n    ```", "```py\n    0.9376\n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    import seaborn as sns\n    %matplotlib inline\n    import matplotlib.pyplot as plt\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import mean_absolute_error\n    from sklearn.model_selection import KFold\n    from sklearn.linear_model import LinearRegression\n    from sklearn.tree import DecisionTreeRegressor\n    from sklearn.neighbors import KNeighborsRegressor\n    from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n    ```", "```py\n    data = pd.read_csv('house_prices.csv')\n    data.head()\n    ```", "```py\n    perc_missing = data.isnull().mean()*100\n    cols = perc_missing[perc_missing < 10].index.tolist() \n    cols\n    ```", "```py\n    data = data.loc[:, cols[1:]]\n    ```", "```py\n    data_obj = pd.get_dummies(data.select_dtypes(include=[np.object]).fillna('NA'))\n    data_num = data.select_dtypes(include=[np.number]).fillna(-1)\n    data_final = pd.concat([data_obj, data_num], axis=1)\n    ```", "```py\n    train, val = train, val = train_test_split(data_final, test_size=0.2, random_state=11)\n    x_train = train.drop(columns=['SalePrice'])\n    y_train = train['SalePrice'].values\n    x_val = val.drop(columns=['SalePrice'])\n    y_val = val['SalePrice'].values\n    ```", "```py\n    train_mae_values, val_mae_values = {}, {}\n    ```", "```py\n    # Decision Tree\n    dt_params = {\n        'criterion': 'mae',\n        'min_samples_leaf': 10,\n        'random_state': 11\n    }\n    dt = DecisionTreeRegressor(**dt_params)\n    dt.fit(x_train, y_train)\n    dt_preds_train = dt.predict(x_train)\n    dt_preds_val = dt.predict(x_val)\n    train_mae_values['dt'] = mean_absolute_error(y_true=y_train, y_pred=dt_preds_train)\n    val_mae_values['dt'] = mean_absolute_error(y_true=y_val, y_pred=dt_preds_val)\n    ```", "```py\n    # k-Nearest Neighbors\n    knn_params = {\n        'n_neighbors': 5\n    }\n    knn = KNeighborsRegressor(**knn_params)\n    knn.fit(x_train, y_train)\n    knn_preds_train = knn.predict(x_train)\n    knn_preds_val = knn.predict(x_val)\n    train_mae_values['knn'] = mean_absolute_error(y_true=y_train, y_pred=knn_preds_train)\n    val_mae_values['knn'] = mean_absolute_error(y_true=y_val, y_pred=knn_preds_val)\n    ```", "```py\n    # Random Forest\n    rf_params = {\n        'n_estimators': 50,\n        'criterion': 'mae',\n        'max_features': 'sqrt',\n        'min_samples_leaf': 10,\n        'random_state': 11,\n        'n_jobs': -1\n    }\n    rf = RandomForestRegressor(**rf_params)\n    rf.fit(x_train, y_train)\n    rf_preds_train = rf.predict(x_train)\n    rf_preds_val = rf.predict(x_val)\n    train_mae_values['rf'] = mean_absolute_error(y_true=y_train, y_pred=rf_preds_train)\n    val_mae_values['rf'] = mean_absolute_error(y_true=y_val, y_pred=rf_preds_val)\n    ```", "```py\n    # Gradient Boosting\n    gbr_params = {\n        'n_estimators': 50,\n        'criterion': 'mae',\n        'max_features': 'sqrt',\n        'max_depth': 3,\n        'min_samples_leaf': 5,\n        'random_state': 11\n    }\n    gbr = GradientBoostingRegressor(**gbr_params)\n    gbr.fit(x_train, y_train)\n    gbr_preds_train = gbr.predict(x_train)\n    gbr_preds_val = gbr.predict(x_val)\n    train_mae_values['gbr'] = mean_absolute_error(y_true=y_train, y_pred=gbr_preds_train)\n    val_mae_values['gbr'] = mean_absolute_error(y_true=y_val, y_pred=gbr_preds_val)\n    ```", "```py\n    num_base_predictors = len(train_mae_values) # 4\n    x_train_with_metapreds = np.zeros((x_train.shape[0], x_train.shape[1]+num_base_predictors))\n    x_train_with_metapreds[:, :-num_base_predictors] = x_train\n    x_train_with_metapreds[:, -num_base_predictors:] = -1\n    ```", "```py\n    kf = KFold(n_splits=5, random_state=11)\n    for train_indices, val_indices in kf.split(x_train):\n        kfold_x_train, kfold_x_val = x_train.iloc[train_indices], x_train.iloc[val_indices]\n        kfold_y_train, kfold_y_val = y_train[train_indices], y_train[val_indices]\n\n        predictions = []\n\n        dt = DecisionTreeRegressor(**dt_params)\n        dt.fit(kfold_x_train, kfold_y_train)\n        predictions.append(dt.predict(kfold_x_val))\n        knn = KNeighborsRegressor(**knn_params)\n        knn.fit(kfold_x_train, kfold_y_train)\n        predictions.append(knn.predict(kfold_x_val))\n        gbr = GradientBoostingRegressor(**gbr_params)\n        rf.fit(kfold_x_train, kfold_y_train)\n        predictions.append(rf.predict(kfold_x_val))\n        gbr = GradientBoostingRegressor(**gbr_params)\n        gbr.fit(kfold_x_train, kfold_y_train)\n        predictions.append(gbr.predict(kfold_x_val))\n\n        for i, preds in enumerate(predictions):\n            x_train_with_metapreds[val_indices, -(i+1)] = preds\n    ```", "```py\n    x_val_with_metapreds = np.zeros((x_val.shape[0], x_val.shape[1]+num_base_predictors))\n    x_val_with_metapreds[:, :-num_base_predictors] = x_val\n    x_val_with_metapreds[:, -num_base_predictors:] = -1\n    ```", "```py\n    predictions = []\n\n    dt = DecisionTreeRegressor(**dt_params)\n    dt.fit(x_train, y_train)\n    predictions.append(dt.predict(x_val))\n    knn = KNeighborsRegressor(**knn_params)\n    knn.fit(x_train, y_train)\n    predictions.append(knn.predict(x_val))\n    gbr = GradientBoostingRegressor(**gbr_params)\n    rf.fit(x_train, y_train)\n    predictions.append(rf.predict(x_val))\n    gbr = GradientBoostingRegressor(**gbr_params)\n    gbr.fit(x_train, y_train)\n    predictions.append(gbr.predict(x_val))\n    for i, preds in enumerate(predictions):\n        x_val_with_metapreds[:, -(i+1)] = preds\n    ```", "```py\n    lr = LinearRegression(normalize=False)\n    lr.fit(x_train_with_metapreds, y_train)\n    lr_preds_train = lr.predict(x_train_with_metapreds)\n    lr_preds_val = lr.predict(x_val_with_metapreds)\n    train_mae_values['lr'] = mean_absolute_error(y_true=y_train, y_pred=lr_preds_train)\n    val_mae_values['lr'] = mean_absolute_error(y_true=y_val, y_pred=lr_preds_val)\n    ```", "```py\n    mae_scores = pd.concat([pd.Series(train_mae_values, name='train'), \n                            pd.Series(val_mae_values, name='val')], \n                           axis=1)\n    mae_scores\n    ```", "```py\n    mae_scores.plot(kind='bar', figsize=(10,7))\n    plt.ylabel('MAE')\n    plt.xlabel('Model')\n    plt.show()\n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    import json\n    %matplotlib inline\n    import matplotlib.pyplot as plt\n    from sklearn.preprocessing import OneHotEncoder\n    from sklearn.model_selection import RandomizedSearchCV, train_test_split\n    from sklearn.ensemble import GradientBoostingClassifier\n    from sklearn.metrics import (accuracy_score, precision_score, recall_score, confusion_matrix, precision_recall_curve)\n    ```", "```py\n    data = pd.read_csv('attrition_train.csv')\n    data.info()\n    ```", "```py\n    with open('categorical_variable_values.json', 'r') as f:\n        cat_values_dict = json.load(f)\n    cat_values_dict\n    ```", "```py\n    num_orig_cols = data.shape[1] - len(cat_values_dict)\n    num_enc_cols = sum([len(cats) for cats in cat_values_dict.values()])\n    print(num_orig_cols, num_enc_cols)\n    ```", "```py\n    26 24\n    ```", "```py\n    X = np.zeros(shape=(data.shape[0], num_orig_cols+num_enc_cols-1))\n    mask = [(each not in cat_values_dict and each != 'Attrition') for each in data.columns]\n    X[:, :num_orig_cols-1] = data.loc[:, data.columns[mask]]\n    ```", "```py\n    cat_cols = list(cat_values_dict.keys())\n    cat_values = [cat_values_dict[col] for col in data[cat_cols].columns]\n    ohe = OneHotEncoder(categories=cat_values, sparse=False, )\n    X[:, num_orig_cols-1:] = ohe.fit_transform(X=data[cat_cols])\n    y = data.Attrition.values\n    print(X.shape)\n    print(y.shape)\n    ```", "```py\n    (1176, 49)\n    (1176,)\n    ```", "```py\n    meta_gbc = GradientBoostingClassifier()\n    param_dist = {\n        'n_estimators': list(range(10, 210, 10)),\n        'criterion': ['mae', 'mse'],\n        'max_features': ['sqrt', 'log2', 0.25, 0.3, 0.5, 0.8, None],\n        'max_depth': list(range(1, 10)),\n        'min_samples_leaf': list(range(1, 10))\n    }\n    ```", "```py\n    rand_search_params = {\n        'param_distributions': param_dist,\n        'scoring': 'accuracy',\n        'n_iter': 100,\n        'cv': 5,\n        'return_train_score': True,\n        'n_jobs': -1,\n        'random_state': 11\n    }\n    random_search = RandomizedSearchCV(meta_gbc, **rand_search_params)\n    random_search.fit(X, y)\n    ```", "```py\n    idx = np.argmax(random_search.cv_results_['mean_test_score'])\n    final_params = random_search.cv_results_['params'][idx]\n    final_params\n    ```", "```py\n    train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.15, random_state=11)\n    print(train_X.shape, train_y.shape, val_X.shape, val_y.shape)\n    ```", "```py\n    ((999, 49), (999,), (177, 49), (177,))\n    ```", "```py\n    gbc = GradientBoostingClassifier(**final_params)\n    gbc.fit(train_X, train_y)\n    preds_train = gbc.predict(train_X)\n    preds_val = gbc.predict(val_X)\n    pred_probs_val = np.array([each[1] for each in gbc.predict_proba(val_X)])\n    ```", "```py\n    print('train accuracy_score = {}'.format(accuracy_score(y_true=train_y, y_pred=preds_train)))\n    print('validation accuracy_score = {}'.format(accuracy_score(y_true=val_y, y_pred=preds_val)))\n    print('confusion_matrix: \\n{}'.format(confusion_matrix(y_true=val_y, y_pred=preds_val)))\n    print('precision_score = {}'.format(precision_score(y_true=val_y, y_pred=preds_val)))\n    print('recall_score = {}'.format(recall_score(y_true=val_y, y_pred=preds_val)))\n    ```", "```py\n    plt.figure(figsize=(10,7))\n    precision, recall, thresholds = precision_recall_curve(val_y, pred_probs_val)\n    plt.plot(recall, precision)\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.show()\n    ```", "```py\n    PR_variation_df = pd.DataFrame({'precision': precision, 'recall': recall}, index=list(thresholds)+[1])\n    PR_variation_df.plot(figsize=(10,7))\n    plt.xlabel('Threshold')\n    plt.ylabel('P/R values')\n    plt.show()\n    ```", "```py\n    final_threshold = 0.3\n    ```", "```py\n    test = pd.read_csv('attrition_test.csv')\n    test.info()\n    num_orig_cols = test.shape[1] - len(cat_values_dict)\n    num_enc_cols = sum([len(cats) for cats in cat_values_dict.values()])\n    print(num_orig_cols, num_enc_cols)\n    test_X = np.zeros(shape=(test.shape[0], num_orig_cols+num_enc_cols))\n    mask = [(each not in cat_values_dict) for each in test.columns]\n    test_X[:, :num_orig_cols] = test.loc[:, test.columns[mask]]\n    cat_cols = list(cat_values_dict.keys())\n    cat_values = [cat_values_dict[col] for col in test[cat_cols].columns]\n    ohe = OneHotEncoder(categories=cat_values, sparse=False, )\n    test_X[:, num_orig_cols:] = ohe.fit_transform(X=test[cat_cols])\n    print(test_X.shape)\n    ```", "```py\n    pred_probs_test = np.array([each[1] for each in gbc.predict_proba(test_X)])\n    preds_test = (pred_probs_test > final_threshold).astype(int)\n    with open('final_predictions.csv', 'w') as f:\n        f.writelines([str(val)+'\\n' for val in preds_test])\n    ```"]