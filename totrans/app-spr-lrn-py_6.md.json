["```py\n    import pandas as pd\n    import numpy as np\n    import pickle\n    %matplotlib inline\n    import matplotlib.pyplot as plt\n    ```", "```py\n    house_prices_reg = pd.read_csv('houseprices_regression.csv')\n    house_prices_reg.head()\n    ```", "```py\n    titanic_clf = pd.read_csv('titanic_classification.csv')\n    titanic_clf.head()\n    ```", "```py\n    with open('../Saved Models/titanic_regression.pkl', 'rb') as f:\n        reg = pickle.load(f)\n    with open('../Saved Models/random_forest_clf.pkl', 'rb') as f:\n        rf = pickle.load(f)\n    ```", "```py\n    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n    from math import sqrt\n    ```", "```py\n    X = house_prices_reg.drop(columns=['y'])\n    y = house_prices_reg['y'].values\n    y_pred = reg.predict(X)\n    ```", "```py\n    print('Mean Absolute Error = {}'.format(mean_absolute_error(y, y_pred)))\n    print('Root Mean Squared Error = {}'.format(sqrt(mean_squared_error(y, y_pred))))\n    print('R Squared Score = {}'.format(r2_score(y, y_pred)))\n    ```", "```py\n    from sklearn.metrics import (accuracy_score, confusion_matrix, precision_score,\n                                 recall_score, f1_score)\n    ```", "```py\n    X = titanic_clf.iloc[:, :-1]\n    y = titanic_clf.iloc[:, -1]\n    y_pred = rf.predict(X)\n    y_pred_probs = rf.predict_proba(X)\n    ```", "```py\n    print('Accuracy Score = {}'.format(accuracy_score(y, y_pred)))\n    ```", "```py\n    print(confusion_matrix(y_pred=y_pred, y_true=y))\n    ```", "```py\n    print('Precision Score = {}'.format(precision_score(y, y_pred)))\n    print('Recall Score = {}'.format(recall_score(y, y_pred)))\n    ```", "```py\n    print('F1 Score = {}'.format(f1_score(y, y_pred)))\n    ```", "```py\n    from sklearn.model_selection import StratifiedKFold\n    from sklearn.ensemble import RandomForestClassifier\n    ```", "```py\n    X = titanic_clf.iloc[:, :-1].values\n    y = titanic_clf.iloc[:, -1].values\n    skf = StratifiedKFold(n_splits=5)\n    ```", "```py\n    scores = []\n    for train_index, val_index in skf.split(X, y):\n        X_train, X_val = X[train_index], X[val_index]\n        y_train, y_val = y[train_index], y[val_index]\n\n        rf_skf = RandomForestClassifier(**rf.get_params())\n\n        rf_skf.fit(X_train, y_train)\n        y_pred = rf_skf.predict(X_val)\n\n        scores.append(accuracy_score(y_val, y_pred))\n\n    print(scores)\n    ```", "```py\n    print('Mean Accuracy Score = {}'.format(np.mean(scores)))\n    ```", "```py\n    from sklearn.model_selection import RandomizedSearchCV\n    ```", "```py\n    X = titanic_clf.iloc[:, :-1].values\n    y = titanic_clf.iloc[:, -1].values\n    rf_rand = RandomForestClassifier()\n    ```", "```py\n    param_dist = {\"n_estimators\": list(range(10,210,10)),\n                  \"max_depth\": list(range(3,20)),\n                  \"max_features\": list(range(1, 10)),\n                  \"min_samples_split\": list(range(2, 11)),\n                  \"bootstrap\": [True, False],\n                  \"criterion\": [\"gini\", \"entropy\"]}\n    ```", "```py\n    n_iter_search = 60\n    random_search = RandomizedSearchCV(rf_rand, param_distributions=param_dist, scoring='accuracy',\n                                       n_iter=n_iter_search, cv=5)\n    random_search.fit(X, y)\n    ```", "```py\n    results = pd.DataFrame(random_search.cv_results_).sort_values('rank_test_score')\n    for i, row in results.head().iterrows():\n        print(\"Model rank: {}\".format(row.rank_test_score))\n        print(\"Mean validation score: {:.3f} (std: {:.3f})\".format(row.mean_test_score, row.std_test_score))\n        print(\"Model Hyperparameters: {}\\n\".format(row.params))\n    ```", "```py\n    feat_imps = pd.DataFrame({'importance': rf.feature_importances_}, index=titanic_clf.columns[:-1])\n    feat_imps.sort_values(by='importance', ascending=False, inplace=True)\n    ```", "```py\n    feat_imps.plot(kind='bar', figsize=(10,7))\n    plt.legend()\n    plt.show()\n    ```"]