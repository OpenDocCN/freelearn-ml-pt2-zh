["```py\n    get_ipython().run_line_magic('matplotlib', 'inline')\n    import matplotlib.pyplot as plt\n    import mpl_toolkits.basemap\n    import numpy\n    import pandas\n    import scipy.stats\n    import seaborn\n    import sklearn.datasets\n    import sklearn.model_selection\n    import sklearn.neighbors\n    seaborn.set()\n    ```", "```py\n    x_vec = numpy.linspace(-30, 30, 10000)[:, numpy.newaxis]\n    vals = numpy.concatenate((\n        numpy.random.normal(loc=1, scale=2.5, size=500), \n        numpy.random.normal(loc=10, scale=4, size=500), \n        numpy.random.normal(loc=-12, scale=5, size=500)\n    ))[:, numpy.newaxis]\n    true_density = (\n        (1 / 3) * scipy.stats.norm(1, 2.5).pdf(x_vec[:, 0]) + \n        (1 / 3) * scipy.stats.norm(10, 4).pdf(x_vec[:, 0]) +\n        (1 / 3) * scipy.stats.norm(-12, 5).pdf(x_vec[:, 0])\n    )\n    ```", "```py\n    position_bandwidth_vec = [\n        (0, 0, 0.1), (0, 1, 0.4), (0, 2, 0.7), \n        (1, 0, 1.0), (1, 1, 1.3), (1, 2, 1.6), \n        (2, 0, 1.9), (2, 1, 2.5), (2, 2, 5.0)\n    ]\n    ```", "```py\n    fig, ax = plt.subplots(3, 3, sharex=True, sharey=True, figsize=(12, 9))\n    fig.suptitle('The Effect of the Bandwidth Value', fontsize=16)\n    for r, c, b in position_bandwidth_vec:\n        kde = sklearn.neighbors.KernelDensity(bandwidth=b).fit(vals)\n        log_density = kde.score_samples(x_vec)\n        ax[r, c].hist(vals, bins=50, density=True, alpha=0.5)\n        ax[r, c].plot(x_vec[:, 0], numpy.exp(log_density), '-', linewidth=2)\n        ax[r, c].set_title('Bandwidth = {}'.format(b))\n    ```", "```py\n    bandwidths = 10 ** numpy.linspace(-1, 1, 100)\n    grid = sklearn.model_selection.GridSearchCV(\n        estimator=sklearn.neighbors.KernelDensity(kernel=\"gaussian\"),\n        param_grid={\"bandwidth\": bandwidths},\n        cv=10 #sklearn.model_selection.LeaveOneOut().get_n_splits(vals)\n    )\n    grid.fit(vals)\n    ```", "```py\n    best_bandwidth = grid.best_params_[\"bandwidth\"]\n    print(\n        \"Best Bandwidth Value: {}\"\n        .format(best_bandwidth)\n    )\n    ```", "```py\n    fig, ax = plt.subplots(figsize=(14, 10))\n    ax.hist(vals, bins=50, density=True, alpha=0.5, label='Sampled Values')\n    ax.fill(\n          x_vec[:, 0], true_density,\n          fc='black', alpha=0.3, label='True Distribution'\n          )\n    log_density = numpy.exp(grid.best_estimator_.score_samples(x_vec))\n    ax.plot(\n            x_vec[:, 0], log_density,\n            '-', linewidth=2, label='Kernel = Gaussian'\n            )\n    ax.legend(loc='upper right')\n    ```", "```py\n    position_kernel_vec = [\n        (0, 0, 'gaussian'), (0, 1, 'tophat'), \n        (1, 0, 'epanechnikov'), (1, 1, 'exponential'), \n        (2, 0, 'linear'), (2, 1, 'cosine'), \n    ]\n    Fit and plot six kernel density estimation models using a different kernel function for each. To truly understand the differences between the kernel functions, we will set the bandwidth value to the optimal bandwidth value found in Exercise 2 and not adjust it:\n    fig, ax = plt.subplots(3, 2, sharex=True, sharey=True, figsize=(12, 9))\n    fig.suptitle('The Effect of Different Kernels', fontsize=16)\n    for r, c, k in position_kernel_vec:\n        kde = sklearn.neighbors.KernelDensity(\n            kernel=k, bandwidth=best_bandwidth\n            ).fit(vals)\n        log_density = kde.score_samples(x_vec)\n        ax[r, c].hist(vals, bins=50, density=True, alpha=0.5)\n        ax[r, c].plot(x_vec[:, 0], numpy.exp(log_density), '-', linewidth=2)\n        ax[r, c].set_title('Kernel = {}'.format(k.capitalize()))\n    ```", "```py\n    def eval_gaussian(x, m, b):\n        numerator = numpy.exp(\n            -numpy.power(x - m, 2) / (2 * numpy.power(b, 2))\n        )\n        denominator = b * numpy.sqrt(2 * numpy.pi)\n        return numerator / denominator\n    ```", "```py\n    m = numpy.array([5.1])\n    b_vec = [0.1, 0.35, 0.8]\n    x_vec = numpy.linspace(1, 10, 100)[:, None]\n    fig, ax = plt.subplots(2, 3, sharex=True, sharey=True, figsize=(15, 10))\n    for i, b in enumerate(b_vec):\n        ax[0, i].hist(m[:], bins=1, fc='#AAAAFF', density=True)\n        ax[0, i].set_title(\"Histogram: Normed\")\n        evaluation = eval_gaussian(x_vec, m=m[0], b=b)\n\n        ax[1, i].fill(x_vec, evaluation, '-k', fc='#AAAAFF')\n        ax[1, i].set_title(\"Gaussian Dist: b={}\".format(b))\n    ```", "```py\n    m = numpy.random.normal(4.7, 0.88, 16)\n    n = len(m)\n    b_vec = [0.1, 0.35, 1.1]\n    x_vec = numpy.linspace(-1, 11, 100)[:, None]\n    fig, ax = plt.subplots(2, 3, sharex=True, sharey=True, figsize=(15, 10))\n    for i, b in enumerate(b_vec):\n        ax[0, i].hist(m[:], bins=n, fc='#AAAAFF', density=True)\n        ax[0, i].set_title(\"Histogram: Normed\")\n\n        sum_evaluation = numpy.zeros(len(x_vec))\n\n        for j in range(n):\n            evaluation = eval_gaussian(x_vec, m=m[j], b=b) / n\n            sum_evaluation += evaluation[:, 0]\n\n            ax[1, i].plot(x_vec, evaluation, '-k', linestyle=\"dashed\")\n        ax[1, i].fill(x_vec, sum_evaluation, '-k', fc='#AAAAFF')\n        ax[1, i].set_title(\"Gaussian Dist: b={}\".format(b))\n    ```", "```py\n    housing = sklearn.datasets.fetch_california_housing()\n    df = pandas.DataFrame(housing['data'], columns=housing['feature_names'])\n    print(\"Dataframe Dimensions: {dims}\".format(dims=df.shape))\n    df.head()\n    ```", "```py\n    dfLess15 = df[df['HouseAge'] <= 15.0]\n    dfLess15 = dfLess15[['Latitude', 'Longitude']]\n    print(\n        \"Less Than Or Equal To 15 Years Dataframe Dimensions: {dims}\"\n        .format(dims=dfLess15.shape)\n    )\n    dfLess15.head()\n    ```", "```py\n    seaborn.jointplot(\"Longitude\", \"Latitude\", dfLess15, kind=\"kde\")\n    ```", "```py\n    dfMore40 = df[df['HouseAge'] > 40.0]\n    dfMore40 = dfMore40[['Latitude', 'Longitude']]\n    print(\n        \"More Than 40 Years Dataframe Dimensions: {dims}\"\n        .format(dims=dfMore40.shape)\n    )\n    dfMore40.head()\n    ```", "```py\n    seaborn.jointplot(\"Longitude\", \"Latitude\", dfMore40, kind=\"kde\")\n    ```", "```py\n    dfLess5 = df[df['HouseAge'] <= 5]\n    x_vals = dfLess5.Population.values\n    y_vals = dfLess5.MedInc.values\n    fig = plt.figure(figsize=(10, 10))\n    plt.scatter(x_vals, y_vals, c='black')\n    plt.xlabel('Population', fontsize=18)\n    plt.ylabel('Median Income', fontsize=16)\n    ```", "```py\n    fig = plt.figure(figsize=(10, 10))\n    ax = seaborn.kdeplot(\n        x_vals, \n        y_vals,\n        kernel='gau',\n        cmap='Blues', \n        shade=True, \n        shade_lowest=False\n    )\n    plt.scatter(x_vals, y_vals, c='black', alpha=0.05)\n    plt.xlabel('Population', fontsize=18)\n    plt.ylabel('Median Income', fontsize=18)\n    plt.title('Density Estimation With Scatterplot Overlay', size=18)\n    ```", "```py\n    xgrid15 = numpy.sort(list(dfLess15['Longitude']))\n    ygrid15 = numpy.sort(list(dfLess15['Latitude']))\n    x15, y15 = numpy.meshgrid(xgrid15, ygrid15)\n    print(\"X Grid Component:\\n{}\\n\".format(x15))\n    print(\"Y Grid Component:\\n{}\\n\".format(y15))\n    xy15 = numpy.vstack([y15.ravel(), x15.ravel()]).T\n    print(\"Grid:\\n{}\\n\".format(xy15))\n    ```", "```py\n    kde = sklearn.neighbors.KernelDensity(\n        bandwidth=0.05, \n        metric='minkowski',\n        kernel='gaussian', \n        algorithm='ball_tree'\n    )\n    kde.fit(dfLess15.values)\n    log_density = kde.score_samples(xy15)\n    density = numpy.exp(log_density)\n    density = density.reshape(x15.shape)\n    print(\"Shape of Density Values:\\n{}\\n\".format(density.shape))\n    ```", "```py\n    fig = plt.figure(figsize=(10, 10))\n    fig.suptitle(\n        \"\"\"\n        Density Estimation:\n        Location of Housing Blocks\n        Where the Median Home Age <= 15 Years\n        \"\"\", \n        fontsize=16\n    )\n    the_map = mpl_toolkits.basemap.Basemap(\n        projection='cyl',\n        llcrnrlat=y15.min(), urcrnrlat=y15.max(),\n        llcrnrlon=x15.min(),urcrnrlon=x15.max(),\n        resolution='c'\n    )\n    the_map.drawcoastlines(linewidth=1)\n    the_map.drawcountries(linewidth=1)\n    the_map.drawstates(linewidth=1)\n    levels = numpy.linspace(0, density.max(), 25)\n    plt.contourf(x15, y15, density, levels=levels, cmap=plt.cm.Reds)\n    plt.show()\n    ```", "```py\n    xgrid40 = numpy.sort(list(dfMore40['Longitude']))\n    ygrid40 = numpy.sort(list(dfMore40['Latitude']))\n    x40, y40 = numpy.meshgrid(xgrid40, ygrid40)\n    print(\"X Grid Component:\\n{}\\n\".format(x40))\n    print(\"Y Grid Component:\\n{}\\n\".format(y40))\n    xy40 = numpy.vstack([y40.ravel(), x40.ravel()]).T\n    print(\"Grid:\\n{}\\n\".format(xy40))\n    ```", "```py\n    kde = sklearn.neighbors.KernelDensity(\n        bandwidth=0.05, \n        metric='minkowski',\n        kernel='gaussian', \n        algorithm='ball_tree'\n    )\n    kde.fit(dfMore40.values)\n    log_density = kde.score_samples(xy40)\n    density = numpy.exp(log_density)\n    density = density.reshape(x40.shape)\n    print(\"Shape of Density Values:\\n{}\\n\".format(density.shape))\n    ```", "```py\n    fig = plt.figure(figsize=(10, 10))\n    fig.suptitle(\n        \"\"\"\n        Density Estimation:\n        Location of Housing Blocks\n        Where the Median Home Age > 40 Years\n        \"\"\", \n        fontsize=16\n    )\n    the_map = mpl_toolkits.basemap.Basemap(\n        projection='cyl',\n        llcrnrlat=y40.min(), urcrnrlat=y40.max(),\n        llcrnrlon=x40.min(),urcrnrlon=x40.max(),\n        resolution='c'\n    )\n    the_map.drawcoastlines(linewidth=1)\n    the_map.drawcountries(linewidth=1)\n    the_map.drawstates(linewidth=1)\n    levels = numpy.linspace(0, density.max(), 25)\n    plt.contourf(x40, y40, density, levels=levels, cmap=plt.cm.Reds)\n    plt.show()\n    ```"]