["```py\n>>> from matplotlib import pyplot as plt\n>>> import numpy as np\n\n>>> # We load the data with load_iris from sklearn\n>>> from sklearn.datasets import load_iris\n>>> data = load_iris()\n\n>>> # load_iris returns an object with several fields\n>>> features = data.data\n>>> feature_names = data.feature_names\n>>> target = data.target\n>>> target_names = data.target_names\n\n>>> for t in range(3):\n...    if t == 0:\n...        c = 'r'\n...        marker = '>'\n...    elif t == 1:\n...        c = 'g'\n...        marker = 'o'\n...    elif t == 2:\n...        c = 'b'\n...        marker = 'x'\n...    plt.scatter(features[target == t,0],\n...                features[target == t,1],\n...                marker=marker,\n...                c=c)\n\n```", "```py\n>>> # We use NumPy fancy indexing to get an array of strings:\n>>> labels = target_names[target]\n\n>>> # The petal length is the feature at position 2\n>>> plength = features[:, 2]\n\n>>> # Build an array of booleans:\n>>> is_setosa = (labels == 'setosa')\n\n>>> # This is the important step:\n>>> max_setosa = plength[is_setosa].max()\n>>> min_non_setosa = plength[~is_setosa].min()\n>>> print('Maximum of setosa: {0}.'.format(max_setosa))\nMaximum of setosa: 1.9.\n\n>>> print('Minimum of others: {0}.'.format(min_non_setosa))\nMinimum of others: 3.0.\n\n```", "```py\n>>> # ~ is the boolean negation operator\n>>> features = features[~is_setosa]\n>>> labels = labels[~is_setosa]\n>>> # Build a new target variable, is_virginica\n>>> is_virginica = (labels == 'virginica')\n\n```", "```py\n>>> # Initialize best_acc to impossibly low value\n>>> best_acc = -1.0\n>>> for fi in range(features.shape[1]):\n...  # We are going to test all possible thresholds\n...  thresh = features[:,fi]\n...  for t in thresh:\n...    # Get the vector for feature `fi`\n...    feature_i = features[:, fi]\n...    # apply threshold `t`\n...    pred = (feature_i > t)\n...    acc = (pred == is_virginica).mean()\n...    rev_acc = (pred == ~is_virginica).mean()\n...    if rev_acc > acc:\n...        reverse = True\n...        acc = rev_acc\n...    else:\n...        reverse = False\n...\n...    if acc > best_acc:\n...      best_acc = acc\n...      best_fi = fi\n...      best_t = t\n...      best_reverse = reverse\n\n```", "```py\ndef is_virginica_test(fi, t, reverse, example):\n \"Apply threshold model to a new example\"\n test = example[fi] > t\n if reverse:\n test = not test\n return test\n\n```", "```py\nTraining accuracy was 96.0%.\nTesting accuracy was 90.0% (N = 50).\n\n```", "```py\n>>> correct = 0.0\n>>> for ei in range(len(features)):\n # select all but the one at position `ei`:\n training = np.ones(len(features), bool)\n training[ei] = False\n testing = ~training\n model = fit_model(features[training], is_virginica[training])\n predictions = predict(model, features[testing])\n correct += np.sum(predictions == is_virginica[testing])\n>>> acc = correct/float(len(features))\n>>> print('Accuracy: {0:.1%}'.format(acc))\nAccuracy: 87.0%\n\n```", "```py\n>>> from sklearn.neighbors import KNeighborsClassifier\n\n```", "```py\n>>> classifier = KNeighborsClassifier(n_neighbors=1)\n\n```", "```py\n>>> from sklearn.cross_validation import KFold\n\n>>> kf = KFold(len(features), n_folds=5, shuffle=True)\n>>> # `means` will be a list of mean accuracies (one entry per fold)\n>>> means = []\n>>> for training,testing in kf:\n...    # We fit a model for this fold, then apply it to the\n...    # testing data with `predict`:\n...    classifier.fit(features[training], labels[training])\n...    prediction = classifier.predict(features[testing])\n...\n...    # np.mean on an array of booleans returns fraction\n...    # of correct decisions for this fold:\n...    curmean = np.mean(prediction == labels[testing])\n...    means.append(curmean)\n>>> print(\"Mean accuracy: {:.1%}\".format(np.mean(means)))\nMean accuracy: 90.5%\n\n```", "```py\n>>> from sklearn.pipeline import Pipeline\n>>> from sklearn.preprocessing import StandardScaler\n\n```", "```py\n>>> classifier = KNeighborsClassifier(n_neighbors=1)\n>>> classifier = Pipeline([('norm', StandardScaler()),\n...         ('knn', classifier)])\n\n```"]