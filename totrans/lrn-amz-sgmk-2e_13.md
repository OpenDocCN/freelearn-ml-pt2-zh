# 第10章：高级训练技巧

在上一章中，你学习了如何使用**Pipe模式**和**分布式训练**等特性来扩展训练任务，以及使用替代的**S3**存储数据集。

在本章中，我们将结束对训练技巧的探索。在本章的第一部分，你将学习如何通过**托管点训练**大幅降低训练成本，如何通过**自动模型调优**从模型中挤出每一滴精度，并且如何使用**SageMaker Debugger**拆解模型。

在本章的第二部分，我们将介绍两个新的SageMaker功能，帮助你构建更高效的工作流和更高质量的模型：**SageMaker Feature Store**和**SageMaker Clarify**。

本章涵盖以下主题：

+   使用托管点训练优化训练成本

+   使用自动模型调优优化超参数

+   使用SageMaker Debugger探索模型

+   使用SageMaker Feature Store管理特征和构建数据集

+   使用SageMaker Clarify检测偏差并解释预测

# 技术要求

你需要一个AWS账户来运行本章中包含的示例。如果你还没有账户，请访问[https://aws.amazon.com/getting-started/](https://aws.amazon.com/getting-started/)来创建一个。你还应该了解AWS免费层（[https://aws.amazon.com/free/](https://aws.amazon.com/free/)），它允许你在一定的使用限制内免费使用许多AWS服务。

你需要为你的账户安装并配置AWS **命令行界面**（**CLI**）（[https://aws.amazon.com/cli/](https://aws.amazon.com/cli/)）。

你将需要一个可用的`pandas`、`numpy`等库。

本书中包含的代码示例可在GitHub上获取，链接为[https://github.com/PacktPublishing/Learn-Amazon-SageMaker-second-edition](https://github.com/PacktPublishing/Learn-Amazon-SageMaker-second-edition)。你需要安装Git客户端来访问它们（[https://git-scm.com/](https://git-scm.com/)）。

# 使用托管点训练优化训练成本

在上一章中，我们在**ImageNet**数据集上训练了**图像分类**算法。这个任务运行了不到4小时。按照每小时$290计算，这个任务大约花费了我们$1,160。那是一大笔钱……但真的那么贵吗？

## 比较成本

在你抛开双手，喊出“*他在想什么？*”之前，请考虑一下让你的组织拥有并运行这个训练集群需要花费多少成本：

1.  一个粗略的资本支出计算（包括服务器、存储、GPU、100 Gbit/s的网络设备）至少需要150万美元。就运营支出而言，托管成本不会便宜，因为每台等效的服务器需要4-5千瓦的电力。这足够填满你典型托管公司的一排机架，因此即使使用高密度机架，你也需要多个。再加上带宽、跨连接等，我的直觉告诉我每月大约需要1.5万美元（在某些地区可能更多）。

1.  我们需要添加硬件支持合同（比如，每年10%，即15万美元）。将这个集群的折旧期设为5年，总月成本为($1.5M + 60*$15K + 5*$150K)/60 = 52.5K美元。为了计算维护服务器等的人工成本，我们将其四舍五入到55K美元。

使用保守估计，这笔开支相当于使用我们为ImageNet示例所用的大型每小时$290集群进行190小时的训练。正如我们在本章稍后将看到的，托管的Spot训练通常能提供70%的节省。因此，现在这笔开支相当于每月大约633小时的ImageNet训练。

这意味着每月87%的使用率（633/720），而且很不可能你会让你的训练集群保持如此繁忙。再加上停机时间、硬件创新带来的加速折旧、硬件保险费用、未将150万美元投资于其他项目的机会成本等等，物理基础设施的商业案例每分钟都在变得更差。

财务问题固然重要，但最糟糕的是你只能拥有一个集群。如果一个潜在的商业机会需要另一个集群怎么办？你会再花150万美元吗？如果不会，是否需要共享现有的集群？当然，只有你能决定什么对你的组织最有利。只要确保你从全局角度来看问题。

现在，让我们来看一下如何轻松享受70%的成本降低。

## 了解Amazon EC2 Spot实例

在任何时候，**Amazon** **EC2**的容量都超过了实际需求。这使得客户可以根据需要随时向他们的平台添加按需容量。可以通过API调用显式创建按需实例，或者在配置了**Auto Scaling**的情况下自动创建。一旦客户获得了按需实例，他们将保留它，直到他们决定释放它，无论是显式释放还是自动释放。

**Spot实例**是利用这些未使用容量并享受非常显著折扣（通常为50-70%）的简单方法。您可以以相同的方式请求它们，它们的行为也相同。唯一的区别是，如果AWS需要容量来构建按需实例，您的Spot实例可能会被回收。在被强制终止之前，它会收到两分钟的中断通知。

这并不像听起来那么糟糕。根据区域和实例系列的不同，抢占式实例可能不会被频繁回收，客户通常可以将它们保留几天甚至更长时间。此外，您可以为此需求架构您的应用程序，例如，在抢占式实例上运行无状态工作负载，并依赖托管服务进行数据存储。成本优势非常明显，不容错过！

查看过去三个月`p3dn.24xlarge`的情况，抢占式价格比按需价格便宜60-70%：

![图 10.1 – 查看 p3dn.24xlarge 的抢占式价格

](img/B17705_10_1.jpg)

图 10.1 – 查看 p3dn.24xlarge 的抢占式价格

这些是EC2的价格，但相同的折扣率也适用于SageMaker价格。折扣因实例类型、区域，甚至可用区而异。您可以使用`describe-spot-price-history` API以编程方式收集这些信息，并将其用于工作流中：

https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-spot-price-history.html

现在，让我们看看这对SageMaker意味着什么。

## 理解托管抢占式训练

使用抢占式实例进行训练在所有SageMaker配置中都可用：单实例训练、分布式训练、内置算法、框架以及您自己的算法。

只需设置几个估算器参数即可。您无需担心处理通知和中断，SageMaker会自动为您处理。

如果训练作业被中断，SageMaker会恢复足够的抢占式容量并重新启动训练作业。如果算法使用了检查点，训练将从最新的检查点继续。如果没有，作业将从头开始。

实现检查点所需的工作量取决于您使用的算法：

+   三个用于计算机视觉和**XGBoost**的内置算法支持检查点功能。

+   所有其他内置算法则没有此功能。您仍然可以使用抢占式实例进行训练。然而，最大运行时间限制为60分钟，以减少潜在的浪费。如果您的训练作业超过60分钟，您应该考虑进行扩展。如果仍然不够，您将不得不使用按需实例。

+   **深度学习容器**适用于**TensorFlow**、**PyTorch**、**Apache** **MXNet**和**Hugging Face**，并内置了检查点功能，您无需修改训练脚本。

+   如果您使用其他框架或自己的自定义代码，您需要实现检查点功能。

在训练过程中，检查点会保存在训练容器内。默认路径为`/opt/ml/checkpoints`，您可以通过估算器参数进行自定义。SageMaker还会自动将这些检查点持久化到用户定义的S3路径。如果您的训练作业被中断并重新启动，检查点会自动复制到容器内。您的代码可以检查它们的存在，并加载适当的检查点来继续训练。

注意

请注意，即使使用按需实例进行训练，检查点功能仍然可用。如果你希望将检查点存储在S3中以便进一步检查或进行增量训练，这将非常有用。唯一的限制是**本地模式**不支持检查点功能。

最后但同样重要的是，检查点功能确实会拖慢任务的速度，尤其是对于大模型来说。然而，这是一个值得支付的小代价，以避免从头开始重新启动长时间运行的任务。

现在，让我们将托管点训练添加到我们在[*第5章*](B17705_05_Final_JM_ePub.xhtml#_idTextAnchor091)中运行的**目标检测**任务中，*训练计算机视觉模型*。

## 使用托管点训练进行目标检测

从按需训练切换到托管点训练非常简单。我们只需设置训练任务的最大持续时间，包括等待Spot实例可用的时间。

我们设置了2小时的最大运行时间，加上8小时的任何点延迟。如果超出了这两个限制，任务将自动终止。这对于终止运行时间过长或因为等待点实例而卡住的任务非常有帮助：

[PRE0]

我们使用与之前相同的配置进行训练：管道模式和`dist_sync`模式。当第一个epoch完成时，训练日志告诉我们检查点功能已经激活。每次验证指标改进时，都会自动保存一个新的检查点：

[PRE1]

一旦训练任务完成，训练日志会告诉我们节省了多少：

[PRE2]

这个任务不仅比按需版本便宜70%，而且价格还不到我们原来单实例任务的一半。这意味着我们可以使用更多的实例，并以相同的预算加速训练任务。实际上，托管点训练让你能够优化任务的持续时间和成本。你可以根据业务需求设定训练预算，然后尽可能地获取基础设施。

让我们尝试另一个例子，在**Keras**中实现检查点功能。

## 使用托管点训练和Keras中的检查点功能

在这个例子中，我们将在TensorFlow 2.1中构建一个简单的`Sequential` API。

### Keras中的检查点功能

首先，让我们来看一下Keras脚本本身。为了简洁起见，这里只展示了重要的步骤。你可以在本书的GitHub仓库中找到完整的代码：

1.  使用脚本模式，我们存储数据集路径和超参数。

1.  接下来，我们加载数据集并将像素值归一化到[0,1]范围内。我们还对类别标签进行独热编码。

1.  我们构建了一个`Sequential`模型：两个卷积块（`Conv2D` / `BatchNormalization` / `ReLU` / `MaxPooling2D` / `Dropout`），然后是两个全连接块（`Dense` / `BatchNormalization` / `ReLU` / `Dropout`），最后是一个用于数据集中10个类别的`softmax`输出层。

1.  我们使用**分类交叉熵**损失函数和**Adam**优化器来编译模型：

    [PRE3]

1.  我们定义一个 Keras 回调，每当验证准确率提高时就保存一个检查点：

    [PRE4]

1.  我们训练模型，添加我们刚刚创建的回调：

    [PRE5]

1.  训练完成后，我们将模型保存为 **TensorFlow Serving** 格式，这是在 SageMaker 上部署时所需的格式：

    [PRE6]

现在，让我们看看我们的训练笔记本。

### 使用托管的 spot 训练和检查点保存进行训练

我们使用之前相同的工作流程：

1.  我们下载 Fashion-MNIST 数据集并将其保存在本地目录。我们将数据集上传到 S3，并定义 SageMaker 应该将检查点复制到的 S3 位置。

1.  我们配置一个 `TensorFlow` 估算器，启用托管的 spot 训练，并传递检查点的 S3 输出位置。这次，我们使用的是 `ml.g4dn.xlarge` 实例。这种非常具成本效益的 GPU 实例（在 `eu-west-1` 区域的价格为 $0.822）足以应对一个小模型：

    [PRE7]

1.  我们像往常一样启动训练，任务达到了93.11%的准确率。训练持续了289秒，我们只需为87秒支付费用， thanks to a 69.9%的折扣。总费用为1.98美分！谁说GPU训练必须昂贵？

1.  在训练日志中，我们看到每当验证准确率提高时，都会创建一个检查点：

    [PRE8]

    在任务运行时，我们还看到检查点被复制到 S3：

    [PRE9]

如果我们的 spot 任务被中断，SageMaker 会在容器内复制检查点，以便我们可以使用它们来恢复训练。这需要在我们的 Keras 脚本中添加一些逻辑，以加载最新的检查点。让我们看看如何实现。

### 从检查点恢复训练

这是一个非常简单的过程——查找检查点，并从最新的检查点继续训练：

1.  我们列出检查点目录：

    [PRE10]

1.  如果有检查点，我们会找到最新的一个以及它的 epoch 编号。然后，我们加载模型：

    [PRE11]

1.  如果没有检查点，我们像往常一样构建模型：

    [PRE12]

1.  我们编译模型，启动训练，并传递最后一个 epoch 的编号：

    [PRE13]

我们怎么测试这个呢？没有办法故意造成一个 spot 中断。

诀窍是：用 `checkpoint_s3_uri` 路径中的现有检查点启动一个新的训练任务，并增加 epoch 的数量。这将模拟恢复一个中断的任务。

将 epoch 数设置为 25，并将检查点保存在 `s3://sagemaker-eu-west-1-123456789012/keras2`

`fashion-mnist/checkpoints`，我们再次启动训练任务。

在训练日志中，我们看到最新的检查点被加载，训练从第 21 个 epoch 继续：

[PRE14]

我们还看到每当验证准确率提高时，新的检查点会被创建，并被复制到 S3：

[PRE15]

如你所见，在 SageMaker 中设置检查点并不困难，你应该也能在其他框架中做到这一点。得益于此，你可以享受由托管的按需训练提供的深度折扣，而在中断发生时也无需担心丢失任何工作。当然，你也可以单独使用检查点来检查中间训练结果，或用于增量训练。

在接下来的部分，我们将介绍另一个重要特性：自动模型调优。

# 使用自动模型调优优化超参数

超参数对训练结果有巨大的影响。就像**混沌理论**中所说的那样，一个单一超参数的微小变化就可能导致准确率的剧烈波动。在大多数情况下，我们无法解释“为什么？”，这让我们对接下来该尝试什么感到困惑。

多年来，已经设计了几种技术来尝试解决选择最佳超参数的问题：

1.  **手动搜索**：这意味着依靠我们的最佳判断和经验来选择“最佳”超参数。说实话：这真的不起作用，尤其是在深度学习和众多训练及网络架构参数的情况下。

1.  **网格搜索**：这意味着系统地探索超参数空间，集中在热点区域，然后重复这一过程。这比手动搜索要好得多。然而，这通常需要训练成百上千的任务。即使有可扩展的基础设施，时间和预算仍然可能是巨大的。

1.  **随机搜索**：指的是随机选择超参数。虽然听起来不合常理，但詹姆斯·伯格斯特拉和约书亚·本吉奥（图灵奖得主）在2012年证明，这一技术在相同计算预算下能比网格搜索交付更好的模型。

1.  [http://www.jmlr.org/papers/v13/bergstra12a.html](http://www.jmlr.org/papers/v13/bergstra12a.html)

1.  **超参数优化**（HPO）：这意味着使用优化技术来选择超参数，例如**贝叶斯优化**和**高斯过程回归**。在相同的计算预算下，HPO通常能以比其他技术少10倍的训练周期交付结果。

## 了解自动模型调优

SageMaker 包含一个**自动模型调优**功能，可以让你轻松探索超参数范围，并通过有限的任务数快速优化任何训练指标。

模型调优支持随机搜索和超参数优化（HPO）。前者是一个有趣的基准，帮助你检查后者是否确实表现更好。你可以在这篇精彩的博客文章中找到非常详细的比较：

https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-automatic-model-tuning-now-supports-random-search-and-hyperparameter-scaling/

模型调优对你使用的算法完全无关。它适用于内置算法，文档中列出了可以调优的超参数。它也适用于所有框架和自定义容器，且超参数传递方式相同。

对于我们想要优化的每一个超参数，我们需要定义以下内容：

+   一个名称

+   一种类型（参数可以是整数、连续的或分类的）

+   探索的值范围

+   一种缩放类型（线性、对数、反对数或自动）——这让我们控制特定参数范围的探索方式

我们还定义了要优化的指标。它可以是任何数值，只要它在训练日志中可见，并且您可以传递正则表达式来提取它。

然后，我们启动调优作业，传递所有这些参数以及要运行的训练作业数量和并行度。使用贝叶斯优化，您可以通过顺序作业（无并行）获得最佳结果，因为优化可以在每个作业后应用。话虽如此，运行少量并行作业是可以接受的。随机搜索对并行性没有限制，因为作业之间完全不相关。

调用`deploy()` API 在调优器对象上部署最佳模型。如果调优仍在进行中，它将部署迄今为止的最佳模型，这对于早期测试非常有用。

让我们使用内置算法运行第一个示例，并了解模型调优 API。

## 使用自动模型调优进行目标检测

我们将优化我们的目标检测作业。查看文档，我们可以看到可调超参数的列表：

https://docs.aws.amazon.com/sagemaker/latest/dg/object-detection-tuning.html

让我们尝试优化学习率、动量和权重衰减：

1.  我们使用管道模式设置输入通道。这里没有变化。

1.  我们还像往常一样配置估算器，设置托管现货训练以最小化成本。我们将在单个实例上训练以获得最高准确度：

    [PRE16]

1.  我们使用与之前相同的超参数：

    [PRE17]

1.  我们定义了我们希望调优的三个额外超参数。我们明确设置学习率的对数缩放，以确保探索不同数量级：

    [PRE18]

1.  我们设置要优化的指标：

    [PRE19]

1.  我们将所有内容整合在一起，使用`HyperparameterTuner`对象。我们决定运行30个作业，其中两个作业并行运行。我们还启用了早停，以淘汰表现较差的作业，从而节省时间和金钱：

    [PRE20]

1.  我们在调优器对象（而不是估算器）上启动训练，而不等待它完成：

    [PRE21]

1.  目前，**SageMaker Studio** 没有提供方便的调优作业查看界面。相反，我们可以在 SageMaker 控制台的 **超参数调优作业** 部分跟踪进度，如下图所示：

![图 10.2 – 在 SageMaker 控制台中查看调优作业](img/B17705_10_2.jpg)

](img/B17705_10_2.jpg)

图 10.2 – 在 SageMaker 控制台中查看调优作业

作业运行了17小时（壁钟时间）。22个作业完成，8个作业提前停止。总训练时间为30小时15分钟。应用70%的现货折扣，总成本为 25.25 * $4.131 * 0.3 = $37.48。

这个调优作业的表现如何？使用默认超参数，我们的独立训练作业达到了`0.2453`。我们的调优作业达到了`0.6337`，如下图所示：

![图 10.3 – 调优作业结果](img/B17705_10_3.jpg)

](img/B17705_10_3.jpg)

图 10.3 – 调优作业结果

验证 mAP 的图表显示在下一张图片中。它告诉我我们可能需要再训练一段时间，以获得更高的准确度：

![图10.4 – 查看mAP指标

](img/B17705_10_4.jpg)

图10.4 – 查看mAP指标

一种方法是使用最佳超参数启动单个训练作业，并让它运行更多周期。我们也可以通过在调优器对象上使用`deploy()`来恢复调优作业，并像任何SageMaker模型一样测试我们的模型。

正如你所见，自动模型调优非常强大。通过运行少量作业，我们将指标提高了158%！与花费时间尝试其他技术相比，成本几乎可以忽略不计。

实际上，使用随机策略运行相同的调优作业可以得到最高准确率0.52。我们肯定需要运行更多的训练作业才能希望达到0.6315。

现在，让我们尝试优化我们在本章前面使用的Keras示例。

## 使用Keras进行自动模型调优

自动模型调优可以轻松应用于SageMaker上的任何算法，当然也包括所有框架。让我们看看Keras是如何工作的。

在本章的前面，我们在Fashion MNIST数据集上训练了我们的Keras CNN，训练了20个周期，得到了93.11%的验证准确率。让我们看看能否通过自动模型调优来提高这个结果。在此过程中，我们还将学习如何优化训练日志中存在的任何指标，而不仅仅是SageMaker中预定义的指标。

### 在自定义指标上的优化

修改我们的训练脚本，安装`keras-metrics`包（[https://github.com/netrack/keras-metrics](https://github.com/netrack/keras-metrics)），并将**精度**、**召回率**和**f1得分**指标添加到训练日志中：

[PRE22]

经过20个周期后，当前的指标如下所示：

[PRE23]

如果我们想优化f1得分，可以像这样定义调优器指标：

[PRE24]

就是这样。只要在训练日志中打印出某个指标，你就可以用它来调优模型。

### 优化我们的Keras模型

现在，让我们运行我们的调优作业：

1.  我们像这样为`HyperparameterTuner`定义指标，优化准确度并同时显示f1得分：

    [PRE25]

1.  我们定义要探索的参数范围：

    [PRE26]

1.  我们使用相同的估算器（20个周期，使用Spot实例），并定义调优器：

    [PRE27]

1.  我们启动调优作业。在作业运行时，我们可以使用**SageMaker SDK**来显示训练作业及其属性的列表：

    [PRE28]

    这将打印出下一个截图中可见的表格：

![图10.5 – 查看调优作业的信息

](img/B17705_10_5.jpg)

图10.5 – 查看调优作业的信息

调优作业运行了2小时8分钟（墙时）。最高验证准确率为93.46%——相比我们的基准，取得了不错的改进。

我们当然可以通过训练更长时间来做得更好。然而，训练时间越长，过拟合的风险越大。我们可以通过早停法来减轻这一问题，这可以通过Keras回调实现。然而，我们应该确保作业报告的是最佳周期的指标，而不是最后一个周期的指标。我们该如何在训练日志中显示这个信息？通过另一个回调！

### 为早期停止添加回调

为早期停止添加一个 Keras 回调非常简单：

1.  我们添加了一个基于验证准确率的早期停止内置回调：

    [PRE29]

1.  我们添加了一个自定义回调，以便在每个 epoch 结束时保存验证准确率，并在训练结束时显示最佳结果：

    [PRE30]

1.  我们将这两个回调添加到训练 API 中：

    [PRE31]

    测试几个单独的作业时，训练日志的最后几行现在看起来是这样的：

    [PRE32]

1.  在笔记本中，我们更新了指标定义，以便提取最佳验证准确率：

    [PRE33]

这次训练了 60 个 epochs（大约 3 小时的壁钟时间），当前的最高验证准确率为 93.78%。看起来通过调整学习率和批大小，已经达到了最佳效果。

## 使用自动模型调优进行架构搜索

我们的神经网络还有很多超参数：卷积滤波器的数量、dropout 等等。让我们也尝试优化这些参数：

1.  我们修改训练脚本，添加命令行参数，以便为模型中 Keras 层使用的以下网络参数提供支持：

    [PRE34]

    正如你猜测的那样，参数允许我们为每一层的卷积滤波器数量、卷积层的 dropout 值和全连接层的 dropout 值设置值。

1.  相应地，在笔记本中，我们定义了这些超参数及其范围。对于学习率和批大小，我们使用了以之前调优作业发现的最佳值为中心的窄范围：

    [PRE35]

1.  我们启动调优作业，运行 50 个作业，每次运行 2 个，总共训练 100 个 epochs。

调优作业运行了大约 12 小时，总费用约为 15 美元。最高验证准确率达到了 94.09%。与我们的基线相比，自动模型调优提高了模型的准确性近 1 个百分点——这是一个非常显著的提升。如果这个模型每天用于预测 100 万个样本，这将意味着多出 10,000 个准确的预测！

总的来说，我们在调优 Keras 模型上花费了不到 50 美元。无论是什么业务指标从额外的准确性中获益，可以公平地说，这笔支出很快就能收回。正如许多客户告诉我的那样，自动模型调优是自我盈利的，甚至会带来更多回报。

这结束了我们对自动模型调优的探索，这是 SageMaker 中我最喜欢的功能之一。你可以在 [https://github.com/awslabs/amazon-sagemaker-examples/tree/master/hyperparameter_tuning](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/hyperparameter_tuning) 找到更多示例。

现在，让我们了解一下 SageMaker Debugger，以及它如何帮助我们理解模型内部发生了什么。

# 使用 SageMaker Debugger 探索模型

SageMaker Debugger让您为训练作业配置*调试规则*。这些规则将检查作业的内部状态，并检测在训练过程中可能出现的特定不良条件。SageMaker Debugger包含一长串内置规则（[https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-built-in-rules.html](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-built-in-rules.html)），并且您可以添加自定义的Python编写规则。

此外，您还可以保存和检查模型状态（如梯度、权重等）以及训练状态（如指标、优化器参数等）。在每个训练步骤中，存储这些值的**张量**可以在接近实时的情况下保存到S3桶中，使得在模型训练过程中就可以对其进行可视化。

当然，您可以选择希望保存的张量**集合**，以及保存的频率等。根据您使用的框架，可用的集合有所不同。您可以在[https://github.com/awslabs/sagemaker-debugger/blob/master/docs/api.md](https://github.com/awslabs/sagemaker-debugger/blob/master/docs/api.md)中找到更多信息。最后但同样重要的是，您可以保存原始张量数据或张量的归约结果，以限制涉及的数据量。归约操作包括最小值、最大值、中位数等。

如果您使用的是支持版本的TensorFlow、PyTorch、Apache MXNet的内置容器，或者内置的XGBoost算法，您可以开箱即用地使用SageMaker Debugger，而无需在脚本中更改一行代码。没错，您没有看错。您只需向估算器中添加额外的参数，就像我们接下来在示例中展示的那样。

对于其他版本，或者使用您自己的容器，仅需进行最小的修改。您可以在[https://github.com/awslabs/sagemaker-debugger](https://github.com/awslabs/sagemaker-debugger)找到最新的信息和示例。

调试规则和保存张量可以在同一个训练作业中进行配置。为了清晰起见，我们将运行两个独立的示例。首先，让我们使用来自[*第4章*](B17705_04_Final_JM_ePub.xhtml#_idTextAnchor069)的XGBoost和波士顿住房示例，*训练机器学习模型*。

## 调试XGBoost作业

首先，我们将配置几个内置规则，训练我们的模型，并检查所有规则的状态：

1.  查看内置规则列表后，我们决定使用`overtraining`和`overfit`。每个规则都有额外的参数，我们可以进行调整。我们保持默认设置，并相应地配置`Estimator`：

    [PRE36]

1.  我们设置超参数并启动训练，而无需等待训练作业完成。训练日志将不会在笔记本中显示，但仍然可以在**CloudWatch Logs**中查看：

    [PRE37]

1.  除了训练作业外，每个规则下还会运行一个调试作业，我们可以查看它们的状态：

    [PRE38]

    这告诉我们调试作业正在运行：

    [PRE39]

1.  在训练作业完成后重新运行相同的单元格时，我们看到没有任何规则被触发：

    [PRE40]

如果触发了规则，我们会收到错误信息，训练任务将被停止。检查存储在S3中的张量有助于我们理解出了什么问题。

## 检查XGBoost任务

让我们配置一个新的训练任务，保存XGBoost的所有张量集合：

1.  我们配置`Estimator`，传入`DebuggerHookConfig`对象。在每个训练步骤中，我们保存三种张量集合：指标、特征重要性和平均**SHAP**（[https://github.com/slundberg/shap](https://github.com/slundberg/shap)）值。这些有助于我们理解数据样本中每个特征如何影响预测值的增减。

    对于更大的模型和数据集，这可能会生成大量数据，加载和分析这些数据需要较长时间。我们可以增加保存间隔，或保存张量缩减值而非完整张量：

    [PRE41]

1.  一旦训练任务开始，我们可以创建一个试验并加载已保存的数据。由于该任务非常短，我们将在一分钟左右查看到所有数据：

    [PRE42]

1.  我们可以列出所有已保存张量的名称：

    [PRE43]

1.  我们还可以列出给定集合中所有张量的名称：

    [PRE44]

1.  对于每个张量，我们可以访问训练步骤和数值。让我们绘制来自`average_shap`和`feature_importance`集合的特征信息：

    [PRE45]

1.  我们构建`average_shap`图：

    [PRE46]

1.  你可以在以下截图中看到——**dis**、**crim**和**nox**的平均值最大：![图10.6 – 绘制SHAP值随时间变化的图

    ](img/B17705_10_6.jpg)

    图10.6 – 绘制SHAP值随时间变化的图

1.  我们构建`feature_importance/weight`图：

    [PRE47]

    你可以在以下截图中看到——**crim**、**age**和**dis**的权重最大：

![图10.7 – 绘制特征权重随时间变化的图

](img/B17705_10_7.jpg)

图10.7 – 绘制特征权重随时间变化的图

现在，让我们在Keras和Fashion-MNIST示例中使用SageMaker Debugger。

## 调试和检查Keras任务

我们可以通过以下步骤检查和调试Keras任务：

1.  TensorFlow 2.x的默认行为是急切模式（eager mode），此时梯度不可用。因此，我们在脚本中禁用急切模式，这是唯一需要修改的地方：

    [PRE48]

1.  我们从相同的估计器开始。数据集包含70,000个样本（60,000个用于训练，10,000个用于验证）。通过30个epoch和批次大小128，我们的训练任务将有大约16,400个步骤（70,000 * 30 / 128）。在每个步骤保存张量可能显得有些过头。我们改为每100步保存一次：

    [PRE49]

1.  查看TensorFlow的内建规则后，我们决定设置`poor_weight_initialization`、`dead_relu`和`check_input_images`。我们需要指定输入张量中的通道信息索引。对于TensorFlow来说，它是4（批次大小、高度、宽度和通道）：

    [PRE50]

1.  查看TensorFlow的集合后，我们决定保存指标、损失、输出、权重和梯度：

    [PRE51]

1.  当训练开始时，我们在训练日志中看到规则被触发：

    [PRE52]

1.  训练完成后，我们检查调试规则的状态：

    [PRE53]

1.  我们使用保存在 S3 中的相同张量创建一个试验：

    [PRE54]

1.  让我们检查第一层卷积层中的过滤器：

    [PRE55]

    在我们的训练脚本中定义，第一层卷积层有64个过滤器。每个过滤器是3x3像素，具有单通道（2D）。因此，梯度具有相同的形状。

1.  我们编写一个函数来绘制过滤器权重和梯度随时间变化的图，并绘制第一层卷积层中最后一个过滤器的权重：

    [PRE56]

    你可以在以下截图中看到图表：

![图 10.8 – 绘制卷积过滤器随时间变化的权重

](img/B17705_10_8.jpg)

图 10.8 – 绘制卷积过滤器随时间变化的权重

如你所见，SageMaker Debugger 使得检查训练作业变得非常简单。如果你使用内置的支持它的容器，你无需修改代码。所有配置都在估算器中完成。

你可以在[https://github.com/awslabs/amazon-sagemaker-examples](https://github.com/awslabs/amazon-sagemaker-examples)找到更多示例，包括一些高级用例，如实时可视化和模型修剪。

这部分内容结束了，我们学习了如何通过托管的临时训练来优化训练作业的成本，通过自动模型调优来提高准确性，以及如何使用 SageMaker Debugger 检查它们的内部状态。

在第二部分中，我们将深入探讨两项高级功能，帮助我们构建更好的训练工作流——SageMaker Feature Store 和 SageMaker Clarify。

# 使用 SageMaker Feature Store 管理特征和构建数据集

直到现在，我们一直在笔记本或 SageMaker Processing 脚本中工程化我们的训练和验证特征，然后将它们存储为 S3 对象。然后，我们直接使用这些对象来训练和评估模型。这是一个完全合理的工作流。然而，随着你的机器学习工作流的增长和成熟，可能会出现以下问题：

+   我们如何对特征应用明确定义的模式？

+   我们如何选择特征的子集来构建不同的数据集？

+   我们如何存储和管理不同版本的特征？

+   我们如何发现并重用其他团队的特征工程？

+   我们如何在预测时访问工程化的特征？

SageMaker Feature Store 被设计用来回答这些问题。让我们将其添加到我们与 BlazingText 和 Amazon Reviews 一起构建的分类训练工作流中，见[*第6章*](B17705_06_Final_JM_ePub.xhtml#_idTextAnchor108)，*训练自然语言处理模型*。

## 使用 SageMaker Processing 工程化特征

我们几乎可以直接重用之前的SageMaker Processing任务。唯一的区别是工程数据的输出格式。在原始任务中，我们将其保存为纯文本文件，按照BlazingText期望的输入格式。此格式对于SageMaker Feature Store来说不太方便，因为我们需要轻松访问每一列。CSV格式也不行，因为评论中包含逗号，因此我们决定改用TSV格式：

1.  因此，我们在处理脚本中添加了几行：

    [PRE57]

1.  和之前一样运行我们的SageMaker Processing任务，我们现在看到两个输出：一个是BlazingText的纯文本输出（如果我们想直接对完整数据集进行训练），另一个是我们将摄取到SageMaker Feature Store中的TSV输出：

    [PRE58]

1.  让我们将TSV文件加载到`pandas`数据框中，并显示前几行：

    [PRE59]

    这将打印出下图所示的表格：

![图 10.9 – 查看前几行

](img/B17705_10_9.jpg)

图 10.9 – 查看前几行

现在，让我们创建一个特征组，以便我们摄取这些数据。

## 创建特征组

**特征组**是一种资源，用于存储相关特征的集合。特征组按行组织，每行都有一个唯一标识符和时间戳。每行包含键值对，其中每一对代表一个特征名称和特征值。

1.  首先，让我们定义特征组的名称：

    [PRE60]

1.  接下来，我们设置包含唯一标识符的特征名称——`review_id`在这里完全适用，你可以使用数据源中任何唯一的值，如主键：

    [PRE61]

1.  然后，我们为`pandas`数据框中的所有行添加了时间戳列。如果你的数据源已经包含时间戳，你可以重用该值，无论是**float64**格式还是**UNIX**日期/时间格式：

    [PRE62]

    现在我们的数据框看起来如下所示：

    ![图 10.10 – 查看时间戳

    ](img/B17705_10_10.jpg)

    图 10.10 – 查看时间戳

1.  下一步是为特征组定义模式。我们可以将其显式提供为JSON文档，或者让SageMaker从pandas数据框中自动提取。我们使用第二种方式：

    [PRE63]

    接下来，我们加载特征定义：

    [PRE64]

1.  最后，我们创建特征组，传递将存储特征的S3位置。这是我们查询它们以构建数据集的地方。我们启用在线存储，这将使我们在预测时以低延迟访问特征。我们还添加了描述和标签，便于发现特征组：

    [PRE65]

几秒钟后，特征组准备就绪，并在SageMaker Studio中可见，位于**组件和注册表** / **特征存储**下，如下图所示：

![图 10.11 – 查看特征组

](img/B17705_10_11.jpg)

图 10.11 – 查看特征组

现在，让我们开始数据摄取。

## 摄取特征

SageMaker Feature Store允许我们通过三种方式摄取数据：

+   调用`PutRecord()` API以摄取单个记录。

+   调用`ingest()` API上传`pandas`数据框的内容。

+   如果我们使用**SageMaker 数据 Wrangler**进行特征工程，可以使用自动生成的笔记本创建特征组并导入数据。

我们在这里使用第二个选项，它与以下代码一样简单：

[PRE66]

一旦数据导入完成，特征将存储在我们指定的 S3 位置以及专用的低延迟后端中。我们可以使用前者来构建数据集。

## 查询特征以构建数据集

当我们创建特征组时，SageMaker 会自动在 **AWS Glue 数据目录** 中为其添加一个新表。这使得使用 **Amazon Athena** 查询数据并按需构建数据集变得更加容易。

假设我们希望构建一个包含至少有 1,000 条评论的畅销相机的数据集：

1.  首先，我们编写一个 SQL 查询，计算每台相机的平均评分，统计每台相机收到的评论数，仅保留至少有 1,000 条评论的相机，并按平均评分降序排列相机：

    [PRE67]

1.  然后，我们使用 Athena 查询我们的特征组，将选中的行存储在 `pandas` 数据框中，并显示前几行：

    [PRE68]

这会打印出下一张图片中可见的表格：

![图 10.12 – 查看查询结果

](img/B17705_10_12.jpg)

图 10.12 – 查看查询结果

从那时起，一切照常。我们可以将这个数据框保存为 CSV 文件，并用它来训练模型。你可以在 GitHub 仓库中找到一个完整的示例。

## 探索 SageMaker Feature Store 的其他功能

随着时间的推移，我们可以存储同一特征的不同版本——即具有相同标识符但时间戳不同的多个记录。这将允许我们通过简单的 SQL 查询来检索数据集的早期版本——在我们的数据中进行“时光旅行”。

最后但同样重要的是，功能也可以在在线商店中使用。我们可以通过 `GetRecord()` API 检索单个记录，并在预测时根据需要使用功能。

再次，你将在 GitHub 仓库中找到这两项功能的代码示例。

为了结束本章内容，让我们看看 Amazon SageMaker Clarify，这是一项通过检测数据集和模型中的潜在偏差，帮助我们构建更高质量模型的功能。

# 使用 SageMaker Clarify 检测数据集中的偏差并解释预测结果

**机器学习**（**ML**）模型的好坏取决于其构建的 dataset。如果数据集不准确或无法公平地代表其应该捕捉的现实情况，那么相应的模型很可能会学习到这种偏差的表示，并在预测中延续这种偏差。作为机器学习实践者，我们需要意识到这些问题，理解它们如何影响预测，并尽可能地减少这种影响。

在这个示例中，我们将使用**成人数据集**，该数据集可在**UCI机器学习库**中找到（[http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)，Dua, D.和Graff, C.，2019）。这个数据集描述了一个二分类任务，我们尝试预测一个人是否年收入超过$50,000。这里，我们想检查这个数据集是否引入了性别偏差。换句话说，它是否有助于我们构建一个对男性和女性的预测效果一样好的模型？

注意

你在GitHub仓库中找到的数据集经过了轻微的处理。标签列已经根据XGBoost的要求被移到前面。类别变量已经进行了独热编码。

## 使用SageMaker Clarify配置偏差分析

SageMaker Clarify计算训练前和训练后的指标，帮助我们理解模型的预测情况。

后训练指标显然需要一个已训练的模型，因此我们首先使用XGBoost训练一个二分类模型。这是我们已经看过很多次的内容，你可以在GitHub仓库中找到相关代码。这个模型的验证AuC达到了92.75%。

一旦训练完成，我们就可以进行偏差分析：

1.  偏差分析作为SageMaker处理任务运行。因此，我们创建一个`SageMakerClarifyProcessor`对象，指定我们的基础设施需求。由于任务规模较小，我们使用一个实例。对于更大的任务，我们可以使用更多实例，并且分析将自动在**Spark**上运行：

    [PRE69]

1.  然后，我们创建一个`DataConfig`对象，描述要分析的数据集：

    [PRE70]

1.  同样地，我们创建一个`ModelConfig`对象，描述要分析的模型：

    [PRE71]

1.  最后，我们创建一个`BiasConfig`对象，描述要计算的指标。`label_values_or_threshold`定义了正向结果的标签值（1，表示年收入高于$50K）。`facet_name`定义了我们希望分析的特征（`Sex_`），而`facet_values_or_threshold`定义了潜在弱势群体的特征值（1，表示女性）。

    [PRE72]

我们现在准备好运行分析了。

## 运行偏差分析

将所有内容整合在一起，我们使用以下命令启动分析：

[PRE73]

一旦分析完成，结果将在SageMaker Studio中可见。报告也会生成并以HTML、PDF和Notebook格式存储在S3中。

在**实验和试验**中，我们找到我们的SageMaker Clarify任务，并右键点击**打开试验详情**。选择**偏差报告**，我们可以看到偏差指标，如下图所示：

![图 10.13 – 查看偏差指标

](img/B17705_10_13.jpg)

图 10.13 – 查看偏差指标

## 分析偏差指标

如果你想了解更多关于偏差指标的信息、它们的含义以及它们是如何计算的，我强烈推荐以下资源：

+   [https://pages.awscloud.com/rs/112-TZM-766/images/Fairness.Measures.for.Machine.Learning.in.Finance.pdf](https://pages.awscloud.com/rs/112-TZM-766/images/Fairness.Measures.for.Machine.Learning.in.Finance.pdf)

+   [https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf](https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf)

+   [https://github.com/aws/amazon-sagemaker-clarify](https://github.com/aws/amazon-sagemaker-clarify)

我们来看两个训练前的度量标准，**类别不平衡**（**CI**）和**标签中正类比例差异**（**DPL**），以及一个训练后的度量标准，**预测标签中正类比例差异**（**DPPL**）。

CI的非零值表明数据集是不平衡的。这里，男性和女性比例的差异是0.35。确实，男性组大约占数据集的三分之二，女性组约占三分之一。这并不是一个非常严重的失衡，但我们也应该查看每个类别的正类标签比例。

DPL衡量每个类别是否具有相同的正类标签比例。换句话说，数据集中男性和女性赚取$50K的比例是否相同？DPL的值为非零（0.20），这告诉我们男性的$50K收入者比例更高。

DPPL是一个训练后度量，类似于DPL。它的值（0.18）表明模型不幸地拾取了数据集中的偏差，只是轻微地减少了它。实际上，模型为男性预测了一个更有利的结果（过度预测$50K收入者），而为女性预测了一个不太有利的结果（低估$50K收入者）。

这显然是一个问题。尽管模型有一个相当不错的验证AuC（92.75%），但它并没有同样好地预测两种类别。

在我们深入分析数据并尝试缓解这个问题之前，先进行一次可解释性分析。

## 运行可解释性分析

SageMaker Clarify可以计算局部和全局的SHAP值（[https://github.com/slundberg/shap](https://github.com/slundberg/shap)）。它们帮助我们理解特征的重要性，以及各个特征值如何影响正面或负面的结果。

偏差分析作为SageMaker处理作业运行，过程类似：

1.  我们创建一个`DataConfig`对象，描述要分析的数据集：

    [PRE74]

1.  我们创建一个`SHAPConfig`对象，描述我们希望如何计算SHAP值——即使用哪个基准（我使用了移除标签后的测试集），使用多少样本（特征数的两倍加2048，这是一个常见的默认值），以及如何聚合值：

    [PRE75]

1.  最后，我们运行分析：

    [PRE76]

结果可以在SageMaker Studio中查看，`Sex`特征是最重要的，这确认了偏差分析的结果。抛开伦理考虑不谈，从商业角度来看，这似乎并不太合理。像教育程度或资本收益这样的特征应该更为重要。

![图10.14 – 查看特征重要性](https://example.org)

](img/B17705_10_14.jpg)

图 10.14 – 查看特征重要性

本地SHAP值也已经计算并存储在S3中。我们可以使用这些值来了解特征值如何影响每个单独样本的预测。

现在，让我们看看如何尝试缓解我们在数据集中检测到的偏差。

## 缓解偏差

这个数据集结合了两个问题。首先，它包含更多的男性而非女性。其次，男性组的正向结果比例较高。这两个问题的结合导致数据集中$50K收入的女性数量比例异常低。这使得模型更难以公平地学习，并且倾向于偏向多数类。

偏差缓解技术包括以下内容：

+   通过删除多数样本来对多数类进行下采样，以重新平衡数据集

+   通过复制现有样本来对少数类进行过采样，增加更多样本

+   通过生成与现有样本具有相似统计属性的新样本，向少数类添加合成样本

    注意

    修改数据不应轻率进行，尤其是在受监管行业中运作的组织中。这可能会产生严重的业务、合规性和法律后果。在生产环境中进行此操作之前，请务必获得批准。

让我们尝试一种结合方法，基于**imbalanced-learn**开源库（https://imbalanced-learn.org）。首先，我们将使用**合成少数类过采样技术**（**SMOTE**）算法向少数类添加合成样本，以匹配多数类样本中$50K收入者的比例。接着，我们将对多数类进行下采样，使其样本数与少数类相匹配。结果将是一个完全平衡的数据集，两个类别的大小相同，$50K收入者的比例也相同。让我们开始吧：

1.  首先，我们需要计算两个类别的比例：

    [PRE77]

    这给出了以下结果，显示多数类（类别 0）拥有远高于$50K收入者的比例：

    [PRE78]

1.  然后，我们生成少数类的合成样本：

    [PRE79]

1.  接下来，我们使用原始多数类和重新平衡的少数类重新构建数据集：

    [PRE80]

1.  最后，我们对原始多数类进行下采样，以重新平衡比例：

    [PRE81]

1.  我们再次计算两个类别的样本数，并重新计算它们的比例：

    [PRE82]

    这显示了以下结果：

    [PRE83]

在使用这个重新平衡的数据集进行训练，并使用相同的测试集时，我们得到了92.95%的验证AuC，相比之下原始模型为92.75%。进行新的偏差分析时，CI为零，DPL和DPPL接近零。

我们不仅构建了一个预测更公平的模型，而且还稍微提高了准确性。难得的是，这次我们似乎做到了两全其美！

# 总结

本章总结了我们对训练技术的探索。你学习了受管训练（managed spot training），这是一种通过减少70％或更多的训练成本的简单方法。你还了解了检查点（checkpointing）如何帮助恢复被中断的任务。接着，你学习了自动模型调优（automatic model tuning），这是一种通过探索超参数范围从模型中提取更多准确性的有效方法。你了解了SageMaker调试器（SageMaker Debugger），这是一个高级功能，能够自动检查训练任务中的不良条件，并将张量集合保存到S3，以便检查和可视化。最后，我们发现了两个有助于你构建更高质量工作流和模型的功能，SageMaker特征存储（SageMaker Feature Store）和SageMaker Clarify。

在下一章，我们将详细学习模型部署。
