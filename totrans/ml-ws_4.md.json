["```py\npreprocessed_data.to_csv(\"census_income_dataset_preprocessed.csv\")\n```", "```py\nLikelihood [A1|E] = P[A1|E1] * P[A1|E2] * … * P[A1|En] * P[A1]\n```", "```py\n    import pandas as pd\n    from sklearn.naive_bayes import GaussianNB\n    ```", "```py\n    data = pd.read_csv(\"fertility_Diagnosis.csv\", header=None)\n    ```", "```py\n    X = data.iloc[:,:9]\n    Y = data.iloc[:,9]\n    ```", "```py\n    model = GaussianNB()\n    model.fit(X, Y)\n    ```", "```py\n    GaussianNB(priors=None, var_smoothing=1e-09)\n    ```", "```py\n    pred = model.predict([[-0.33,0.69,0,1,1,0,0.8,0,0.88]])\n    print(pred)\n    ```", "```py\n    ['N']\n    ```", "```py\n    import pandas as pd\n    from sklearn.tree import DecisionTreeClassifier\n    ```", "```py\n    data = pd.read_csv(\"fertility_Diagnosis.csv\", header=None)\n    ```", "```py\n    X = data.iloc[:,:9]\n    Y = data.iloc[:,9]\n    ```", "```py\n    model = DecisionTreeClassifier()\n    model.fit(X, Y)\n    ```", "```py\n    DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n                           criterion='gini', max_depth=None,\n                           max_features=None, max_leaf_nodes=None,\n                           min_impurity_decrease=0.0,\n                           min_impurity_split=None,\n                           min_samples_leaf=1, min_samples_split=2,\n                           min_weight_fraction_leaf=0.0,\n                           presort='deprecated',\n                           random_state=None, splitter='best')\n    ```", "```py\n    pred = model.predict([[-0.33,0.69,0,1,1,0,0.8,0,0.88]])\n    print(pred)\n    ```", "```py\n    ['N']\n    ```", "```py\n    import pandas as pd\n    from sklearn.svm import SVC\n    ```", "```py\n    data = pd.read_csv(\"fertility_Diagnosis.csv\", header=None)\n    ```", "```py\n    X = data.iloc[:,:9]\n    Y = data.iloc[:,9]\n    ```", "```py\n    model = SVC()\n    model.fit(X, Y)\n    ```", "```py\n    SVC(C=1.0, break_ties=False, cache_size=200,\n        class_weight=None, coef0=0.0,\n        decision_function_shape='ovr', degree=3,\n        gamma='scale', kernel='rbf', max_iter=-1,\n        probability=False, random_state=None, shrinking=True,\n        tol=0.001, verbose=False)\n    ```", "```py\n    pred = model.predict([[-0.33,0.69,0,1,1,0,0.8,0,0.88]])\n    print(pred)\n    ```", "```py\n    ['N']\n    ```", "```py\n    from sklearn.metrics import accuracy_score, \\\n    precision_score, recall_score\n    ```", "```py\n    X_sets = [X_train, X_dev, X_test]\n    Y_sets = [Y_train, Y_dev, Y_test]\n    ```", "```py\n    metrics = {\"NB\":{\"Acc\":[],\"Pre\":[],\"Rec\":[]},\n               \"DT\":{\"Acc\":[],\"Pre\":[],\"Rec\":[]},\n               \"SVM\":{\"Acc\":[],\"Pre\":[],\"Rec\":[]}}\n    ```", "```py\n    for i in range(0,len(X_sets)):\n        pred_NB = model_NB.predict(X_sets[i])\n        metrics[\"NB\"][\"Acc\"].append(accuracy_score(Y_sets[i], \\\n                                    pred_NB))\n        metrics[\"NB\"][\"Pre\"].append(precision_score(Y_sets[i], \\\n                                    pred_NB))\n        metrics[\"NB\"][\"Rec\"].append(recall_score(Y_sets[i], \\\n                                    pred_NB))\n        pred_tree = model_tree.predict(X_sets[i])\n        metrics[\"DT\"][\"Acc\"].append(accuracy_score(Y_sets[i], \\\n                                    pred_tree))\n        metrics[\"DT\"][\"Pre\"].append(precision_score(Y_sets[i], \\\n                                    pred_tree))\n        metrics[\"DT\"][\"Rec\"].append(recall_score(Y_sets[i], \\\n                                    pred_tree))\n        pred_svm = model_svm.predict(X_sets[i])\n        metrics[\"SVM\"][\"Acc\"].append(accuracy_score(Y_sets[i], \\\n                                     pred_svm))\n        metrics[\"SVM\"][\"Pre\"].append(precision_score(Y_sets[i], \\\n                                     pred_svm))\n        metrics[\"SVM\"][\"Rec\"].append(recall_score(Y_sets[i], \\\n                                     pred_svm))\n    ```", "```py\n    print(metrics)\n    ```"]