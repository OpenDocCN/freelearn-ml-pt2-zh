- en: Appendix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 1\. Introduction to Scikit-Learn
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 1.01: Selecting a Target Feature and Creating a Target Matrix'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load the `titanic` dataset using the `seaborn` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The first couple of rows should look as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.22: An image showing the first 10 instances of the Titanic dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15781_01_22.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.22: An image showing the first 10 instances of the Titanic dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select your preferred target feature for the goal of this activity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The preferred target feature could be either `survived` or `alive`. This is
    mainly because both of them label whether a person survived the crash. For the
    following steps, the variable that's been chosen is `survived`. However, choosing
    `alive` will not affect the final shape of the variables.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create both the features matrix and the target matrix. Make sure that you store
    the data from the features matrix in a variable, X, and the data from the target
    matrix in another variable, Y:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print out the shape of `X`, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Do the same for `Y`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/37BwgSv](https://packt.live/37BwgSv).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2MXFtuP](https://packt.live/2MXFtuP).
    You must execute the entire Notebook in order to get the desired result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You have successfully split the dataset into two subsets, which will be used
    later on to train a model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 1.02: Pre-processing an Entire Dataset'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `seaborn` and the `LabelEncoder` class from scikit-learn. Next, load
    the `titanic` dataset and create the features matrix, including the following
    features: `sex`, `age`, `fare`, `class`, `embark_town`, and `alone`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The features matrix was created as copies of the dataset in order to avoid getting
    a warning message every time the matrix was to be updated through the preprocessing
    process.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check for missing values in all the features. As we did previously, use `isnull()`
    to determine whether a value is missing and use `sum()` to sum up the occurrences
    of missing values along each feature:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will look as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As you can see from the preceding output, only one feature contains a significant
    amount of missing values: `age`. As it contains many missing values that account
    for almost 20% of the total, the values should be replaced. The mean imputation
    methodology will be applied, as shown in the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, discover the outliers present in the numeric features. Let''s use three
    standard deviations as the measure to calculate the min and max threshold for
    numeric features:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The total count of outliers for the age and fare features is 7 and 20, respectively,
    reducing the shape of the initial matrix by 27 instances.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, using a `for` loop, discover outliers present in text features. The `value_counts()`
    function is used to count the occurrence of the classes in each feature:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.23: Count of occurrence of the classes in each feature'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15781_01_23.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.23: Count of occurrence of the classes in each feature'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: None of the classes for any of the features are considered to be outliers as
    they all represent over 5% of the entire dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Convert all text features into their numeric representations. Use scikit-learn''s
    `LabelEncoder` class, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print out the top five instances of the features matrix to view the result
    of the conversion:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.24: A screenshot displaying the first five instances of the features
    matrix'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15781_01_24.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.24: A screenshot displaying the first five instances of the features
    matrix'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Rescale your data, either by normalizing or standardizing it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As you can see from the following code, all features go through the normalization
    process, but only those that don''t meet the criteria of a normalized variable
    are changed:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The top 10 rows of the final output are shown in the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.25: Displaying the first 10 instances of the normalized dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15781_01_25.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.25: Displaying the first 10 instances of the normalized dataset'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2MY1wld](https://packt.live/2MY1wld).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3e2lyqt](https://packt.live/3e2lyqt).
    You must execute the entire Notebook in order to get the desired result.
  prefs: []
  type: TYPE_NORMAL
- en: You have successfully performed data preprocessing over a dataset, which can
    now be used to train a ML algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Unsupervised Learning – Real-Life Applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 2.01: Using Data Visualization to Aid the Pre-processing Process'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import all the required elements to load the dataset and pre-process it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the previously downloaded dataset by using pandas'' `read_csv()` function.
    Store the dataset in a pandas DataFrame named `data`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check for missing values in your DataFrame. Using the `isnull()` function plus
    the `sum()` function, count the missing values of the entire dataset at once:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see from the preceding screenshot, there are no missing values in
    the dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Check for outliers in your DataFrame. Mark as outliers all the values that are
    three standard deviations away from the mean.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following code snippet allows you to look for outliers in the entire set
    of features at once. However, another valid method would be to check for outliers
    one feature at a time:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The count of outliers for each of the features is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see from the preceding screenshot, some features do have outliers.
    Considering that there are only a few outliers for each feature, there are two
    possible ways to handle them.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'First, you could decide to delete the outliers. This decision can be supported
    by displaying a histogram for the features with outliers:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.14: An example histogram plot for the “Fresh” feature'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15781_02_14.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.15: A pie chart showing the participation of outliers from the Detergents_papers
    feature in the dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15781_02_15.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.15: A pie chart showing the participation of outliers from the Detergents_papers
    feature in the dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The preceding diagram shows the participation of the outliers from the `Detergents_papers`
    feature, which was the feature with the most outliers in the dataset. Only 2.27%
    of the values are outliers, a value so low that it will not affect the performance
    of the model either.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For the solution in this book, it was decided to keep the outliers since they
    are not likely to affect the performance of the model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Rescale the data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For this solution, the formula for standardization has been used. Note that
    the formula can be applied to the entire dataset at once, instead of being applied
    individually to each feature:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.16: Rescaled data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15781_02_16.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.16: Rescaled data'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2Y3ooGh](https://packt.live/2Y3ooGh).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2B8vKPI](https://packt.live/2B8vKPI).
    You must execute the entire Notebook in order to get the desired result.
  prefs: []
  type: TYPE_NORMAL
- en: You have successfully pre-processed the Wholesale Customers dataset, which will
    be used in subsequent activities to build a model that will classify these observations
    into clusters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 2.02: Applying the k-means Algorithm to a Dataset'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the Jupyter Notebook that you used for the previous activity. There, you
    should have imported all the required libraries and performed the necessary steps
    to pre-process the dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The standardized data should look as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.17: A screenshot displaying the first five instances of the standardized
    dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15781_02_17.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.17: A screenshot displaying the first five instances of the standardized
    dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Calculate the average distance of data points from its centroid in relation
    to the number of clusters. Based on this distance, select the appropriate number
    of clusters to train the model on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, import the algorithm class:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, using the code in the following snippet, calculate the average distance
    of data points from its centroid based on the number of clusters created:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, plot the relation to find the breaking point of the line and select
    the number of clusters:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.18: The output of the plot function used'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15781_02_18.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.18: The output of the plot function used'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Again, the *x-axis* represents the number of clusters, while the *y-axis* refers
    to the calculated average distance of the data points in a cluster from their
    centroid.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Train the model and assign a cluster to each data point in your dataset. Plot
    the results.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To train the model, use the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The number of clusters selected is `6`; however, since there is no exact breaking
    point, values between 5 and 10 are also acceptable.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Finally, plot the results of the clustering process. Since the dataset contains
    eight different features, choose two features to draw at once, as shown in the
    following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.19: Two example plots obtained after the clustering process'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15781_02_19.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.19: Two example plots obtained after the clustering process'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this activity, please refer to [https://packt.live/3fhgO0y](https://packt.live/3fhgO0y).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3eeEOB6](https://packt.live/3eeEOB6).
    You must execute the entire Notebook in order to get the desired result.
  prefs: []
  type: TYPE_NORMAL
- en: The `subplots()` function from `matplotlib` has been used to plot two scatter
    graphs at a time. For each graph, the axes represent the values for a selected
    feature in relation to the values of another feature. As can be seen from the
    plots, there is no obvious visual relation due to the fact that we are only able
    to use two of the eight features present in the dataset. However, the final output
    of the model creates six different clusters that represent six different profiles
    of clients.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 2.03: Applying the Mean-Shift Algorithm to a Dataset'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the Jupyter Notebook that you used for the previous activity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the model and assign a cluster to each data point in your dataset. Plot the results.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, import the algorithm class:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To train the model, use the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The model was trained using a bandwidth of `0.4`. However, feel free to test
    other values to see how the result changes.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Finally, plot the results of the clustering process. As the dataset contains
    eight different features, choose two features to draw at once, as shown in the
    following snippet. Similar to the previous activity, the separation between clusters
    is not seen visually due to the capability to only draw two out of the eight features:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.20: Example plots obtained at the end of the process'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15781_02_20.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.20: Example plots obtained at the end of the process'
  prefs: []
  type: TYPE_NORMAL
- en: For each of the plots, the axes represent the values of a selected feature,
    against the values of another feature.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this activity, please refer to [https://packt.live/3fviVy1](https://packt.live/3fviVy1).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2Y1aqEF](https://packt.live/2Y1aqEF).
    You must execute the entire Notebook in order to get the desired result.
  prefs: []
  type: TYPE_NORMAL
- en: You have successfully applied the mean-shift algorithm over the Wholesale Customers
    dataset. Later on, you will be able to compare the results of the different algorithms
    over the same dataset to choose the one that performs the best.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 2.04: Applying the DBSCAN Algorithm to the Dataset'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the Jupyter Notebook that you used for the previous activity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the model and assign a cluster to each data point in your dataset. Plot
    the results.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, import the algorithm class:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To train the model, use the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The model was trained using an epsilon value of `0.8`. However, feel free to
    test other values to see how the results change.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Finally, plot the results of the clustering process. As the dataset contains
    eight different features, choose two features to draw at once, as shown in the
    following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.21: Example plots obtained at the end of the clustering process'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15781_02_21.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.21: Example plots obtained at the end of the clustering process'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this activity, please refer to [https://packt.live/2YCFvh8](https://packt.live/2YCFvh8).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2MZgnvC](https://packt.live/2MZgnvC).
    You must execute the entire Notebook in order to get the desired result.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to the previous activity, the separation between clusters is not seen
    visually due to the capability to only draw two out of the eight features at once.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 2.05: Measuring and Comparing the Performance of the Algorithms'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the Jupyter Notebook that you used for the previous activity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate both the Silhouette Coefficient score and the Calinski–Harabasz index
    for all the models that you trained previously.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, import the metrics:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calculate the Silhouette Coefficient score for all the algorithms, as shown
    in the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The scores come to be around `0.3515`, `0.0933`, and `0.1685` for the k-means,
    mean-shift, and DBSCAN algorithms, respectively.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Finally, calculate the Calinski–Harabasz index for all the algorithms. The
    following is a snippet of the code for this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The scores come to be approximately `145.73`, `112.90`, and `42.45` for the
    three algorithms in the order given in the preceding code snippet.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this activity, please refer to [https://packt.live/2Y2xHWR](https://packt.live/2Y2xHWR).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3hszegy](https://packt.live/3hszegy).
    You must execute the entire Notebook in order to get the desired result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: By quickly looking at the results we obtained for both metrics, it is possible
    to conclude that the k-means algorithm outperforms the other models, and hence
    should be the one that's selected to solve the data problem.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Supervised Learning – Key Steps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 3.01: Data Partitioning on a Handwritten Digit Dataset'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import all the required elements to split a dataset, as well as the `load_digits`
    function from scikit-learn to load the `digits` dataset. Use the following code
    to do so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the `digits` dataset and create Pandas DataFrames containing the features
    and target matrices:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The shape of your features and target matrices should be as follows, respectively:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Perform the conventional split approach, using a split ratio of 60/20/20%.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Using the `train_test_split` function, split the data into an initial train
    set and a test set:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The shape of the sets that you created should be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, calculate the value of `test_size`, which sets the size of the dev set
    equal to the size of the test set that was created previously:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The result of the preceding operation is `0.2505`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Finally, split `X_new` and `Y_new` into the final train and dev sets. Use the
    following code to do so:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output from the preceding snippet is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Using the same DataFrames, perform a 10-fold cross-validation split.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, divide the datasets into initial training and testing sets:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using the `KFold` class, perform a 10-fold split:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Remember that cross-validation performs a different configuration of splits,
    shuffling data each time. Considering this, perform a `for` loop that will go
    through all the split configurations:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The code in charge of training and evaluating the model should be inside the
    body of the `for` loop in order to train and evaluate the model with each configuration
    of splits:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'By printing the shape of all the subsets, as per the preceding snippet, the
    output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/37xatv3](https://packt.live/37xatv3).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2Y2nolS](https://packt.live/2Y2nolS).
    You must execute the entire Notebook in order to get the desired result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You have successfully split a dataset using both the conventional split approach,
    as well as the cross-validation one. These sets can now be used to train outstanding
    models that perform well on unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 3.02: Evaluating the Performance of the Model Trained on a Handwritten
    Dataset'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import all the required elements to load and split a dataset in order to train
    a model and evaluate the performance of the classification tasks:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the `digits` toy dataset from scikit-learn and create Pandas DataFrames
    containing the features and target matrices:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Split the data into training and testing sets. Use 20% as the size of the testing
    set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Train a decision tree on the train set. Then, use the model to predict the
    class label on the test set (hint: to train the decision tree, revisit *Exercise
    3.04*, *Calculating Different Evaluation Metrics on a Classification Task*):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use scikit-learn to construct a confusion matrix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of the confusion matrix is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.14: Output of the confusion matrix'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15781_03_14.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.14: Output of the confusion matrix'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Calculate the accuracy of the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The accuracy is equal to `84.72`%.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Calculate the precision and recall. Considering that both the precision and
    recall can only be calculated on binary data, we''ll assume that we are only interested
    in classifying instances as number 6 or any other number:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output from the preceding code snippet is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: According to this, the precision and recall scores should be equal to `98.41`%
    and `98.10`%, respectively.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2UJMFPC](https://packt.live/2UJMFPC).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2zwqkgX](https://packt.live/2zwqkgX).
    You must execute the entire Notebook in order to get the desired result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You have successfully measured the performance of classification tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 3.03: Performing Error Analysis on a Model Trained to Recognize Handwritten
    Digits'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the required elements to load and split a dataset. We will do this to
    train the model and measure its accuracy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the `digits` toy dataset from scikit-learn and create Pandas DataFrames
    containing the features and target matrices:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Split the data into training, validation, and testing sets. Use `0.1` as the
    size of the test set, and an equivalent number to build a validation set of the
    same shape:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The resulting shapes are as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a train/dev set for both the features and the target values that contains
    `90` instances/labels of the train set and `90` instances/labels of the dev set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The resulting shapes are as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Train a decision tree on that training set data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calculate the error rate for all sets of data and determine which condition
    is affecting the performance of the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The error rates can be seen in the following table:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.15: Error rates of the Handwritten Digits model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15781_03_15.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.15: Error rates of the Handwritten Digits model'
  prefs: []
  type: TYPE_NORMAL
- en: From the preceding results, it can be concluded that the model is equally suffering
    from variance and data mismatch.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3d0c4uM](https://packt.live/3d0c4uM).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3eeFlTC](https://packt.live/3eeFlTC).
    You must execute the entire Notebook in order to get the desired result.
  prefs: []
  type: TYPE_NORMAL
- en: You have now successfully performed an error analysis to determine a course
    of action to improve the model's performance.
  prefs: []
  type: TYPE_NORMAL
- en: '4\. Supervised Learning Algorithms: Predicting Annual Income'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 4.01: Training a Naïve Bayes Model for Our Census Income Dataset'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In a Jupyter Notebook, import all the required elements to load and split the
    dataset, as well as to train a Naïve Bayes algorithm:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the pre-processed Census Income dataset. Next, separate the features from
    the target by creating two variables, `X` and `Y`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that there are several ways to achieve the separation of `X` and `Y`. Use
    the one that you feel most comfortable with. However, take into account that `X`
    should contain the features of all instances, while `Y` should contain the class
    labels of all instances.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Divide the dataset into training, validation, and testing sets, using a split
    ratio of 10%:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The final shape will look as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `fit` method to train a Naïve Bayes model on the training sets (`X_train`
    and `Y_train`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, perform a prediction using the model that you trained previously for
    a new instance with the following values for each feature – `39`, `6`, `13`, `4`,
    `0`, `2174`, `0`, `40`, `38`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output from the prediction is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3ht1TCs](https://packt.live/3ht1TCs).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2zwqxkf](https://packt.live/2zwqxkf).
    You must execute the entire Notebook in order to get the desired result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This means that the individual has an income less than or equal to 50K, considering
    that 0 is the label for individuals with a salary less than or equal to 50K.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 4.02: Training a Decision Tree Model for Our Census Income Dataset'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the Jupyter Notebook that you used for the previous activity and import
    the decision tree algorithm from scikit-learn:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Train the model using the `fit` method on the `DecisionTreeClassifier` class
    from scikit-learn. To train the model, use the training set data from the previous
    activity (`X_train` and `Y_train`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, perform a prediction using the model that you trained before for a
    new instance with the following values for each feature – `39`, `6`, `13`, `4`,
    `0`, `2174`, `0`, `40`, `38`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output from the preceding code snippet is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2zxQIqV](https://packt.live/2zxQIqV).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2AC7iWX](https://packt.live/2AC7iWX).
    You must execute the entire Notebook in order to get the desired result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This means that the subject has an income lower than or equal to 50K.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 4.03: Training an SVM Model for Our Census Income Dataset'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the Jupyter Notebook that you used for the previous activity and import
    the SVM algorithm from scikit-learn:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Train the model using the `fit` method on the `SVC` class from scikit-learn.
    To train the model, use the training set data from the previous activity (`X_train`
    and `Y_train`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, perform a prediction using the model that you trained before for a
    new instance with the following values for each feature – `39`, `6`, `13`, `4`,
    `0`, `2174`, `0`, `40`, `38`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The prediction for the individual is equal to zero, which means that the individual
    has an income below or equal to `50K`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2Nb6J9z](https://packt.live/2Nb6J9z).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3hbpCGm](https://packt.live/3hbpCGm).
    You must execute the entire Notebook in order to get the desired result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5\. Artificial Neural Networks: Predicting Annual Income'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 5.01: Training an MLP for Our Census Income Dataset'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import all the elements required to load and split a dataset, to train an MLP,
    and to measure accuracy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using the preprocessed Census Income Dataset, separate the features from the
    target, creating the variables `X` and `Y`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As explained previously, there are several ways to achieve the separation of
    `X` and `Y`, and the main thing to consider is that `X` should contain the features
    for all instances, while `Y` should contain the class label of all instances.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Divide the dataset into training, validation, and testing sets, using a split
    ratio of 10%:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The shape of the sets created should be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate the `MLPClassifier` class from scikit-learn and train the model
    with the training data. Leave the hyperparameters to their default values. Again,
    use a `random_state` equal to `101`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calculate the accuracy of the model for all three sets (training, validation,
    and testing):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The accuracy score for the three sets should be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3hneWFr](https://packt.live/3hneWFr).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This section does not currently have an online interactive example, and will
    need to be run locally.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You have successfully trained an MLP model to solve a real-life data problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 5.02: Comparing Different Models to Choose the Best Fit for the Census
    Income Data Problem'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the Jupyter Notebooks that you used to train the models.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare the four models, based only on their accuracy scores.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'By taking the accuracy scores of the models from the previous chapter, and
    the accuracy of the model trained in this chapter, it is possible to perform a
    final comparison to choose the model that best solves the data problem. To do
    so, the following table displays the accuracy scores for all four models:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.15: Accuracy scores of all four models for the Census Income Dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15781_05_15.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.15: Accuracy scores of all four models for the Census Income Dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: On the basis of the accuracy scores, identify the model that best solves the
    data problem.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To identify the model that best solves the data problem, begin by comparing
    the accuracy rates over the training sets. From this, it is possible to conclude
    that the decision tree model is a better fit for the data problem. Nonetheless,
    the performance over the validation and testing sets is lower than the one achieved
    using the MLP, which is an indication of the presence of high variance in the
    decision tree model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Hence, a good approach would be to address the high variance of the decision
    tree model by simplifying the model. This can be achieved by adding a pruning
    argument that "trims" the leaves of the tree to simplify it and ignore some of
    the details of the tree in order to generalize the model to the data. Ideally,
    the model should be able to reach a similar level of accuracy for all three sets,
    which would make it the best model for the data problem.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: However, if the model is not able to overcome the high variance, and assuming
    that all the models have been fine-tuned to achieve the maximum performance possible,
    the MLP should be the model that is selected, considering that it performs best
    over the testing sets. This is mainly because the performance of the model over
    the testing set is the one that defines its overall performance over unseen data,
    which means that the one with higher testing-set performance will be more useful
    in the long term.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 6\. Building Your Own Program
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 6.01: Performing the Preparation and Creation Stages for the Bank
    Marketing Dataset'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To ensure the reproducibility of the results available at [https://packt.live/2RpIhn9](https://packt.live/2RpIhn9),
    make sure that you use a `random_state` of `0` when splitting the datasets and
    a `random_state` of `2` when training the models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a Jupyter Notebook and import all the required elements:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the dataset into the notebook. Make sure that you load the one that was
    edited previously, named `bank-full-dataset.csv`, which is also available at [https://packt.live/2wnJyny](https://packt.live/2wnJyny):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.8: A screenshot showing the first 10 instances of the dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15781_06_08.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.8: A screenshot showing the first 10 instances of the dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The missing values are shown as `NaN`, as explained previously.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select the metric that's the most appropriate for measuring the performance
    of the model, considering that the purpose of the study is to detect clients who
    would subscribe to the term deposit.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The metric to evaluate the performance of the model is the **precision** metric,
    as it compares the correctly classified positive labels against the total number
    of instances predicted as positive.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Pre-process the dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The process of handling missing values is handled as per the concepts we learned
    about in *Chapter 1*, *Introduction to Scikit-Learn*, and that have been applied
    throughout this book. Use the following code to check for missing values:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Based on the results, you will observe that only four features contain missing
    values: `job` (288), `education` (1,857), `contact` (13,020), and `poutcome` (36,959).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The first two features can be left unhandled, considering that the missing values
    represent less than 5% of the entire data. On the other hand, 28.8% of the values
    are missing from the `contact` feature, and taking into account that the feature
    refers to the mode of contact, which is considered to be irrelevant for determining
    whether a person will subscribe to a new product, it is safe to remove this feature
    from the study. Finally, the `poutcome` feature is missing 81.7% of its values,
    which is why this feature is also removed from the study.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Using the following code, the preceding two features are dropped:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As we explained in *Chapter 1*, *Introduction to Scikit-Learn*, and applied
    throughout this book, the process of converting categorical features into their
    numeric form is as follows.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For all nominal features, use the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The preceding code, as explained in previous chapters, converts all the qualitative
    features into their numeric forms.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, to handle the ordinal feature, we must use the following code, as mentioned
    in *Step 4*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, the first line converts `NaN` values into the word `unknown`, while the
    second line sets the order of the values in the feature. Next, a `for` loop is
    used to replace each word with a number that follows an order. For the preceding
    example, `0` will be used to replace the word `unknown`, then `1` will be used
    instead of `primary`, and so on. Finally, the whole column is converted into an
    integer type since the `replace` function writes down the numbers as strings.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'If we display the head of the resulting DataFrame, the output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.9: A screenshot showing the first five instances of the dataset
    after converting the categorical features into numerical ones'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15781_06_09.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If we print the resulting dictionary, we get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As we can see, the outliers do not account for more than 5% of the total values
    in each feature, which is why they can be left unhandled.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This can be verified by taking the feature with the most outliers (`pdays`)
    and dividing the number of outliers by the total number of instances (1,723 divided
    by 45,211). The result from that operation is 0.038, which is equivalent to 3.8%.
    This means that the feature only has 3.8% of the outlier values.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Separate the features from the class label and split the dataset into three
    sets (training, validation, and testing).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To separate the features from the target value, use the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, to perform a 60/20/20 split, use the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If we print the shape of all the subsets, the output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the decision tree algorithm on the dataset and train the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As a reminder, the output from calling the `fit` method consists of the model
    currently being trained with all the parameters that it takes in.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the multilayer perceptron algorithm on the dataset and train the model.
    To revisit this, go to *Chapter 5*, *Artificial Neural Networks: Predicting Annual
    Income*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Evaluate both models by using the metric that was selected previously.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Using the following code, it is possible to measure the precision score of
    the decision tree model:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If we print the list containing the precision score for each of the sets for
    the decision tree model, the output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The same code can be modified to calculate the score for the multilayer perceptron:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If we print the list containing the precision score for each of the sets for
    the multilayer perceptron model, the output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The precision score for all subsets of data for both models is shown in the
    following table:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.10: Precision scores for both models'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15781_06_10.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.10: Precision scores for both models'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Fine-tune some of the hyperparameters to fix the issues that were detected during
    the evaluation of the model by performing error analysis.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Although the precision of the decision tree on the training sets is perfect,
    on comparing it against the results of the other two sets, it is possible to conclude
    that the model suffers from high variance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: On the other hand, the multilayer perceptron has a similar performance on all
    three sets, but the overall performance is low, which means that the model is
    more likely to be suffering from high bias.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Considering this, for the decision tree model, both the minimum number of samples
    required to be at a leaf node and the maximum depth of the tree are changed in
    order to simplify the model. On the other hand, for the multilayer perceptron,
    the number of iterations, the number of hidden layers, the number of units in
    each layer, and the tolerance for optimization are changed.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The following code shows the final values that were used for the hyperparameters
    of the decision tree algorithm, considering that to arrive at them it is required
    to try different values:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following snippet displays the final values used for the hyperparameters
    of the multilayer perceptron algorithm:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As a reminder, the output from calling the `fit` method consists of the model
    currently being trained with all the parameters that it takes in.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Compare the final versions of your models and select the one that you consider
    best fits the data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Using the same code as in previous steps, it is possible to calculate the precision
    of the decision tree model over the different sets of data:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output list should look as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To calculate the precision of the multilayer perceptron, the following code
    snippet can be used:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The resulting list should look as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'By calculating the precision score for all three sets for the newly trained
    models, we obtain the following values:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.11: Precision scores for the newly trained models'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15781_06_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.11: Precision scores for the newly trained models'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2RpIhn9](https://packt.live/2RpIhn9).
  prefs: []
  type: TYPE_NORMAL
- en: This section does not currently have an online interactive example, and will
    need to be run locally.
  prefs: []
  type: TYPE_NORMAL
- en: An improvement in performance for both models is achieved, and by comparing
    the values, it is possible to conclude that the multilayer perceptron outperforms
    the decision tree model. Based on this, the multilayer perceptron is selected
    as the better model for solving the data problem.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: You are encouraged to continue to fine-tune the parameters to reach an even
    higher precision score.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 6.02: Saving and Loading the Final Model for the Bank Marketing Dataset'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the Jupyter Notebook from *Activity 6.01*, *Performing the Preparation
    and Creation Stages for the Bank Marketing Dataset*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For learning purposes, take the model that you selected as the best model, remove
    the `random_state` argument, and run it a couple of times.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save the model that you choose as the best performing one into a file named
    `final_model.pkl`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Open a new Jupyter Notebook and import the required modules and class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the saved model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Perform a prediction for an individual by using the following values: `42`,
    `2`, `0`, `0`, `1`, `2`, `1`, `0`, `5`, `8`, `380`, `1`, `-1`, `0`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2UIWFss](https://packt.live/2UIWFss).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This section does not currently have an online interactive example, and will
    need to be run locally.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If we printing the `pred` variable, the output is `0`, which is the numeric
    form of `No`. This means that the individual is more likely to not subscribe to
    the new product.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 6.03: Allowing Interaction with the Bank Marketing Dataset Model'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In a text editor, create a class object that contains two main functions. One
    should be an initializer that loads the saved model, while the other should be
    a `predict` method where the data is fed to the model to retrieve an output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As per the preceding snippet, the first step is to import all the required
    elements to locate the saved model and deserialize it:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, as per the preceding code snippet, the class that will connect the saved
    model with the channel of interaction is programmed. It should have an initializer
    method to deserialize and load the saved model, and a `predict` method to feed
    the input data to the model to perform a prediction.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In a Jupyter Notebook, import and initialize the class that you created in
    the previous step. Next, create the variables that will hold the values for the
    features of a new observation and use the following values: `42`, `2`, `0`, `0`,
    `1`, `2`, `1`, `0`, `5`, `8`, `380`, `1`, `-1`, `0`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Perform a prediction by applying the `predict` method:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'By printing the variable, the prediction is equal to `0`; that is, the individual
    with the given features is not likely to subscribe to the product, as can be seen
    here:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE123]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2Y2yBCJ](https://packt.live/2Y2yBCJ).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3d6ku3E](https://packt.live/3d6ku3E).
    You must execute the entire Notebook in order to get the desired result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Throughout the activities in this chapter, you have successfully learned how
    to develop a complete machine learning solution, going from data pre-processing
    and training the model to selecting the best performing model using error analysis
    and saving the model to be able to make use of it effectively.
  prefs: []
  type: TYPE_NORMAL
