["```py\nfrom keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate\nfrom keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nimport numpy as np\nimport pandas as pd\n```", "```py\ndef get_data():\n    # Read the data and drop timestamp\n    data = pd.read_csv('ratings.csv')\n    data.drop('timestamp', axis=1, inplace=True)\n\n    # Re-map the indices\n    users = data.userId.unique()\n    movies = data.movieId.unique()\n    # Create maps from old to new indices\n    moviemap={}\n    for i in range(len(movies)):\n        moviemap[movies[i]]=i\n    usermap={}\n    for i in range(len(users)):\n        usermap[users[i]]=i\n\n    # Change the indices\n    data.movieId = data.movieId.apply(lambda x: moviemap[x]) \n    data.userId = data.userId.apply(lambda x: usermap[x]) \n\n    # Shuffle the data\n    data = data.sample(frac=1.0).reset_index(drop=True)\n\n    # Create a train/test split\n    train, test = train_test_split(data, test_size=0.2)\n\n    n_users = len(users)\n    n_movies = len(movies)\n\n    return train, test, n_users, n_movies\ntrain, test, n_users, n_movies = get_data()\n```", "```py\nfts = 5\n\n# Movie part. Input accepts the index as input\n# and passes it to the Embedding layer. Finally,\n# Flatten transforms Embedding's output to a\n# one-dimensional tensor.\nmovie_in = Input(shape=[1], name=\"Movie\")\nmov_embed = Embedding(n_movies, fts, name=\"Movie_Embed\")(movie_in)\nflat_movie = Flatten(name=\"FlattenM\")(mov_embed)\n\n# Repeat for the user.\nuser_in = Input(shape=[1], name=\"User\")\nuser_inuser_embed = Embedding(n_users, fts, name=\"User_Embed\")(user_in)\nflat_user = Flatten(name=\"FlattenU\")(user_inuser_embed)\n```", "```py\n# Calculate the dot-product of the two embeddings\nprod = Dot(name=\"Mult\", axes=1)([flat_movie, flat_user])\n\n# Create and compile the model\nmodel = Model([user_in, movie_in], prod)\nmodel.compile('adam', 'mean_squared_error')\n```", "```py\n# Train the model on the train set\nmodel.fit([train.userId, train.movieId], train.rating, epochs=10, verbose=1)\n\n# Evaluate on the test set\nprint(metrics.mean_squared_error(test.rating, \n      model.predict([test.userId, test.movieId])))\n```", "```py\n# Movie part. Input accepts the index as input\n# and passes it to the Embedding layer. Finally,\n# Flatten transforms Embedding's output to a\n# one-dimensional tensor.\nmovie_in = Input(shape=[1], name=\"Movie\")\nmov_embed = Embedding(n_movies, fts, name=\"Movie_Embed\")(movie_in)\nflat_movie = Flatten(name=\"FlattenM\")(mov_embed)\n\n# Repeat for the user.\nuser_in = Input(shape=[1], name=\"User\")\nuser_inuser_embed = Embedding(n_users, fts, name=\"User_Embed\")(user_in)\nflat_user = Flatten(name=\"FlattenU\")(user_inuser_embed)\n\n# Concatenate the Embedding layers and feed them \n# to the Dense part of the network\nconcat = Concatenate()([flat_movie, flat_user])\ndense_1 = Dense(128)(concat)\ndense_2 = Dense(32)(dense_1)\nout = Dense(1)(dense_2)\n\n# Create and compile the model\nmodel = Model([user_in, movie_in], out)\nmodel.compile('adam', 'mean_squared_error')\n```", "```py\ndef create_model(n_features=5, train_model=True, load_weights=False):\n    fts = n_features\n\n    # Movie part. Input accepts the index as input\n    # and passes it to the Embedding layer. Finally,\n    # Flatten transforms Embedding's output to a\n    # one-dimensional tensor.\n    movie_in = Input(shape=[1], name=\"Movie\")\n    mov_embed = Embedding(n_movies, fts, name=\"Movie_Embed\")(movie_in)\n    flat_movie = Flatten(name=\"FlattenM\")(mov_embed)\n\n    # Repeat for the user.\n    user_in = Input(shape=[1], name=\"User\")\n    user_inuser_embed = Embedding(n_users, fts, name=\"User_Embed\")(user_in)\n    flat_user = Flatten(name=\"FlattenU\")(user_inuser_embed)\n\n    # Concatenate the Embedding layers and feed them \n    # to the Dense part of the network\n    concat = Concatenate()([flat_movie, flat_user])\n    dense_1 = Dense(128)(concat)\n    dense_2 = Dense(32)(dense_1)\n    out = Dense(1)(dense_2)\n\n    # Create and compile the model\n    model = Model([user_in, movie_in], out)\n    model.compile('adam', 'mean_squared_error')\n    # Train the model\n    model.fit([train.userId, train.movieId], train.rating, epochs=10, verbose=1)\n\n    return model\n\ndef predictions(model):\n    preds = model.predict([test.userId, test.movieId])\n    return preds\n```", "```py\n# Create base and meta learner\nmodel5 = create_model(5)\nmodel10 = create_model(10)\nmodel15 = create_model(15)\nmeta_learner = BayesianRidge()\n\n# Predict on the test set\npreds5 = predictions(model5)\npreds10 = predictions(model10)\npreds15 = predictions(model15)\n# Create a single array with the predictions\npreds = np.stack([preds5, preds10, preds15], axis=-1).reshape(-1, 3)\n```", "```py\n# Fit the meta learner on all but the last 1000 test samples\nmeta_learner.fit(preds[:-1000], test.rating[:-1000])\n\n# Evaluate the base learners and the meta learner on the last\n# 1000 test samples\nprint('Base Learner 5 Features')\nprint(metrics.mean_squared_error(test.rating[-1000:], preds5[-1000:]))\nprint('Base Learner 10 Features')\nprint(metrics.mean_squared_error(test.rating[-1000:], preds10[-1000:]))\nprint('Base Learner 15 Features')\nprint(metrics.mean_squared_error(test.rating[-1000:], preds15[-1000:]))\nprint('Ensemble')\nprint(metrics.mean_squared_error(test.rating[-1000:], meta_learner.predict(preds[-1000:])))\n```"]