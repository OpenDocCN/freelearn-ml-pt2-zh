["```py\n> -0.60 * log2(0.60) - 0.40 * log2(0.40)\n[1] 0.9709506\n\n```", "```py\n> curve(-x * log2(x) - (1 - x) * log2(1 - x),\n col = \"red\", xlab = \"x\", ylab = \"Entropy\", lwd = 4)\n\n```", "```py\n> credit <- read.csv(\"credit.csv\")\n\n```", "```py\n> str(credit)\n'data.frame':1000 obs. of  17 variables:\n $ checking_balance : Factor w/ 4 levels \"< 0 DM\",\"> 200 DM\",..\n $ months_loan_duration: int  6 48 12 ...\n $ credit_history      : Factor w/ 5 levels \"critical\",\"good\",..\n $ purpose             : Factor w/ 6 levels \"business\",\"car\",..\n $ amount              : int  1169 5951 2096 ...\n\n```", "```py\n> table(credit$checking_balance)\n < 0 DM   > 200 DM 1 - 200 DM    unknown \n 274         63        269        394\n> table(credit$savings_balance)\n < 100 DM > 1000 DM  100 - 500 DM 500 - 1000 DM   unknown \n 603        48           103            63       183\n\n```", "```py\n> summary(credit$months_loan_duration)\n Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 4.0    12.0    18.0    20.9    24.0    72.0 \n> summary(credit$amount)\n Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 250    1366    2320    3271    3972   18420\n\n```", "```py\n> table(credit$default)\n no yes \n700 300\n\n```", "```py\n> set.seed(123)\n> train_sample <- sample(1000, 900)\n\n```", "```py\n> str(train_sample)\n int [1:900] 288 788 409 881 937 46 525 887 548 453 ... \n\n```", "```py\n> credit_train <- credit[train_sample, ]\n> credit_test  <- credit[-train_sample, ]\n\n```", "```py\n> prop.table(table(credit_train$default))\n no       yes \n0.7033333 0.2966667 \n\n> prop.table(table(credit_test$default))\n no  yes \n0.67 0.33\n\n```", "```py\n> credit_model <- C5.0(credit_train[-17], credit_train$default)\n\n```", "```py\n> credit_model\n\nCall:\nC5.0.default(x = credit_train[-17], y = credit_train$default)\n\nClassification Tree\nNumber of samples: 900 \nNumber of predictors: 16 \n\nTree size: 57 \n\nNon-standard options: attempt to group attributes\n\n```", "```py\n> summary(credit_model)\n\n```", "```py\nEvaluation on training data (900 cases):\n\n Decision Tree \n ---------------- \n Size      Errors \n 56  133(14.8%)   <<\n\n (a)   (b)    <-classified as\n ----  ----\n 598    35    (a): class no\n 98   169    (b): class yes\n\n```", "```py\n> credit_pred <- predict(credit_model, credit_test)\n\n```", "```py\n> library(gmodels)\n> CrossTable(credit_test$default, credit_pred,\n prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,\n dnn = c('actual default', 'predicted default'))\n\n```", "```py\n> credit_boost10 <- C5.0(credit_train[-17], credit_train$default,\n trials = 10)\n\n```", "```py\n> credit_boost10\nNumber of boosting iterations: 10 \nAverage tree size: 47.5\n\n```", "```py\n> summary(credit_boost10)\n\n (a)   (b)    <-classified as\n ----  ----\n 629     4    (a): class no\n 30   237    (b): class yes\n\n```", "```py\n> credit_boost_pred10 <- predict(credit_boost10, credit_test)\n> CrossTable(credit_test$default, credit_boost_pred10,\n prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,\n dnn = c('actual default', 'predicted default'))\n\n```", "```py\n> matrix_dimensions <- list(c(\"no\", \"yes\"), c(\"no\", \"yes\"))\n> names(matrix_dimensions) <- c(\"predicted\", \"actual\")\n\n```", "```py\n> matrix_dimensions\n$predicted\n[1] \"no\"  \"yes\"\n\n$actual\n[1] \"no\"  \"yes\"\n\n```", "```py\n> error_cost <- matrix(c(0, 1, 4, 0), nrow = 2,\n dimnames = matrix_dimensions)\n\n```", "```py\n> error_cost\n actual\npredicted no yes\n no   0   4\n yes  1   0\n\n```", "```py\n> credit_cost <- C5.0(credit_train[-17], credit_train$default,\n costs = error_cost)\n> credit_cost_pred <- predict(credit_cost, credit_test)\n> CrossTable(credit_test$default, credit_cost_pred,\n prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,\n dnn = c('actual default', 'predicted default'))\n\n```", "```py\n> mushrooms <- read.csv(\"mushrooms.csv\", stringsAsFactors = TRUE)\n\n```", "```py\n$ veil_type : Factor w/ 1 level \"partial\": 1 1 1 1 1 1 ...\n\n```", "```py\n> mushrooms$veil_type <- NULL\n\n```", "```py\n> table(mushrooms$type)\n edible poisonous \n 4208      3916\n\n```", "```py\n> mushroom_1R <- OneR(type ~ ., data = mushrooms)\n\n```", "```py\n> mushroom_1R\n\nodor:\n almond  -> edible\n anise  -> edible\n creosote  -> poisonous\n fishy  -> poisonous\n foul  -> poisonous\n musty  -> poisonous\n none  -> edible\n pungent  -> poisonous\n spicy  -> poisonous\n(8004/8124 instances correct)\n\n```", "```py\n> summary(mushroom_1R)\n\n=== Summary ===\nCorrectly Classified Instances        8004  98.5229 %\nIncorrectly Classified Instances       120  1.4771 %\nKappa statistic                          0.9704\nMean absolute error                      0.0148\nRoot mean squared error                  0.1215\nRelative absolute error                  2.958  %\nRoot relative squared error             24.323  %\nCoverage of cases (0.95 level)          98.5229 %\nMean rel. region size (0.95 level)      50      %\nTotal Number of Instances             8124 \n\n=== Confusion Matrix ===\n a    b   <-- classified as\n 4208    0 |    a = edible\n 120 3796 |    b = poisonous\n\n```", "```py\n> mushroom_JRip <- JRip(type ~ ., data = mushrooms)\n\n```", "```py\n> mushroom_JRip\n\nJRIP rules:\n===========\n(odor = foul) => type=poisonous (2160.0/0.0)\n(gill_size = narrow) and (gill_color = buff) => type=poisonous (1152.0/0.0)\n(gill_size = narrow) and (odor = pungent) => type=poisonous (256.0/0.0)\n(odor = creosote) => type=poisonous (192.0/0.0)\n(spore_print_color = green) => type=poisonous (72.0/0.0)\n(stalk_surface_below_ring = scaly) and (stalk_surface_above_ring = silky) => type=poisonous (68.0/0.0)\n(habitat = leaves) and (cap_color = white) => type=poisonous (8.0/0.0)\n(stalk_color_above_ring = yellow) => type=poisonous (8.0/0.0)\n => type=edible (4208.0/0.0)\nNumber of Rules : 9\n\n```"]