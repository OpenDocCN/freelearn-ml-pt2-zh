<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer028">
			<h1 id="_idParaDest-15"><a id="_idTextAnchor013"/>Chapter 1: Introducing Amazon SageMaker</h1>
			<p><strong class="bold">Machine learning</strong> (<strong class="bold">ML</strong>) practitioners use a large collection of tools in the course of their projects: open source libraries, deep learning frameworks, and more. In addition, they often have to write their own tools for automation and orchestration. Managing these tools and their underlying infrastructure is time-consuming and error-prone. </p>
			<p>This is the very problem that Amazon SageMaker was designed to address (<a href="https://aws.amazon.com/sagemaker/">https://aws.amazon.com/sagemaker/</a>). Amazon SageMaker is a fully managed service that helps you quickly build and deploy machine learning models. Whether you're just beginning with machine learning or you're an experienced practitioner, you'll find SageMaker features to improve the agility of your workflows, as well as the performance of your models. You'll be able to focus 100% on the machine learning problem at hand, without spending any time installing, managing, and scaling machine learning tools and infrastructure.</p>
			<p>In this first chapter, we're going to learn what the main capabilities of SageMaker are, how they help solve pain points faced by machine learning practitioners, and how to set up SageMaker. This chapter will comprise the following topics:</p>
			<ul>
				<li>Exploring the capabilities of Amazon SageMaker</li>
				<li>Setting up Amazon SageMaker on your local machine</li>
				<li>Setting up Amazon SageMaker Studio</li>
				<li>Deploying one-click solutions and models with Amazon SageMaker JumpStart</li>
			</ul>
			<h1 id="_idParaDest-16"><a id="_idTextAnchor014"/>Technical requirements</h1>
			<p>You will need an AWS account to run the examples included in this chapter. If you haven't got one already, please point your browser to <a href="https://aws.amazon.com/getting-started/">https://aws.amazon.com/getting-started/</a> to learn about AWS and its core concepts, and to create an AWS account. You should also familiarize yourself with the AWS Free Tier (<a href="https://aws.amazon.com/free/">https://aws.amazon.com/free/</a>), which lets you use many AWS services for free within certain usage limits.</p>
			<p>You will need to install and configure the AWS CLI for your account (<a href="https://aws.amazon.com/cli/">https://aws.amazon.com/cli/</a>).</p>
			<p>You will need a working Python 3.x environment. Installing the Anaconda distribution (<a href="https://www.anaconda.com/">https://www.anaconda.com/</a>) is not mandatory but is strongly encouraged as it includes many projects that we will need (Jupyter, <strong class="source-inline">pandas</strong>, <strong class="source-inline">numpy</strong>, and more).</p>
			<p>Code examples included in the book are available on GitHub at <a href="https://github.com/PacktPublishing/Learn-Amazon-SageMaker-second-edition">https://github.com/PacktPublishing/Learn-Amazon-SageMaker-second-edition</a>. You will need to install a Git client to access them (<a href="https://git-scm.com/">https://git-scm.com/</a>). </p>
			<h1 id="_idParaDest-17"><a id="_idTextAnchor015"/>Exploring the capabilities of Amazon SageMaker</h1>
			<p>Amazon SageMaker was launched at AWS re:Invent 2017. Since<a id="_idIndexMarker000"/> then, a lot of new features have been added: you can see the full (and ever-growing) list at <a href="https://aws.amazon.com/about-aws/whats-new/machine-learning">https://aws.amazon.com/about-aws/whats-new/machine-learning</a>. </p>
			<p>In this section, you'll learn about the main capabilities of Amazon SageMaker and its purpose. Don't worry, we'll dive deep into each of them in later chapters. We will also talk about the SageMaker <strong class="bold">Application</strong> <strong class="bold">Programming</strong> <strong class="bold">Interfaces</strong> (<strong class="bold">APIs</strong>), and the <strong class="bold">Software</strong> <strong class="bold">Development</strong> <strong class="bold">Kits</strong> (<strong class="bold">SDKs</strong>) that implement them.</p>
			<h2 id="_idParaDest-18"><a id="_idTextAnchor016"/>The main capabilities of Amazon SageMaker</h2>
			<p>At the core of<a id="_idIndexMarker001"/> Amazon SageMaker is the ability to prepare, build, train, optimize, and deploy models on fully managed infrastructure at any scale. This lets you focus on studying and solving the machine learning problem at hand, instead of spending time and resources on building and managing infrastructure. Simply put, you can go from building to training to deploying more quickly. Let's zoom in on each step and highlight relevant SageMaker capabilities.</p>
			<h3>Preparing</h3>
			<p>Amazon SageMaker includes powerful tools to label and prepare datasets:</p>
			<ul>
				<li><strong class="bold">Amazon SageMaker Ground Truth</strong>: Annotate <a id="_idIndexMarker002"/>datasets at any scale. Workflows for popular use cases are built in (image detection, entity extraction, and more), and you can implement your own. Annotation jobs can be distributed to workers that belong to private, third-party, or public workforces.</li>
				<li><strong class="bold">Amazon SageMaker Processing</strong>: Run batch jobs for data processing (and other tasks such as model evaluation) using your own code written with scikit-learn or Spark.</li>
				<li><strong class="bold">Amazon SageMaker Data Wrangler</strong>: Using a graphical interface, apply hundreds of built-in transforms (or your own) to tabular datasets, and export them in one click to a Jupyter notebook.</li>
				<li><strong class="bold">Amazon SageMaker Feature Store</strong>: Store your engineered features offline in Amazon S3 to build datasets, or online to use them at prediction time.</li>
				<li><strong class="bold">Amazon SageMaker Clarify</strong>: Using a variety of statistical metrics, analyze potential bias present in your datasets and models, and explain how your models predict.</li>
			</ul>
			<h3>Building</h3>
			<p>Amazon SageMaker provides you with two <a id="_idIndexMarker003"/>development environments: </p>
			<ul>
				<li><strong class="bold">Notebook instances</strong>: Fully managed Amazon EC2 instances that come preinstalled with the most popular tools<a id="_idIndexMarker004"/> and libraries: Jupyter, Anaconda, and so on. </li>
				<li><strong class="bold">Amazon SageMaker Studio</strong>: An end-to-end integrated <a id="_idIndexMarker005"/>development environment for machine learning projects, providing an intuitive graphical interface for many SageMaker capabilities. Studio is now the preferred way to run notebooks, and we recommend that you use it instead of notebook instances.</li>
			</ul>
			<p>When it comes to experimenting with algorithms, you can choose from the following:</p>
			<ul>
				<li>A collection of 17 <strong class="bold">built-in algorithms</strong> for machine<a id="_idIndexMarker006"/> learning and deep learning, already implemented and optimized to run efficiently on AWS. No Machine learning code to write!</li>
				<li>A collection of built-in, open source frameworks (<strong class="bold">TensorFlow</strong>, <strong class="bold">PyTorch</strong>, <strong class="bold">Apache MXNet</strong>, <strong class="bold">scikit-learn</strong>, and more), where you simply bring your own code.</li>
				<li>Your own code running in your own container: custom Python, R, C++, Java, and so on.</li>
				<li>Algorithms and pre-trained models from AWS Marketplace for machine learning (<a href="https://aws.amazon.com/marketplace/solutions/machine-learning">https://aws.amazon.com/marketplace/solutions/machine-learning</a>).</li>
				<li>Machine learning solutions and state-of-the-art models available in one click in <strong class="bold">Amazon SageMaker JumpStart</strong>.</li>
			</ul>
			<p>In addition, <strong class="bold">Amazon SageMaker Autopilot</strong> uses AutoMachine learning to <a id="_idIndexMarker007"/>automatically build, train, and optimize models without the need to write a single line of Machine learning code.</p>
			<h3>Training</h3>
			<p>As mentioned earlier, Amazon SageMaker takes care of provisioning and managing your training infrastructure. You'll never <a id="_idIndexMarker008"/>spend any time managing servers, and you'll be able to focus on machine learning instead. On top of this, SageMaker <a id="_idIndexMarker009"/>brings advanced capabilities such as the following:</p>
			<ul>
				<li><strong class="bold">Managed storage</strong> using either Amazon S3, Amazon EFS, or Amazon FSx for Lustre depending on your performance requirements.</li>
				<li><strong class="bold">Managed spot training</strong>, using Amazon EC2 Spot instances for training in order to reduce costs by up to 80%.</li>
				<li><strong class="bold">Distributed training</strong> automatically distributes large-scale training jobs on a cluster of managed instances, using advanced techniques such as data parallelism and model parallelism.</li>
				<li><strong class="bold">Pipe mode</strong> streams infinitely large datasets from Amazon S3 to the training instances, saving the need to copy data around.</li>
				<li><strong class="bold">Automatic model tuning</strong> runs hyperparameter optimization to deliver high-accuracy models more quickly. </li>
				<li><strong class="bold">Amazon SageMaker Experiments</strong> easily tracks, organizes, and compares all your SageMaker jobs.</li>
				<li><strong class="bold">Amazon SageMaker Debugger</strong> captures the internal model state during training, inspects it to observe how the model learns, detects unwanted conditions that hurt accuracy, and profiles the performance of your training job.</li>
			</ul>
			<h3>Deploying</h3>
			<p>Just as with training, Amazon <a id="_idIndexMarker010"/>SageMaker takes care of all your deployment infrastructure, and brings a slew of additional features:</p>
			<ul>
				<li><strong class="bold">Real-time endpoints</strong> create an HTTPS API that serves predictions from your model. As you would expect, autoscaling is available.</li>
				<li><strong class="bold">Batch transform</strong> uses <a id="_idIndexMarker011"/>a model to predict data in batch mode.</li>
				<li><strong class="bold">Amazon Elastic Inference</strong> adds fractional GPU acceleration to CPU-based endpoints to find the best cost/performance ratio for your prediction infrastructure.</li>
				<li><strong class="bold">Amazon SageMaker Model Monitor</strong> captures data sent to an endpoint and compares it with a baseline to identify and alert on data quality issues (missing features, data drift, and more).</li>
				<li><strong class="bold">Amazon SageMaker Neo</strong> compiles models for a specific hardware architecture, including embedded platforms, and deploys an optimized version using a lightweight runtime.</li>
				<li><strong class="bold">Amazon SageMaker Edge Manager</strong> helps you deploy and manage your models on edge devices.</li>
				<li>Last but not least, <strong class="bold">Amazon SageMaker Pipelines</strong> lets you build end-to-end automated pipelines to run and manage your data preparation, training, and deployment workloads.</li>
			</ul>
			<h2 id="_idParaDest-19"><a id="_idTextAnchor017"/>The Amazon SageMaker API </h2>
			<p>Just like all other AWS services, Amazon<a id="_idIndexMarker012"/> SageMaker is driven by APIs that are implemented in the language SDKs supported by AWS (<a href="https://aws.amazon.com/tools/">https://aws.amazon.com/tools/</a>). In addition, a<a id="_idIndexMarker013"/> dedicated Python SDK, aka the SageMaker SDK is also available. Let's look at both, and discuss their respective benefits.</p>
			<h3>The AWS language SDKs </h3>
			<p>Language SDKs implement service-specific<a id="_idIndexMarker014"/> APIs for all AWS<a id="_idIndexMarker015"/> services: S3, EC2, and so on. Of course, they also include SageMaker APIs, which are documented here: <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/api-and-sdk-reference.html">https://docs.aws.amazon.com/sagemaker/latest/dg/api-and-sdk-reference.htma</a>chine learning.</p>
			<p>When it comes to data science <a id="_idIndexMarker016"/>and machine learning, Python is the most popular language, so let's take a look at the SageMaker APIs available in <strong class="source-inline">boto3</strong>, the AWS SDK for the Python language (<a href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html">https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.htma</a>chine learning). These APIs are quite low-level and verbose: for example, <strong class="source-inline">create_training_job()</strong> has a lot of JSON parameters that don't look very obvious. You can see some of them in the<a id="_idIndexMarker017"/> next screenshot. You may<a id="_idIndexMarker018"/> think that this doesn't look very appealing for everyday Machine learning experimentation… and I would totally agree! </p>
			<div>
				<div id="_idContainer005" class="IMG---Figure">
					<img src="Images/B17705_01_001.jpg" alt="Figure 1.1 – A (partial) view of the create_training_job() API in boto3&#13;&#10;" width="670" height="747"/>
				</div>
			</div>
			<p class="figure-caption">Figure 1.1 – A (partial) view of the create_training_job() API in boto3</p>
			<p>Indeed, these service-level APIs are not meant to be used for experimentation in notebooks. Their purpose is automation, through either bespoke scripts or Infrastructure as Code tools such as<a id="_idIndexMarker019"/> AWS CloudFormation (<a href="https://aws.amazon.com/cloudformation">https://aws.amazon.com/cloudformation</a>) and Terraform (<a href="https://terraform.io">https://terraform.io</a>). Your DevOps team will use them to <a id="_idIndexMarker020"/>manage production, where they do need full control over each possible parameter.</p>
			<p>So, what should you use for<a id="_idIndexMarker021"/> experimentation? You should use the Amazon SageMaker SDK.</p>
			<h3>The Amazon SageMaker SDK </h3>
			<p>The Amazon<a id="_idIndexMarker022"/> SageMaker SDK (<a href="https://github.com/aws/sagemaker-python-sdk">https://github.com/aws/sagemaker-python-sdk</a>) is a Python<a id="_idIndexMarker023"/> SDK specific to Amazon SageMaker. You can find its documentation at <a href="https://sagemaker.readthedocs.io/en/stable/">https://sagemaker.readthedocs.io/en/stable/</a>. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">Every effort has been made to check the code examples<a id="_idIndexMarker024"/> in this book with the latest SageMaker SDK (v2.58.0 at the time of writing).</p>
			<p>Here, the abstraction level is much higher: the SDK contains objects for models, estimators, models, predictors, and so on. We're definitely back in Machine learning territory.</p>
			<p>For instance, this SDK makes it extremely easy and comfortable to fire up a training job (one line of code) and to deploy a model (one line of code). Infrastructure concerns are abstracted away, and we can focus on Machine learning instead. Here's an example. Don't worry about the details for now:</p>
			<p class="source-code"># Configure the training job</p>
			<p class="source-code">my_estimator = TensorFlow(</p>
			<p class="source-code">    entry_point='my_script.py',</p>
			<p class="source-code">    role=my_sagemaker_role,</p>
			<p class="source-code">    train_instance_type='machine learning.p3.2xlarge',</p>
			<p class="source-code">    instance_count=1,</p>
			<p class="source-code">    framework_version='2.1.0')</p>
			<p class="source-code"># Train the model</p>
			<p class="source-code">my_estimator.fit('s3://my_bucket/my_training_data/')</p>
			<p class="source-code"># Deploy the model to an HTTPS endpoint</p>
			<p class="source-code">my_predictor = my_estimator.deploy(</p>
			<p class="source-code">    initial_instance_count=1, </p>
			<p class="source-code">    instance_type='machine learning.c5.2xlarge')</p>
			<p>Now that we know a little more about<a id="_idIndexMarker025"/> Amazon SageMaker, let's see how we can set it up.</p>
			<h1 id="_idParaDest-20"><a id="_idTextAnchor018"/>Setting up Amazon SageMaker on your local machine</h1>
			<p>A common<a id="_idIndexMarker026"/> misconception is that you can't use SageMaker outside of the AWS cloud. Obviously, it is a cloud-based service, and its most appealing capabilities require cloud infrastructure to run. However, many developers like to set up their development environment their own way, and SageMaker lets them do that: in this section, you will learn how to install the SageMaker SDK on your local machine or on a local server. In later chapters, you'll learn how to train and deploy models locally.</p>
			<p>It's good practice to isolate Python environments in order to avoid dependency hell. Let's see how we can achieve this using two<a id="_idIndexMarker027"/> popular projects: <strong class="source-inline">virtualenv</strong> (<a href="https://virtualenv.pypa.io">https://virtualenv.pypa.io</a>) and Anaconda (<a href="https://www.anaconda.com/">https://www.anaconda.com/</a>). </p>
			<h2 id="_idParaDest-21"><a id="_idTextAnchor019"/>Installing the SageMaker SDK with virtualenv</h2>
			<p>If you've<a id="_idIndexMarker028"/> never worked with <strong class="source-inline">virtualenv</strong> before, please<a id="_idIndexMarker029"/> read this tutorial before proceeding: <a href="https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/">https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/</a>:</p>
			<ol>
				<li>First, let's create a new environment named <strong class="source-inline">sagemaker</strong> and activate it:<p class="source-code"><strong class="bold">$ mkdir workdir</strong></p><p class="source-code"><strong class="bold">$ cd workdir</strong></p><p class="source-code"><strong class="bold">$ python3 -m venv sagemaker</strong></p><p class="source-code"><strong class="bold">$ source sagemaker/bin/activate</strong></p></li>
				<li>Now, let's install <strong class="source-inline">boto3</strong>, the <a id="_idIndexMarker030"/>SageMaker SDK, and the <strong class="source-inline">pandas</strong> library (<a href="https://pandas.pydata.org/">https://pandas.pydata.org/</a>), which is also required:<p class="source-code"><strong class="bold">$ pip3 install boto3 sagemaker pandas</strong></p></li>
				<li>Now, let's quickly check that we can import these SDKs into Python:<p class="source-code"><strong class="bold">$ python3</strong></p><p class="source-code"><strong class="bold">Python 3.9.5 (default, May  4 2021, 03:29:30)</strong></p><p class="source-code"><strong class="bold">&gt;&gt;&gt; import boto3</strong></p><p class="source-code"><strong class="bold">&gt;&gt;&gt; import sagemaker</strong></p><p class="source-code"><strong class="bold">&gt;&gt;&gt; print(boto3.__version__)</strong></p><p class="source-code"><strong class="bold">1.17.70</strong></p><p class="source-code"><strong class="bold">&gt;&gt;&gt; print(sagemaker.__version__)</strong></p><p class="source-code"><strong class="bold">2.39.1</strong></p><p class="source-code"><strong class="bold">&gt;&gt;&gt; exit()</strong></p></li>
			</ol>
			<p>The installation looks fine. Your own versions will certainly be newer and that's fine. Now, let's run a quick test with a local Jupyter server (<a href="https://jupyter.org/">https://jupyter.org/</a>). If Jupyter isn't installed on your machine, you can<a id="_idIndexMarker031"/> find instructions at <a href="https://jupyter.org/install">https://jupyter.org/install</a>:</p>
			<ol>
				<li value="1">First, let's create a Jupyter kernel based on our virtual environment:<p class="source-code"><strong class="bold">$ pip3 install jupyter ipykernel</strong></p><p class="source-code"><strong class="bold">$ python3 -m ipykernel install --user --name=sagemaker</strong></p></li>
				<li>Then, we can launch Jupyter:<p class="source-code"><strong class="bold">$ jupyter notebook</strong></p></li>
				<li>Creating a new notebook, we can <a id="_idIndexMarker032"/>see that the <strong class="source-inline">sagemaker</strong> kernel is available, so let's select it in the <strong class="bold">New</strong> menu, as seen in<a id="_idIndexMarker033"/> the following screenshot:<div id="_idContainer006" class="IMG---Figure"><img src="Images/B17705_01_002.jpg" alt="Figure 1.2 – Creating a new notebook&#13;&#10;" width="654" height="341"/></div><p class="figure-caption">Figure 1.2 – Creating a new notebook</p></li>
				<li>Finally, we can check that the SDKs are available by importing them and printing their version, as shown in the following screenshot:</li>
			</ol>
			<div>
				<div id="_idContainer007" class="IMG---Figure">
					<img src="Images/B17705_01_003.jpg" alt="Figure 1.3 – Checking the SDK version&#13;&#10;" width="1085" height="548"/>
				</div>
			</div>
			<p class="figure-caption">Figure 1.3 – Checking the SDK version</p>
			<p>This completes<a id="_idIndexMarker034"/> the installation with <strong class="source-inline">virtualenv</strong>. Don't forget to<a id="_idIndexMarker035"/> terminate Jupyter, and to deactivate your <strong class="source-inline">virtualenv</strong>:</p>
			<p class="source-code">$ deactivate</p>
			<p>You can also install the SDK using Anaconda.</p>
			<h2 id="_idParaDest-22"><a id="_idTextAnchor020"/>Installing the SageMaker SDK with Anaconda </h2>
			<p><strong class="bold">Anaconda</strong> includes a package<a id="_idIndexMarker036"/> manager named <strong class="source-inline">conda</strong> that lets you create<a id="_idIndexMarker037"/> and manage isolated environments. If you've never worked with <strong class="source-inline">conda</strong> before, you should do the following:</p>
			<ul>
				<li>Install<a id="_idIndexMarker038"/> Anaconda: <a href="https://docs.anaconda.com/anaconda/install/">https://docs.anaconda.com/anaconda/install/</a>.</li>
				<li>Read this tutorial: <a href="https://docs.conda.io/projects/conda/en/latest/user-guide/getting-started.html">https://docs.conda.io/projects/conda/en/latest/user-guide/getting-started.htma</a>chine learning.</li>
			</ul>
			<p>We will get started using the following steps:</p>
			<ol>
				<li value="1">Let's create and activate a new <strong class="source-inline">conda</strong> environment named <strong class="source-inline">conda-sagemaker</strong>:<p class="source-code"><strong class="bold">$ conda create -y -n conda-sagemaker</strong></p><p class="source-code"><strong class="bold">$ conda activate conda-sagemaker</strong></p></li>
				<li>Then, we install <strong class="source-inline">pandas</strong>, <strong class="source-inline">boto3</strong>, and the SageMaker SDK. The latter has to be installed with <strong class="source-inline">pip</strong> as it's not available as a <strong class="source-inline">conda</strong> package:<p class="source-code"><strong class="bold">$ conda install -y boto3 pandas</strong></p><p class="source-code"><strong class="bold">$ pip3 install sagemaker</strong></p></li>
				<li>Now, let's add Jupyter and its dependencies to the environment, and create a new kernel:<p class="source-code"><strong class="bold">$ conda install -y jupyter ipykernel</strong></p><p class="source-code"><strong class="bold">$ python3 -m ipykernel install --user --name conda-sagemaker</strong></p></li>
				<li>Then, we can launch Jupyter:<p class="source-code"><strong class="bold">$ jupyter notebook</strong></p><p>Check that the <strong class="source-inline">conda-sagemaker</strong> kernel is present in the <strong class="bold">New</strong> menu, as is<a id="_idIndexMarker039"/> visible in the following screenshot:</p><div id="_idContainer008" class="IMG---Figure"><img src="Images/B17705_01_004.jpg" alt="Figure 1.4 – Creating a new conda environment&#13;&#10;" width="747" height="363"/></div><p class="figure-caption">Figure 1.4 – Creating a new conda environment</p></li>
				<li>Just like in the previous section, we can create a notebook using this kernel and check that the SDKs are imported correctly.</li>
			</ol>
			<p>This completes the installation with <strong class="source-inline">conda</strong>. Whether you'd rather use it instead of <strong class="source-inline">virtualenv</strong> is largely a matter of personal preference. You can definitely run all notebooks in this book and build your<a id="_idIndexMarker040"/> own projects with <a id="_idIndexMarker041"/>one or the other.</p>
			<h2 id="_idParaDest-23"><a id="_idTextAnchor021"/>A word about AWS permissions</h2>
			<p><strong class="bold">Amazon Identity and Access Management</strong> (IAM) enables <a id="_idIndexMarker042"/>you to manage access to AWS services and resources<a id="_idIndexMarker043"/> securely (<a href="https://aws.amazon.com/iam">https://aws.amazon.com/iam</a>). Of course, this applies to Amazon SageMaker as well, and you need to make sure that your AWS user has sufficient permissions to invoke the SageMaker API. </p>
			<p class="callout-heading">IAM permissions</p>
			<p class="callout">If you're not familiar with IAM at all, please read the following documentation:</p>
			<p class="callout"><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.html">https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.htma</a>chine learning</p>
			<p>You can run a quick test by using the AWS CLI on one of the SageMaker APIs, for example, <strong class="source-inline">list-endpoints</strong>. I'm using the <strong class="source-inline">eu-west-1</strong> region here, but feel free to use the region that is nearest to you:</p>
			<p class="source-code">$ aws sagemaker list-endpoints --region eu-west-1</p>
			<p class="source-code">{</p>
			<p class="source-code">    "Endpoints": []</p>
			<p class="source-code">}</p>
			<p>If you get an error message complaining about insufficient permissions, you need to update the IAM role attached to your AWS user. </p>
			<p>If you own the AWS account in question, you can easily do this yourself in the IAM console by adding the <strong class="source-inline">AmazonSageMakerFullAccess</strong> managed policy to your role. Note that this policy is extremely permissive: this is fine for a development account, but certainly not for a production account.</p>
			<p>If you work with an <a id="_idIndexMarker044"/>account where you don't have administrative rights (such as a company-provided account), please contact your IT administrator to add SageMaker permissions to your AWS user.</p>
			<p>For more information on<a id="_idIndexMarker045"/> SageMaker permissions, please refer to the documentation: <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/security-iam.html">https://docs.aws.amazon.com/sagemaker/latest/dg/security-iam.htma</a>chine learning. </p>
			<h1 id="_idParaDest-24"><a id="_idTextAnchor022"/>Setting up Amazon SageMaker Studio</h1>
			<p>Experimentation is a key part<a id="_idIndexMarker046"/> of the Machine learning process. Developers and data scientists use a collection of open source tools and libraries for data exploration, data processing, and, of course, to evaluate candidate algorithms. Installing and maintaining these tools takes a fair amount of time, which would probably be better spent on studying the Machine learning problem itself!</p>
			<p>Amazon SageMaker Studio brings you the machine learning tools you need from experimentation to production. At its core is an integrated development environment based on Jupyter that makes it instantly familiar. </p>
			<p>In addition, SageMaker Studio is integrated with other SageMaker capabilities, such as SageMaker Experiments to track and compare all jobs, SageMaker Autopilot to automatically create machine learning models, and more. A lot of operations can be achieved in just a few clicks, without having to write any code. </p>
			<p>SageMaker Studio also further simplifies infrastructure management. You won't have to create notebook instances: SageMaker Studio provides you with compute environments that are readily available to run <a id="_idIndexMarker047"/>your notebooks.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">This section requires basic knowledge of Amazon S3, Amazon VPC, and Amazon IAM. If you're not familiar with them at all, please read the following documentation:</p>
			<p class="callout"><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.htma</a>chine learning</p>
			<p class="callout"><a href="https://docs.aws.amazon.com/vpc/latest/userguide/what-is-amazon-vpc.html">https://docs.aws.amazon.com/vpc/latest/userguide/what-is-amazon-vpc.htma</a>chine learning</p>
			<p class="callout"><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.html">https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.htma</a>chine learning</p>
			<p class="callout">Now would also probably be a good time to take a look at (and bookmark) the SageMaker pricing page: <a href="https://aws.amazon.com/sagemaker/pricing/">https://aws.amazon.com/sagemaker/pricing/</a>.</p>
			<h2 id="_idParaDest-25"><a id="_idTextAnchor023"/>Onboarding to Amazon SageMaker Studio</h2>
			<p>You can access SageMaker <a id="_idIndexMarker048"/>Studio using any of these three options:</p>
			<ul>
				<li><strong class="bold">Use the quick start procedure</strong>: This is the easiest option for individual accounts, and we'll walk through it in the following paragraphs.</li>
				<li><strong class="bold">Use</strong> <strong class="bold">AWS Single Sign-On</strong> (<strong class="bold">SSO</strong>): If your <a id="_idIndexMarker049"/>company has an SSO application set up, this is probably the best option. You can learn more about SSO onboarding at <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/onboard-sso-users.html">https://docs.aws.amazon.com/sagemaker/latest/dg/onboard-sso-users.htma</a>chine learning. Please contact your IT administrator for details.</li>
				<li><strong class="bold">Use Amazon IAM</strong>: If your company doesn't use SSO, this is probably the best option. You can learn<a id="_idIndexMarker050"/> more about SSO onboarding at <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/onboard-iam.html">https://docs.aws.amazon.com/sagemaker/latest/dg/onboard-iam.htma</a>chine learning. Again, please contact your IT administrator for details.</li>
			</ul>
			<h2 id="_idParaDest-26"><a id="_idTextAnchor024"/>Onboarding with the quick start procedure</h2>
			<p>There are several steps to the quick start procedure:</p>
			<ol>
				<li value="1">First, open the <a id="_idIndexMarker051"/>AWS Console in one of the regions where Amazon SageMaker Studio is <a id="_idIndexMarker052"/>available, for example, <a href="https://us-east-2.console.aws.amazon.com/sagemaker/">https://us-east-2.console.aws.amazon.com/sagemaker/</a>.</li>
				<li>As shown in the following screenshot, the left-hand vertical panel has a link to <strong class="bold">SageMaker Studio</strong>:<div id="_idContainer009" class="IMG---Figure"><img src="Images/B17705_01_005.jpg" alt="Figure 1.5 – Opening SageMaker Studio&#13;&#10;" width="984" height="310"/></div><p class="figure-caption">Figure 1.5 – Opening SageMaker Studio</p></li>
				<li>Clicking on this link opens<a id="_idIndexMarker053"/> the onboarding screen, and you can see its first section in the next screenshot:<div id="_idContainer010" class="IMG---Figure"><img src="Images/B17705_01_006.jpg" alt="Figure 1.6 – Running Quick start&#13;&#10;" width="922" height="487"/></div><p class="figure-caption">Figure 1.6 – Running Quick start</p></li>
				<li>Let's select <strong class="bold">Quick start</strong>. Then, we<a id="_idIndexMarker054"/> enter the username we'd like to use to log in to SageMaker Studio, and we create a new IAM role as shown in the preceding screenshot. This opens the following screen:<div id="_idContainer011" class="IMG---Figure"><img src="Images/B17705_01_007.jpg" alt="Figure 1.7 – Creating an IAM role&#13;&#10;" width="840" height="608"/></div><p class="figure-caption">Figure 1.7 – Creating an IAM role</p><p>The only decision we have to make here is<a id="_idIndexMarker055"/> whether we want to allow our notebook instance to access specific Amazon S3 buckets. Let's select <strong class="bold">Any S3 bucket</strong> and click on <strong class="bold">Create role</strong>. This is the most flexible setting for development and testing, but we'd want to apply much stricter settings for production. Of course, we can edit this role later on in the IAM console, or create a new one.</p></li>
				<li>Once we've clicked on <strong class="bold">Create role</strong>, we're back to the previous screen. Please make sure that project templates and JumpStart are enabled for this account. (this should be the default setting).</li>
				<li>We just have to click on <strong class="bold">Submit</strong> to launch the onboarding procedure. Depending on your account setup, you may get an extra screen asking you to select a VPC and a subnet. I'd recommend selecting any subnet in your default VPC.</li>
				<li>A few minutes later, SageMaker Studio<a id="_idIndexMarker056"/> is in service, as shown in the following screenshot. We could add extra users if we needed to, but for now, let's just click on <strong class="bold">Open Studio</strong>:<div id="_idContainer012" class="IMG---Figure"><img src="Images/B17705_01_008.jpg" alt="Figure 1.8 – Launching SageMaker Studio&#13;&#10;" width="909" height="606"/></div><p class="figure-caption">Figure 1.8 – Launching SageMaker Studio</p><p>Don't worry if this takes a few more minutes, as SageMaker Studio needs to complete the first-run setup of your environment. As shown in the following screenshot, once we open SageMaker Studio, we see the familiar JupyterLab layout:</p><p class="callout-heading">Note</p><p class="callout">SageMaker Studio is a living thing. By the time you're reading this, some screens may have been updated. Also, you may notice small differences from one region to the next, as some features or instance types are not available there.</p><div id="_idContainer013" class="IMG---Figure"><img src="Images/B17705_01_009.jpg" alt="Figure 1.9 – SageMaker Studio welcome screen&#13;&#10;" width="1193" height="656"/></div><p class="figure-caption">Figure 1.9 – SageMaker Studio welcome screen</p></li>
				<li>We can immediately create our first notebook. In the <strong class="bold">Launcher</strong> tab, in the <strong class="bold">Notebooks and compute resources</strong> section, let's select <strong class="bold">Data Science</strong>, and click on <strong class="bold">Notebook</strong> – <strong class="bold">Python 3</strong>.</li>
				<li>This opens a notebook, as is <a id="_idIndexMarker057"/>visible in the following screenshot. We first check that SDKs are readily available. As this is the first time we are launching the <strong class="bold">Data Science</strong> kernel, we need to wait for a couple of minutes.<p class="figure-caption"> </p><div id="_idContainer014" class="IMG---Figure"><img src="Images/B17705_01_010.jpg" alt="Figure 1.10 – Checking the SDK version&#13;&#10;" width="982" height="258"/></div><p class="figure-caption">Figure 1.10 – Checking the SDK version</p></li>
				<li>As is visible in the following screenshot, we can easily list resources that are currently running in our Studio instance: an <strong class="bold">machine learning.t3.medium</strong> instance, the data science image supporting the kernel used in our notebook, and the notebook itself:<div id="_idContainer015" class="IMG---Figure"><img src="Images/B17705_01_011.jpg" alt="Figure 1.11 – Viewing Studio resources&#13;&#10;" width="408" height="303"/></div><p class="figure-caption">Figure 1.11 – Viewing Studio resources</p></li>
				<li>To avoid unnecessary costs, we should shut these resources down when we're done working with them. For example, we can shut down the instance and all resources running on it, as you can see in the following screenshot. Don't do it now, we'll need the instance to run the next examples!<div id="_idContainer016" class="IMG---Figure"><img src="Images/B17705_01_012.jpg" alt="Figure 1.12 – Shutting down an instance&#13;&#10;" width="481" height="192"/></div><p class="figure-caption">Figure 1.12 – Shutting down an instance</p></li>
				<li><strong class="bold">Machine learning.t3.medium</strong> is the default instance size that Studio uses. You can switch to other instance types by clicking on <strong class="bold">2 vCPU + 4 GiB</strong> at the top of your notebook. This lets you select a new instance size and launch it in Studio. After a few minutes, the instance is up and your notebook code has been migrated automatically. Don't forget to shut down the previous instance, as explained earlier.</li>
				<li>When we're done working with SageMaker Studio, all we have to do is close the browser tab. If we want to resume working, we just have to go back to the SageMaker console and click on <strong class="bold">Open Studio</strong>. </li>
				<li>If we wanted to shut down the Studio instance itself, we'd simply select <strong class="bold">Shut Down</strong> in the <strong class="bold">File</strong> menu. All files would still be preserved until we deleted Studio completely in the SageMaker console.</li>
			</ol>
			<p>Now that we've completed the setup, I'm sure you're impatient to get started with machine learning. Let's start deploying some models!</p>
			<h1 id="_idParaDest-27"><a id="_idTextAnchor025"/>Deploying one-click solutions and models with Amazon SageMaker JumpStart</h1>
			<p>If you're new to machine learning, you may find it difficult<a id="_idIndexMarker058"/> to get started with real-life projects. You've run all the toy examples, and you've read several blog posts on the state of the models for COMPUTER VISION OR NATURAL LANGUAGE PROCESSING. Now what? How can you start using these complex models on your own data to solve your own business problems?</p>
			<p>Even if you're an experienced<a id="_idIndexMarker059"/> practitioner, building end-to-end machine learning solutions is not an easy task. Training and deploying models<a id="_idIndexMarker060"/> is just part of the equation: what about data preparation, automation, and so on?</p>
			<p><strong class="bold">Amazon SageMaker JumpStart</strong> was specifically built<a id="_idIndexMarker061"/> to help everyone get started more quickly with their<a id="_idIndexMarker062"/> machine learning projects. In literally one click, you can deploy the following:</p>
			<ul>
				<li>16 end-to-end solutions for real-life business problems such as fraud detection in financial transactions, explaining credit decisions, predictive maintenance, and more</li>
				<li>Over 180 TensorFlow and PyTorch models pre-trained on a variety of computer vision and natural language processing tasks</li>
				<li>Additional learning resources, such as sample notebooks, blog posts, and video tutorials</li>
			</ul>
			<p>Time to deploy a solution.</p>
			<h2 id="_idParaDest-28"><a id="_idTextAnchor026"/>Deploying a solution</h2>
			<p>Let's begin:</p>
			<ol>
				<li value="1">Starting from<a id="_idIndexMarker063"/> the icon bar on the left, we open JumpStart. The following screenshot shows the opening screen:<div id="_idContainer017" class="IMG---Figure"><img src="Images/B17705_01_013.jpg" alt="Figure 1.13 – Viewing solutions in JumpStart&#13;&#10;" width="1650" height="599"/></div><p class="figure-caption">Figure 1.13 – Viewing solutions in JumpStart</p></li>
				<li>Select <strong class="bold">Fraud Detection in Financial Transactions</strong>. As can be seen in the following screenshot, this is a fascinating<a id="_idIndexMarker064"/> example that uses graph data and graph neural networks to predict fraudulent activities based on interactions: <div id="_idContainer018" class="IMG---Figure"><img src="Images/B17705_01_014.jpg" alt="Figure 1.14 – Viewing solution details&#13;&#10;" width="1471" height="838"/></div><p class="figure-caption">Figure 1.14 – Viewing solution details</p></li>
				<li>Once we've read the solution details, all we have to do is click on the <strong class="bold">Launch</strong> button. This will run an AWS CloudFormation<a id="_idIndexMarker065"/> template in charge of building all the AWS resources required by the solution.<p class="callout-heading">CloudFormation</p><p class="callout">If you're curious about<a id="_idIndexMarker066"/> CloudFormation, you may find this introduction useful: <a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html">https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.htma</a>chine learning.</p></li>
				<li>A few minutes later, the solution is ready, as can be seen in the following screenshot. We click on <strong class="bold">Open Notebook</strong> to open the first notebook.<div id="_idContainer019" class="IMG---Figure"><img src="Images/B17705_01_015.jpg" alt="Figure 1.15 – Opening a solution&#13;&#10;" width="1049" height="574"/></div><p class="figure-caption">Figure 1.15 – Opening a solution</p></li>
				<li>As you can see in the following screenshot, we can browse solution files in the left-hand pane: notebooks, training code, and so on:<div id="_idContainer020" class="IMG---Figure"><img src="Images/B17705_01_016.jpg" alt="Figure 1.16 – Viewing solution files&#13;&#10;" width="1515" height="481"/></div><p class="figure-caption">Figure 1.16 – Viewing solution files</p></li>
				<li>From then on, you can start running and tweaking the notebook. If you're not familiar with the SageMaker SDK yet, don't worry about the details. </li>
				<li>Once you're done, please go<a id="_idIndexMarker067"/> back to the solution page and click on <strong class="bold">Delete all resources</strong> to clean up and avoid unnecessary costs, as shown in the following screenshot:</li>
			</ol>
			<div>
				<div id="_idContainer021" class="IMG---Figure">
					<img src="Images/B17705_01_017.jpg" alt="Figure 1.17 – Deleting a solution&#13;&#10;" width="1122" height="373"/>
				</div>
			</div>
			<p class="figure-caption">Figure 1.17 – Deleting a solution</p>
			<p>As you can see, JumpStart solutions are a great way to explore how to solve business problems with machine learning and to start thinking about how you could do the same in your own business environment.</p>
			<p>Now, let's see how we can deploy pre-trained models.</p>
			<h2 id="_idParaDest-29"><a id="_idTextAnchor027"/>Deploying a model</h2>
			<p>JumpStart includes over 180 TensorFlow and PyTorch models pre-trained<a id="_idIndexMarker068"/> on a variety of computer vision and natural language processing tasks. Let's take a look at computer vision models:</p>
			<ol>
				<li value="1">Starting from the JumpStart main screen, we open <strong class="bold">Vision models</strong>, as can be seen in the following screenshot:<div id="_idContainer022" class="IMG---Figure"><img src="Images/B17705_01_018.jpg" alt="Figure 1.18 – Viewing computer vision models&#13;&#10;" width="1461" height="686"/></div><p class="figure-caption">Figure 1.18 – Viewing computer vision models</p></li>
				<li>Let's say that we're interested in trying out object detection models based on the <strong class="bold">Single Shot Detector</strong> (<strong class="bold">SSD</strong>) architecture. We click on the <strong class="bold">SSD</strong> model from the PyTorch Hub (the fourth one from the left).</li>
				<li>This opens the model<a id="_idIndexMarker069"/> details page, telling us where the model comes from, what dataset it has been trained on, and which labels it can predict. We can also select which instance type to deploy the model. Sticking to the default, we click on <strong class="bold">Deploy</strong> to deploy the model on a real-time endpoint, as shown in the following screenshot:<div id="_idContainer023" class="IMG---Figure"><img src="Images/B17705_01_019.jpg" alt="Figure 1.19 – Deploying a JumpStart model&#13;&#10;" width="617" height="469"/></div><p class="figure-caption">Figure 1.19 – Deploying a JumpStart model</p></li>
				<li>A few minutes later, the model<a id="_idIndexMarker070"/> has been deployed. As can be seen in the following screenshot, we can see the endpoint status in the left-hand panel, and we simply click on <strong class="bold">Open Notebook</strong> to test it.<div id="_idContainer024" class="IMG---Figure"><img src="Images/B17705_01_020.jpg" alt="Figure 1.20 – Opening a JumpStart notebook&#13;&#10;" width="1041" height="561"/></div><p class="figure-caption">Figure 1.20 – Opening a JumpStart notebook</p></li>
				<li>Clicking through the notebook<a id="_idIndexMarker071"/> cells, we download a test image and we predict which objects it contains. Bounding boxes, classes, and probabilities are visible in the following screenshot:<div id="_idContainer025" class="IMG---Figure"><img src="Images/B17705_01_021.jpg" alt="Figure 1.21 – Detecting objects in a picture&#13;&#10;" width="981" height="656"/></div><p class="figure-caption">Figure 1.21 – Detecting objects in a picture</p></li>
				<li>When you're done, please make sure to delete the endpoint to avoid unnecessary charges: simply click on <strong class="bold">Delete</strong> in the endpoint details screen visible in <em class="italic">Figure 1.20</em>.</li>
			</ol>
			<p>Not only does JumpStart make it extremely easy to experiment with state-of-the-art models, but it also provides you with code that you can readily use in your own projects: loading an image for prediction, predicting with an endpoint, plotting results, and so on. </p>
			<p>As useful as pre-trained models are, we often need to fine-tune them on our own datasets. Let's see how we can do that with JumpStart.</p>
			<h2 id="_idParaDest-30"><a id="_idTextAnchor028"/>Fine-tuning a model</h2>
			<p>Let's use an image classification model this time:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">A word of warning about fine-tuning text models: complex models such as BERT can take a very long time to fine-tune, sometimes several hours per epoch on a single GPU. In addition to the long waiting time, the cost won't be negligible, so I'd recommend avoiding these examples unless you have a real-life business project to work on.</p>
			<ol>
				<li value="1">We select the <strong class="bold">Resnet 18</strong> model (the second from the left in <em class="italic">Figure 1.18</em>).</li>
				<li>On the model<a id="_idIndexMarker072"/> details page, we see that this model can be fine-tuned either<a id="_idIndexMarker073"/> on a default dataset available for testing (a TensorFlow dataset with five flower classes) or on our own dataset stored in S3. Scrolling down, we learn about the format that our dataset should have.</li>
				<li>As visible in the following figure we stick to the default dataset. We also leave the deployment configuration and training parameters unchanged. Then, we click on <strong class="bold">Train</strong> to launch the fine-tuning job.<div id="_idContainer026" class="IMG---Figure"><img src="Images/B17705_01_022.jpg" alt="Figure 1.22 – Fine-tuning a model&#13;&#10;" width="605" height="336"/></div><p class="figure-caption">Figure 1.22 – Fine-tuning a model</p></li>
				<li>After just a few minutes, fine-tuning is complete (which is why I picked this example!). We can see<a id="_idIndexMarker074"/> the output path in S3 where the fine-tuned model has been stored. Let's write down that path; we're going to need it in a minute.<div id="_idContainer027" class="IMG---Figure"><img src="Images/B17705_01_023.jpg" alt="Figure 1.23 – Viewing fine-tuning results&#13;&#10;" width="792" height="381"/></div><p class="figure-caption">Figure 1.23 – Viewing fine-tuning results</p></li>
				<li>Then, we click on <strong class="bold">Deploy</strong> just like in the previous example. Once the model has been deployed, we open the sample notebook showing us how to predict with the initial pre-trained model. </li>
				<li>This notebook uses<a id="_idIndexMarker075"/> images from the original dataset that the model was pre-trained on. No problem, let's adapt it! Even if we're not yet familiar with the SageMaker SDK, the notebook is simple enough that we can understand what's going on, and add a few cells to predict a flower image with our fine-tuned model.</li>
				<li>First, we add a cell to copy the fine-tuned model artifact from S3, and we extract the list of classes and class indexes that JumpStart added:<p class="source-code">%%sh</p><p class="source-code">aws s3 cp s3://sagemaker-REGION_NAME-123456789012/smjs-d-pt-ic-resnet18-20210511-142657/output/model.tar.gz .</p><p class="source-code">tar xfz model.tar.gz</p><p class="source-code">cat class_label_to_prediction_index.json</p><p class="source-code"><strong class="bold">{"daisy": 0, "dandelion": 1, "roses": 2, "sunflowers": 3, "tulips": 4}</strong></p></li>
				<li>As expected, the fine-tuned model can predict five classes. Let's add a cell to download a sunflower image from Wikipedia:<p class="source-code">%%sh</p><p class="source-code">wget https://upload.wikimedia.org/wikipedia/commons/a/a9/A_sunflower.jpg</p></li>
				<li>Now, we load the image and invoke the endpoint:<p class="source-code">import boto3</p><p class="source-code">endpoint_name = 'jumpstart-ftd-pt-ic-resnet18'</p><p class="source-code">client = boto3.client('runtime.sagemaker')</p><p class="source-code">with open('A_sunflower.jpg', 'rb') as file:</p><p class="source-code">    image = file.read()</p><p class="source-code">response = client.invoke_endpoint(</p><p class="source-code">    EndpointName=endpoint_name, </p><p class="source-code">    ContentType='application/x-image',</p><p class="source-code">    Body=image)</p></li>
				<li>Finally, we print<a id="_idIndexMarker076"/> out the predictions. The highest probability is class #3 at 60.67%, confirming that our image contains a sunflower!<p class="source-code">import json</p><p class="source-code">model_predictions = json.loads(response['Body'].read())</p><p class="source-code">print(model_predictions)</p><p class="source-code"><strong class="bold">[0.30362239480018616, 0.06462913751602173, 0.007234351709485054, 0.6067869663238525, 0.017727158963680267]</strong></p></li>
				<li>When you're done testing, please make sure to delete the endpoint to avoid unnecessary charges.</li>
			</ol>
			<p>This example illustrates how easy<a id="_idIndexMarker077"/> it is to fine-tune pre-trained models on your own datasets with SageMaker JumpStart and to use them to predict your own data. This is a great way to experiment with different models and find out which one could work best on the particular problem you're trying to solve.</p>
			<p>This is the end of the first chapter, and it was already quite action-packed, wasn't it? It's now time to review what we've learned.</p>
			<h1 id="_idParaDest-31"><a id="_idTextAnchor029"/>Summary</h1>
			<p>In this chapter, you discovered the main capabilities of Amazon SageMaker, and how they can help solve your machine learning pain points. By providing you with managed infrastructure and pre-installed tools, SageMaker lets you focus on the machine learning problem itself. Thus, you can go more quickly from experimenting with models to deploying them in production.</p>
			<p>Then, you learned how to set up Amazon SageMaker on your local machine and in Amazon SageMaker Studio. The latter is a managed machine learning IDE where many other SageMaker capabilities are just a few clicks away. </p>
			<p>Finally, you learned about Amazon SageMaker JumpStart, a collection of machine learning solutions and state-of-the-art models that you can deploy in one click, and start testing in minutes.</p>
			<p>In the next chapter, we'll see how you can use Amazon SageMaker and other AWS services to prepare your datasets for training.</p>
		</div>
	</div></body></html>