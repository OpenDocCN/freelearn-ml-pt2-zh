<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Manipulating Data with the Pandas Library</h1>
                </header>
            
            <article>
                
<p>In the next few portions of the book, we are going to get our hands dirty by building the various kinds of recommender systems that were introduced in chapter one. However, before we do so, it is important that we know how to handle, manipulate, and analyze data efficiently in Python.</p>
<p>The datasets we'll be working with will be several megabytes in size. Historically, Python has never been well-known for its speed of execution. Therefore, analyzing such huge amounts of data using vanilla Python and the built-in data structures it provides us is simply impossible.</p>
<p>In this chapter, we're going to get ourselves acquainted with the pandas library, which aims to overcome the aforementioned limitations, making data analysis in Python extremely efficient and user-friendly. We'll also introduce ourselves to the <em>Movies Dataset </em>that we're going to use to build our recommenders as well as use pandas to extract some interesting facts and narrate the history of movies using data.</p>
<div class="packt_infobox"><strong>Disclaimer:<br/></strong><span>If you are already familiar with the pandas library, you may skip this chapter and move on to the next, <em>Building an IMDB Top 250 Clone with p</em></span><em>andas</em>.<br/>
<br/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>You will be required to have Python installed on a system. Finally, to use the Git repository of this book, the user needs to install Git.</p>
<p>The code files of this chapter can be found on GitHub:<br/>
<a href="https://github.com/PacktPublishing/Hands-On-Recommendation-Systems-with-Python">https://github.com/PacktPublishing/Hands-On-Recommendation-Systems-with-Python</a><a href="https://github.com/PacktPublishing/Hands-On-Recommendation-Systems-with-Python">.</a></p>
<p>Check out the following video to see the code in action:</p>
<p><a href="http://bit.ly/2LoZEUj">http://bit.ly/2LoZEUj</a><a href="http://bit.ly/2LoZEUj">.</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Setting up the environment</h1>
                </header>
            
            <article>
                
<p>Before we start coding, we should probably set up our development environment. For data scientists and analysts using Python, the Jupyter Notebook is, by far, the most popular tool for development. Therefore, we strongly advise that you use this environment.</p>
<p>We will also need to download the pandas library. The easiest way to obtain both is to download Anaconda. Anaconda is a distribution that comes with the Jupyter software and the SciPy packages (which includes pandas). </p>
<div class="packt_quote packt_tip"><strong><span><br/></span></strong> <span>You can download the distribution here</span><strong><span>: </span></strong><a href="https://www.anaconda.com/download/">https://www.anaconda.com/download/</a>.</div>
<p>The next step is to create a new folder (I'm going to name it <kbd>RecoSys</kbd>) in your desired location. This will be the master folder that contains all the code we write as part of this book. Within this folder, create another folder named <kbd>Chapter2</kbd>, which will contain all the code we write as part of this chapter.</p>
<p>Next, open your Terminal application, navigate to the <kbd>Chapter2</kbd><em> </em>folder, and run the <kbd>jupyter notebook</kbd> command. The commands should look something like this if you're on a Mac or Linux (the cd<em> </em>path will differ in Windows):</p>
<pre><strong>[rounakbanik:~]$</strong> <strong>cd RecoSys/Chapter2</strong><br/><strong>[rounakbanik:~/RecoSys/Chapter2]$ jupyter notebook</strong></pre>
<p class="mce-root"/>
<p>Jupyter Notebooks run on the browser on the localhost. Therefore, they're OS-independent. In other words, the experience will be the same regardless of whether you're on a Mac, a PC, or a Linux box.</p>
<p>Upon running the <kbd>jupyter notebook</kbd><em> </em>command, your default browser should open up to the <kbd>localhost:8888/tree</kbd><em> </em>URL and a window that looks as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/c47502be-6824-45a2-a0a1-712a0b5bf4ea.png" style="width:60.17em;height:37.67em;"/></div>
<p>To the right of the window, you should be able to see a <span class="packt_screen">New</span><em> </em>dropdown. Click it and create a new Python 3 (or Python 2) Notebook. Doing so will open a new tab with an untitled notebook. You'll also be able to see an input cell<em> </em>with a pointer in it. This is space where we write our code (and markdown). Go ahead and type the following lines:</p>
<pre>import pandas as pd<br/>pd.__version__</pre>
<p>To execute the code in this cell, press <em>Shift </em>+ <em>Enter. </em>If all goes well, you should see a new output cell, which prints the version of the pandas library (for us, it is 0.20.3):</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/e403f392-9129-4d5b-aa26-efa72fa65a3a.png" style="width:43.83em;height:11.75em;"/></div>
<p>Congratulations!</p>
<p class="mce-root"/>
<p>You've now successfully set up your development environment. Of course, there is much more to Jupyter Notebooks than running a cell. We will be talking about these other features as and when we use them. Since this is not a book on Jupyter, we will be redirecting you to the free tutorials online if you're interested in learning the fundamentals of the Jupyter Notebook first. DataCamp has a definitive article on the subject. </p>
<div class="packt_tip"><strong><br/></strong> You can find the DataCamp Jupyter Notebook Tutorial here: <a href="https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook">https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook</a>.</div>
<div class="packt_infobox">In case you're having trouble setting up your environment, googling the error should direct you to a page suggesting a suitable solution. Websites such as Stack Overflow have thousands of questions on Anaconda setup and it is extremely likely that the problem you're facing has been faced by someone else before.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Pandas library</h1>
                </header>
            
            <article>
                
<p>Pandas is a package that gives us access to high-performance, easy-to-use tools and data structures for data analysis in Python. </p>
<p>As we stated in the introduction, Python is a slow language. Pandas overcomes this by implementing heavy optimization using the C programming language. It also gives us access to Series and DataFrame, two extremely powerful and user-friendly data structures imported from the R Statistical Package.</p>
<p>Pandas also makes importing data from external files into the Python environment a breeze. It supports a wide variety of formats, such as JSON, CSV, HDF5, SQL, NPY, and XLSX.</p>
<p>As a first step toward working with pandas, let's import our movies data into our Jupyter Notebook. To do this, we need the path to where our dataset is located. This can be a URL on the internet or your local computer. We highly recommend downloading the data to your local computer and accessing it from a local path instead of from a web URL.</p>
<div class="packt_quote packt_infobox">Go to the following URL to download the required CSV file<strong>:</strong> <a href="https://www.kaggle.com/rounakbanik/the-movies-dataset/downloads/movies_metadata.csv/7.">https://www.kaggle.com/rounakbanik/the-movies-dataset/downloads/movies_metadata.csv/7.</a></div>
<p class="mce-root"/>
<p>Create a new folder called <kbd>data</kbd> in the <kbd>RecoSys</kbd> directory and move the <kbd>movies_metadata.csv</kbd> file that you just downloaded into this folder. Now, let's witness some pandas magic. In the Jupyter Notebook you ran in the previous section, go to the second cell and type the following code:</p>
<pre>#Read the CSV File into df<br/>df = pd.read_csv('../data/movies_metadata.csv')<br/><br/>#We will find out what the following code does a little later!<br/>df.head()</pre>
<p>Et voila! You should be able to see a table-like structure with five rows, each row representing a movie. You can also see that the table has 24 columns, although the columns were truncated to fit in the display.</p>
<p>What is this structure though? Let's find out by running the familiar <kbd>type</kbd><em> </em>command:</p>
<pre>#Output the type of df<br/>type(df)</pre>
<p>You should get an output stating that df is a <kbd>pandas.core.frame.DataFrame</kbd><em>. </em>In other words, our code has read the CSV file into a pandas DataFrame object. But what are DataFrames? Let's find that out in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Pandas DataFrame</h1>
                </header>
            
            <article>
                
<p>As we saw in the previous section, the <kbd>df.head()</kbd><em> </em>code outputted a table-like structure. In essence, the DataFrame is just that: a two-dimensional data structure with columns of different data types. You can think of it as an SQL Table. Of course, just being a table of rows and columns isn't what makes the DataFrame special. The DataFrame gives us access to a wide variety of functionality, some of which we're going to explore in this section.</p>
<p>Each row in our DataFrame represents a movie. But how many movies are there? We can find this out by running the following code:</p>
<pre>#Output the shape of df<br/>df.shape<br/><br/><strong>OUTPUT:<br/>(45466, 24)</strong></pre>
<p>The result gives us the number of rows and columns present in df. We can see that we have data on 45,466 movies.</p>
<p>We also see that we have 24 columns. Each column represents a feature or a piece of metadata about the movie. When we ran <kbd>df.head()</kbd><em>, </em>we saw that most of the columns were truncated to fit in the display. To view all the columns (henceforth, called features) we have, we can run the following:</p>
<pre>#Output the columns of df<br/>df.columns<br/><br/><strong>OUTPUT:</strong><br/><br/>Index(['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id',<br/>       'imdb_id', 'original_language', 'original_title', 'overview',<br/>       'popularity', 'poster_path', 'production_companies',<br/>       'production_countries', 'release_date', 'revenue', 'runtime',<br/>       'spoken_languages', 'status', 'tagline', 'title', 'video',<br/>       'vote_average', 'vote_count'],<br/>      dtype='object')</pre>
<p>We see that we have a lot of information on these movies, including their title, budget, genres, release date, and revenue.</p>
<p>Next, let's find out how to access a particular movie (or row). The first way to do this is by using the <kbd>.iloc</kbd><em> </em>method. This allows us to select rows based on the numeric position, starting from zero. For example, if we wanted to access the second movie in the DataFrame, we'd run:</p>
<pre>#Select the second movie in df<br/>second = df.iloc[1]<br/>second</pre>
<p><span>The output will give you information about the movie on each of its 24 features. We see that the title of the movie is </span><em>Jumanji</em> <span>and that it was released on December  15th, 1995, among other things.</span></p>
<div class="packt_infobox">A cell will always print the output of the last line of code. Therefore, we don't need to explicitly write it within a <kbd>print</kbd><em> </em>function.</div>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>The second way to do it is by accessing the DataFrame index. Since we didn't explicitly set an index while reading the CSV file, pandas defaulted it to zero-based indexing. We can change the index of df quite easily. Let's change the index to the title of the movie and try to access <kbd>Jumanji</kbd> using this index:</p>
<pre>#Change the index to the title<br/>df = df.set_index('title')<br/><br/>#Access the movie with title 'Jumanji'<br/>jum = df.loc['Jumanji']<br/>jum</pre>
<p>You should see an output identical to the previous cell. Let's revert back to our zero-based numeric index:</p>
<pre>#Revert back to the previous zero-based indexing<br/>df = df.reset_index()</pre>
<p>It is also possible to create a new, smaller DataFrame with fewer columns. Let's create a new DataFrame that only has the following features: <kbd>title</kbd>, <kbd>release_date</kbd>, <kbd>budget</kbd>, <kbd>revenue</kbd>, <kbd>runtime</kbd>, and <kbd>genres</kbd>:</p>
<pre>#Create a smaller dataframe with a subset of all features<br/>small_df = df[['title', 'release_date', 'budget', 'revenue', 'runtime', 'genres']]<br/><br/>#Output only the first 5 rows of small_df<br/>small_df.head()</pre>
<p>You should see a table with five movies and only the features that we've mentioned. The <kbd>.head()</kbd><em> </em>method simply displays the first five rows of the DataFrame. You can display as many rows as you want by passing it as an argument into <kbd>.head()</kbd><em>:</em></p>
<pre>#Display the first 15 rows<br/>small_df.head(15)</pre>
<p>Next, let's check out the data types of our various features:</p>
<pre class="mce-root">#Get information of the data types of each feature<br/>small_df.info()<br/><br/><strong>OUTPUT:<br/>&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 45466 entries, 0 to 45465<br/>Data columns (total 6 columns):<br/>title 45460 non-null object<br/>release_date 45379 non-null object<br/>budget 45466 non-null object<br/>revenue 45460 non-null float64<br/>runtime 45203 non-null float64<br/>genres 45466 non-null object<br/>dtypes: float64(2), object(4)<br/>memory usage: 2.1+ MB</strong></pre>
<p>A curious observation here is that pandas correctly deciphers <kbd>revenue</kbd><em> </em>and <kbd>runtime</kbd><em> </em>as float data, but assigns the generic object data type to <kbd>budget</kbd><em>. </em></p>
<p>However, pandas allows us to manually convert the data type of a feature. Let's try to convert the <kbd>budget</kbd><em> </em>feature to <kbd>float</kbd>:</p>
<pre>#Convert budget to float<br/>df['budget'] = df['budget'].astype('float')<br/><br/><strong>OUTPUT:<br/></strong>...<br/>...<br/><strong>ValueError: could not convert string to float: '/zaSf5OG7V8X8gqFvly88zDdRm46.jpg'</strong></pre>
<p>Running this cell throws <kbd>ValueError</kbd>. It is easy to guess that one of the budget fields had a <kbd>'/zaSf...'</kbd> string as its value, and pandas was not able to convert this into a floating number.</p>
<p>To solve this problem, we will use the <kbd>apply()</kbd><em> </em>method. This will allow us to apply a function to every field in a particular column and convert it into the return value. We are going to convert every number field in <kbd>budget</kbd><em> </em>to float and, if that fails, convert it to <kbd>NaN</kbd>:</p>
<pre>#Import the numpy library <br/>import numpy as np<br/><br/>#Function to convert to float manually<br/>def to_float(x):<br/>    try:<br/>        x = float(x)<br/>    except: <br/>        x = np.nan<br/>    return x<br/><br/>#Apply the to_float function to all values in the budget column<br/>small_df['budget'] = small_df['budget'].apply(to_float)<br/><br/>#Try converting to float using pandas astype<br/>small_df['budget'] = small_df['budget'].astype('float')<br/><br/>#Get the data types for all features<br/>small_df.info()</pre>
<p>This time around, there are no errors thrown. Also, we notice that the <kbd>budget</kbd><em> </em>feature is now of the <kbd>float64</kbd> type.</p>
<p>Now, let's try to define a new feature, called <kbd>year</kbd>, that represents the year of release. The recommended way to do this would be by using the <kbd>datetime</kbd> functionality that pandas gives us:</p>
<pre>#Convert release_date into pandas datetime format<br/>small_df['release_date'] = pd.to_datetime(small_df['release_date'], errors='coerce')<br/><br/>#Extract year from the datetime<br/>small_df['year'] = small_df['release_date'].apply(lambda x: str(x).split('-')[0] if x != np.nan else np.nan)<br/><br/>#Display the DataFrame with the new 'year' feature<br/>small_df.head()</pre>
<p>What are the oldest movies available in this dataset? To answer this question, we can sort the DataFrame based on the year of release:</p>
<pre>#Sort DataFrame based on release year<br/>small_df = small_df.sort_values('year')<br/><br/>small_df.head()</pre>
<p>We see that we have movies from as early as the 1870s, with <em>Passage of Venus </em>being the oldest movie on record. Next, let's find out the most successful movies of all time. To do this, we'll use the <kbd>sort_values()</kbd><em> </em>method once again, but with an additional <kbd>ascending=False</kbd><em> </em>parameter to sort <kbd>DataFrame</kbd> in descending order:</p>
<pre>#Sort Movies based on revenue (in descending order)<br/>small_df = small_df.sort_values('revenue', ascending=False)<br/><br/>small_df.head()</pre>
<p>From our results, we observe that <em>Avatar </em>is the most successful movie of all time, with a revenue of over $2.78 billion.</p>
<p class="mce-root"/>
<p>Let's say we wanted to create a new DataFrame of movies that satisfied a certain condition. For instance, we only want movies that earned more than $1 billion. Pandas makes this possible using its Boolean Indexing feature. Let's see this in action:</p>
<pre>#Select only those movies which earned more than 1 billion<br/>new = small_df[small_df['revenue'] &gt; 1e9]<br/>new</pre>
<p>It is also possible to apply multiple conditions. For instance, let's say we only wanted movies that earned more than $1 billion, but where the outlay less than $150 million, we'd do it as follows:</p>
<pre>#Select only those movies which earned more than 1 billion and spent less than 150 million<br/><br/>new2 = small_df[(small_df['revenue'] &gt; 1e9) &amp; (small_df['budget'] &lt; 1.5e8)]<br/>new2</pre>
<p>Only four movies make it into this list.</p>
<p>There is, of course, much more to what you can do with DataFrames (such as handling missing data), but we'll stop our exploration with it for now. Let's move on to another data structure we have unknowingly used extensively in this section: the Pandas Series.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Pandas Series</h1>
                </header>
            
            <article>
                
<p>When we accessed the Jumanji<em> </em>movie using <kbd>.loc</kbd><em> </em>and <kbd>.iloc</kbd><em>, </em>the data structures returned to us were Pandas Series objects. You may have also noticed that we were accessing entire columns using <kbd>df[column_name]</kbd><em>. </em>This, too, was a Pandas Series object:</p>
<pre>type(small_df['year'])<br/><br/><strong>OUTPUT:<br/>pandas.core.series.Series</strong></pre>
<p>The Pandas Series is a one-dimensional labelled array capable of holding data of any type. You may think of it as a Python list on steroids. When we were using the <kbd>.apply()</kbd><em> </em>and <kbd>.astype()</kbd><em> </em>methods in the previous section, we were actually using them on these Series objects. </p>
<p>Therefore, like the DataFrame, the Series object comes with its own group of extremely useful methods that make data analysis a breeze. </p>
<p class="mce-root"/>
<p>First, let's check out the shortest- and longest-running movies of all time. We will do this by accessing the <kbd>runtime</kbd><em> </em>column of the DataFrame as a Series object and applying its methods on it:</p>
<pre>#Get the runtime Series object<br/>runtime = small_df['runtime']<br/><br/>#Print the longest runtime of any movie<br/>print(runtime.max())<br/><br/>#Print the shortest runtime of any movie<br/>print(runtime.min())</pre>
<p>We see that the longest movie is more than 1,256 minutes in length and the shortest is 0! Of course, such strange results demand a deeper inspection of the data but we shall skip that, for now.</p>
<p>It is also possible to calculate the mean and median of the Series in this way. Let's do so for the movie budgets:</p>
<pre>#Get the budget Series object<br/>budget = small_df['budget']<br/><br/>#Print the mean budget of the movies<br/>print(budget.mean())<br/><br/>#Print the median budget of the movies<br/>print(budget.median())</pre>
<p>The average budget of a movie is $4.2 million and the median budget is 0! This suggests that at least half the movies in our dataset have no budget at all! Like in the previous case, such strange results demand closer inspection. In this case, it is highly likely that a zero budget indicates that the data is not available.</p>
<p>What is the revenue that the 90th-percentile movie generated? We can discover this using the <kbd>quantile</kbd><em> </em>function:</p>
<pre>#Get the revenue Series object<br/>revenue = small_df['revenue']<br/><br/>#Revenue generated by the 90th percentile movie<br/>revenue.quantile(0.90)</pre>
<p>We get a result of $8.26 million. What this means is that only 10% of the movies in our dataset earned more than $8.26 million in revenue.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Finally, let's find out the number of movies released each year. We do this using the <kbd>value_counts()</kbd><em> </em>method on the <kbd>year</kbd><em> </em>series:</p>
<pre>#Get number of movies released each year<br/>small_df['year'].value_counts()</pre>
<p>We have the highest number of movies released in 2014. There are also six years in our dataset (including 2020) that have only one movie on record.</p>
<p>We'll stop our tour of the pandas library here. As I have already mentioned, there is much more to pandas than what we have covered in this chapter. However, this should be sufficient to tackle the data-wrangling and analysis tasks that we'll encounter while building our recommenders. </p>
<p>You may rename the notebook as <kbd>Chapter2</kbd><em> </em>by clicking on <span class="packt_screen">Untitled</span> and then close it. For the next chapter, we will create a new notebook.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we gained an understanding of the limitations of using vanilla Python and its built-in data structures. We acquainted ourselves with the Pandas library and learned how it overcomes the aforementioned difficulties by giving us access to extremely powerful and easy-to-use data structures. We then explored the two main data structures, Series and DataFrame, by analyzing our movies-metadata dataset. </p>
<p>In the next chapter, we will use our newfound skills to build an IMDB Top 250 Clone and its variant, a type of knowledge-based recommender.</p>


            </article>

            
        </section>
    </body></html>