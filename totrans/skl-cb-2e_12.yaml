- en: Create a Simple Estimator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a simple estimator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are going to make a custom estimator with scikit-learn. We will take traditional
    statistical math and programming and turn it into machine learning. You are able
    to turn any statistics into machine learning by using scikit-learn's powerful
    cross-validation capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Create a simple estimator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are going to do some work towards building our own scikit-learn estimator.
    The custom scikit-learn estimator consists of at least three methods:'
  prefs: []
  type: TYPE_NORMAL
- en: 'An `__init__` initialization method: This method takes as input the estimator''s
    parameters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A `fit` method: This trains the estimator'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A `predict` method: This method performs a prediction on unseen data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Schematically, the class looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Load the breast cancer dataset from scikit learn:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Split the data into training and testing sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A scikit estimator should have a `fit` method, that returns the class itself,
    and a `predict` method, that returns the predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a classifier we call `RidgeClassifier`. Import `BaseEstimator`
    and `ClassifierMixin` from `sklearn.base` and pass them along as arguments to
    your new classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Let's focus on the `__init__` method. There, we input a single parameter; it
    corresponds to the regularization parameter in the underlying ridge regressor.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `fit` method, we perform all of the work. The work consists of using
    an internal ridge regressor and storing the class labels within the data. We might
    want to throw an error if there are more than two classes, as many classes usually
    do not map well to a set of real numbers. In this example, there are two possible
    targets: malignant cancer or benign cancer. They  map to real numbers as the degree
    of malignancy, which can be viewed as diametrically opposed to benignness. In
    the iris dataset, there are Setosa, Versicolor, and Virginica flowers. The Setosaness
    quality does not have a guaranteed diametric opposite except looking at the classifier
    in a one-versus-rest manner.'
  prefs: []
  type: TYPE_NORMAL
- en: In the `predict` method, you find the class label that is closest to what the
    ridge regressor predicts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now write a few lines applying your new ridge classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'It scores pretty well on the test set. You can perform a grid search on it
    as well:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The point of making your own estimator is that the estimator inherits properties
    from the scikit-learn base estimator and classifier classes. In the line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Your classifier looked at the default accuracy score for all scikit-learn classifiers.
    Conveniently, you did not have to look it up or implement it. Besides, when it
    came to using your classifier, the procedure was very similar to using any scikit
    classifier.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we use a logistic regression classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Your new classifier did slightly better than logistic regression.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At times, statistical packages such as Python's `statsmodels` or `rpy` (an interface
    to R within Python) contain very interesting statistical methods and you would
    want to pass them through scikit's cross-validation. Alternatively, you could
    have written the method and would like to cross-validate it.
  prefs: []
  type: TYPE_NORMAL
- en: The following is a custom estimator constructed using the `statsmodels` **general
    estimating equation** (**GEE**) available at [http://www.statsmodels.org/dev/gee.html](http://www.statsmodels.org/dev/gee.html).
  prefs: []
  type: TYPE_NORMAL
- en: The GEEs use general linear models (that borrow from R) and we can choose a
    group-like variable where observations are possibly correlated within a cluster
    but uncorrelated across clusters—in the words of the documentation. Thus we can
    group, or cluster, by some variable and see within-group correlations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we create a model from the breast cancer data based on the R-style formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We cluster by the feature `mean_concavity` (the variable `mean_concavity` is
    not included in the R-style formula). Start by importing the `statsmodels` module''s
    libraries. The example is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The code within the `fit` method is similar to the code within the GEE documentation.
    You can work it out for your particular situation or statistical method. The code
    within the `predict` method is similar to the ridge classifier you created.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you run the code like you did for the ridge estimator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The point is that you turned a traditional statistical method into a machine
    learning method using scikit-learn's cross-validation.
  prefs: []
  type: TYPE_NORMAL
- en: Trying the new GEE classifier on the Pima diabetes dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Try the GEE classifier on the Pima diabetes dataset. Load the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Split the dataset into training and testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Predict by using the GEE classifier. We will use the `blood_pressure` column
    as the column to group by:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also try the ridge classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: You can compare these—the ridge classifier and GEE classifier—with logistic
    regression in the [Chapter 5](d2473ebe-f050-4e72-bbf9-fabe5d62d441.xhtml), *Linear
    Models – Logistic Regression*.
  prefs: []
  type: TYPE_NORMAL
- en: Saving your trained estimator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Saving your custom estimator is the same as saving any scikit-learn estimator.
    Save the trained ridge classifier in the file `rc_inst.save` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'To retrieve the trained classifier and use it, do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: It is very simple to save a trained custom estimator in scikit-learn.
  prefs: []
  type: TYPE_NORMAL
