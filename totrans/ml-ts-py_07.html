<html><head></head><body>
  <div id="_idContainer301">
    <h1 class="chapterNumber">8</h1>
    <h1 id="_idParaDest-126" class="chapterTitle">Online Learning for Time-Series</h1>
    <p class="normal">In this chapter, we are going to dive into online learning and streaming data for time-series. Online learning means that we continually update our model as new data is coming in. The advantage of online learning algorithms is that they can handle the high speed and possibly large size of streaming data and are able to adapt to new distributions of the data.</p>
    <p class="normal">We will discuss drift, which is important because the performance of a machine learning model can be strongly affected by changes to the dataset to the point that a model will become obsolete (stale).</p>
    <p class="normal">We are going to discuss what online learning is, how data can change (drift), and how adaptive learning algorithms combine drift detection methods to adjust to this change in order to avoid the degradation of performance or costly retraining.</p>
    <p class="normal">We're going to cover the following topics:</p>
    <ul>
      <li class="bullet">Online learning for time-series<ul>
          <li class="bullet-l2">Online algorithms</li>
        </ul>
      </li>
      <li class="bullet">Drift<ul>
          <li class="bullet-l2">Drift detection methods</li>
        </ul>
      </li>
      <li class="bullet">Adaptive learning methods</li>
      <li class="bullet">Python practice</li>
    </ul>
    <p class="normal">We'll start with a discussion of online learning.</p>
    <h1 id="_idParaDest-127" class="title">Online learning for time-series</h1>
    <p class="normal">There are two main scenarios of learning – online learning and offline learning. <strong class="keyword">Online learning</strong> means that <a id="_idIndexMarker626"/>you are fitting your model incrementally as the <a id="_idIndexMarker627"/>data flows in (streaming data). On the other hand, <strong class="keyword">offline learning</strong>, the more commonly known approach, implies that you have a static dataset <a id="_idIndexMarker628"/>that you know from the start, and the parameters of your <a id="_idIndexMarker629"/>machine learning algorithm are adjusted to the whole dataset at once (often loading the whole dataset into memory or in batches).</p>
    <p class="normal">There are three major use cases for online learning:</p>
    <ul>
      <li class="bullet">Big data</li>
      <li class="bullet">Time <a id="_idIndexMarker630"/>constraints (for example, real time)</li>
      <li class="bullet">Dynamic environments</li>
    </ul>
    <p class="normal">Typically, in online learning settings, you have more data, and it is appropriate for big data. Online learning can be applied to large datasets, where it would be computationally infeasible to train over the entire dataset.</p>
    <p class="normal">Another use case for online learning is where the inference and fitting are performed under time constraints (for example, a real-time application), and many online algorithms are very resource-efficient in comparison to offline algorithms.</p>
    <p class="normal">A common application of online learning is on time-series data, and a particular challenge is that the underlying generating process of the time-series observations can change over time. This is called concept drift. While in the offline setting the parameters are fixed, in online learning, the parameters are continuously adapted based on new data. Therefore, online learning <a id="_idIndexMarker631"/>algorithms can deal with <a id="_idIndexMarker632"/>changes in the data, and some can deal with concept drift.</p>
    <p class="normal">The table below summarizes some more differences between online and offline learning:</p>
    <table id="table001-5" class="No-Table-Style _idGenTablePara-1">
      <colgroup>
        <col/>
        <col/>
        <col/>
      </colgroup>
      <tbody>
        <tr class="No-Table-Style">
          <td class="No-Table-Style"/>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Offline</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Online</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Necessity to monitor</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Yes, models can become stale (the model will lose performance)</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Adapt to changing data</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Retraining costs</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Expensive (from scratch)</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Cheap (incremental)</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Memory requirements</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Possibly high memory demands</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Low</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Applications</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Image classifiers, speech recognition, etc, where data is assumed to be static</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Finance, e-commerce, economics, and health-care, where data is dynamically changing</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Tools</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">tslearn, sktime, prophet</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Scikit-Multiflow, River</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="packt_figref">Figure 8.1: Online vs offline learning methods in time-series</p>
    <p class="normal">There are lots of other tools that are not specific to online learning but support online learning, such as <a id="_idIndexMarker633"/>the most popular deep learning libraries – PyTorch and TensorFlow, where models inherently support online learning and data <a id="_idIndexMarker634"/>loaders support streaming scenarios – through iterators, where data can be loaded in as needed.</p>
    <p class="normal">A streaming formulation of a supervised machine learning problem can be posed as follows:</p>
    <ol>
      <li class="numbered">A data point <img src="../Images/B17577_08_001.png" alt="" style="height: 1em;"/> is received at time <em class="italic">t</em> </li>
      <li class="numbered">The online algorithm predicts the label</li>
      <li class="numbered">The true label is revealed before the next data point comes in</li>
    </ol>
    <p class="normal">In a batch setting, a set of <em class="italic">n</em> points <img src="../Images/B17577_08_002.png" alt="" style="height: 1em;"/> arrive all at once at time <em class="italic">t</em>, and all <em class="italic">n</em> points will be predicted by the online model before the true labels are revealed and the next batch of points arrives.</p>
    <p class="normal">We can demonstrate the difference in Python code snippets to show the characteristic patterns of machine learning in online and offline settings. You should be familiar with offline learning, which looks like this for features <code class="Code-In-Text--PACKT-">X</code>, target vector <code class="Code-In-Text--PACKT-">y</code>, and model parameters <code class="Code-In-Text--PACKT-">params</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> linear_model
offline_model = linear_model.LogisticRegression(params)
offline_model.fit(X, Y)
</code></pre>
    <p class="normal">This should be familiar from previous chapters such as <em class="chapterRef">Chapter 7</em><span class="mediaobject">, </span><em class="italic">Machine Learning Models for Time-Series</em>. For simplicity, we are omitting data loading, preprocessing, cross-validation, and parameter tuning, among other issues.</p>
    <p class="normal">Online learning follows this pattern:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> river <span class="hljs-keyword">import</span> linear_model
online_model = linear_model.LogisticRegression(params)
<span class="hljs-keyword">for</span> xi, yi <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(X, y):
    online_model.learn_one(xi, yi)
</code></pre>
    <p class="normal">Here, we are feeding point by point to the model. Again, this is simplified – I've omitted setting the parameters, loading the dataset, and more.</p>
    <p class="normal">These snippets should make the main difference clear: learning on the whole dataset at once (offline) against learning on single points one by one (online).</p>
    <p class="normal">I should mention evaluation methods for online methods:</p>
    <ul>
      <li class="bullet">Holdout</li>
      <li class="bullet">Prequential</li>
    </ul>
    <p class="normal">In <strong class="keyword">Holdout</strong>, we can apply the current model to the independent test set. This is popular in batch as well as online (stream) learning <a id="_idIndexMarker635"/>and gives an unbiased performance estimation.</p>
    <p class="normal">In <strong class="keyword">Prequential Evaluation</strong>, we test as we are going through the sequence. Each new data point is first <a id="_idIndexMarker636"/>tested and then trained on.</p>
    <p class="normal">An interesting aspect of online learning is model selection, that is, how to select the best model among a set of candidate models. We looked at model selection for time-series models in <em class="chapterRef">Chapter 4</em><span class="mediaobject">, </span><em class="italic">Machine Learning Models for Time-Series</em>. There are different options for model selection in the online setting.</p>
    <p class="normal">In a <strong class="keyword">Multi-Armed Bandit</strong> (also <strong class="keyword">K-Armed Bandit</strong>) problem, limited resources must be allocated between competing choices in a way that maximizes expected gain. Each choice ("arm") comes <a id="_idIndexMarker637"/>with its reward, which can be learned over time. Over time, we can adapt our preference for each of these arms and choose optimally in terms of <a id="_idIndexMarker638"/>expected reward. Similarly, by learning expected rewards for competing classification or regression models, methods for multi-armed bandits can be applied for model selection. In the practice section, we'll discuss multi-armed bandits for model selection.</p>
    <p class="normal">In the following sections, we'll look at incremental methods and drift in more detail.</p>
    <h2 id="_idParaDest-128" class="title">Online algorithms</h2>
    <p class="normal">Where data becomes available <a id="_idIndexMarker639"/>gradually over time or its size exceeds system memory limits, then incremental machine learning algorithms, whether supervised learning or unsupervised, can update parameters on parts of the data rather than starting the learning from scratch. <strong class="keyword">Incremental learning</strong> is where parameters are continuously adapted to adjust a model to new input data.</p>
    <p class="normal">Some machine learning <a id="_idIndexMarker640"/>methods inherently support incremental learning. Neural networks (as in deep learning), nearest neighbor, and evolutionary methods (for example, genetic algorithms) are incremental and can therefore be applied in online learning settings, where they are continuously updated.</p>
    <p class="normal">Incremental algorithms may have random access to previous samples or prototypes (selected samples). These algorithms, such as based on the nearest neighbor algorithm, are called incremental algorithms with partial memory. Their variants can be suitable for cyclic drift scenarios.</p>
    <p class="normal">Many well-known machine learning algorithms have incremental variants such as the adaptive random forest, the adaptive XGBoost classifier, or the incremental support vector machine.</p>
    <p class="normal">Both reinforcement learning and active learning can be seen as types of online learning because they work in an online or active manner. We are going to discuss reinforcement learning in <em class="chapterRef">Chapter 11</em>, <em class="italic">Reinforcement Learning for Time-Series</em>.</p>
    <p class="normal">In online learning, updates are calculated continuously. At the heart of this is running statistics, so it could be illustrative to show how mean and variance can be calculated incrementally (in an online setting).</p>
    <p class="normal">Let's look at the formulas <a id="_idIndexMarker641"/>for online arithmetic mean and online variance. As for the <strong class="keyword">online mean</strong>, updating the mean <img src="../Images/B17577_08_003.png" alt="" style="height: 1em;"/> at time point <em class="italic">t</em> can be done as follows:</p>
    <figure class="mediaobject"><img src="../Images/B17577_08_004.png" alt="" style="height: 2.8em;"/></figure>
    <p class="normal">where <img src="../Images/B17577_08_005.png" alt="" style="height: 1em;"/> is the number of previous updates – sometimes this is written as <img src="../Images/B17577_08_006.png" alt="" style="height: 1em;"/>.</p>
    <p class="normal">The <strong class="keyword">online variance</strong> <img src="../Images/B17577_08_007.png" alt="" style="height: 1em;"/> can be calculated <a id="_idIndexMarker642"/>based on the online mean and the running sum of squares <img src="../Images/B17577_08_008.png" alt="" style="height: 1em;"/>:</p>
    <figure class="mediaobject"><img src="../Images/B17577_08_009.png" alt="" style="height: 1.5em;"/></figure>
    <figure class="mediaobject"><span class="mediaobject"><img src="../Images/B17577_08_010.png" alt="" style="height: 2.8em;"/></span></figure>
    <p class="normal">A downside to offline algorithms is that they are sometimes more difficult to implement and that there's a learning curve to getting up to speed with libraries, algorithms, and methods.</p>
    <p class="normal">scikit-learn, the standard <a id="_idIndexMarker643"/>library for machine learning in Python, only has a limited number of incremental <a id="_idIndexMarker644"/>algorithms. It is focused on batch-learning models. In contrast, there are specialized libraries for online learning with adaptive and incremental algorithms that cover many use cases, such as imbalanced datasets.</p>
    <p class="normal">Research engineers, students, and machine learning researchers from the University of Waikato (New Zealand), Télécom ParisTech, and the École Polytechnique in Paris have been working on the <strong class="keyword">River library</strong>. River is the result of merging two libraries: Creme (intended as a pun <a id="_idIndexMarker645"/>on incremental) and Scikit-Multiflow. River comes with many meta and ensemble methods. As a cherry on top, many of these meta or ensemble methods can use scikit-learn models as base models.</p>
    <p class="normal">At the time of writing, the River library has 1,700 stars and implements many unsupervised and supervised algorithms. At the time of writing, the documentation of River is still a work in progress, but lots of functionality is available, as we'll see in the practical section at the end of this chapter.</p>
    <p class="normal">This chart shows the popularity of River and Scikit-Multiflow over time (by the number of stars on GitHub):</p>
    <figure class="mediaobject"><img src="../Images/B17577_08_01.png" alt="online_learning-star_history.png"/></figure>
    <p class="packt_figref">Figure 8.2: Star histories of the River and Scikit-Multiflow libraries</p>
    <p class="normal">We can see that, while Scikit-Multiflow has risen steadily, this rise has been mostly flat. River overtook Scikit-Multiflow in 2019 and has continued to receive many star ratings from GitHub users. These star <a id="_idIndexMarker646"/>ratings are similar to a "like" on a social media platform.</p>
    <p class="normal">This table shows a few online algorithms, some of which are suitable for drift scenarios:</p>
    <table id="table002-4" class="No-Table-Style _idGenTablePara-1">
      <colgroup>
        <col/>
        <col/>
      </colgroup>
      <tbody>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Algorithm</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Description</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-"><strong class="keyword">Very Fast Decision Tree</strong> (<strong class="keyword">VFDT</strong>)</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Decision tree made up of splits based on a few examples. Also called Hoeffding Tree. Struggles with drift.</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-"><strong class="keyword">Extremely Fast Decision Tree</strong> (<strong class="keyword">EFDT</strong>)</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Incrementally builds a tree by creating a split when confident and replaces the split if a better split is available. Assumes a stationary distribution.</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Learn++.NSE</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Ensemble of classifiers for incremental learning from non-stationary environments.</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="packt_figref">Figure 8.3: Online machine learning algorithms – some of them suitable for drift</p>
    <p class="normal">The online algorithm par excellence is the <strong class="keyword">Hoeffding Tree</strong> (Geoff Hulten, Laurie Spencer, and Pedro Domingos, 2001), also <a id="_idIndexMarker647"/>called <strong class="keyword">Very Fast Decision Tree</strong> (<strong class="keyword">VFDT</strong>). It is one of the most widely <a id="_idIndexMarker648"/>used online decision tree induction algorithms.</p>
    <p class="normal">While some online learning algorithms are reasonably efficient, the attained performance can be highly sensitive to the ordering of data points, and potentially, they might never escape from a local minimum they ended up in, driven by early examples. Appealingly, VFDTs provide high classification accuracy with theoretical guarantees that they will converge toward the performance of decision trees over time. In fact, the probability that a VFDT and a <a id="_idIndexMarker649"/>conventionally trained tree will <a id="_idIndexMarker650"/>differ in their tree splits decreases exponentially with the number of examples.</p>
    <p class="normal">The <strong class="keyword">Hoeffding bound</strong>, proposed by Wassily Hoeffding in 1963, states that with probability <img src="../Images/B17577_08_011.png" alt="" style="height: 1em;"/>, the calculated mean <img src="../Images/B17577_08_012.png" alt="" style="height: 1em;"/> of a random variable <em class="italic">Z</em>, calculated over <em class="italic">n</em> samples, deviates less than <img src="../Images/B17577_08_013.png" alt="" style="height: 0.7em;"/> from the true mean <img src="../Images/B17577_08_014.png" alt="" style="height: 1em;"/>:</p>
    <figure class="mediaobject"><img src="../Images/B17577_08_015.png" alt="" style="height: 4em;"/></figure>
    <p class="normal">In this equation, <em class="italic">R</em> is the range of the random variable <em class="italic">Z</em>. This bound is independent of the probability distribution that is generating the observations.</p>
    <p class="normal">As data comes in, new branches are continuously added and obsolete branches are cut out from the Hoeffding Tree. Problematically, however, under concept drift, some nodes may no longer satisfy the Hoefdding boundary.</p>
    <p class="normal">In the next section, we'll look at drift, why you should care, and what to do about drift.</p>
    <h1 id="_idParaDest-129" class="title">Drift</h1>
    <p class="normal">A major determinant of data quality is drift. <strong class="keyword">Drift</strong> (also: <strong class="keyword">dataset shift</strong>) means that the patterns in data <a id="_idIndexMarker651"/>change over time. Drift is important because the performance of a <a id="_idIndexMarker652"/>machine learning model can be adversely affected by changes to the dataset.</p>
    <p class="normal">Drift transitions can occur abruptly, incrementally, gradually, or be recurring. This is illustrated here:</p>
    <figure class="mediaobject"><img src="../Images/B17577_08_02.png" alt="../Conceptdrift4%20-%20page%201.png"/></figure>
    <p class="packt_figref">Figure 8.4: Four types of concept drift transitions</p>
    <p class="normal">When the transition is abrupt, it happens from one time step to another without apparent preparation <a id="_idIndexMarker653"/>or warning. In contrast, it can also be incremental in the sense that there's first a little shift, then a bigger shift, then a bigger shift again. </p>
    <p class="normal">When a transition happens gradually, it can look like a back and forth between different <a id="_idIndexMarker654"/>forces until a new baseline is established. Yet another type of transition is recurring or cyclical when there's a regular or recurring shift between different baselines.</p>
    <p class="normal">There are different kinds of drift:</p>
    <ul>
      <li class="bullet">Covariate drift</li>
      <li class="bullet">Prior-probability drift</li>
      <li class="bullet">Concept drift</li>
    </ul>
    <p class="normal"><strong class="keyword">Covariate drift</strong> describes a change in the independent variables (features). An example could be a regulatory <a id="_idIndexMarker655"/>intervention, where new laws would shake up the market landscape, and consumer <a id="_idIndexMarker656"/>behavior would follow different behaviors <a id="_idIndexMarker657"/>from before. An example would be if we want to predict chronic disease within 10 years given smoking behaviors, and smoking suddenly becomes much less prevalent, because of new laws. This means that our prediction could be less reliable.</p>
    <p class="normal"><strong class="keyword">Probability drift</strong> is a change in the target variable. An example could be that in fraud detection, the fraud <a id="_idIndexMarker658"/>incidence ratio changes; in retail, the average value of <a id="_idIndexMarker659"/>merchandise increases. One reason for drift could be seasonality – for example, selling more coats in winter.</p>
    <p class="normal">In <strong class="keyword">concept drift</strong>, a change occurs in the relationship between the independent and the target variables. The concept the <a id="_idIndexMarker660"/>term refers to is the relationship between independent and <a id="_idIndexMarker661"/>dependent variables. For example, if we wanted to predict the number of cigarettes smoked, we could assume that our model would become useless after the introduction of new laws. Please note that often, the term concept drift is applied in a broader sense as anything non-stationary.</p>
    <div class="note">
      <p class="Information-Box--PACKT-"><strong class="keyword">Covariate drift</strong>: a change in the features <em class="italic">P(x)</em>.</p>
      <p class="Information-Box--PACKT-"><strong class="keyword">Label drift (</strong>or <strong class="keyword">prior probability drift)</strong>: a change <a id="_idIndexMarker662"/>in the target variable <em class="italic">P(y)</em>.</p>
      <p class="Information-Box--PACKT-"><strong class="keyword">Concept drift</strong>: (in supervised machine learning) changes in the conditional distribution of the target – in other words, the relationship between independent and dependent variables changes <em class="italic">P(y|X)</em>.</p>
    </div>
    <p class="normal">Commonly, when building machine learning models, we assume that points within different parts of the dataset belong to the same distribution.</p>
    <p class="normal">While occasional anomalies, such as abnormal events, would usually be treated as noise and ignored, when there is a change in the distribution, models often have to be rebuilt from scratch based on new samples in order to capture the latest characteristics. This is the reason why we are testing time-series models with walk-forward validation as discussed in <em class="chapterRef">Chapter 7</em><span class="mediaobject">, </span><em class="italic">Machine Learning Models for Time-Series</em>. However, this training from scratch can be time-consuming and heavy on computing resources.</p>
    <p class="normal">Drift causes problems for machine learning models since models can become stale – they become unreliable over time since the relationships they capture are no longer valid. This results in the performance degradation of these models. Therefore, approaches to forecasting, classification, regression, or anomaly detection should be able to detect and react to concept drift in a timely manner, so that the model can be updated as soon as <a id="_idIndexMarker663"/>possible. Machine learning models are often retrained periodically to avoid performance degradation happening. Alternatively, retraining can be triggered when needed based on either the performance monitoring of models or based on change detection methods.</p>
    <p class="normal">As for applications on time-series, in many domains, such as finance, e-commerce, economics, and healthcare, the statistical properties of the time-series can change, rendering forecasting models useless. Puzzlingly, although the concept of the drift problem is well investigated in the literature, little effort has been invested in tackling it with time-series methods.</p>
    <p class="normal">Gustavo Oliveira and others proposed in 2017 ("<em class="italic">Time-Series Forecasting in the Presence of Concept Drift: A PSO-based Approach</em>") training several time-series forecasting models. At each point in time, the parameters for each of these models were changed weighted by the latest performance (particle swarm optimization). When the best models (best particles) diverged beyond a certain confidence interval, retraining of models was triggered.</p>
    <p class="normal">The charts below illustrate a combination of error-triggered retraining and online learning, one approach to time-series forecasting:</p>
    <figure class="mediaobject"><img src="../Images/B17577_08_03.png" alt="https://github.com/GustavoHFMO/IDPSO-ELM-S/raw/master/images/idpso_elm_s_execution.png"/></figure>
    <p class="packt_figref">Figure 8.5: Online learning and retraining for time-series forecasting (IDPSO-ELM-S)</p>
    <p class="normal">You can see the error rates <a id="_idIndexMarker664"/>increasing periodically as concept drift is occurring, and, where, based on the concept of drift detection, retraining is triggered.</p>
    <p class="normal">Many online models have been specifically adapted to be robust to or handle concept drift. In this section, we'll discuss some of the most popular or best-performing ones. We'll also discuss methods for drift detection.</p>
    <h2 id="_idParaDest-130" class="title">Drift detection methods</h2>
    <p class="normal">There are lots of different methods to explicitly detect drift and distributional changes in data streams. Page-Hinkley (Page, 1954) and Geometric Moving Average (Roberts, 2000) are two of the pioneers.</p>
    <p class="normal">Drift detectors monitor the <a id="_idIndexMarker665"/>model performance usually through a performance metric, however, they can also be based on input features, although this is more of an exception. The basic idea is that when there is a change in the class distribution of the samples, the model does not correspond anymore to the current distribution, and the performance degrades (the error rate increases). Therefore, quality control of the model performance can serve as drift detection.</p>
    <p class="normal">Drift detection methods can be categorized into at least three groups (after João Gama and others, 2014):</p>
    <ul>
      <li class="bullet">Statistical process control</li>
      <li class="bullet">Sequential analysis</li>
      <li class="bullet">Windows-based comparison</li>
    </ul>
    <p class="normal">Statistical process control methods take into account summary statistics such as the mean and standard deviation of model predictions. For example, the <strong class="keyword">Drift Detection Method</strong> (<strong class="keyword">DDM</strong>; João Gama and others, 2004) alerts if the error rate surpasses the previously recorded <a id="_idIndexMarker666"/>minimum error rate by three standard deviations. According to statistical learning theory, in a continuously trained model, errors should diminish with the number of samples, so this threshold should only be exceeded in the case of drift.</p>
    <p class="normal">Sequential methods are based on thresholds of model predictions. For example, in the <strong class="keyword">Linear Four Rates</strong> (Wang, 2015) method, the rates in the contingency table are updated incrementally. Significance is <a id="_idIndexMarker667"/>calculated according to a threshold that is estimated once at the start by Monte Carlo sampling. This method can handle class imbalance better than DDM.</p>
    <div class="note">
      <p class="Information-Box--PACKT-"><strong class="keyword">Contingency table</strong>: a table that compares the frequency distribution of variables. Specifically in machine learning classification, the table displays the predicted number <a id="_idIndexMarker668"/>of labels over the test set against the actual labels. In the case of binary classification, the cells show true positives, false positives, false negatives, and true negatives.</p>
    </div>
    <p class="normal">Windows-based approaches monitor the distribution of errors. For example, <strong class="keyword">ADWIN</strong> (<strong class="keyword">ADaptive WINdowing</strong>) was published by Albert Bifet and Ricard Gavaldà in 2007. Prediction errors <a id="_idIndexMarker669"/>within a time window <em class="italic">W</em> are partitioned into smaller windows, and the differences in mean error rates within these windows are <a id="_idIndexMarker670"/>compared to the Hoeffding bound. The original version proposes a variation of this strategy that has a time complexity of <em class="italic">O(log W)</em>, where <em class="italic">W</em> is the length of the window.</p>
    <p class="normal">Some methods for drift detection are listed here:</p>
    <table id="table003-2" class="No-Table-Style _idGenTablePara-1">
      <colgroup>
        <col/>
        <col/>
        <col/>
      </colgroup>
      <tbody>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Algorithm</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Description</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Type</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-"><strong class="keyword">Adaptive Windowing</strong> (<strong class="keyword">ADWIN</strong>)</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Adaptive sliding window algorithm based on thresholds.</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Window-based</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-"><strong class="keyword">Drift Detection Method</strong> (<strong class="keyword">DDM</strong>)</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Based on the premise that the model's error rate should decrease over time.</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Statistical</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-"><strong class="keyword">Early Drift Detection Method</strong> (<strong class="keyword">EDDM</strong>)</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Statistics over the average distance between two errors. Similar to DDM, but better for gradual drift.</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Statistical</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-"><strong class="keyword">Hoffding's Drift Detection</strong> (<strong class="keyword">HDDM</strong>)</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Non-parametric method based on Hoeffding's bounds – either moving average-test or moving weighted average-test.</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Window-based</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-"><strong class="keyword">Kolmogorov-Smirnov Windowing</strong> (<strong class="keyword">KSWIN</strong>)</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Kolmogorov-Smirnov test in windows of a time-series.</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Window-based</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Page-Hinkley</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Statistical test for mean changes in Gaussian signals.</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Sequential</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="packt_figref">Figure 8.6: Drift detection algorithms</p>
    <p class="normal">Kolmogorov-Smirnov is a nonparametric test of the equality of continuous, one-dimensional probability distributions.</p>
    <p class="normal">These methods can be used in the context of both regression and classification (and, by extension, forecasting). They can be used to trigger the retraining of models. For example, Hassan Mehmood and others (2021) retrained time-series forecasting models (among other models, they used Facebook's Prophet) if drift was detected.</p>
    <p class="normal">Drift detectors all have <a id="_idIndexMarker671"/>their assumptions regarding input data. It is important to know these assumptions, and I've tried to outline these in the table, so you use the right detector with your dataset.</p>
    <p class="normal">The drift detection methods listed above all incur a labeling cost. Since they all monitor the prediction results of a base classifier or an ensemble, they require that the class labels is available right after prediction. This constraint is unrealistic in some practical problems. There are other methods, not listed here, that can be based on anomaly detection (or novelty detection), feature distribution monitoring, or model-dependent monitoring. We saw a few of these methods in <em class="chapterRef">Chapter 6</em>, <em class="italic">Unsupervised Methods for Time-Series</em>.</p>
    <p class="normal">In the next section, we'll look at some methods that were designed to be resistant to drift.</p>
    <h1 id="_idParaDest-131" class="title">Adaptive learning methods</h1>
    <p class="normal"><strong class="keyword">Adaptive learning</strong> refers to incremental methods with drift adjustment. This concept refers to updating <a id="_idIndexMarker672"/>predictive models online to react to concept drifts. The goal is that <a id="_idIndexMarker673"/>by taking drift into account, models can ensure consistency with the current data distribution.</p>
    <p class="normal">Ensemble methods can be coupled with drift detectors to trigger the retraining of base models. They can monitor the performance of base models (often with ADWIN) – underperforming models get replaced with retrained models if the new models are more accurate.</p>
    <p class="normal">As a case in point, the <strong class="keyword">Adaptive XGBoost</strong> algorithm (<strong class="keyword">AXGB</strong>; Jacob Montiel and others, 2020) is an adaptation of XGBoost for evolving data streams, where new subtrees are created from mini-batches <a id="_idIndexMarker674"/>of data as new data becomes available. The maximum ensemble size is fixed, and once this size is reached, the ensemble is updated on new data.</p>
    <p class="normal">In the Scikit-Multiflow and River libraries, there are several methods that couple machine learning methods with drift-detection methods, which regulate adaptation. Many of these were published by the maintainers of the two libraries. Here's a list with a few of <a id="_idIndexMarker675"/>these methods:</p>
    <table id="table004-1" class="No-Table-Style _idGenTablePara-1">
      <colgroup>
        <col/>
        <col/>
      </colgroup>
      <tbody>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Algorithm</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Heading--PACKT-">Description</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-"><strong class="keyword">K-Nearest Neighbors</strong> (<strong class="keyword">KNN</strong>) classifier with ADWIN change detector</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">KNN with ADWIN change detector to decide which samples to keep or forget.</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Adaptive Random Forest</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Includes drift detectors per tree. It starts training in the background after a warning has been detected, and replaces the old tree if drift occurs.</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Additive Expert ensemble classifier</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Implements pruning strategies – the oldest or weakest base model will be removed.</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-"><strong class="keyword">Hoeffding Adaptive Tree</strong> (<strong class="keyword">HAT</strong>)</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Pairs ADWIN to detect drift and a Hoeffding Tree model to learn.</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Very Fast Decision Rules</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Similar to VFDT, but rule ensembles instead of a tree. In Scikit-Multiflow drift detection with ADWIN, DDM, and EDDM is supported.</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Oza Bagging ADWIN</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Instead of sampling with replacement, each sample is given a weight. In River, this can be combined with the ADWIN change detector.</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Online CSB2</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Online boosting algorithm that compromises between AdaBoost and AdaC2, and optionally uses a change detector.</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">Online Boosting</p>
          </td>
          <td class="No-Table-Style">
            <p class="Table-Column-Content--PACKT-">AdaBoost with ADWIN drift detection.</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="packt_figref">Figure 8.7: Adaptive learning algorithms</p>
    <p class="normal">These methods are robust to drift by regulating the adaptation or learning with the concept of drift detection.</p>
    <p class="normal">Let's try out a few of these methods!</p>
    <h1 id="_idParaDest-132" class="title">Python practice</h1>
    <p class="normal">The installation in this chapter is very simple, since, in this chapter, we'll only use River. We can quickly install <a id="_idIndexMarker676"/>it from the terminal (or similarly from Anaconda Navigator):</p>
    <pre class="programlisting con"><code class="hljs-con">pip install river
</code></pre>
    <p class="normal">We'll execute the commands from the Python (or IPython) terminal, but equally, we could execute them from a Jupyter notebook (or a different environment).</p>
    <h2 id="_idParaDest-133" class="title">Drift detection</h2>
    <p class="normal">Let's start off by trying out drift detection with an artificial time-series. This follows the example in <a id="_idIndexMarker677"/>the tests of the River library.</p>
    <p class="normal">We'll first create an artificial time-series that we can test:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
np.random.seed(<span class="hljs-number">12345</span>)
data_stream = np.concatenate(
    (np.random.randint(<span class="hljs-number">2</span>, size=<span class="hljs-number">1000</span>), np.random.randint(<span class="hljs-number">8</span>, size=<span class="hljs-number">1000</span>))
)
</code></pre>
    <p class="normal">This time-series is composed of two series that have different characteristics. Let's see how quickly the drift detection algorithms pick up on this.</p>
    <p class="normal">Running the drift detector over this means iterating over this dataset and feeding the values into the drift detector. We'll create a function for this:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">perform_test</span><span class="hljs-function">(</span><span class="hljs-params">drift_detector, data_stream</span><span class="hljs-function">):</span>
    detected_indices = []
    <span class="hljs-keyword">for</span> i, val <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(data_stream):
        in_drift, in_warning = drift_detector.update(val)
        <span class="hljs-keyword">if</span> in_drift:
            detected_indices.append(i)
    <span class="hljs-keyword">return</span> detected_indices
</code></pre>
    <p class="normal">Now we can try the ADWIN drift detection method on this time-series. Let's create another method to plot the drift points overlaid over the time-series:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">show_drift</span><span class="hljs-function">(</span><span class="hljs-params">data_stream, indices</span><span class="hljs-function">):</span>
    fig, ax = plt.subplots(figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">6</span>))
    ax.plot(data_stream)
    ax.plot(
        indices,
        data_stream[indices],
        <span class="hljs-string">"ro"</span>,
        alpha=<span class="hljs-number">0.6</span>,
        marker=<span class="hljs-string">r'$\circ$'</span>,
        markersize=<span class="hljs-number">22</span>,
        linewidth=<span class="hljs-number">4</span>
    )
plt.tight_layout()
</code></pre>
    <p class="normal">This is the plot <a id="_idIndexMarker678"/>for the ADWIN drift points: </p>
    <figure class="mediaobject"><img src="../Images/B17577_08_04.png" alt="ADWIN_drift_detection.png"/></figure>
    <p class="packt_figref">Figure 8.9: ADWIN drift points on our artificial dataset</p>
    <p class="normal">I'd encourage you to play around with this and to also try out the other drift detection methods.</p>
    <p class="normal">Next, we'll do a regression task.</p>
    <h2 id="_idParaDest-134" class="title">Regression</h2>
    <p class="normal">We are going to estimate the occurrence of medium-class solar flares.</p>
    <p class="normal">For this, we'll use the solar flares dataset from the UCI machine learning repository. The River library ships with <a id="_idIndexMarker679"/>a zipped column-separated dataset of the dataset, and we'll load this, specify the column types, and choose the outputs we are interested in.</p>
    <p class="normal">Let's plot the ADWIN results now:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> river <span class="hljs-keyword">import</span> stream
<span class="hljs-keyword">from</span> river.datasets <span class="hljs-keyword">import</span> base
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">SolarFlare</span><span class="hljs-class">(</span><span class="hljs-params">base.FileDataset</span><span class="hljs-class">):</span>
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        <span class="hljs-built_in">super</span>().__init__(
            n_samples=<span class="hljs-number">1066</span>,
            n_features=<span class="hljs-number">10</span>,
            n_outputs=<span class="hljs-number">1</span>,
            task=base.MO_REG,
            filename=<span class="hljs-string">"solar-flare.csv.zip"</span>,
        )
    <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__iter__</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
        <span class="hljs-keyword">return</span> stream.iter_csv(
            self.path,
            target=<span class="hljs-string">"m-class-flares"</span>,
            converters={
                <span class="hljs-string">"zurich-class"</span>: <span class="hljs-built_in">str</span>,
                <span class="hljs-string">"largest-spot-size"</span>: <span class="hljs-built_in">str</span>,
                <span class="hljs-string">"spot-distribution"</span>: <span class="hljs-built_in">str</span>,
                <span class="hljs-string">"activity"</span>: <span class="hljs-built_in">int</span>,
                <span class="hljs-string">"evolution"</span>: <span class="hljs-built_in">int</span>,
                <span class="hljs-string">"previous-24h-flare-activity"</span>: <span class="hljs-built_in">int</span>,
                <span class="hljs-string">"hist-complex"</span>: <span class="hljs-built_in">int</span>,
                <span class="hljs-string">"hist-complex-this-pass"</span>: <span class="hljs-built_in">int</span>,
                <span class="hljs-string">"area"</span>: <span class="hljs-built_in">int</span>,
                <span class="hljs-string">"largest-spot-area"</span>: <span class="hljs-built_in">int</span>,
                <span class="hljs-string">"c-class-flares"</span>: <span class="hljs-built_in">int</span>,
                <span class="hljs-string">"m-class-flares"</span>: <span class="hljs-built_in">int</span>,
                <span class="hljs-string">"x-class-flares"</span>: <span class="hljs-built_in">int</span>,
            },
        )
</code></pre>
    <p class="normal">Please note how <a id="_idIndexMarker680"/>we are choosing the number of targets and the converters, which contain the types for all feature columns.</p>
    <p class="normal">Let's have a look at what this looks like:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> pprint <span class="hljs-keyword">import</span> pprint
<span class="hljs-keyword">from</span> river <span class="hljs-keyword">import</span> datasets
<span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> SolarFlare():
    pprint(x)
    pprint(y)
    <span class="hljs-keyword">break</span>
</code></pre>
    <p class="normal">We see the first <a id="_idIndexMarker681"/>point of the dataset (the first row of the dataset):</p>
    <figure class="mediaobject"><img src="../Images/B17577_08_05.png" alt="/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_XK8zOB/Screenshot 2021-07-05 at 23.37.50.png"/></figure>
    <p class="packt_figref">Figure 8.10: First point of the solar flare dataset for medium-sized flares</p>
    <p class="normal">We see the ten feature columns as a dictionary and the output as a float.</p>
    <p class="normal">Let's build our model pipeline in River:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> numbers
<span class="hljs-keyword">from</span> river <span class="hljs-keyword">import</span> compose
<span class="hljs-keyword">from</span> river <span class="hljs-keyword">import</span> preprocessing
<span class="hljs-keyword">from</span> river <span class="hljs-keyword">import</span> tree
num = compose.SelectType(numbers.Number) | preprocessing.MinMaxScaler()
cat = compose.SelectType(<span class="hljs-built_in">str</span>) | preprocessing.OneHotEncoder(sparse=<span class="hljs-literal">False</span>)
model = tree.HoeffdingTreeRegressor()
pipeline = (num + cat) | model
</code></pre>
    <p class="normal">A pipeline like this is very pleasant to read: numeric features get min-max scaled, while string features get one-hot encoded. The preprocessed features get fed into a Hoeffding Tree model for regression.</p>
    <p class="normal">We can now learn our model prequentially, by predicting values and then training them as discussed before:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> river <span class="hljs-keyword">import</span> evaluate
<span class="hljs-keyword">from</span> river <span class="hljs-keyword">import</span> metrics
metric = metrics.MAE()
evaluate.progressive_val_score(SolarFlare(), pipeline, metric)
</code></pre>
    <p class="normal">We are <a id="_idIndexMarker682"/>using the <strong class="keyword">Mean Absolute Error</strong> (<strong class="keyword">MAE</strong>) as our metric. </p>
    <p class="normal">We get an MAE of 0.096979.</p>
    <p class="normal">This prequential <a id="_idIndexMarker683"/>evaluation <code class="Code-In-Text--PACKT-">evaluate.progressive_val_score()</code> is equivalent to the following:</p>
    <pre class="programlisting code"><code class="hljs-code">errors = []
<span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> SolarFlare():
    y_pred = pipeline.predict_one(x)
    metric = metric.update(y, y_pred)
    errors.append(metric.get())
    pipeline = pipeline.learn_one(x, y)
</code></pre>
    <p class="normal">I've added two extra lines to collect the error over time as the algorithm learns. </p>
    <p class="normal">Let's plot this:</p>
    <pre class="programlisting code"><code class="hljs-code">fig, ax = plt.subplots(figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">6</span>))
ax.plot(
    errors,
    <span class="hljs-string">"ro"</span>,
    alpha=<span class="hljs-number">0.6</span>,
    markersize=<span class="hljs-number">2</span>,
    linewidth=<span class="hljs-number">4</span>
)
ax.set_xlabel(<span class="hljs-string">"number of points"</span>)
ax.set_ylabel(<span class="hljs-string">"MAE"</span>)
</code></pre>
    <p class="normal">This plot shows how this error evolves as a function of the number of points the algorithm encounters:</p>
    <figure class="mediaobject"><img src="../Images/B17577_08_06.png" alt="solar_flares_regression_mae.png"/></figure>
    <p class="packt_figref">Figure 8.11: MAE by the number of points</p>
    <p class="normal">We can see that, after 20-30 points, after the metric stabilizes, the Hoeffding Tree starts learning and the <a id="_idIndexMarker684"/>error keeps decreasing until about 800 points, at which point the error increases again. This could be a row ordering effect.</p>
    <p class="normal">A dataset that has concept drift is the use case for an adaptive model. Let's compare adaptive and non-adaptive models on a dataset with concept drift:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> river <span class="hljs-keyword">import</span> (
    synth, ensemble, tree,
    evaluate, metrics
)
models = [
    tree.HoeffdingTreeRegressor(),
    tree.HoeffdingAdaptiveTreeRegressor(),
    ensemble.AdaptiveRandomForestRegressor(seed=<span class="hljs-number">42</span>)
]
</code></pre>
    <p class="normal">We will compare the Hoeffding Tree Regressor, the Adaptive Hoeffding Tree Regressor, and the Adaptive Random Forest Regressor. We take the default settings for each model.</p>
    <p class="normal">We can use a synthetic <a id="_idIndexMarker685"/>dataset for this test. We can train each of the aforementioned models on the data stream and look at the <strong class="keyword">Mean Squared Error</strong> (<strong class="keyword">MSE</strong>) metric:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> models:
    metric = metrics.MSE()
    dataset = synth.ConceptDriftStream(
        seed=<span class="hljs-number">42</span>, position=<span class="hljs-number">500</span>, width=<span class="hljs-number">40</span>
    ).take(<span class="hljs-number">1000</span>)
    evaluate.progressive_val_score(dataset, model, metric)
    print(<span class="hljs-string">f"</span><span class="hljs-subst">{</span><span class="hljs-built_in">str</span><span class="hljs-subst">(model.__class__).split(</span><span class="hljs-string">'.'</span><span class="hljs-subst">)[-</span><span class="hljs-number">1</span><span class="hljs-subst">][:-</span><span class="hljs-number">2</span><span class="hljs-subst">]}</span><span class="hljs-string">: </span><span class="hljs-subst">{metric.get():e}</span><span class="hljs-string">"</span>)
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">evaluate.progressive_val_score</code> method iterates over each point of the dataset and updates the metric. We get the following result:</p>
    <pre class="programlisting code"><code class="hljs-code">HoeffdingTreeRegressor: 8.427388e+42
HoeffdingAdaptiveTreeRegressor: 8.203782e+42 AdaptiveRandomForestRegressor: 1.659533037987239+42
</code></pre>
    <p class="normal">Your results might vary a bit because of the nature of these algorithms. We could set a random number generator <a id="_idIndexMarker686"/>seed to avoid this, however, I found it worth emphasizing this point.</p>
    <p class="normal">We see the model error (MSE) in scientific notation, which helps in understanding the numbers, since they are quite large. You see the errors expressed in two parts, first a factor and then the order of magnitude as exponents to ten. The orders of magnitudes are the same for the three models, however, the Adaptive Random Forest Regressor obtained about a fifth of the error of what the other two got.</p>
    <p class="normal">We can also visualize the error over time as the models learn and adapt:</p>
    <figure class="mediaobject"><img src="../Images/B17577_08_07.png" alt="performance_adaptive_models.png"/></figure>
    <p class="packt_figref">Figure 8.12: Model performance for a concept drift data stream (MSE)</p>
    <p class="normal">There's no non-adaptive version of the random forest algorithm in River, so we can't compare this. We can't draw a clear conclusion about whether adaptive algorithms actually work better.</p>
    <p class="normal">There are lots of other models, meta models, and preprocessors to try out if you want to have a play around.</p>
    <h2 id="_idParaDest-135" class="title">Model selection</h2>
    <p class="normal">We've mentioned model selection with multi-armed bandits earlier in this chapter, and here we'll go through <a id="_idIndexMarker687"/>a practical example. This is based on documentation in River.</p>
    <p class="normal">Let's use <code class="Code-In-Text--PACKT-">UCBRegressor</code> to select the best learning rate for a linear regression model. The same pattern can be used more generally to select between any set of (online) regression models.</p>
    <p class="normal">First, we define the models:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> river <span class="hljs-keyword">import</span> compose
<span class="hljs-keyword">from</span> river <span class="hljs-keyword">import</span> linear_model
<span class="hljs-keyword">from</span> river <span class="hljs-keyword">import</span> preprocessing
<span class="hljs-keyword">from</span> river <span class="hljs-keyword">import</span> optim
models = [
    compose.Pipeline(
        preprocessing.StandardScaler(),
        linear_model.LinearRegression(optimizer=optim.SGD(lr=lr))
    )
    <span class="hljs-keyword">for</span> lr <span class="hljs-keyword">in</span> [<span class="hljs-number">1e-4</span>, <span class="hljs-number">1e-3</span>, <span class="hljs-number">1e-2</span>, <span class="hljs-number">1e-1</span>]
]
</code></pre>
    <p class="normal">We build and evaluate our models on the TrumpApproval dataset:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> river <span class="hljs-keyword">import</span> datasets
dataset = datasets.TrumpApproval()
</code></pre>
    <p class="normal">We'll apply the UCB bandit, which calculates reward for regression models:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> river.expert <span class="hljs-keyword">import</span> UCBRegressor
bandit = UCBRegressor(models=models, seed=<span class="hljs-number">1</span>)
</code></pre>
    <p class="normal">The bandit provides methods to train its models in an online fashion:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> dataset:
    bandit = bandit.learn_one(x=x, y=y)
</code></pre>
    <p class="normal">We can inspect the number of times (as a percentage) each arm has been pulled.</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">for</span> model, pct <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(bandit.models, bandit.percentage_pulled):
    lr = model[<span class="hljs-string">"LinearRegression"</span>].optimizer.learning_rate
    print(<span class="hljs-string">f"</span><span class="hljs-subst">{lr:</span><span class="hljs-number">.1</span><span class="hljs-subst">e}</span><span class="hljs-string"> — </span><span class="hljs-subst">{pct:</span><span class="hljs-number">.2</span><span class="hljs-subst">%}</span><span class="hljs-string">"</span>)
</code></pre>
    <p class="normal">The percentages <a id="_idIndexMarker688"/>for the four models are as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">1.0e-04 — 2.45%
1.0e-03 — 2.45%
1.0e-02 — 92.25%
1.0e-01 — 2.85%
</code></pre>
    <p class="normal">We can also look at the average reward of each model:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">for</span> model, avg <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(bandit.models, bandit.average_reward):
    lr = model[<span class="hljs-string">"LinearRegression"</span>].optimizer.learning_rate
    print(<span class="hljs-string">f"</span><span class="hljs-subst">{lr:</span><span class="hljs-number">.1</span><span class="hljs-subst">e}</span><span class="hljs-string"> — </span><span class="hljs-subst">{avg:</span><span class="hljs-number">.2</span><span class="hljs-subst">f}</span><span class="hljs-string">"</span>)
</code></pre>
    <p class="normal">The reward is as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">1.0e-04 — 0.00
1.0e-03 — 0.00
1.0e-02 — 0.74
1.0e-01 — 0.05
</code></pre>
    <p class="normal">We can also plot the reward over time as it gets updated based on model performance:</p>
    <figure class="mediaobject"><img src="../Images/B17577_08_08.png" alt="bandit_reward.png"/></figure>
    <p class="packt_figref">Figure 8.13: Reward over time</p>
    <p class="normal">You can see that the rewards slowly become known as we step through the data and the models get updated. The model rewards clearly separate at around 100 time steps, and at around 1,000 time steps, seem to have converged.</p>
    <p class="normal">We can also plot the <a id="_idIndexMarker689"/>percentage of the time each of the different models have been chosen at each step (this is based on the reward):</p>
    <figure class="mediaobject"><img src="../Images/B17577_08_09.png" alt="bandit_percentage.png"/></figure>
    <p class="packt_figref">Figure 8.14: Ratios of models chosen over time</p>
    <p class="normal">This distribution roughly follows the reward distribution over time. This should be expected since the model choice depends on reward (and a random number that regulates exploration).</p>
    <p class="normal">We can also select the best model (the one with the highest average reward).</p>
    <pre class="programlisting code"><code class="hljs-code">best_model = bandit.best_model
</code></pre>
    <p class="normal">The learning rate chosen by the bandit is:</p>
    <pre class="programlisting code"><code class="hljs-code">best_model[<span class="hljs-string">"LinearRegression"</span>].intercept_lr.learning_rate
</code></pre>
    <p class="normal">The learning rate is 0.01.</p>
    <h1 id="_idParaDest-136" class="title">Summary</h1>
    <p class="normal">In this chapter, we've discussed online learning. We've talked about some of the advantages of online learning methods:</p>
    <ul>
      <li class="bullet">They are efficient and can handle high-speed throughput</li>
      <li class="bullet">They can work on very large datasets</li>
      <li class="bullet">And they can adjust to changes in data distributions</li>
    </ul>
    <p class="normal">Concept drift is a change in the relationship between data and the target to learn. We've talked about the importance of drift, which is that the performance of a machine learning model can be strongly affected by changes to the dataset to the point that a model will become obsolete (stale).</p>
    <p class="normal">Drift detectors don't monitor the data itself, but they are used to monitor model performance. Drift detectors can make stream learning methods robust against concept drift, and in River, many adaptive models use a drift detector for partial resets or for changing learning parameters. Adaptive models are algorithms that combine drift detection methods to avoid the degradation of performance or costly retraining. We've given an overview of a few adaptive learning algorithms.</p>
    <p class="normal">In the Python practice, we've played around with a few of the algorithms in the River library, including drift detection, regression, and model selection with a multi-armed bandit approach.</p>
  </div>
</body></html>