- en: '*Appendix*'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: About
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section is included to assist the students to perform the activities present
    in the book. It includes detailed steps that are to be performed by the students
    to complete and achieve the objectives of the book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Chapter 1: Introduction to Clustering'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Activity 1: Implementing k-means Clustering'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load the Iris data file using pandas, a package that makes data wrangling much
    easier through the use of DataFrames:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Separate out the `X` features and the provided `y` species labels, since we
    want to treat this as an unsupervised learning problem:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Get an idea of what our features look like:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.22: First five rows of the data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_01_22.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.22: First five rows of the data'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Bring back the `k_means` function we made earlier for reference:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Convert our Iris `X` feature DataFrame to a `NumPy` matrix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run our `k_means` function on the Iris matrix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'See what labels we get by looking at just the list of predicted species per
    sample:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.23: List of predicted species'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_01_23.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.23: List of predicted species'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Visualize how our k-means implementation performed on the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.24: Plot of performed k-means implementation'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_01_24.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.24: Plot of performed k-means implementation'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Visualize the clusters of Iris species as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.25: Clusters of Iris species'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_01_25.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.25: Clusters of Iris species'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Calculate the Silhouette Score using scikit-learn implementation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You will get an SSI roughly equal to 0.369\. Since we are only using two features,
    this is acceptable, combined with the visualization of cluster memberships seen
    in the final plot.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Chapter 2: Hierarchical Clustering'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Activity 2: Applying Linkage Criteria'
  prefs: []
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Visualize the `x` dataset that we created in *Exercise 7*, *Building a Hierarchy*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.20: A scatter plot of the generated cluster dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_02_20.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.20: A scatter plot of the generated cluster dataset'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Create a list with all the possible linkage method hyperparameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Loop through each of the methods in the list that you just created and display
    the effect that they have on the same dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.21: A scatter plot for all the methods'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_02_21.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.21: A scatter plot for all the methods'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see from the preceding plots, by simply changing the linkage criteria,
    you can dramatically change the efficacy of your clustering. In this dataset,
    centroid and average linkage work best at finding discrete clusters that make
    sense. This is clear from the fact that we generated a dataset of eight clusters,
    and centroid and average linkage are the only ones that show the clusters that
    are represented using eight different colors. The other linkage types fall short
    â€“ most noticeably, single linkage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 3: Comparing k-means with Hierarchical Clustering'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary packages from scikit-learn (`KMeans`, `AgglomerativeClustering`,
    and `silhouette_score`), as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Read the wine dataset into the pandas DataFrame and print a small sample:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.22: The output of the wine dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_02_22.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.22: The output of the wine dataset'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Visualize the wine dataset to understand the data structure:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.23: A plot of raw wine data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_02_23.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.23: A plot of raw wine data'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Use the sklearn implementation of k-means on the wine dataset, knowing that
    there are three wine types:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the sklearn implementation of hierarchical clustering on the wine dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the predicted clusters from k-means, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.24: A plot of clusters from k-means clustering'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_02_24.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.24: A plot of clusters from k-means clustering'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Plot the predicted clusters from hierarchical clustering, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.25: A plot of clusters from agglomerative clustering'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_02_25.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.25: A plot of clusters from agglomerative clustering'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Compare the silhouette score of each clustering method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.26: Silhouette scores for the wine dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_02_26.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.26: Silhouette scores for the wine dataset'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see from the preceding silhouette metric, agglomerative clustering
    narrowly beats k-means clustering when it comes to separating the clusters by
    mean intra-cluster distance. This is not the case for every version of agglomerative
    clustering, however. Instead, try different linkage types and examine how the
    silhouette score and clustering changes between each!
  prefs: []
  type: TYPE_NORMAL
- en: 'Chapter 3: Neighborhood Approaches and DBSCAN'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Activity 4: Implement DBSCAN from Scratch'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate a random cluster dataset as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Visualize the generated data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.14: Plot of generated data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_03_14.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.14: Plot of generated data'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Create functions from scratch that allow you to call DBSCAN on a dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use your created DBSCAN implementation to find clusters in the generated dataset.
    Feel free to use hyperparameters as you see fit, tuning them based on their performance
    in step five:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Visualize the clustering performance of your DBSCAN implementation from scratch:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.15: Plot of DBSCAN implementation'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_03_15.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.15: Plot of DBSCAN implementation'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you may have noticed, it takes quite some time for a custom implementation
    to run. This is because we explored the non-vectorized version of this algorithm
    for the sake of clarity. Moving forward, you should aim to use the DBSCAN implementation
    provided by scikit-learn, as it is highly optimized.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 5: Comparing DBSCAN with k-means and Hierarchical Clustering'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the wine dataset from *Chapter 2*, *Hierarchical Clustering* and familiarize
    yourself again with what the data looks like:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.16: First five rows of wine dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_03_16.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.16: First five rows of wine dataset'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Visualize the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.17: Plot of the data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_03_17.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.17: Plot of the data'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Generate clusters using k-means, agglomerative clustering, and DBSCAN:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Evaluate a few different options for DSBSCAN hyperparameters and their effect
    on the silhouette score:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.18: Printing the silhouette score for clusters'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_03_18.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.18: Printing the silhouette score for clusters'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Generate the final clusters based on the highest silhouette score (`eps`: 35,
    `min_samples`: 3):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Visualize clusters generated using each of the three methods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.19: Plot of clusters using different algorithms'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_03_19.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.19: Plot of clusters using different algorithms'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Evaluate the silhouette score of each approach:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.20: Silhouette score'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_03_20.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.20: Silhouette score'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see, DBSCAN isn't automatically the best choice for your clustering
    needs. One key trait that makes it different form other algorithms is the use
    of noise as a potential clustering. In some cases, this is great, as it removes
    outliers, however, there may be situations where it is not tuned well enough and
    classifies too many points as noise. Can you improve the silhouette score by tuning
    the hyperparameters?
  prefs: []
  type: TYPE_NORMAL
- en: 'Chapter 4: Dimension Reduction and PCA'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Activity 6: Manual PCA versus scikit-learn'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Solution
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the `pandas`, `numpy`, and `matplotlib` plotting libraries and the scikit-learn
    `PCA` model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the dataset and select only the sepal features as per the previous exercises.
    Display the first five rows of the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.43: The first five rows of the data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_04_43.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.43: The first five rows of the data'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Compute the `covariance` matrix for the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.44: The covariance matrix for the data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_04_44.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.44: The covariance matrix for the data'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Transform the data using the scikit-learn API and only the first principal
    component. Store the transformed data in the `sklearn_pca` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Transform the data using the manual PCA and only the first principal component.
    Store the transformed data in the `manual_pca` variable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the `sklearn_pca` and `manual_pca` values on the same plot to visualize
    the difference:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.45: A plot of the data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_04_45.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.45: A plot of the data'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Notice that the two plots look almost identical, except that one is a mirror
    image of another and there is an offset between the two. Display the components
    of the `sklearn_pca` and `manual_pca` models:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now print `P`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Notice the difference in the signs; the values are identical, but the signs
    are different, producing the mirror image result. This is just a difference in
    convention, nothing meaningful.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Multiply the `manual_pca` models by `-1` and re-plot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.46: Re-plotted data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_04_46.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.46: Re-plotted data'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, all we need to do is deal with the offset between the two. The scikit-learn
    API subtracts the mean of the data prior to the transform. Subtract the mean of
    each column from the dataset before completing the transform with manual PCA:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Multiply the result by `-1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Re-plot the individual `sklearn_pca` and `manual_pca` values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.47: Re-plotting the data'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_04_47.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.47: Re-plotting the data'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The final plot will demonstrate that the dimensionality reduction completed
    by the two methods are, in fact, the same. The differences lie in the differences
    in the signs of the `covariance` matrices, as the two methods simply use a different
    feature as the baseline for comparison. Finally, there is also an offset between
    the two datasets, which is attributed to the mean samples being subtracted before
    executing the transform in the scikit-learn PCA.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 7: PCA Using the Expanded Iris Dataset'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pandas` and `matplotlib`. To enable 3D plotting, you will also need
    to import `Axes3D`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Read in the dataset and select the columns `Sepal Length`, `Sepal Width`, and
    `Petal Width`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.48: Sepal Length, Sepal Width, and Petal Width'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_04_48.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.48: Sepal Length, Sepal Width, and Petal Width'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Plot the data in three dimensions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.49: Expanded Iris dataset plot'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_04_49.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.49: Expanded Iris dataset plot'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Create a `PCA` model without specifying the number of components:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the model to the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.50: The model fitted to the dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_04_50.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.50: The model fitted to the dataset'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Display the eigenvalues or `explained_variance_ratio_`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We want to reduce the dimensionality of the dataset, but still keep at least
    90% of the variance. What are the minimum number of components required to keep
    90% of the variance?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The first two components are required for at least 90% variance. The first two
    components provide 94.7% of the variance within the dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a new `PCA` model, this time specifying the number of components required
    to keep at least 90% of the variance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Transform the data using the new model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the transformed data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.51: Plot of the transformed data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_04_51.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.51: Plot of the transformed data'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Restore the transformed data to the original dataspace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the restored data in three dimensions in one subplot and the original
    data in a second subplot to visualize the effect of removing some of the variance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.52: Plot of the expanded and the restored Iris datasets'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_04_52.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.52: Plot of the expanded and the restored Iris datasets'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Looking at *Figure 4.52*, we can see that, as we did with the 2D plots, we have
    removed much of the noise within the data, but retained the most important information
    regarding the trends within the data. It can be seen that in general, the sepal
    length increases with the petal width and that there seems to be two clusters
    of data within the plots, one sitting above the other.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When applying PCA, it is important to keep in mind the size of the data being
    modelled, as well as the available system memory. The singular value decomposition
    process involves separating the data into the eigenvalues and eigenvectors, and
    can be quite memory intensive. If the dataset is too large, you may either be
    unable to complete the process, suffer significant performance loss, or lock up
    your system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Chapter 5: Autoencoders'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Activity 8: Modeling Neurons with a ReLU Activation Function'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `numpy` and matplotlib:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Allow latex symbols to be used in labels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the ReLU activation function as a Python function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the inputs (`x`) and tunable weights (`theta`) for the neuron. In this
    example, the inputs (`x`) will be 100 numbers linearly spaced between -5 and 5\.
    Set `theta = 1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.35: Printing the inputs'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_05_35.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.35: Printing the inputs'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Compute the output (`y`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the output of the neuron versus the input:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.36: Plot of the neuron versus input'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_05_36.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.36: Plot of the neuron versus input'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, set `theta = 5` and recompute and store the output of the neuron:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, set `theta = 0.2` and recompute and store the output of the neuron:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the three different output curves of the neuron (`theta = 1`, `theta =
    5`, `theta = 0.2`) on one graph:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.37: Three output curves of the neuron'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_05_37.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.37: Three output curves of the neuron'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In this activity, we created a model of a ReLU-based artificial neural network
    neuron. We can see that the output of this neuron is very different to the sigmoid
    activation function. There is no saturation region for values greater than 0 because
    it simply returns the input value of the function. In the negative direction,
    there is a saturation region where only 0 will be returned if the input is less
    than 0\. The ReLU function is an extremely powerful and commonly used activation
    function that has shown to be more powerful than the sigmoid function in some
    circumstances. ReLU is often a good first-choice activation function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 9: MNIST Neural Network'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this activity, you will train a neural network to identify images in the
    MNIST dataset and reinforce your skills in training neural networks:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pickle`, `numpy`, `matplotlib`, and the `Sequential` and `Dense` classes
    from Keras:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the `mnist.pkl` file, which contains the first 10,000 images and corresponding
    labels from the MNIST dataset that are available in the accompanying source code.
    The MNIST dataset is a series of 28 x 28 grayscale images of handwritten digits
    0 through 9\. Extract the images and labels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the first 10 samples along with the corresponding labels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.38: First 10 samples'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_05_38.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.38: First 10 samples'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Encode the labels using one hot encoding:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.39: Result of one hot encoding'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_05_39.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.39: Result of one hot encoding'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Prepare the images for input into a neural network. As a hint, there are two
    separate steps in this process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Construct a neural network model in Keras that accepts the prepared images,
    has a hidden layer of 600 units with a ReLU activation function, and an output
    of the same number of units as classes. The output layer uses a `softmax` activation
    function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compile the model using multiclass cross-entropy, stochastic gradient descent,
    and an accuracy performance metric:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Train the model. How many epochs are required to achieve at least 95% classification
    accuracy on the training data? Let''s have a look:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.40: Training the model'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_05_40.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.40: Training the model'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 15 epochs are required to achieve at least 95% classification accuracy on the
    training set.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we have measured the performance of the neural network classifier
    using the data that the classifier was trained with. In general, this method should
    not be used as it typically reports a higher level of accuracy than one should
    expect from the model. In supervised learning problems, there are a number of
    **cross-validation** techniques that should be used instead. As this is a book
    on unsupervised learning, cross-validation lies outside the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 10: Simple MNIST Autoencoder'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pickle`, `numpy`, and `matplotlib`, and the `Model`, `Input`, and `Dense`
    classes from Keras:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the images from the supplied sample of the MNIST dataset that is provided
    with the accompanying source code (`mnist.pkl`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Prepare the images for input into a neural network. As a hint, there are **two**
    separate steps in this process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Construct a simple autoencoder network that reduces the image size to 10 x
    10 after the encoding stage:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compile the autoencoder using a binary cross-entropy loss function and `adadelta`
    gradient descent:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the encoder model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.41: Training the model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_05_41.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.41: Training the model'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Calculate and store the output of the encoding stage for the first five samples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Reshape the encoder output to 10 x 10 (10 x 10 = 100) pixels and multiply by
    255:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calculate and store the output of the decoding stage for the first five samples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Reshape the output of the decoder to 28 x 28 and multiply by 255:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the original image, the encoder output, and the decoder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.42: The original image, the encoder output, and the decoder'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_05_42.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.42: The original image, the encoder output, and the decoder'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: So far, we have shown how a simple single hidden layer in both the encoding
    and decoding stage can be used to reduce the data to a lower dimension space.
    We can also make this model more complicated by adding additional layers to both
    the encoding and the decoding stages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 11: MNIST Convolutional Autoencoder'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pickle`, `numpy`, `matplotlib`, and the `Model` class from `keras.models`
    and import `Input`, `Conv2D`, `MaxPooling2D`, and `UpSampling2D` from `keras.layers`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Rescale the images to have values between 0 and 1:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We need to reshape the images to add a single depth channel for use with convolutional
    stages. Reshape the images to have a shape of 28 x 28 x 1:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define an input layer. We will use the same shape input as an image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add a convolutional stage with 16 layers or filters, a 3 x 3 weight matrix,
    a ReLU activation function, and using same padding, which means the output has
    the same length as the input image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add a max pooling layer to the encoder with a 2 x 2 kernel:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add a decoding convolutional layer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add an upsampling layer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the final convolutional stage, using one layer as per the initial image
    depth:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Construct the model by passing the first and last layers of the network to
    the `Model` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Display the structure of the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.43: Structure of model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_05_43.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.43: Structure of model'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Compile the autoencoder using a binary cross-entropy loss function and `adadelta`
    gradient descent:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let''s fit the model; again, we pass the images as the training data and
    as the desired output. Train for 20 epochs as convolutional networks take a lot
    longer to compute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.44: Training the model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_05_44.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.44: Training the model'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Calculate and store the output of the encoding stage for the first five samples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Reshape the encoder output for visualization, where each image is X*Y in size:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Get the output of the decoder for the first five images:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Reshape the decoder output to 28 x 28 in size:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Reshape the original images back to 28 x 28 in size:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the original image, the mean encoder output, and the decoder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.45: The original image, the encoder output, and the decoder'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_05_45.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.45: The original image, the encoder output, and the decoder'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: At the end of this activity, you will have developed an autoencoder comprising
    convolutional layers within the neural network. Note the improvements made in
    the decoder representations. This architecture has a significant performance benefit
    over fully-connected neural network layers and is extremely useful in working
    with image-based datasets and generating artificial data samples.
  prefs: []
  type: TYPE_NORMAL
- en: 'Chapter 6: t-Distributed Stochastic Neighbor Embedding (t-SNE)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Activity 12: Wine t-SNE'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pandas`, `numpy`, `matplotlib`, and the `t-SNE` and `PCA` models from
    scikit-learn:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the Wine dataset using the `wine.data` file included in the accompanying
    source code and display the first five rows of data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.24: The first five rows of the wine dataset.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_06_24.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.24: The first five rows of the wine dataset.'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The first column contains the labels; extract this column and remove it from
    the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Execute PCA to reduce the dataset to the first six components:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Determine the amount of variance within the data described by these six components:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a t-SNE model using a specified random state and a `verbose` value of
    1:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.25: Creating t-SNE model.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_06_25.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.25: Creating t-SNE model.'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Fit the PCA data to the t-SNE model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.26: Fitting PCA data t-SNE model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_06_26.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.26: Fitting PCA data t-SNE model'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Confirm that the shape of the t-SNE fitted data is two dimensional:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a scatter plot of the two-dimensional data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.27: Scatterplot of two-dimensional data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_06_27.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.27: Scatterplot of two-dimensional data'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Create a secondary scatter plot of the two-dimensional data with the class
    labels applied to visualize any clustering that may be present:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.28: Secondary plot of two-dimensional data'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_06_28.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.28: Secondary plot of two-dimensional data'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note that while there is an overlap between the wine classes, it can also be
    seen that there is some clustering within the data. The first wine class is predominantly
    positioned in the top left-hand corner of the plot, the second wine class in the
    bottom-right, and the third wine class between the first two. This representation
    certainly couldn't be used to classify individual wine samples with great confidence,
    but it shows an overall trend and series of clusters contained within the high-dimensional
    data that we were unable to see earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 13: t-SNE Wine and Perplexity'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pandas`, `numpy`, `matplotlib`, and the `t-SNE` and `PCA` models from
    scikit-learn:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the Wine dataset and inspect the first five rows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.29: The first five rows of wine data.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_06_29.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.29: The first five rows of wine data.'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The first column provides the labels; extract them from the DataFrame and store
    them in a separate variable. Ensure that the column is removed from the DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Execute PCA on the dataset and extract the first six components:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE123]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Construct a loop that iterates through the perplexity values (1, 5, 20, 30,
    80, 160, 320). For each loop, generate a t-SNE model with the corresponding perplexity
    and print a scatter plot of the labeled wine classes. Note the effect of different
    perplexity values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'A perplexity value of 1 fails to separate the data into any particular structure:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.30: Plot for perplexity value 1'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_06_30.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.30: Plot for perplexity value 1'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Increasing the perplexity to 5 leads to a very non-linear structure that is
    difficult to separate, and it''s hard to identify any clusters or patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.31: Plot for perplexity of 5'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_06_31.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.31: Plot for perplexity of 5'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'A perplexity of 20 finally starts to show some sort of horse-shoe structure.
    While visually obvious, this can still be tricky to implement:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.32: Plot for perplexity of 20'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_06_32.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.32: Plot for perplexity of 20'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'A perplexity of 30 demonstrates quite good results. There is a linear relationship
    between the projected structure with some separation between the types of wine:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.33: Plot for perplexity of 30'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_06_33.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.33: Plot for perplexity of 30'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Finally, the last two images in the activity show the extent to which the plots
    can become increasingly complex and non-linear with increasing perplexity:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.34: Plot for perplexity of 80'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_06_34.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.34: Plot for perplexity of 80'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Here''s the plot for a perplexity of 160:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.35: Plot for perplexity of 160'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_06_35.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.35: Plot for perplexity of 160'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Looking at the individual plots for each of the perplexity values, the effect
    perplexity has on the visualization of data is immediately obvious. Very small
    or very large perplexity values produces a range of unusual shapes that don't
    indicate the presence of any persistent pattern. The most plausible value seems
    to be 30, which produced the most linear plot we saw in the previous activity.
  prefs: []
  type: TYPE_NORMAL
- en: In this activity, we demonstrated the need to be careful when selecting the
    perplexity and that some iteration may be required to determine the correct value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 14: t-SNE Wine and Iterations'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pandas`, `numpy`, `matplotlib`, and the `t-SNE` and `PCA` models from
    scikit-learn:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE125]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the Wine dataset and inspect the first five rows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE126]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.36: The first five rows of wine dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_06_36.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.36: The first five rows of wine dataset'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The first column provides the labels; extract these from the DataFrame and
    store them in a separate variable. Ensure that the column is removed from the
    DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE127]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Execute PCA on the dataset and extract the first six components:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Construct a loop that iterates through the iteration values (`250`, `500`,
    `1000`). For each loop, generate a t-SNE model with the corresponding number of
    iterations and identical number of iterations without progress values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Construct a scatter plot of the labeled wine classes. Note the effect of different
    iteration values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE130]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.37: Scatterplot of wine classes with 250 iterations'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_06_37.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.37: Scatterplot of wine classes with 250 iterations'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Here''s the plot for 500 iterations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.38: Scatterplot of wine classes with 500 iterations'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_06_38.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.38: Scatterplot of wine classes with 500 iterations'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Here''s the plot for 1,000 iterations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.39: Scatterplot of wine classes with 1,000 iterations'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_06_39.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6.39: Scatterplot of wine classes with 1,000 iterations'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Again, we can see the improvement in the structure of the data as the number
    of iterations increase. Even in a relatively simple dataset such as this, 250
    iterations are not sufficient to project any structure of data into the lower-dimensional
    space.
  prefs: []
  type: TYPE_NORMAL
- en: As we observed in the corresponding activity, there is a balance to find in
    setting the iteration parameter. In this example, 250 iterations were insufficient,
    and at least 1,000 iterations were required for the final stabilization of the
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Chapter 7: Topic Modeling'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Activity 15: Loading and Cleaning Twitter Data'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE131]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the LA Times health Twitter data (`latimeshealth.txt`) from [https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-Python/tree/master/Lesson07/Activity15-Activity17](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-Python/tree/master/Lesson07/Activity15-Activity17):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run a quick exploratory analysis to ascertain the data size and structure:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE133]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.54: Shape, column names, and head of data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_07_54.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.54: Shape, column names, and head of data'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Extract the tweet text and convert it to a list object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.55: Headlines and their length'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_07_55.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.55: Headlines and their length'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Write a function to perform language detection, tokenization on whitespaces,
    and replace screen names and URLs with `SCREENNAME` and `URL`, respectively. The
    function should also remove punctuation, numbers, and the `SCREENNAME` and `URL`
    replacements. Convert everything to lowercase, except `SCREENNAME` and `URL`.
    It should remove all stop words, perform lemmatization, and keep words with five
    or more letters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Apply the function defined in *step 5* to every tweet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Remove elements of output list equal to `None`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE137]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.56: Headline and length after removing None'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_07_56.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.56: Headline and length after removing None'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Turn the elements of each tweet back into a string. Concatenate using white
    space:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The first 10 elements of the output list should resemble the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.57: Tweets cleaned for modeling'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_07_57.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.57: Tweets cleaned for modeling'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Keep the notebook open for future modeling.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Activity 16: Latent Dirichlet Allocation and Health Tweets'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Specify the `number_words`, `number_docs`, and `number_features` variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE139]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a bag-of-words model and assign the feature names to another variable
    for use later on:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE140]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE141]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Identify the optimal number of topics:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE142]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.58: Number of topics versus perplexity score data frame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_07_58.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.58: Number of topics versus perplexity score data frame'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Fit the LDA model using the optimal number of topics:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE143]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.59: LDA model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_07_59.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.59: LDA model'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Create and print the word-topic table:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE144]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.60: Word-topic table for the health tweet data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_07_60.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.60: Word-topic table for the health tweet data'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Print the document-topic table:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE145]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.61: Document topic table'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_07_61.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.61: Document topic table'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Create a biplot visualization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE146]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 7.62: A histogram and biplot for the LDA model trained on health tweets'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_07_62.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.62: A histogram and biplot for the LDA model trained on health tweets'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Keep the notebook open for future modeling.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Activity 17: Non-Negative Matrix Factorization'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the appropriate bag-of-words model and output the feature names as another
    variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE147]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define and fit the NMF algorithm using the number of topics (`n_components`)
    value from activity two:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE148]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.63: Defining the NMF model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_07_63.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.63: Defining the NMF model'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Get the topic-document and word-topic result tables. Take a few minutes to
    explore the word groupings and try to define the abstract topics:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE149]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 7.64: The word-topic table with probabilities'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_07_64.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.64: The word-topic table with probabilities'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Adjust the model parameters and rerun *step 3* and *step 4*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Chapter 8: Market Basket Analysis'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Activity 18: Loading and Preparing Full Online Retail Data'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load the online retail dataset file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE150]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Clean and prep the data for modeling, including turning the cleaned data into
    a list of lists:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE151]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Encode the data and recast it as a DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE152]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.35: A subset of the cleaned, encoded, and recast DataFrame built
    from the complete online retail dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_08_35.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.35: A subset of the cleaned, encoded, and recast DataFrame built from
    the complete online retail dataset'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Activity 19: Apriori on the Complete Online Retail Dataset'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the Apriori algorithm on the full data with reasonable parameter settings:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE153]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.36: The Apriori algorithm results using the complete online retail
    dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_08_36.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 8.36: The Apriori algorithm results using the complete online retail
    dataset'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Filter the results down to the item set containing `10 COLOUR SPACEBOY PEN`.
    Compare the support value with that under *Exercise 44*, *Executing the Apriori
    algorithm*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE154]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.37: Result of item set containing 10 COLOUR SPACEBOY PEN'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_08_37.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 8.37: Result of item set containing 10 COLOUR SPACEBOY PEN'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: The support value does change. When the dataset is expanded to include all transactions,
    the support for this item set increases from 0.015 to 0.015793\. That is, in the
    reduced dataset used for the exercises, this item set appears in 1.5% of the transactions,
    while in the full dataset, it appears in approximately 1.6% of transactions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Add another column containing the item set length. Then, filter down to those
    item sets whose length is two and whose support is in the range [0.02, 0.021].
    Are the item sets the same as those found in *Exercise 44*, *Executing the Apriori
    algorithm,* *Step 6*?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE155]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 8.38: The section of the results of filtering based on length and
    support'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_08_38.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 8.38: The section of the results of filtering based on length and support'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: The results did change. Before even looking at the particular item sets and
    their support values, we see that this filtered DataFrame has fewer item sets
    than the DataFrame in the previous exercise. When we use the full dataset, there
    are fewer item sets that match the filtering criteria; that is, only 14 item sets
    contain 2 items and have a support value greater than or equal to 0.02, and less
    than 0.021\. In the previous exercise, 17 item sets met these criteria.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Plot the `support` values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE156]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 8.39: The distribution of support values'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_08_27.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.39: The distribution of support values'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This plot shows the distribution of support values for the full transaction
    dataset. As you might have assumed, the distribution is right skewed; that is,
    most of the item sets have lower support values and there is a long tail of support
    values on the higher end of the spectrum. Given how many unique item sets exist,
    it is not surprising that no single item set appears in a high percentage of the
    transactions. With this information, we could tell management that even the most
    prominent item set only appears in approximately 10% of the transactions, and
    that the vast majority of item sets appear in less than 2% of transactions. These
    results may not support changes in store layout, but could very well inform pricing
    and discounting strategies. We would gain more information on how to build these
    strategies by formalizing some association rules.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 20: Finding the Association Rules on the Complete Online Retail Dataset'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Fit the association rule model on the full dataset. Use metric confidence and
    a minimum threshold of 0.6:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE157]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.40: The association rules based on the complete online retail dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_08_40.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 8.40: The association rules based on the complete online retail dataset'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Count the number of association rules. Is the number different to that found
    in *Exercise 45*, *Deriving Association Rules*, *Step 1*?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE158]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: There are `498` association rules.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Plot confidence against support:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE159]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.41: The plot of confidence against support'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_08_41.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 8.41: The plot of confidence against support'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: The plot reveals that there are some association rules featuring relatively
    high support and confidence values for this dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Look at the distributions of lift, leverage, and conviction:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE160]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.42: The distribution of lift values'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_08_42.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.42: The distribution of lift values'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[PRE161]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.43: The distribution of leverage values'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_08_43.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.43: The distribution of leverage values'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[PRE162]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.44: The distribution of conviction values'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_08_44.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.44: The distribution of conviction values'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Having derived association rules, we can return to management with additional
    information, the most important of which would be that there are roughly seven
    item sets that have reasonably high values for both support and confidence. Look
    at the scatterplot of confidence against support to see the seven item sets that
    are separated from all the others. These seven item sets also have high lift values,
    as can be seen in the lift histogram. It seems that we have identified some actionable
    association rules, rules that we can use to drive business decisions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Chapter 9: Hotspot Analysis'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Activity 21: Estimating Density in One Dimension'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new notebook and install all the necessary libraries.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE163]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Sample 1,000 data points from the standard normal distribution. Add 3.5 to
    each of the last 625 values of the sample (that is, the indices between 375 and
    1,000). To do this, set a random state of 100 using `numpy.random.RandomState`
    to guarantee the same sampled values, and then randomly generate the data points
    using the `randn(1000)` call:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE164]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the 1,000-point sample data as a histogram and add a scatterplot below
    it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE165]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.29: A histogram of the random sample with a scatterplot underneath'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_09_29.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9.29: A histogram of the random sample with a scatterplot underneath'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Define a grid of bandwidth values. Then, define and fit a grid search cross-validation
    algorithm:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE166]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Extract the optimal bandwidth value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE167]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Replot the histogram from *Step 3* and overlay the estimated density:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE168]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.30: A histogram of the random sample with the optimal estimated
    density overlaid'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_09_30.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.30: A histogram of the random sample with the optimal estimated density
    overlaid'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Activity 22: Analyzing Crime in London'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load the crime data. Use the path where you saved the downloaded directory,
    create a list of the year-month tags, use the `read_csv` command to load the individual
    files iteratively, and then concatenate these files together:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE169]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.31: An example of one of the individual crime files'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_09_31.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9.31: An example of one of the individual crime files'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: This printed information is just for the first of the loaded files, which will
    be the criminal information from the Metropolitan Police Service for July 2018\.
    This one file has nearly 100,000 entries. You will notice that there is a great
    deal of interesting information in this dataset, but we will focus on `Longitude`,
    `Latitude`, `Month`, and `Crime type`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print diagnostics of the complete (six months) and concatenated dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE170]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.32: Descriptors of the full crime dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_09_32.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9.32: Descriptors of the full crime dataset'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Subset the DataFrame down to four variables (`Longitude`, `Latitude`, `Month`,
    and `Crime type`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE171]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.33: Crime data in DataFrame form subset down to the Longitude, Latitude,
    Month, and Crime type columns'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_09_33.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9.33: Crime data in DataFrame form subset down to the Longitude, Latitude,
    Month, and Crime type columns'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Using the `jointplot` function from `seaborn`, fit and visualize three kernel
    density estimation models for bicycle theft in July, September, and December 2018:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE172]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.34: The estimated joint and marginal densities for bicycle thefts
    in July 2018'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_09_34.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9.34: The estimated joint and marginal densities for bicycle thefts
    in July 2018'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: '[PRE173]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.35: The estimated joint and marginal densities for bicycle thefts
    in September 2018'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_09_35.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9.35: The estimated joint and marginal densities for bicycle thefts
    in September 2018'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: '[PRE174]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.36: The estimated joint and marginal densities for bicycle thefts
    in December 2018'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_09_36.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9.36: The estimated joint and marginal densities for bicycle thefts
    in December 2018'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: From month to month, the density of bicycle thefts stays quite constant. There
    are slight differences between the densities, which is to be expected given that
    the data that is the foundation of these estimated densities is three one-month
    samples. Given these results, police or criminologists should be confident in
    predicting where future bicycle thefts are most likely to occur.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Repeat *Step 4*; this time, use shoplifting crimes for the months of August,
    October, and November 2018:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE175]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.37: The estimated joint and marginal densities for shoplifting incidents
    in August 2018'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_09_37.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9.37: The estimated joint and marginal densities for shoplifting incidents
    in August 2018'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: '[PRE176]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.38: The estimated joint and marginal densities for shoplifting incidents
    in October 2018'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_09_38.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9.38: The estimated joint and marginal densities for shoplifting incidents
    in October 2018'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: '[PRE177]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.39: The estimated joint and marginal densities for shoplifting incidents
    in November 2018'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12626_09_39.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9.39: The estimated joint and marginal densities for shoplifting incidents
    in November 2018'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Like the bicycle theft results, the shoplifting densities are quite stable across
    the months. The density from August 2018 looks different from the other two months;
    however, if you look at the longitude and latitude values, you will notice that
    the density is very similar, but it has just shifted and scaled. The reason for
    this is that there were probably a number of outliers forcing the creation of
    a much larger plotting region.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Repeat *Step 5*; this time use burglary crimes for the months of July, October,
    and December 2018:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE178]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.40: The estimated joint and marginal densities for burglaries in
    July 2018'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_09_40.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.40: The estimated joint and marginal densities for burglaries in July
    2018'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[PRE179]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.41: The estimated joint and marginal densities for burglaries in
    October 2018'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_09_41.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.41: The estimated joint and marginal densities for burglaries in October
    2018'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[PRE180]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.42: The estimated joint and marginal densities for burglaries in
    December 2018'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12626_09_42.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.42: The estimated joint and marginal densities for burglaries in December
    2018'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Once again, we can see that the distributions are quite similar across the months.
    The only difference is that the densities seem to widen or spread from July to
    December. As always, the noise and inherent lack of information contained in the
    sample data is causing small shifts in the estimated densities.
  prefs: []
  type: TYPE_NORMAL
