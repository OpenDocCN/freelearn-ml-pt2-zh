["```py\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport pandas as pd\n%matplotlib inline\n\ncat_burrito = mpimg.imread('images/grayscale_cat_burrito.jpg')\ncat_burrito\n```", "```py\ncat_burrito.shape\n```", "```py\nprint(cat_burrito.max())\nprint(cat_burrito.min())\n```", "```py\nplt.axis('off')\nplt.imshow(cat_burrito, cmap='gray');\n```", "```py\ncolor_cat_burrito = mpimg.imread('images/color_cat_burrito.jpg')\ncolor_cat_burrito.shape\n```", "```py\nplt.axis('off')\nplt.imshow(color_cat_burrito);\n```", "```py\n# flattening our grayscale cat_burrito and checking the length\nlen(cat_burrito.flatten())\n```", "```py\nimport numpy as np\nmax_pooled = np.array([[255,255],[255,255]])\nmax_pooled\n```", "```py\nmax_pooled.shape\n```", "```py\nflattened = max_pooled.flatten()\nflattened.shape\n```", "```py\ncd ~/Desktop/\ngit clone git@github.com:zalandoresearch/fashion-mnist.git\n```", "```py\nimport sys\nimport numpy as np\nimport pandas as pd\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPool2D\nfrom keras.utils import np_utils, plot_model\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n```", "```py\nsys.path.append('/Users/Mike/Desktop/fashion-mnist/utils/')\nimport mnist_reader\n```", "```py\nX_train, y_train = mnist_reader.load_mnist('/Users/Mike/Desktop/fashion-mnist/data/fashion', kind='train')\nX_test, y_test = mnist_reader.load_mnist('/Users/Mike/Desktop/fashion-mnist/data/fashion', kind='t10k')\n```", "```py\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)\n```", "```py\nprint(type(X_train))\nprint(type(y_train))\nprint(type(X_test))\nprint(type(y_test))\n```", "```py\nimage_1 = X_train[0].reshape(28,28)\nplt.axis('off')\nplt.imshow(image_1, cmap='gray');\n```", "```py\ny_train[0]\n```", "```py\nmapping = {0: \"T-shirt/top\", 1:\"Trouser\", 2:\"Pullover\", 3:\"Dress\", \n 4:\"Coat\", 5:\"Sandal\", 6:\"Shirt\", 7:\"Sneaker\", 8:\"Bag\", 9:\"Ankle Boot\"}\n```", "```py\ndef show_fashion_mnist(plot_rows, plot_columns, feature_array, target_array, cmap='gray', random_seed=None):\n '''Generates a plot_rows * plot_columns grid of randomly selected images from a feature         array. Sets the title of each subplot equal to the associated index in the target array and     unencodes (i.e. title is in plain English, not numeric). Takes as optional args a color map     and a random seed. Meant for EDA.'''\n # Grabs plot_rows*plot_columns indices at random from X_train. \n if random_seed is not None:\n np.random.seed(random_seed)\n\n feature_array_indices = np.random.randint(0,feature_array.shape[0], size = plot_rows*plot_columns)\n\n # Creates our plots\n fig, ax = plt.subplots(plot_rows, plot_columns, figsize=(18,18))\n\n reshaped_images_list = []\n\n for feature_array_index in feature_array_indices:\n # Reshapes our images, appends tuple with reshaped image and class to a reshaped_images_list.\n reshaped_image = feature_array[feature_array_index].reshape((28,28))\n image_class = mapping[target_array[feature_array_index]]\n reshaped_images_list.append((reshaped_image, image_class))\n\n # Plots each image in reshaped_images_list to its own subplot\n counter = 0\n for row in range(plot_rows):\n for col in range(plot_columns):\n ax[row,col].axis('off')\n ax[row, col].imshow(reshaped_images_list[counter][0], \n                                cmap=cmap)\n ax[row, col].set_title(reshaped_images_list[counter][1])\n counter +=1\n```", "```py\nshow_fashion_mnist(4,4, X_train, y_train, random_seed=72)\n```", "```py\nshow_fashion_mnist(4,4, X_train, y_train)\n```", "```py\ny = pd.Series(np.concatenate((y_train, y_test)))\nplt.figure(figsize=(10,6))\nplt.bar(x=[mapping[x] for x in y.value_counts().index], height = y.value_counts());\nplt.xlabel(\"Class\")\nplt.ylabel(\"Number of Images per Class\")\nplt.title(\"Distribution of Target Classes\");\n```", "```py\nprint(X_train.max())\nprint(X_train.min())\nprint(X_test.max())\nprint(X_test.min())\n```", "```py\n# First we cast as float\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n# Then normalize\nX_train /= 255\nX_test /= 255\n```", "```py\nprint(X_train.max())\nprint(X_train.min())\nprint(X_test.max())\nprint(X_test.min())\n```", "```py\nX_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n```", "```py\ny_train = np_utils.to_categorical(y_train, 10)\ny_test = np_utils.to_categorical(y_test, 10)\n```", "```py\nmodel = Sequential()\nmodel.add(Conv2D(filters = 35, kernel_size=(3,3), input_shape=(28,28,1), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters = 35, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters = 45, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n```", "```py\nmodel.summary()\n```", "```py\nplot_model(model, to_file='Conv_model1.png', show_shapes=True)\nImage.open('Conv_model1.png')\n```", "```py\nmy_fit_model = model.fit(X_train, y_train, epochs=25, validation_data=\n                        (X_test, y_test))\n```", "```py\nplt.plot(my_fit_model.history['val_loss'], label=\"Validation\")\nplt.plot(my_fit_model.history['loss'], label = \"Train\")\nplt.xlabel(\"Epoch\", size=15)\nplt.ylabel(\"Cat. Crossentropy Loss\", size=15)\nplt.title(\"Conv Net Train and Validation loss over epochs\", size=18)\nplt.legend();\n```", "```py\nplt.plot(my_fit_model.history['val_acc'], label=\"Validation\")\nplt.plot(my_fit_model.history['acc'], label = \"Train\")\nplt.xlabel(\"Epoch\", size=15)\nplt.ylabel(\"Accuracy\", size=15)\nplt.title(\"Conv Net Train and Validation accuracy over epochs\", \n           size=18)\nplt.legend();\n```", "```py\nprint(max(my_fit_model.history['val_acc']))\nprint(my_fit_model.history['val_acc'].index(max(my_fit_model.history['v\n      al_acc'])))\n```", "```py\nmodel = Sequential()\nmodel.add(Conv2D(filters = 35, kernel_size=(3,3), input_shape=\n         (28,28,1), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters = 35, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters = 45, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.35))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.35))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n```", "```py\nmodel.summary()\n```", "```py\nmy_fit_model = model.fit(X_train, y_train, epochs=25, validation_data=\n                        (X_test, y_test))\n```", "```py\nprint(max(my_fit_model.history['val_acc']))\nprint(my_fit_model.history['val_acc'].index(max(my_fit_model.history['v\n      al_acc'])))\n```"]