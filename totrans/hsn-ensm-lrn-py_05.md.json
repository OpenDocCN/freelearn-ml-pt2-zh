["```py\n# --- SECTION 1 ---\n# Import the required libraries\nfrom sklearn import datasets, linear_model, svm, neighbors\nfrom sklearn.metrics import accuracy_score\nfrom numpy import argmax\n# Load the dataset\nbreast_cancer = datasets.load_breast_cancer()\nx, y = breast_cancer.data, breast_cancer.target\n```", "```py\n# --- SECTION 2 ---\n# Instantiate the learners (classifiers)\nlearner_1 = neighbors.KNeighborsClassifier(n_neighbors=5)\nlearner_2 = linear_model.Perceptron(tol=1e-2, random_state=0)\nlearner_3 = svm.SVC(gamma=0.001)\n```", "```py\n# --- SECTION 3 ---\n# Split the train and test samples\ntest_samples = 100\nx_train, y_train = x[:-test_samples], y[:-test_samples]\nx_test, y_test = x[-test_samples:], y[-test_samples:]\n\n# Fit learners with the train data\nlearner_1.fit(x_train, y_train)\nlearner_2.fit(x_train, y_train)\nlearner_3.fit(x_train, y_train)\n```", "```py\n#--- SECTION 4 ---\n# Each learner predicts the classes of the test data\npredictions_1 = learner_1.predict(x_test)\npredictions_2 = learner_2.predict(x_test)\npredictions_3 = learner_3.predict(x_test)\n```", "```py\n# --- SECTION 5 ---\n# We combine the predictions with hard voting\nhard_predictions = []\n# For each predicted sample\nfor i in range(test_samples):\n    # Count the votes for each class\n    counts = [0 for _ in range(2)]\n    counts[predictions_1[i]] = counts[predictions_1[i]]+1\n    counts[predictions_2[i]] = counts[predictions_2[i]]+1\n    counts[predictions_3[i]] = counts[predictions_3[i]]+1\n    # Find the class with most votes\n    final = argmax(counts)\n    # Add the class to the final predictions\n    hard_predictions.append(final) \n```", "```py\n# --- SECTION 6 ---\n# Accuracies of base learners\nprint('L1:', accuracy_score(y_test, predictions_1))\nprint('L2:', accuracy_score(y_test, predictions_2))\nprint('L3:', accuracy_score(y_test, predictions_3))\n# Accuracy of hard voting\nprint('-'*30)\nprint('Hard Voting:', accuracy_score(y_test, hard_predictions))\n```", "```py\nL1: 0.94\nL2: 0.93\nL3: 0.88\n------------------------------\nHard Voting: 0.95\n```", "```py\n# --- SECTION 1 ---\n# Import the required libraries\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nmpl.style.use('seaborn-paper')\n```", "```py\n# --- SECTION 2 ---\n# Calculate the errors \nerrors_1 = y_test-predictions_1\nerrors_2 = y_test-predictions_2\nerrors_3 = y_test-predictions_3\n```", "```py\n# --- SECTION 3 ---\n# Discard correct predictions and plot each learner's errors\nx=[]\ny=[]\nfor i in range(len(errors_1)):\n    if not errors_1[i] == 0:\n        x.append(i)\n        y.append(errors_1[i])\nplt.scatter(x, y, s=120, label='Learner 1 Errors')\n\nx=[]\ny=[]\nfor i in range(len(errors_2)):\n     if not errors_2[i] == 0:\n         x.append(i)\n         y.append(errors_2[i])\nplt.scatter(x, y, marker='x', s=60, label='Learner 2 Errors')\n\nx=[]\ny=[]\nfor i in range(len(errors_3)):\n    if not errors_3[i] == 0:\n        x.append(i)\n        y.append(errors_3[i])\nplt.scatter(x, y, s=20, label='Learner 3 Errors')\n```", "```py\nplt.title('Learner errors')\nplt.xlabel('Test sample')\nplt.ylabel('Error')\nplt.legend()\nplt.show()\n```", "```py\n# --- SECTION 1 ---\n# Import the required libraries\nfrom sklearn import datasets, linear_model, svm, neighbors\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import accuracy_score\n# Load the dataset\nbreast_cancer = datasets.load_breast_cancer()\nx, y = breast_cancer.data, breast_cancer.target\n\n# Split the train and test samples\ntest_samples = 100\nx_train, y_train = x[:-test_samples], y[:-test_samples]\nx_test, y_test = x[-test_samples:], y[-test_samples:]\n\n# --- SECTION 2 ---\n# Instantiate the learners (classifiers)\nlearner_1 = neighbors.KNeighborsClassifier(n_neighbors=5)\nlearner_2 = linear_model.Perceptron(tol=1e-2, random_state=0)\nlearner_3 = svm.SVC(gamma=0.001)\n```", "```py\n# --- SECTION 3 ---\n# Instantiate the voting classifier\nvoting = VotingClassifier([('KNN', learner_1),\n                           ('Prc', learner_2),\n                           ('SVM', learner_3)])\n```", "```py\n# --- SECTION 4 ---\n# Fit classifier with the training data\nvoting.fit(x_train, y_train)\n\n# --- SECTION 5 ---\n# Predict the most voted class\nhard_predictions = voting.predict(x_test)\n```", "```py\n# --- SECTION 6 ---\n# Accuracy of hard voting\nprint('-'*30)\nprint('Hard Voting:', accuracy_score(y_test, hard_predictions))\n```", "```py\n------------------------------\nHard Voting: 0.95\n```", "```py\n# --- SECTION 1 ---\n# Import the required libraries\nfrom sklearn import datasets, naive_bayes, svm, neighbors\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import accuracy_score\n# Load the dataset\nbreast_cancer = datasets.load_breast_cancer()\nx, y = breast_cancer.data, breast_cancer.target\n\n# Split the train and test samples\ntest_samples = 100\nx_train, y_train = x[:-test_samples], y[:-test_samples]\nx_test, y_test = x[-test_samples:], y[-test_samples:]\n```", "```py\n# --- SECTION 2 ---\n# Instantiate the learners (classifiers)\nlearner_1 = neighbors.KNeighborsClassifier(n_neighbors=5)\nlearner_2 = naive_bayes.GaussianNB()\nlearner_3 = svm.SVC(gamma=0.001, probability=True)\n\n# --- SECTION 3 ---\n# Instantiate the voting classifier\nvoting = VotingClassifier([('KNN', learner_1),\n                           ('NB', learner_2),\n                           ('SVM', learner_3)],\n                            voting='soft')\n```", "```py\n# --- SECTION 4 ---\n# Fit classifier with the training data\nvoting.fit(x_train, y_train)\nlearner_1.fit(x_train, y_train)\nlearner_2.fit(x_train, y_train)\nlearner_3.fit(x_train, y_train)\n```", "```py\n# --- SECTION 5 ---\n# Predict the most probable class\nhard_predictions = voting.predict(x_test)\n\n# --- SECTION 6 ---\n# Get the base learner predictions\npredictions_1 = learner_1.predict(x_test)\npredictions_2 = learner_2.predict(x_test)\npredictions_3 = learner_3.predict(x_test)\n```", "```py\n# --- SECTION 7 ---\n# Accuracies of base learners\nprint('L1:', accuracy_score(y_test, predictions_1))\nprint('L2:', accuracy_score(y_test, predictions_2))\nprint('L3:', accuracy_score(y_test, predictions_3))\n# Accuracy of hard voting\nprint('-'*30)\nprint('Hard Voting:', accuracy_score(y_test, hard_predictions))\n```", "```py\nL1: 0.94\nL2: 0.96\nL3: 0.88\n------------------------------\nHard Voting: 0.94\n```", "```py\n# --- SECTION 1 ---\n# Import the required libraries\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nmpl.style.use('seaborn-paper')\n```", "```py\n\n# --- SECTION 2 ---\n# Get the wrongly predicted instances\n# and the predicted probabilities for the whole test set\nerrors = y_test-hard_predictions\n\nprobabilities_1 = learner_1.predict_proba(x_test)\nprobabilities_2 = learner_2.predict_proba(x_test)\nprobabilities_3 = learner_3.predict_proba(x_test)\n```", "```py\n# --- SECTION 2 ---\n# Store the predicted probability for \n# each wrongly predicted instance, for each base learner\n# as well as the average predicted probability\n#\nx=[]\ny_1=[]\ny_2=[]\ny_3=[]\ny_avg=[]\n\nfor i in range(len(errors)):\n    if not errors[i] == 0:\n         x.append(i)\n         y_1.append(probabilities_1[i][0])\n         y_2.append(probabilities_2[i][0])\n         y_3.append(probabilities_3[i][0])\n         y_avg.append((probabilities_1[i][0]+\n                       probabilities_2[i][0]+probabilities_3[i][0])/3)\n```", "```py\n\n# --- SECTION 3 ---\n# Plot the predicted probaiblity of each base learner as \n# a bar and the average probability as an X\nplt.bar(x, y_1, 3, label='KNN')\nplt.bar(x, y_2, 2, label='NB')\nplt.bar(x, y_3, 1, label='SVM')\nplt.scatter(x, y_avg, marker='x', c='k', s=150, \n            label='Average Positive', zorder=10)\n\ny = [0.5 for x in range(len(errors))]\nplt.plot(y, c='k', linestyle='--')\n\nplt.title('Positive Probability')\nplt.xlabel('Test sample')\nplt.ylabel('probability')\nplt.legend()\nplt.show()\n```", "```py\nL1: 0.94\nL2: 0.96\nL3: 0.95\n------------------------------\nHard Voting: 0.97\n```"]