- en: Classifying Fraudulent Transactions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will attempt to classify fraudulent transactions in a dataset
    concerning credit card transactions from European card holders that occurred during
    September 2013\. The main problem in this dataset is the extremely small number
    of fraudulent transactions, compared to the dataset's size. These types of datasets
    are called unbalanced, as there are unequal percentages of each label. We will
    try to create ensembles that can classify our particular dataset, which contains
    a small number of fraudulent transactions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Getting familiar with the dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploratory analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Voting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stacking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bagging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boosting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using random forests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Comparative analysis of ensembles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will require basic knowledge of machine learning techniques and algorithms.
    Furthermore, a knowledge of python conventions and syntax is required. Finally,
    familiarity with the NumPy library will greatly help the reader to understand
    some custom algorithm implementations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code files of this chapter can be found on GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Hands-On-Ensemble-Learning-with-Python/tree/master/Chapter09](https://github.com/PacktPublishing/Hands-On-Ensemble-Learning-with-Python/tree/master/Chapter09)'
  prefs: []
  type: TYPE_NORMAL
- en: Check out the following video to see the Code in Action: [http://bit.ly/2ShwarF](http://bit.ly/2ShwarF)[.](http://bit.ly/2ShwarF)
  prefs: []
  type: TYPE_NORMAL
- en: Getting familiar with the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The dataset was originally utilized in the PhD thesis of Andrea Dal Pozzolo,
    [Adaptive Machine learning for credit card fraud detection](http://di.ulb.ac.be/map/adalpozz/pdf/Dalpozzolo2015PhD.pdf)
    ULB MLG, and has since been released by its authors for public use ([www.ulb.ac.be/di/map/adalpozz/data/creditcard.Rdata](http://www.ulb.ac.be/di/map/adalpozz/data/creditcard.Rdata)).
    The dataset contains more than 284,000 instances, but only 492 instances of fraud
    (almost 0.17%).
  prefs: []
  type: TYPE_NORMAL
- en: 'Its target class value is 0 if the transaction was not a fraud, and 1 if it
    was. The dataset''s features are a number of principal components, as the dataset
    has been transformed using **Principle Components Analysis** (**PCA**), in order
    to retain the confidentiality of the data. The dataset''s features are comprised
    of 28 PCA components, as well as the transaction’s amount and the time elapsed
    from the first transaction in the dataset. Descriptive statistics about the dataset
    are provided as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Feature** | **Time** | **V1** | **V2** | **V3** | **V4** |'
  prefs: []
  type: TYPE_TB
- en: '| **count** | 284,807 | 284,807 | 284,807 | 284,807 | 284,807 |'
  prefs: []
  type: TYPE_TB
- en: '| **mean** | 94,813.86 | 1.17E-15 | 3.42E-16 | -1.37E-15 | 2.09E-15 |'
  prefs: []
  type: TYPE_TB
- en: '| **std** | 47,488.15 | 1.96 | 1.65 | 1.52 | 1.42 |'
  prefs: []
  type: TYPE_TB
- en: '| **min** | 0.00 | -56.41 | -72.72 | -48.33 | -5.68 |'
  prefs: []
  type: TYPE_TB
- en: '| **max** | 172,792.00 | 2.45 | 22.06 | 9.38 | 16.88 |'
  prefs: []
  type: TYPE_TB
- en: '| **Feature** | **V5** | **V6** | **V7** | **V8** | **V9** |'
  prefs: []
  type: TYPE_TB
- en: '| **count** | 284,807 | 284,807 | 284,807 | 284,807 | 284,807 |'
  prefs: []
  type: TYPE_TB
- en: '| **mean** | 9.60E-16 | 1.49E-15 | -5.56E-16 | 1.18E-16 | -2.41E-15 |'
  prefs: []
  type: TYPE_TB
- en: '| **std** | 1.38 | 1.33 | 1.24 | 1.19 | 1.10 |'
  prefs: []
  type: TYPE_TB
- en: '| **min** | -113.74 | -26.16 | -43.56 | -73.22 | -13.43 |'
  prefs: []
  type: TYPE_TB
- en: '| **max** | 34.80 | 73.30 | 120.59 | 20.01 | 15.59 |'
  prefs: []
  type: TYPE_TB
- en: '| **Feature** | **V10** | **V11** | **V12** | **V13** | **V14** |'
  prefs: []
  type: TYPE_TB
- en: '| **count** | 284,807 | 284,807 | 284,807 | 284,807 | 284,807 |'
  prefs: []
  type: TYPE_TB
- en: '| **mean** | 2.24E-15 | 1.67E-15 | -1.25E-15 | 8.18E-16 | 1.21E-15 |'
  prefs: []
  type: TYPE_TB
- en: '| **std** | 1.09 | 1.02 | 1.00 | 1.00 | 0.96 |'
  prefs: []
  type: TYPE_TB
- en: '| **min** | -24.59 | -4.80 | -18.68 | -5.79 | -19.21 |'
  prefs: []
  type: TYPE_TB
- en: '| **max** | 23.75 | 12.02 | 7.85 | 7.13 | 10.53 |'
  prefs: []
  type: TYPE_TB
- en: '| **Feature** | **V15** | **V16** | **V17** | **V18** | **V19** |'
  prefs: []
  type: TYPE_TB
- en: '| **count** | 284,807 | 284,807 | 284,807 | 284,807 | 284,807 |'
  prefs: []
  type: TYPE_TB
- en: '| **mean** | 4.91E-15 | 1.44E-15 | -3.80E-16 | 9.57E-16 | 1.04E-15 |'
  prefs: []
  type: TYPE_TB
- en: '| **std** | 0.92 | 0.88 | 0.85 | 0.84 | 0.81 |'
  prefs: []
  type: TYPE_TB
- en: '| **min** | -4.50 | -14.13 | -25.16 | -9.50 | -7.21 |'
  prefs: []
  type: TYPE_TB
- en: '| **max** | 8.88 | 17.32 | 9.25 | 5.04 | 5.59 |'
  prefs: []
  type: TYPE_TB
- en: '| **Feature** | **V20** | **V21** | **V22** | **V23** | **V24** |'
  prefs: []
  type: TYPE_TB
- en: '| **count** | 284,807 | 284,807 | 284,807 | 284,807 | 284,807 |'
  prefs: []
  type: TYPE_TB
- en: '| **mean** | 6.41E-16 | 1.66E-16 | -3.44E-16 | 2.58E-16 | 4.47E-15 |'
  prefs: []
  type: TYPE_TB
- en: '| **std** | 0.77 | 0.73 | 0.73 | 0.62 | 0.61 |'
  prefs: []
  type: TYPE_TB
- en: '| **min** | -54.50 | -34.83 | -10.93 | -44.81 | -2.84 |'
  prefs: []
  type: TYPE_TB
- en: '| **max** | 39.42 | 27.20 | 10.50 | 22.53 | 4.58 |'
  prefs: []
  type: TYPE_TB
- en: '| **Feature** | **V25** | **V26** | **V27** | **V28** | **Amount** |'
  prefs: []
  type: TYPE_TB
- en: '| **count** | 284,807 | 284,807 | 284,807 | 284,807 | 284,807 |'
  prefs: []
  type: TYPE_TB
- en: '| **mean** | 5.34E-16 | 1.69E-15 | -3.67E-16 | -1.22E-16 | 88.34962 |'
  prefs: []
  type: TYPE_TB
- en: '| **std** | 0.52 | 0.48 | 0.40 | 0.33 | 250.12 |'
  prefs: []
  type: TYPE_TB
- en: '| **min** | -10.30 | -2.60 | -22.57 | -15.43 | 0.00 |'
  prefs: []
  type: TYPE_TB
- en: '| **max** | 7.52 | 3.52 | 31.61 | 33.85 | 25,691.16 |'
  prefs: []
  type: TYPE_TB
- en: Descriptive statistics of the credit card transaction dataset
  prefs: []
  type: TYPE_NORMAL
- en: Exploratory analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One important characteristic of the dataset is that there are no missing values,
    as it is indicated by the count statistic. All features have the same number of
    values. Another important aspect is that most features are normalized. This is
    due to the PCA applied to the data. PCA normalizes the data before decomposing
    it into principal components. The only two features not normalized are the **Time**
    and **Amount** features. The following histogram for each feature is depicted:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d2650536-5a54-41da-a4de-3ece14168987.png)'
  prefs: []
  type: TYPE_IMG
- en: Histograms for the dataset's features
  prefs: []
  type: TYPE_NORMAL
- en: 'It is interesting to examine more closely the **Time** and **Amount** of each
    transaction. In the **Time** histogram, we notice a sudden drop in transaction
    frequency between 75,000 and 125,000 seconds after the first transaction (around
    13 hours). This is probably due to daily time cycles (for example, during the
    night, when most stores are closed). The histogram for each transaction''s amount
    is provided as follows in the logarithmic scale. It is evident that most transactions
    concern small amounts, with the average being almost €88.00:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4a7a51a9-e8e5-4a22-99a5-91c40bea7ca9.png)'
  prefs: []
  type: TYPE_IMG
- en: Histogram for amount, logarithmic scale for *y*-axis
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to avoid problems with uneven distribution of weights between features,
    we will standardize the features **Amount** and **Time**. Algorithms that employ
    distance metrics for example (such as K-Nearest Neighbors), can under perform
    when features are not scaled correctly. The standardized features'' histograms
    are provided as follows. Note that standardization transforms the variables in
    order to have a mean value close to 0 and standard deviation of 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eb30b820-bc32-49e7-bc9b-1d80402ae12c.png)'
  prefs: []
  type: TYPE_IMG
- en: Standardized amount histogram
  prefs: []
  type: TYPE_NORMAL
- en: 'The following plot depicts the histogram for standardized time. We can see
    that it does not affect the drop in transactions during the night time:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0be32d14-cf53-4fd0-9cd8-b49d1b786ece.png)'
  prefs: []
  type: TYPE_IMG
- en: Standardized time histogram
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As our dataset is highly skewed (that is, it has a high degree of class imbalance),
    we cannot utilize accuracy in order to evaluate our models. This is due to the
    fact that by classifying all instances as non-frauds, we can achieve an accuracy
    of 99.82%. Certainly, this number does not represent an acceptable performance,
    as we are unable to detect any fraudulent transactions. Thus, in order to evaluate
    our models, we will use recall (the percentage of frauds we detected) and F1 score,
    a weighted average between recall and precision (a measure of how many of the
    transactions predicted as fraudulent were indeed fraudulent).
  prefs: []
  type: TYPE_NORMAL
- en: Voting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will try to classify the dataset by using voting ensembles.
    For our initial ensemble, we will utilize a Naive Bayes classifier, a logistic
    regression, and a decision tree. This will be implemented in two parts, first
    by testing each base learner itself and then combining the base learners into
    an ensemble.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the base learners
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To test the base learners, we will benchmark the base learners by themselves,
    which will help us gauge how well they perform on their own. In order to do so,
    first, we load the libraries and dataset and then split the data with 70% in the
    train set and 30% in the test set. We use `pandas` in order to easily import the
    CSV. Our goal is to train and evaluate each individual base learner before we
    train and evaluate the ensemble as a whole:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'After loading the libraries and data, we train each classifier and print the
    required metrics from the `sklearn.metrics` package. F1 score is implemented by
    the `f1_score` function and recall is implemented by the `recall_score` function.
    The decision tree is restricted to a maximum depth of three (`max_depth=3`), in
    order to avoid overfitting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are depicted in the following table. As is evident, the decision
    tree outperforms the other three learners. Naive Bayes has a higher recall score,
    but its F1 score is considerably worse, compared to the decision tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Learner** | **Metric** | **Value** |'
  prefs: []
  type: TYPE_TB
- en: '| **Decision Tree** | F1 | 0.770 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.713 |'
  prefs: []
  type: TYPE_TB
- en: '| **Naive Bayes** | F1 | 0.107 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.824 |'
  prefs: []
  type: TYPE_TB
- en: '| **Logistic Regression** | F1 | 0.751 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.632 |'
  prefs: []
  type: TYPE_TB
- en: 'We can also experiment with the number of features present in the dataset.
    By plotting their correlation to the target, we can filter out features that present
    low correlation to the target. This table depicts each feature''s correlation
    to the target:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a82e49d0-da26-4a48-90ad-b643051f7851.png)'
  prefs: []
  type: TYPE_IMG
- en: Correlation between each variable and the target
  prefs: []
  type: TYPE_NORMAL
- en: By filtering any feature with a lower absolute value than 0.1, we hope that
    the base learners will be able to better detect the fraudulent transactions, as
    the dataset's noise will be reduced.
  prefs: []
  type: TYPE_NORMAL
- en: In order to test our theory, we repeat the experiment, but remove any columns
    from the DataFrame where the absolute correlation is lower than 0.1, as indicated
    by `fs = list(correlations[(abs(correlations)>threshold)].index.values)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, `fs` holds all column names with a correlation greater than the indicated
    threshold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, we present the results in the following table. As we can see, the decision
    tree has increased its F1 score, while reducing its recall. Naive Bayes has improved
    on both metrics, while the logistic regression model has become considerably worse:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Learner** | **Metric** | **Value** |'
  prefs: []
  type: TYPE_TB
- en: '| **Decision Tree** | F1 | 0.785 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.699 |'
  prefs: []
  type: TYPE_TB
- en: '| **Naive Bayes** | F1 | 0.208 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.846 |'
  prefs: []
  type: TYPE_TB
- en: '| **Logistic Regression** | F1 | 0.735 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.610 |'
  prefs: []
  type: TYPE_TB
- en: Performance metrics for the three base learners for the filtered dataset
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing the decision tree
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can try to optimize the tree's depth in order to maximize F1 or recall. In
    order to do so, we will experiment with depths in the range of *[3, 11]* on the
    train set.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following graph depicts the F1 score and recall for the various maximum
    depths, both for the original and filtered datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eacb8254-b19c-4a12-be0a-cc9e23b99e35.png)'
  prefs: []
  type: TYPE_IMG
- en: Test metrics for various tree depths
  prefs: []
  type: TYPE_NORMAL
- en: Here, we observe that for a maximum depth of 5, F1 and recall are optimized
    for the filtered dataset. Furthermore, recall is optimized for the original dataset
    as well. We will continue with a maximum depth of 5 as trying to further optimize
    the metrics can lead to overfitting, especially since the number of instances
    relevant to the metrics is extremely small. Furthermore, with a maximum depth
    of 5, there is an improvement both in F1, as well as in recall, when the filtered
    dataset is used.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the ensemble
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can now proceed and create the ensemble. Again, we will first evaluate the
    ensemble on the original dataset, and then proceed to test it on the filtered
    dataset. The code is similar to the previous example. First, we load the libraries
    and data, and create train and test splits as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'After loading the required libraries and data, we create our ensemble, and
    then train and evaluate it. Finally, we repeat the experiment as follows with
    reduced features by filtering out features with low correlations to the target
    variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The following table summarizes the results. For the original dataset, voting
    provides a model with a better combination of F1 and recall, compared to any single
    classifier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Still, the decision tree with a maximum depth of 5 slightly outperforms it
    in F1 score, while Naive Bayes is able to recall a greater percentage of fraudulent
    transactions:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Dataset** | **Metric** | **Value** |'
  prefs: []
  type: TYPE_TB
- en: '| **Original** | F1 | 0.822 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.779 |'
  prefs: []
  type: TYPE_TB
- en: '| **Filtered** | F1 | 0.828 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.794 |'
  prefs: []
  type: TYPE_TB
- en: Voting results for both datasets
  prefs: []
  type: TYPE_NORMAL
- en: We can try to further diversify our ensemble by also including two additional
    Decision Trees, with maximum depth of three and eight, respectively. This boosts
    the ensemble’s performance to the following numbers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although the performance remains the same for the filtered dataset, the ensemble
    is able to perform better in the original dataset. Especially for the F1 metric,
    it is able to outperform all other dataset/model combinations:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Dataset** | **Metric** | **Value** |'
  prefs: []
  type: TYPE_TB
- en: '| **Original** | F1 | 0.829 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.787 |'
  prefs: []
  type: TYPE_TB
- en: '| **Filtered** | F1 | 0.828 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.794 |'
  prefs: []
  type: TYPE_TB
- en: Voting results for both datasets with two additional decision trees
  prefs: []
  type: TYPE_NORMAL
- en: Stacking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can also try to stack the base learners, instead of using Voting. First,
    we will try to stack a single decision tree with depth five, a Naive Bayes classifier,
    and a logistic regression. As a meta-learner, we will use a logistic regression.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code is responsible for loading the required libraries and data,
    training, and evaluating the ensemble on the original and filtered datasets. We
    first load the required libraries and data, while creating train and test splits:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'After creating our train and test splits, we train and evaluate our ensemble
    on the original dataset, as well as a reduced-features dataset as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'As it is seen in the following resultant table, the ensemble achieves a slightly
    better F1 score on the original dataset, but worse recall score, compared to the
    voting ensemble with the same base learners:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Dataset** | **Metric** | **Value** |'
  prefs: []
  type: TYPE_TB
- en: '| **Original** | F1 | 0.823 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.750 |'
  prefs: []
  type: TYPE_TB
- en: '| **Filtered** | F1 | 0.828 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.794 |'
  prefs: []
  type: TYPE_TB
- en: Stacking ensemble performance with three base learners
  prefs: []
  type: TYPE_NORMAL
- en: We can further experiment with different base learners. By adding two decision
    trees with maximum depths of three and eight, respectively (same with the second
    Voting setup), observe how stacking exhibits the same behavior. It outperforms
    on the F1 score and underperforms on the recall score for the original dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the filtered dataset, the performance remains on par with Voting. Finally,
    we experiment with second level of base learners, consisting of a Decision Tree
    with depth two and a linear support vector machine, which performs worse than
    the five base learners'' setup:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Dataset** | **Metric** | **Value** |'
  prefs: []
  type: TYPE_TB
- en: '| **Original** | F1 | 0.844 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.757 |'
  prefs: []
  type: TYPE_TB
- en: '| **Filtered** | F1 | 0.828 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.794 |'
  prefs: []
  type: TYPE_TB
- en: Performance with five base learners
  prefs: []
  type: TYPE_NORMAL
- en: The following table depicts the results for the stacking ensemble with an additional
    level of base learners. As it is evident, it performs worse than the original
    ensemble.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Dataset** | **Metric** | **Value** |'
  prefs: []
  type: TYPE_TB
- en: '| **Original** | F1 | 0.827 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.757 |'
  prefs: []
  type: TYPE_TB
- en: '| **Filtered** | F1 | 0.827 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.772 |'
  prefs: []
  type: TYPE_TB
- en: Performance with five base learners on level 0 and two on level 1
  prefs: []
  type: TYPE_NORMAL
- en: Bagging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will classify the dataset using bagging. As we have previously
    shown, decision trees with maximum depth of five are optimal thus, we will use
    these trees for our bagging example.
  prefs: []
  type: TYPE_NORMAL
- en: 'We would like to optimize the ensemble''s size. We will generate validation
    curves for the original train set by testing sizes in the range of *[5, 30]*.
    The actual curves are depicted here in the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ac802720-c0d2-49ed-88ed-6190c2a50a75.png)'
  prefs: []
  type: TYPE_IMG
- en: Validation curves for the original train set, for various ensemble sizes
  prefs: []
  type: TYPE_NORMAL
- en: We observe that variance is minimized for an ensemble size of 10, thus we will
    utilize ensembles of size 10.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code loads the data and libraries (*Section 1*), splits the data
    into train and test sets, and fits and evaluates the ensemble on the original
    dataset (*Section 2*) and the reduced-features dataset (*Section 3*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'After creating our train and test splits, we train and evaluate our ensemble
    on the original dataset, as well as a reduced-features dataset as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Using bagging ensembles with trees of a maximum depth of 5 and 10 trees per
    ensemble, we are able to achieve the following F1 and recall scores. It outperforms
    both stacking and voting in both datasets on all metrics, with one exception.
    The F1 score for the original dataset is slightly worse than stacking (0.843 compared
    to 0.844):'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Dataset** | **Metric** | **Value** |'
  prefs: []
  type: TYPE_TB
- en: '| **Original** | F1 | 0.843 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.787 |'
  prefs: []
  type: TYPE_TB
- en: '| **Filtered** | F1 | 0.831 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.794 |'
  prefs: []
  type: TYPE_TB
- en: Bagging performance for the original and filtered datasets
  prefs: []
  type: TYPE_NORMAL
- en: Although we have concluded that a maximum depth of 5 is optimal for a single
    decision tree, it does restrict the diversity of each tree. By increasing the
    maximum depth to 8, we are able to achieve an F1 score of 0.864 and a recall score
    of 0.816 on the filtered dataset, the best performance up to now.
  prefs: []
  type: TYPE_NORMAL
- en: 'Nonetheless, performance on the original dataset suffers, confirming that the
    features that we removed were, indeed, noise, as the trees are now able to model
    in-sample noise, and thus, their out-of-sample performance suffers:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Dataset** | **Metric** | **Value** |'
  prefs: []
  type: TYPE_TB
- en: '| **Original** | F1 | 0.840 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.772 |'
  prefs: []
  type: TYPE_TB
- en: '| **Filtered** | F1 | 0.864 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.816 |'
  prefs: []
  type: TYPE_TB
- en: Boosting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we move on, we will start to utilize generative methods. The first generative
    method we will experiment with is boosting. We will first try to classify the
    datasets using AdaBoost. As AdaBoost resamples the dataset based on misclassifications,
    we expect that it will be able to handle our imbalanced dataset relatively well.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we must decide on the ensemble''s size. We generate validation curves
    for a number of ensemble sizes depicted as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4657f347-9b54-4486-a151-250f44e7548e.png)'
  prefs: []
  type: TYPE_IMG
- en: Validation curves of various ensemble sizes for AdaBoost
  prefs: []
  type: TYPE_NORMAL
- en: As we can observe, 70 base learners provide the best trade-off between bias
    and variance. As such, we will proceed with ensembles of size 70.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code implements the training and evaluation for AdaBoost:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We then train and evaluate our ensemble, using 70 estimators and a learning
    rate of 1.0:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We reduce the number of features, by selecting only features with high correlation
    with respect to the target. Finally, we repeat the procedure of training and evaluating
    the ensemble:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are depicted in the following table. As it is evident, it does
    not perform as well as our previous models:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Dataset** | **Metric** | **Value** |'
  prefs: []
  type: TYPE_TB
- en: '| **Original** | F1 | 0.778 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.721 |'
  prefs: []
  type: TYPE_TB
- en: '| **Filtered** | F1 | 0.794 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.721 |'
  prefs: []
  type: TYPE_TB
- en: Performance of AdaBoost
  prefs: []
  type: TYPE_NORMAL
- en: 'We can try to increase the learning rate to 1.3, which seems to improve overall
    performance. If we further increase it to 1.4, we notice a drop in performance.
    If we increase the number of base learners to 80, we notice an increase in performance
    for the filtered dataset, while the original dataset seems to trade recall for
    F1 performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Dataset** | **Metric** | **Value** |'
  prefs: []
  type: TYPE_TB
- en: '| **Original** | F1 | 0.788 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.765 |'
  prefs: []
  type: TYPE_TB
- en: '| **Filtered** | F1 | 0.815 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.743 |'
  prefs: []
  type: TYPE_TB
- en: Performance of AdaBoost, learning_rate=1.3
  prefs: []
  type: TYPE_NORMAL
- en: '| **Dataset** | **Metric** | **Value** |'
  prefs: []
  type: TYPE_TB
- en: '| Original | F1 | 0.800 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.765 |'
  prefs: []
  type: TYPE_TB
- en: '| Filtered | F1 | 0.800 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.735 |'
  prefs: []
  type: TYPE_TB
- en: Performance of AdaBoost, learning_rate=1.4
  prefs: []
  type: TYPE_NORMAL
- en: '| **Dataset** | **Metric** | **Value** |'
  prefs: []
  type: TYPE_TB
- en: '| **Original** | F1 | 0.805 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.757 |'
  prefs: []
  type: TYPE_TB
- en: '| **Filtered** | F1 | 0.805 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.743 |'
  prefs: []
  type: TYPE_TB
- en: Performance of AdaBoost, learning_rate=1.4, ensemble_size=80
  prefs: []
  type: TYPE_NORMAL
- en: 'We can, in fact, observe a Pareto front of F1 and Recall, which is directly
    linked to the learning rate and number of base learners present in the ensemble.
    The front is depicted in the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b4c0bdd0-25cf-454d-8b46-f74471c4c2ab.png)'
  prefs: []
  type: TYPE_IMG
- en: Pareto front of F1 and Recall for AdaBoost
  prefs: []
  type: TYPE_NORMAL
- en: XGBoost
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will also try to classify the dataset using XGBoost. As XGBoost uses trees
    of a maximum depth of three, we expect that it will outperform AdaBoost without
    any fine-tuning. Indeed, XGBoost is able to achieve better performance in both
    datasets and for all metrics (as shown in the following table), compared to most
    previous ensembles:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Dataset** | **Metric** | **Value** |'
  prefs: []
  type: TYPE_TB
- en: '| **Original** | F1 | 0.846 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.787 |'
  prefs: []
  type: TYPE_TB
- en: '| **Filtered** | F1 | 0.849 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.809 |'
  prefs: []
  type: TYPE_TB
- en: XGBoost out-of-the-box performance
  prefs: []
  type: TYPE_NORMAL
- en: 'By increasing the maximum depth of each tree to five, the ensemble is able
    to perform even better, yielding the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Dataset** | **Metric** | **Value** |'
  prefs: []
  type: TYPE_TB
- en: '| **Original** | F1 | 0.862 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.801 |'
  prefs: []
  type: TYPE_TB
- en: '| **Filtered** | F1 | 0.862 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.824 |'
  prefs: []
  type: TYPE_TB
- en: Performance with max_depth=5
  prefs: []
  type: TYPE_NORMAL
- en: Using random forests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Finally, we will employ a random forest ensemble. Once again, using validation
    curves, we will determine the optimal ensemble size. From the following graph,
    we conclude that 50 trees provide the least possible variance in our model, thus
    we proceed with ensemble size 50:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0a1e5ed3-be7c-4e14-a232-a87f9dc3aea7.png)'
  prefs: []
  type: TYPE_IMG
- en: Validation curves for random forest
  prefs: []
  type: TYPE_NORMAL
- en: 'We provide the training and validation code as follows, as well as the achieved
    performance for both datasets. The following code is responsible for loading the
    required libraries and data, and training and evaluating the ensemble on the original
    and filtered datasets. We first load the required libraries and data, while creating
    train and test splits:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We then train and evaluate the ensemble, both on the original dataset, as well
    as on the filtered dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '| **Dataset** | **Metric** | **Value** |'
  prefs: []
  type: TYPE_TB
- en: '| **Original** | F1 | 0.845 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.743 |'
  prefs: []
  type: TYPE_TB
- en: '| **Filtered** | F1 | 0.867 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.794 |'
  prefs: []
  type: TYPE_TB
- en: Random forest performance
  prefs: []
  type: TYPE_NORMAL
- en: 'As our dataset is highly skewed, we can speculate that changing the criterion
    for a tree’s split to entropy would benefit our model. Indeed, by specifying `criterion=''entropy''`
    in the constructor (`ensemble = RandomForestClassifier(n_jobs=4)`), we are able
    to increase the performance on the original dataset to an **F1** score of **0.859**
    and a **Recall** score of **0.786**, two of the highest scores for the original
    dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Dataset** | **Metric** | **Value** |'
  prefs: []
  type: TYPE_TB
- en: '| **Original** | F1 | 0.859 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.787 |'
  prefs: []
  type: TYPE_TB
- en: '| **Filtered** | F1 | 0.856 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Recall | 0.787 |'
  prefs: []
  type: TYPE_TB
- en: Performance with entropy as the splitting criterion
  prefs: []
  type: TYPE_NORMAL
- en: Comparative analysis of ensembles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we experimented with a reduced feature dataset, where we removed features
    without a strong correlation to the target variable, we would like to provide
    the final scores for the best parameters of each method. In the following graph,
    the results are depicted, sorted in ascending order. Bagging seems to be the most
    robust method when applied to the filtered dataset. XGBoost is the second best
    alternative, providing decent F1 and Recall scores when applied to the filtered
    dataset as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a127e35e-debc-4407-80ba-5b68e485ecc9.png)'
  prefs: []
  type: TYPE_IMG
- en: F1 scores
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall scores, depicted in the following plot, show the clear advantage XGBoost
    has on this metric over the other methods, as it is able to outperform all others
    for both the original and filtered datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0df8e22b-871a-4cb9-a2de-fbfc5cb1b38c.png)'
  prefs: []
  type: TYPE_IMG
- en: Recall scores
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored the possibility of detecting fraudulent transactions
    using various ensemble learning methods. While some performed better than others,
    due to the dataset's nature, it is difficult to produce good results without resampling
    the dataset in some way (either over-sampling or under-sampling).
  prefs: []
  type: TYPE_NORMAL
- en: We were able to show how to use each ensemble learning method and how to explore
    the possibility of fine-tuning its respective parameters in order to achieve better
    performance. In the next chapter, we will try to leverage ensemble learning techniques
    in order to predict Bitcoin prices.
  prefs: []
  type: TYPE_NORMAL
