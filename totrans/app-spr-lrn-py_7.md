# *附录*

## 关于

本节内容帮助学生完成书中的活动。它包括学生为实现活动目标所需执行的详细步骤。

## 第1章：Python 机器学习工具包

### 活动1：pandas 函数

**解决方案**

1.  打开一个新的 Jupyter Notebook。

1.  使用 pandas 加载 Titanic 数据集：

    [PRE0]

    使用 `head()` 函数查看数据集，如下：

    [PRE1]

    输出结果如下：

    ![图1.65：前五行

    ](img/C12622_01_65.jpg)

    ###### 图1.65：前五行

    使用 `describe` 函数如下：

    [PRE2]

    输出结果如下：

    ![图1.66：describe()的输出

    ](img/C12622_01_66.jpg)

    ###### 图1.66：describe()的输出

1.  我们不需要 `Unnamed: 0` 列。我们可以通过以下方式删除该列，而不使用 `del` 命令：

    [PRE3]

    输出结果如下：

    ![图1.67：删除 `Unnamed: 0` 列后的前五行

    ](img/C12622_01_67.jpg)

    ###### 图1.67：删除 `Unnamed: 0` 列后的前五行

1.  计算 DataFrame 列的均值、标准差、最小值和最大值，而不使用 `describe`：

    [PRE4]

1.  33%、66% 和 99% 的四分位数如何？使用 `quantile` 方法如下：

    [PRE5]

1.  每个班级的乘客有多少人？让我们来看一下，使用`groupby`方法：

    [PRE6]

1.  每个班级的乘客有多少人？你可以通过使用选择/索引方法来统计每个班级的成员数量：

    [PRE7]

    *第6步* 和 *第7步* 的答案是匹配的。

1.  确定第三类中的最年长乘客是谁：

    [PRE8]

    输出结果如下：

    ![图1.68：第三类中的最年长乘客

    ](img/C12622_01_68.jpg)

    ###### 图1.68：第三类中的最年长乘客

1.  对于许多机器学习问题，通常会将数值缩放到 0 到 1 之间。使用 `agg` 方法与 Lambda 函数将 `Fare` 和 `Age` 列缩放到 0 到 1 之间：

    [PRE9]

    输出结果如下：

    ![图1.69：将数值缩放到0到1之间

    ](img/C12622_01_69.jpg)

    ###### 图1.69：将数值缩放到0到1之间

1.  数据集中有一个个体没有列出 `Fare` 票价：

    [PRE10]

    这是输出：

![图1.70：没有列出票价的个体

](img/C12622_01_70.jpg)

###### 图1.70：没有列出票价的个体

使用 `groupby` 方法，将此行的 `NaN` 值替换为与相同班级和 `Embarked` 位置对应的平均 `Fare` 值：

[PRE11]

输出结果如下：

[PRE12]

## 第2章：探索性数据分析与可视化

### 活动2：汇总统计与缺失值

**解决方案**

完成此活动的步骤如下：

1.  读取数据。使用 pandas 的 `.read_csv` 方法将 CSV 文件读取为 pandas DataFrame：

    [PRE13]

1.  使用 pandas 的 `.info()` 和 `.describe()` 方法查看数据集的汇总统计：

    [PRE14]

    `info()` 的输出将是：

    ![图2.39：info() 方法的输出

    ](img/C12622_02_39.jpg)

    ###### 图2.39：info() 方法的输出

    `describe()`方法的输出将是：

    ![图2.40：describe()方法的输出

    ](img/C12622_02_40.jpg)

    ###### 图2.40：describe()方法的输出

1.  找出DataFrame中每列的缺失值总数和缺失值百分比，并按缺失值百分比降序显示至少有一个空值的列：

    正如我们在*练习12：可视化缺失值*中所做的那样，我们将使用`.isnull()`函数在DataFrame上获取掩码，通过在掩码DataFrame上使用`.sum()`函数找出每列的空值数量，并通过在掩码DataFrame上使用`.mean()`函数计算空值的比例，再乘以100将其转换为百分比。然后，我们使用`pd.concat()`将空值的总数和百分比合并成一个单独的DataFrame，并按缺失值的百分比排序行：

    [PRE15]

    输出结果如下：

    ![图2.41：每列缺失值的总数和百分比

    ](img/C12622_02_41.jpg)

    ###### 图2.41：每列缺失值的总数和百分比

1.  绘制空值矩阵和空值相关性热图。首先，我们找出包含至少一个空值的列名列表。然后，我们使用`missingno`库绘制空值矩阵（正如我们在*练习12：可视化缺失值*中所做的那样），并对这些列中的数据绘制空值相关性热图（样本为500个点）：

    [PRE16]

    空值矩阵将如下所示：

    ![图2.42：空值矩阵

    ](img/C12622_02_42.jpg)

    ###### 图2.42：空值矩阵

    空值相关性热图将如下所示：

    ![图2.43：空值相关性热图

    ](img/C12622_02_43.jpg)

    ###### 图2.43：空值相关性热图

1.  删除缺失值超过80%的列。使用我们在*第3步*中创建的DataFrame的`.loc`操作符，只选择缺失值少于80%的列：

    [PRE17]

1.  用NA值替换`FireplaceQu`列中的空值。使用`.fillna()`方法将空值替换为`NA`字符串：

    [PRE18]

### 活动3：可视化表示值的分布

**解决方案**

1.  使用Matplotlib绘制目标变量`SalePrice`的直方图。首先，我们使用`plt.figure`命令初始化图形并设置图形大小。然后，使用Matplotlib的`.hist()`函数作为主要绘图函数，将`SalePrice`系列对象传入以绘制直方图。最后，指定坐标轴标签并显示图形：

    [PRE19]

    输出结果如下：

    ![图2.44：目标变量的直方图

    ](img/C12622_02_44.jpg)

    ###### 图2.44：目标变量的直方图

1.  找出每一列具有对象类型的唯一值的数量。通过在原始 DataFrame 上使用 `.select_dtypes` 函数，选择具有 `numpy.object` 数据类型的列，创建一个名为 `object_variables` 的新 DataFrame。然后，使用 `.nunique()` 函数查找该 DataFrame 中每一列的唯一值数量，并对结果系列进行排序：

    [PRE20]

    输出结果将是：

    ![图 2.45：每一列具有对象类型的唯一值的数量

    ](img/C12622_02_45.jpg)

    ###### 图 2.45：每一列具有对象类型的唯一值的数量

1.  创建一个 DataFrame，表示 `HouseStyle` 列中每个类别值的出现次数。使用 `.value_counts()` 函数计算每个值的频率，按降序以 pandas 系列的形式表示，然后重置索引，得到一个 DataFrame，并按索引对值进行排序：

    [PRE21]

    输出结果将是：

    ![图 2.46：HouseStyle 列中每个类别值的出现次数

    ](img/C12622_02_46.jpg)

    ###### 图 2.46：HouseStyle 列中每个类别值的出现次数

1.  绘制表示这些计数的饼图。如同 *步骤 1*，我们使用 `plt.figure()` 初始化图像，并分别使用 `plt.title()` 和 `plt.show()` 方法来设置图形标题并显示图像。主要使用的绘图函数是 `plt.pie()`，将我们在前一步创建的系列传递给它：

    [PRE22]

    输出结果如下：

    ![图 2.47：表示计数的饼图

    ](img/C12622_02_47.jpg)

    ###### 图 2.47：表示计数的饼图

1.  找出每一列具有数字类型的唯一值的数量。如同 *步骤 2*，现在选择具有 `numpy.number` 数据类型的列，并使用 `.nunique()` 查找每一列的唯一值数量。按降序对结果系列进行排序：

    [PRE23]

    输出结果如下：

    ![图 2.48：每一列具有数字类型的唯一值的数量

    ](img/C12622_02_48.jpg)

    ###### 图 2.48：每一列具有数字类型的唯一值的数量

1.  使用 Seaborn 绘制 `LotArea` 变量的直方图。使用 Seaborn 的 `.distplot()` 函数作为主要绘图函数，并将 DataFrame 中的 `LotArea` 系列传递给它（去除空值；使用 `.dropna()` 函数删除空值）。为了改善图形的显示，还可以设置 `bins` 参数，并使用 `plt.xlim()` 指定 *X* 轴的限制：

    [PRE24]

    输出结果如下：

    ![图 2.49：LotArea 变量的直方图

    ](img/C12622_02_49.jpg)

    ###### 图 2.49：LotArea 变量的直方图

1.  计算每一列数值的偏斜值和峰度值：

    [PRE25]

    偏斜值的输出结果将是：

![图 2.50：每一列的偏斜值

](img/C12622_02_50.jpg)

###### 图 2.50：每一列的偏斜值

峰度值的输出结果将是：

![图 2.51：每一列的峰度值

](img/C12622_02_51.jpg)

###### 图 2.51：每一列的峰度值

### 活动4：数据中的关系

**解答**

1.  绘制数据集的相关性热力图。正如我们在*练习23：相关性热力图*中所做的那样，使用Seaborn的`.heatmap()`函数绘制热力图，并传递特征相关性矩阵（通过使用pandas的`.corr()`函数在数据框上确定）。此外，使用`cmap`参数将颜色图设置为`RdBu`，并通过`vmin`和`vmax`参数分别将颜色刻度的最小值和最大值设置为`-1`和`1`：

    [PRE26]

    输出结果如下：

    ![图2.52：数据集的热力图

    ](img/C12622_02_52.jpg)

    ###### 图2.52：数据集的热力图

1.  使用以下特征子集绘制一个更紧凑的热力图，并带有相关值的注释：

    [PRE27]

    现在，按照上一步的方法操作，这次只选择数据集中上述列，并向主绘图函数添加一个值为`True`的`annot`参数，其他保持不变：

    [PRE28]

    输出结果如下：

    ![图2.53：带有相关值注释的热力图

    ](img/C12622_02_53.jpg)

    ###### 图2.53：带有相关值注释的热力图

1.  显示同一特征子集的配对图，主对角线为KDE图，其它部分为散点图。使用Seaborn的`.pairplot()`函数绘制数据框中选定列的非空值的配对图。要将主对角线图设置为KDE图，可以将`kde`传递给`diag_kind`参数，要将其它图设置为散点图，则将`scatter`传递给`kind`参数：

    [PRE29]

    输出结果如下：

    ![图2.54：同一特征子集的配对图

    ](img/C12622_02_54.jpg)

    ###### 图2.54：同一特征子集的配对图

1.  创建一个箱型图，显示每个`GarageCars`类别中的`SalePrice`变动。这里使用的主要绘图函数是Seaborn的`.boxplot()`函数，我们将数据框以及`x`和`y`参数传递给它，前者是分类变量，后者是我们希望看到在每个类别中变动的连续变量，即`GarageCars`和`SalePrice`：

    [PRE30]

    输出结果如下：

    ![图2.55：显示每个`GarageCars`类别中`SalePrice`变动的箱型图

    ](img/C12622_02_55.jpg)

    ###### 图2.55：显示每个`GarageCars`类别中`SalePrice`变动的箱型图

1.  使用Seaborn绘制折线图，显示较旧和较新建公寓的`SalePrice`变化。在这里，我们将使用Seaborn的`.lineplot()`函数绘制折线图。由于我们希望查看`SalePrice`的变化，因此将其作为*y*变量，而由于变化跨越一段时间，我们将`YearBuilt`作为*x*变量。记住这一点，我们将相应的系列作为值传递给主绘图函数的`y`和`x`参数。同时，我们传递`ci=None`参数，以隐藏图中折线周围的标准差指示器：

    [PRE31]

    输出结果如下：

![图 2.56：显示旧公寓和新建公寓的SalePrice变化的折线图

](img/C12622_02_56.jpg)

###### 图 2.56：显示旧公寓和新建公寓的SalePrice变化的折线图

## 第三章：回归分析

### 活动 5：使用移动平均绘制数据

**解答**

1.  从CSV文件中将数据集加载到pandas DataFrame中：

    [PRE32]

    输出结果将显示`austin_weather.csv`文件的前五行：

    ![图 3.74：奥斯汀天气数据的前五行

    ](img/C12622_03_74.jpg)

    ###### 图 3.74：奥斯汀天气数据的前五行

1.  由于我们只需要`Date`和`TempAvgF`列，因此我们将从数据集中删除其他所有列：

    [PRE33]

    输出结果如下：

    ![图 3.75：奥斯汀天气数据的日期和TempAvgF列

    ](img/C12622_03_75.jpg)

    ###### 图 3.75：奥斯汀天气数据的日期和TempAvgF列

1.  最初，我们只关心第一年的数据，因此我们只需要提取该信息。在DataFrame中为年份创建一列，从`Date`列的字符串中提取年份值作为整数，并将这些值分配给`Year`列。请注意，温度是按天记录的：

    [PRE34]

    输出结果如下：

    ![图 3.76：提取年份

    ](img/C12622_03_76.jpg)

    ###### 图 3.76：提取年份

1.  重复此过程以提取月份值，并将值以整数形式存储在`Month`列中：

    [PRE35]

    输出结果如下：

    ![图 3.77：提取月份

    ](img/C12622_03_77.jpg)

    ###### 图 3.77：提取月份

1.  将第一年的数据复制到DataFrame中：

    [PRE36]

    输出结果如下：

    ![图 3.78：复制数据到新的数据框

    ](img/C12622_03_78.jpg)

    ###### 图 3.78：复制数据到新的数据框

1.  计算20天的移动平均滤波器：

    [PRE37]

    输出结果如下：

    [PRE38]

1.  绘制原始数据和移动平均信号，*x*轴为年份中的天数：

    [PRE39]

    输出结果如下：

![图 3.79：全年温度的散点图

](img/C12622_03_79.jpg)

###### 图 3.79：全年温度的散点图

### 活动 6：使用最小二乘法进行线性回归

**解答**

1.  可视化测量值：

    [PRE40]

    输出结果如下：

    ![图 3.80：activity2_measurements.csv数据集的前五行

    ](img/C12622_03_80.jpg)

    ###### 图 3.80：activity2_measurements.csv数据集的前五行

1.  可视化滚动平均值：

    [PRE41]

    输出结果如下：

    ![图 3.81：滚动头平均值

    ](img/C12622_03_81.jpg)

    ###### 图 3.81：滚动头平均值

1.  使用默认参数创建线性回归模型；即，计算模型的*y*截距并且不对数据进行归一化：

    [PRE42]

    输出结果如下：

    [PRE43]

1.  现在拟合模型，其中输入数据为年份的天数（1到365），输出为平均温度。为了便于后续计算，插入一列（`DayOfYear`），该列与该测量的年份天数对应：

    [PRE44]

    输出结果如下：

    ![图 3.82: 添加年份中的日期列

    ](img/C12622_03_82.jpg)

    ###### 图 3.82: 添加年份中的日期列

1.  使用 `DayOfYear` 值作为输入，`df_first_year.TempAvgF` 作为输出，拟合模型：

    [PRE45]

    输出将如下所示：

    [PRE46]

1.  打印模型的参数：

    [PRE47]

    输出将如下所示：

    [PRE48]

1.  我们可以通过使用线性方程中的第一个、中间和最后的值（年份中的天数）来计算趋势线值：

    [PRE49]

    输出将如下所示：

    [PRE50]

1.  绘制这些值与趋势线：

    [PRE51]

    输出将如下所示：

    ![图 3.83: 全年温度散点图与预测趋势线

    ](img/C12622_03_83.jpg)

    ###### 图 3.83: 全年温度的散点图与预测趋势线

1.  评估模型的表现。模型如何拟合数据？计算 r2 分数来找出答案：

    [PRE52]

    输出将如下所示：

    [PRE53]

### 活动 7: 虚拟变量

**解决方案**

1.  绘制原始数据（`df`）和移动平均值（`rolling`）：

    [PRE54]

    输出将如下所示：

    ![图 3.84: 全年温度的散点图

    ](img/C12622_03_84.jpg)

    ###### 图 3.84: 全年温度的散点图

1.  从前面的图来看，似乎在第 250 天左右有一个拐点。创建一个虚拟变量，将此特征引入线性模型：

    [PRE55]

1.  检查首尾样本，确认虚拟变量是否正确。检查前五个样本：

    [PRE56]

    输出将如下所示：

    ![图 3.85: 前五列

    ](img/C12622_03_85.jpg)

    ###### 图 3.85: 前五列

    然后，检查最后五个样本：

    [PRE57]

    输出将如下所示：

    ![图 3.86: 最后五列

    ](img/C12622_03_86.jpg)

    ###### 图 3.86: 最后五列

1.  使用最小二乘法线性回归模型，将模型拟合到 `DayOfYear` 值和虚拟变量上，以预测 `TempAvgF`：

    [PRE58]

    输出将如下所示：

    [PRE59]

1.  计算 r2 分数：

    [PRE60]

    输出将如下所示：

    [PRE61]

1.  使用 `DayOfYear` 值，创建一组预测值，使用模型构建趋势线：

    [PRE62]

    输出将如下所示：

    [PRE63]

1.  绘制趋势线与数据和移动平均值的对比：

    [PRE64]

    输出将如下所示：

![图 3.87: 预测趋势线

](img/C12622_03_87.jpg)

###### 图 3.87: 预测趋势线

### 活动 8: 其他类型的线性回归模型

**解决方案**

1.  使用正弦曲线函数作为模型的基础：

    [PRE65]

    输出将如下所示：

    ![图 3.88: 前五行

    ](img/C12622_03_88.jpg)

    ###### 图 3.88: 前五行

1.  拟合模型：

    [PRE66]

    输出将如下所示：

    [PRE67]

1.  打印模型的参数：

    [PRE68]

    输出将如下所示：

    [PRE69]

1.  计算 r2 值来衡量模型的表现：

    [PRE70]

    输出将如下所示：

    [PRE71]

1.  构建趋势线值：

    [PRE72]

    输出将如下所示：

    [PRE73]

1.  绘制趋势线与原始数据和移动平均值：

    [PRE74]

    输出将如下所示：

![图 3.89: 预测趋势线

](img/C12622_03_89.jpg)

###### 图 3.89: 预测趋势线

### 活动 9: 梯度下降法

**解决方案**

1.  创建一个通用的梯度下降模型，并将年份中的日期值归一化为 0 到 1 之间：

    [PRE75]

1.  拟合模型：

    [PRE76]

    输出将如下所示：

    [PRE77]

1.  打印模型的详细信息：

    [PRE78]

    输出将如下所示：

    [PRE79]

1.  准备 *x* (`_trend_x`) 趋势线值，通过将其除以最大值。使用梯度下降模型预测 `y_trend_values`：

    [PRE80]

    输出将如下所示：

    [PRE81]

1.  绘制数据和带趋势线的移动平均图：

    [PRE82]

    输出将如下所示：

![图 3.90：梯度下降预测的趋势线

](img/C12622_03_90.jpg)

###### 图 3.90：梯度下降预测的趋势线

### 活动 10：自回归模型

**解决方案**

1.  绘制完整的平均温度值（`df.TempAvgF`）图，*x* 轴为年份：

    [PRE83]

    输出将是：

    ![图 3.91：通过年份的温度变化图

    ](img/C12622_03_91.jpg)

    ###### 图 3.91：通过年份的温度变化图

1.  创建一个 20 天滞后，并将滞后数据绘制到原始数据集上：

    [PRE84]

    输出将是：

    ![图 3.92：带有 20 天滞后的温度变化图

    ](img/C12622_03_92.jpg)

    ###### 图 3.92：带有 20 天滞后的温度变化图

1.  构建自相关图，查看是否可以使用自回归模型来预测平均温度。对于自回归模型，在哪些地方滞后是可接受的，在哪些地方滞后不可接受？

    [PRE85]

    我们将得到以下输出：

    ![图 3.93：自相关与滞后关系图

    ](img/C12622_03_93.jpg)

    ###### 图 3.93：自相关与滞后关系图

    只有当自相关线超出 99% 置信区间（由虚线表示）时，滞后才是可接受的。

1.  选择一个可接受滞后和不可接受滞后，并使用这些值构建滞后图示：

    [PRE86]

    我们将得到以下输出：

    ![图 3.94：可接受滞后的图示

    ](img/C12622_03_94.jpg)

    ###### 图 3.94：可接受滞后的图示

    使用这些值来表示不可接受的滞后：

    [PRE87]

    我们将得到以下输出：

    ![图 3.95：不可接受滞后的图示

    ](img/C12622_03_95.jpg)

    ###### 图 3.95：不可接受滞后的图示

1.  创建一个自回归模型，注意选择的滞后值，计算 R2 值，并将自回归模型与原始图一起绘制。该模型用于预测超出可用数据的 1,000 个样本：

    [PRE88]

1.  将模型拟合到数据：

    [PRE89]

    输出将是：

    [PRE90]

1.  创建一个预测集，预测最后一个样本之后的 1,000 天：

    [PRE91]

    输出将是：

    [PRE92]

1.  绘制预测图以及原始数据集：

    [PRE93]

    输出将是：

    ![图 3.96：通过年份的温度变化图

    ](img/C12622_03_96.jpg)

    ###### 图 3.96：通过年份的温度变化图

1.  通过显示第 100 到第 200 个样本，增强视图以查看差异：

    [PRE94]

    我们将得到以下输出：

![图 3.97：带有原始数据集的预测图

](img/C12622_03_97.jpg)

###### 图 3.97：带有原始数据集的预测图

## 第四章：分类

### 活动 11：线性回归分类器 - 二类分类器

**解决方案**

1.  导入所需的依赖项：

    [PRE95]

1.  将 MNIST 数据加载到内存中：

    [PRE96]

1.  可视化数据的一个样本：

    [PRE97]

    我们将得到以下输出：

    ![图 4.76：样本数据

    ](img/C12622_04_76.jpg)

    ###### 图 4.76：样本数据

1.  构建一个线性分类器模型来分类数字0和1。我们将要创建的模型是确定样本是否为数字0或1。为此，我们首先需要仅选择这些样本：

    [PRE98]

1.  可视化选择的信息。以下是零的代码：

    [PRE99]

    输出将如下所示：

    ![图 4.77：第一个样本数据

    ](img/C12622_04_77.jpg)

    ###### 图 4.77：第一个样本数据

    这是零的代码：

    [PRE100]

    输出将为：

    ![图 4.78：第二个样本数据

    ](img/C12622_04_78.jpg)

    ###### 图 4.78：第二个样本数据

1.  为了将图像信息提供给模型，我们必须首先将数据展平，使得每个图像变为1 x 784像素的形状：

    [PRE101]

    输出将为：

    [PRE102]

1.  让我们构建模型；使用`LinearRegression` API并调用`fit`函数：

    [PRE103]

    输出将为：

    [PRE104]

1.  确定训练集的R2评分：

    [PRE105]

    输出将为：

    [PRE106]

1.  使用0.5的阈值来确定每个训练样本的标签预测。大于0.5的值分类为一；小于或等于0.5的值分类为零：

    [PRE107]

    输出将为：

    [PRE108]

1.  计算预测的训练值与真实值之间的分类准确性：

    [PRE109]

    输出将为：

    [PRE110]

1.  与测试集的性能进行比较：

    [PRE111]

    输出将为：

    [PRE112]

### 活动12：使用逻辑回归进行鸢尾花分类

**解决方案**

1.  导入所需的包。对于此活动，我们需要使用pandas包加载数据，Matplotlib包绘图，以及scikit-learn创建逻辑回归模型。导入所有必要的包和相关模块：

    [PRE113]

1.  使用pandas加载鸢尾花数据集并检查前五行：

    [PRE114]

    输出将为：

    ![图 4.79：鸢尾花数据集的前五行

    ](img/C12622_04_79.jpg)

    ###### 图 4.79：鸢尾花数据集的前五行

1.  下一步是特征工程。我们需要选择最合适的特征，以便提供最强大的分类模型。绘制多个不同特征与分配的物种分类之间的关系，例如，萼片长度与花瓣长度及物种。目视检查图表，寻找任何可能表示物种间分离的模式：

    [PRE115]

    输出将为：

    ![图 4.80：物种分类图

    ](img/C12622_04_80.jpg)

    ###### 图 4.80：物种分类图

1.  通过在以下列表中写入列名来选择特征：

    [PRE116]

1.  在构建模型之前，我们必须先将`species`值转换为模型中可以使用的标签。将`Iris-setosa`物种字符串替换为值`0`，将`Iris-versicolor`物种字符串替换为值`1`，将`Iris-virginica`物种字符串替换为值`2`：

    [PRE117]

1.  使用`selected_features`和分配的`species`标签创建模型：

    [PRE118]

    输出将为：

    [PRE119]

1.  计算模型在训练集上的准确性：

    [PRE120]

    输出将为：

    [PRE121]

1.  使用你第二选择的 `selected_features` 构建另一个模型，并比较其性能：

    [PRE122]

    输出将如下：

    [PRE123]

1.  使用所有可用信息构建另一个模型并比较其性能：

    [PRE124]

    输出将如下：

    [PRE125]

### 活动 13: K-NN 多分类器

**解决方案**

1.  导入以下包：

    [PRE126]

1.  将 MNIST 数据加载到内存中。

    训练图像：

    [PRE127]

    训练标签：

    [PRE128]

    测试图像：

    [PRE129]

    测试标签：

    [PRE130]

1.  可视化数据样本：

    [PRE131]

    输出将如下：

    ![图 4.81: 示例图像

    ](img/C12622_04_81.jpg)

    ###### 图 4.81: 示例图像

1.  构建一个 K-NN 分类器，使用三个最近邻来分类 MNIST 数据集。同样，为了节省处理能力，我们随机抽取 5,000 张图像用于训练：

    [PRE132]

1.  为了将图像信息提供给模型，我们必须先将数据展平，使得每个图像的形状为 1 x 784 像素：

    [PRE133]

    输出将如下：

    [PRE134]

1.  构建三邻近 KNN 模型并将数据拟合到模型中。请注意，在本活动中，我们为模型提供的是 784 个特征或维度，而不仅仅是 2：

    [PRE135]

    输出将如下：

    [PRE136]

1.  确定与训练集的得分：

    [PRE137]

    输出将如下所示：

    [PRE138]

1.  显示模型对训练数据的前两个预测：

    [PRE139]

    输出将如下：

    ![图 4.82: 第一个预测值

    ](img/C12622_04_82.jpg)

    ###### 图 4.82: 第一个预测值

1.  与测试集的表现进行比较：

    [PRE140]

    输出将如下：

    [PRE141]

## 第 5 章: 集成模型

### 活动 14: 使用独立和集成算法进行堆叠

**解决方案**

1.  导入相关库：

    [PRE142]

1.  读取数据并打印前五行：

    [PRE143]

    输出将如下：

    ![图 5.19: 前五行

    ](img/C12622_05_19.jpg)

    ###### 图 5.19: 前五行

1.  对数据集进行预处理，移除空值并对类别变量进行独热编码，以准备建模数据。

    首先，我们删除所有超过 10% 值为空的列。为此，使用 `.isnull()` 方法计算缺失值的比例，得到一个掩码 DataFrame，并使用 `.mean()` 方法计算每一列的空值比例。将结果乘以 100，得到百分比形式的系列。

    然后，找到该系列中百分比值低于 10 的子集，并将索引（这将给我们列名）保存为列表。打印该列表以查看我们得到的列：

    [PRE144]

    输出将如下：

    ![图 5.20: 数据集预处理的输出

    ](img/C12622_05_20.jpg)

    ###### 图 5.20: 数据集预处理的输出

    由于第一列是 `id`，我们也将排除这一列，因为它对模型没有任何帮助。

    我们将从数据中提取所有在`col`列表中的列，除了第一个元素`id`：

    [PRE145]

    对于类别变量，我们用字符串 `NA` 替换空值，并使用 pandas 的 `.get_dummies()` 方法进行独热编码，而对于数值变量，我们将空值替换为 `-1`。然后，我们将数值列和类别列合并，得到最终的数据框：

    [PRE146]

1.  将数据集划分为训练和验证 DataFrame。

    我们使用 scikit-learn 的 `train_test_split()` 方法将最终的 DataFrame 按 4:1 的比例划分为训练集和验证集。然后，我们将每个数据集进一步拆分为各自的 `x` 和 `y` 值，分别表示特征和目标变量：

    [PRE147]

1.  初始化字典，用于存储训练和验证的 MAE 值。我们将创建两个字典，用于存储训练和验证数据集上的 MAE 值：

    [PRE148]

1.  训练一个决策树模型并保存分数。我们将使用 scikit-learn 的 `DecisionTreeRegressor` 类来训练一个回归模型，使用单棵决策树：

    [PRE149]

1.  训练一个 k 最近邻模型并保存分数。我们将使用 scikit-learn 的 `kNeighborsRegressor` 类来训练一个回归模型，*k=5*：

    [PRE150]

1.  训练一个随机森林模型并保存分数。我们将使用 scikit-learn 的 `RandomForestRegressor` 类来训练一个回归模型，采用自助法（bagging）：

    [PRE151]

1.  训练一个梯度提升模型并保存分数。我们将使用 scikit-learn 的 `GradientBoostingRegressor` 类来训练一个增强回归模型：

    [PRE152]

1.  使用在之前步骤中使用的相同超参数准备训练和验证数据集，其中包含四个元估计器。我们将创建一个 `num_base_predictors` 变量，表示堆叠模型中基估计器的数量，以帮助计算训练和验证数据集的形状。这个步骤几乎可以像本章的练习一样编写代码，只不过基估计器的数量（和类型）不同。

1.  首先，我们创建一个新的训练集，增加来自基估计器的预测列，方法与之前相同：

    [PRE153]

    然后，我们使用 k 折交叉验证策略训练基模型。在每次迭代中，我们将预测值保存在列表中，并遍历列表，将预测值分配到该折中的列：

    [PRE154]

    之后，我们创建一个新的验证集，增加来自基估计器的预测列：

    [PRE155]

1.  最后，我们在完整的训练集上拟合基模型，以获取验证集的元特征：

    [PRE156]

1.  训练一个线性回归模型作为堆叠模型。为了训练堆叠模型，我们在训练数据集的所有列上训练逻辑回归模型，外加基估计器的元预测。然后，我们使用最终预测值来计算 MAE 值，并将其存储在相同的 `train_mae_values` 和 `val_mae_values` 字典中：

    [PRE157]

1.  可视化每个独立模型和堆叠模型的训练和验证误差。然后，我们将字典转换为两个系列，并将它们组合成一个 Pandas DataFrame 的两列：

    [PRE158]

    输出将如下所示：

    ![图 5.21：每个独立模型和堆叠模型的训练和验证误差

    ](img/C12622_05_21.jpg)

    ###### 图 5.21：每个独立模型和堆叠模型的训练和验证误差

1.  然后，我们从这个 DataFrame 绘制条形图，使用每个模型可视化训练集和验证集的 MAE 值：

    [PRE159]

    输出将如下所示：

![图 5.22：可视化 MAE 值的条形图

](img/C12622_05_22.jpg)

###### 图 5.22：可视化 MAE 值的条形图

正如我们在图中所看到的，线性回归堆叠模型在训练和验证数据集上都具有最低的平均绝对误差值，甚至低于其他集成模型（随机森林和梯度增强回归器）。

## 第 6 章：模型评估

### 活动 15：最终测试项目

**解决方案**

1.  导入相关的库：

    [PRE160]

1.  读取 `attrition_train.csv` 数据集。将 CSV 文件读取到 DataFrame 中，并打印 DataFrame 的 `.info()`：

    [PRE161]

    输出将如下所示：

    ![图 6.33：info() 输出

    ](img/C12622_06_33.jpg)

    ###### 图 6.33：info() 输出

1.  读取包含分类变量详情的 JSON 文件。该 JSON 文件包含一个字典，字典的键是分类特征的列名，值是该特征的类别列表。这个文件将帮助我们将分类特征进行独热编码，转换为数值特征。使用 `json` 库加载文件对象到字典中，并打印该字典：

    [PRE162]

    输出将如下所示：

    ![图 6.34：JSON 文件

    ](img/C12622_06_34.jpg)

    ###### 图 6.34：JSON 文件

1.  处理数据集，将所有特征转换为数值。首先，找出那些保持原始形式的列（即数值特征）和需要进行独热编码的列（即分类特征）。`data.shape[1]` 给我们提供了 `data` 的列数，我们从中减去 `len(cat_values_dict)`，就能得到数值列的数量。要找出分类列的数量，我们只需从 `cat_values_dict` 字典中统计所有分类变量的类别总数：

    [PRE163]

    输出将是：

    [PRE164]

    创建一个全零的 NumPy 数组作为占位符，其形状等于先前确定的总列数减去 1（因为 `Attrition` 目标变量也包含在内）。对于数值列，我们接着创建一个掩码，从 DataFrame 中选择数值列，并将它们赋值给数组 `X` 中的前 `num_orig_cols-1` 列：

    [PRE165]

    接下来，我们从 scikit-learn 初始化 `OneHotEncoder` 类，传入一个包含每个分类列的值列表的列表。然后，我们将分类列转换为独热编码列，并将它们赋值给 `X` 中剩余的列，并将目标变量的值保存在 `y` 变量中：

    [PRE166]

    输出将是：

    [PRE167]

1.  选择一个基础模型，并定义要在超参数调优时搜索的超参数值范围。我们选择使用梯度增强分类器作为模型。然后，我们定义一个字典形式的所有超参数的值范围，以便进行调优：

    [PRE168]

1.  定义初始化`RandomizedSearchCV`对象的参数，并使用K折交叉验证来寻找最佳模型超参数。定义随机搜索所需的参数，包括`cv`为`5`，表示通过5折交叉验证来选择超参数。然后，初始化`RandomizedSearchCV`对象并使用`.fit()`方法开始优化：

    [PRE169]

    输出将如下所示：

    ![图 6.35：优化过程的输出

    ](img/C12622_06_35.jpg)

    ###### 图 6.35：优化过程的输出

    一旦调优完成，找到获得最高均值测试分数的位置（迭代次数）。找出相应的超参数并将其保存到字典中：

    [PRE170]

    输出将如下所示：

    ![图 6.36：超参数字典

    ](img/C12622_06_36.jpg)

    ###### 图 6.36：超参数字典

1.  将数据集拆分为训练集和验证集，并使用最终超参数在训练数据集上训练一个新模型。使用scikit-learn的`train_test_split()`方法将`X`和`y`拆分为训练集和测试集，其中测试集占数据集的15%：

    [PRE171]

    输出将如下所示：

    [PRE172]

    使用最终超参数训练梯度提升分类模型，并对训练集和验证集进行预测。还计算验证集上的概率：

    [PRE173]

1.  计算验证集上的准确度、精度和召回率，并打印混淆矩阵：

    [PRE174]

    输出将如下所示：

    ![图 6.37：准确度、精度、召回率和混淆矩阵

    ](img/C12622_06_37.jpg)

    ###### 图 6.37：准确度、精度、召回率和混淆矩阵

1.  尝试不同的阈值以找到最佳的高召回率点。

    绘制精度-召回曲线：

    [PRE175]

    输出将如下所示：

    ![图 6.38：精度-召回曲线

    ](img/C12622_06_38.jpg)

    ###### 图 6.38：精度-召回曲线

    绘制精度和召回率随着阈值增加的变化：

    [PRE176]

    输出将如下所示：

    ![图 6.39：精度和召回率随着阈值增加的变化

    ](img/C12622_06_39.jpg)

    ###### 图 6.39：精度和召回率随着阈值增加的变化

1.  确定一个最终的阈值，用于在测试数据集上进行预测。我们确定一个值，例如0.3。这个值完全依赖于你在前一步的探索中认为最优的结果：

    [PRE177]

1.  读取并处理测试数据集，将所有特征转换为数值。这将以类似于*步骤 4*的方式进行，唯一的区别是我们不需要考虑目标变量列，因为数据集中不包含它：

    [PRE178]

1.  在测试数据集上预测最终值并保存到文件。使用在*步骤 10*中确定的最终阈值来找到训练集中的每个值的类别。然后，将最终预测写入`final_predictions.csv`文件：

    [PRE179]

    输出将是一个 CSV 文件，如下所示：

![图 6.40：CSV 文件](img/C12622_06_40.jpg)

###### 图 6.40：CSV 文件
