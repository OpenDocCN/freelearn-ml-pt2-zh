["```py\nfrom sklearn import linear_model\noffline_model = linear_model.LogisticRegression(params)\noffline_model.fit(X, Y) \n```", "```py\nfrom river import linear_model\nonline_model = linear_model.LogisticRegression(params)\nfor xi, yi in zip(X, y):\n    online_model.learn_one(xi, yi) \n```", "```py\npip install river \n```", "```py\nimport numpy as np\nnp.random.seed(12345)\ndata_stream = np.concatenate(\n    (np.random.randint(2, size=1000), np.random.randint(8, size=1000))\n) \n```", "```py\ndef perform_test(drift_detector, data_stream):\n    detected_indices = []\n    for i, val in enumerate(data_stream):\n        in_drift, in_warning = drift_detector.update(val)\n        if in_drift:\n            detected_indices.append(i)\n    return detected_indices \n```", "```py\nimport matplotlib.pyplot as plt\ndef show_drift(data_stream, indices):\n    fig, ax = plt.subplots(figsize=(16, 6))\n    ax.plot(data_stream)\n    ax.plot(\n        indices,\n        data_stream[indices],\n        \"ro\",\n        alpha=0.6,\n        marker=r'$\\circ$',\n        markersize=22,\n        linewidth=4\n    )\nplt.tight_layout() \n```", "```py\nfrom river import stream\nfrom river.datasets import base\nclass SolarFlare(base.FileDataset):\n    def __init__(self):\n        super().__init__(\n            n_samples=1066,\n            n_features=10,\n            n_outputs=1,\n            task=base.MO_REG,\n            filename=\"solar-flare.csv.zip\",\n        )\n    def __iter__(self):\n        return stream.iter_csv(\n            self.path,\n            target=\"m-class-flares\",\n            converters={\n                \"zurich-class\": str,\n                \"largest-spot-size\": str,\n                \"spot-distribution\": str,\n                \"activity\": int,\n                \"evolution\": int,\n                \"previous-24h-flare-activity\": int,\n                \"hist-complex\": int,\n                \"hist-complex-this-pass\": int,\n                \"area\": int,\n                \"largest-spot-area\": int,\n                \"c-class-flares\": int,\n                \"m-class-flares\": int,\n                \"x-class-flares\": int,\n            },\n        ) \n```", "```py\nfrom pprint import pprint\nfrom river import datasets\nfor x, y in SolarFlare():\n    pprint(x)\n    pprint(y)\n    break \n```", "```py\nimport numbers\nfrom river import compose\nfrom river import preprocessing\nfrom river import tree\nnum = compose.SelectType(numbers.Number) | preprocessing.MinMaxScaler()\ncat = compose.SelectType(str) | preprocessing.OneHotEncoder(sparse=False)\nmodel = tree.HoeffdingTreeRegressor()\npipeline = (num + cat) | model \n```", "```py\nfrom river import evaluate\nfrom river import metrics\nmetric = metrics.MAE()\nevaluate.progressive_val_score(SolarFlare(), pipeline, metric) \n```", "```py\nerrors = []\nfor x, y in SolarFlare():\n    y_pred = pipeline.predict_one(x)\n    metric = metric.update(y, y_pred)\n    errors.append(metric.get())\n    pipeline = pipeline.learn_one(x, y) \n```", "```py\nfig, ax = plt.subplots(figsize=(16, 6))\nax.plot(\n    errors,\n    \"ro\",\n    alpha=0.6,\n    markersize=2,\n    linewidth=4\n)\nax.set_xlabel(\"number of points\")\nax.set_ylabel(\"MAE\") \n```", "```py\nfrom river import (\n    synth, ensemble, tree,\n    evaluate, metrics\n)\nmodels = [\n    tree.HoeffdingTreeRegressor(),\n    tree.HoeffdingAdaptiveTreeRegressor(),\n    ensemble.AdaptiveRandomForestRegressor(seed=42)\n] \n```", "```py\nfor model in models:\n    metric = metrics.MSE()\n    dataset = synth.ConceptDriftStream(\n        seed=42, position=500, width=40\n    ).take(1000)\n    evaluate.progressive_val_score(dataset, model, metric)\n    print(f\"{str(model.__class__).split('.')[-1][:-2]}: {metric.get():e}\") \n```", "```py\nHoeffdingTreeRegressor: 8.427388e+42\nHoeffdingAdaptiveTreeRegressor: 8.203782e+42 AdaptiveRandomForestRegressor: 1.659533037987239+42 \n```", "```py\nfrom river import compose\nfrom river import linear_model\nfrom river import preprocessing\nfrom river import optim\nmodels = [\n    compose.Pipeline(\n        preprocessing.StandardScaler(),\n        linear_model.LinearRegression(optimizer=optim.SGD(lr=lr))\n    )\n    for lr in [1e-4, 1e-3, 1e-2, 1e-1]\n] \n```", "```py\nfrom river import datasets\ndataset = datasets.TrumpApproval() \n```", "```py\nfrom river.expert import UCBRegressor\nbandit = UCBRegressor(models=models, seed=1) \n```", "```py\nfor x, y in dataset:\n    bandit = bandit.learn_one(x=x, y=y) \n```", "```py\nfor model, pct in zip(bandit.models, bandit.percentage_pulled):\n    lr = model[\"LinearRegression\"].optimizer.learning_rate\n    print(f\"{lr:.1e} — {pct:.2%}\") \n```", "```py\n1.0e-04 — 2.45%\n1.0e-03 — 2.45%\n1.0e-02 — 92.25%\n1.0e-01 — 2.85% \n```", "```py\nfor model, avg in zip(bandit.models, bandit.average_reward):\n    lr = model[\"LinearRegression\"].optimizer.learning_rate\n    print(f\"{lr:.1e} — {avg:.2f}\") \n```", "```py\n1.0e-04 — 0.00\n1.0e-03 — 0.00\n1.0e-02 — 0.74\n1.0e-01 — 0.05 \n```", "```py\nbest_model = bandit.best_model \n```", "```py\nbest_model[\"LinearRegression\"].intercept_lr.learning_rate \n```"]