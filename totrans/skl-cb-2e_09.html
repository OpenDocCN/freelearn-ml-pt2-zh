<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Tree Algorithms and Ensembles</h1>
                </header>
            
            <article>
                
<p>In this chapter we will cover the following recipes:</p>
<ul>
<li><span>Doing basic classifications with decision trees</span></li>
<li>Visualizing a decision tree with pydot</li>
<li>Tuning a decision tree</li>
<li>Using decision trees for regression</li>
<li>Reducing overfitting with cross-validation</li>
<li>Implementing random forest regression</li>
<li><span>Bagging regression with nearest neighbor</span></li>
<li>Tuning gradient boosting trees</li>
<li>Tuning an AdaBoost regressor</li>
<li>Writing a stacking aggregator with scikit-learn</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction</h1>
                </header>
            
            <article>
                
<p>In this chapter, we focus on decision trees and ensemble algorithms. Decision algorithms are easy to interpret and visualize as they are outlines of the decision making process we are familiar with. Ensembles can be partially interpreted and visualized, but they have many parts (base estimators), so we cannot always read them easily.</p>
<p>The goal of ensemble learning is that several estimators can work better than a single one. There are two families of ensemble methods implemented in scikit-learn: averaging methods and boosting methods. Averaging methods (random forest, bagging, extra trees) reduce variance by averaging the predictions of several estimators. Boosting methods (gradient boost and AdaBoost) reduce bias by sequential building base estimators with the goal of reducing the bias of the whole ensemble.</p>
<p>A common characteristic of many ensemble constructions is using randomness to build predictors. Random forest, for example, uses randomness (as its name implies), and we will use a search through many model parameters using randomness. Use the ideas of randomness in this chapter to build on them at work, reduce the computational cost, and produce better-scoring algorithms.</p>
<p>We finish the chapter with a stacking aggregator, which is an ensemble of potentially very different models. Part of the data analysis in stacking is taking predictions of several machine learning algorithms <span>as input</span><span>.</span></p>
<div class="packt_infobox">A lot of data science is computationally intensive. If possible, use a multi-core computer. Throughout, there is a parameter called <kbd>n_jobs</kbd> set to <kbd>-1</kbd>, which utilizes all of your computer's cores.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Doing basic classifications with decision trees</h1>
                </header>
            
            <article>
                
<p>Here, we perform basic classification with decision trees. Decision trees for classification are sequences of decisions that determine a classification, or a categorical outcome. Additionally, the decision tree can be examined in SQL by other individuals <span>within the same company </span><span>looking at the data.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Start by loading the iris dataset once again and dividing the data into training and testing sets:</p>
<pre class="mce-root"><strong>from sklearn.datasets import load_iris</strong><br/><br/><strong>iris = load_iris()</strong><br/><br/><strong>X = iris.data</strong><br/><strong>y = iris.target</strong><br/><br/><strong>from sklearn.model_selection import train_test_split</strong><br/><br/><strong>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Import the decision tree classifier and train it on the training set:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.tree import DecisionTreeClassifier</strong><br/><br/><strong>dtc = DecisionTreeClassifier()     #Instantiate tree class</strong><br/><strong>dtc.fit(X_train, y_train)</strong></pre>
<ol start="2">
<li>Then measure the accuracy on the test set:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.metrics import accuracy_score</strong><br/><br/><strong>y_pred = dtc.predict(X_test)</strong><br/><strong>accuracy_score(y_test, y_pred)</strong><br/><br/><strong>0.91111111111111109</strong></pre>
<p>The decision tree appears to be accurate. Let's examine it further.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Visualizing a decision tree with pydot</h1>
                </header>
            
            <article>
                
<p>If you would like to produce graphs, install the <kbd>pydot</kbd> <span>library</span>. Unfortunately, for Windows this installation could be non-trivial. Please focus on looking at the graphs rather than reproducing them if you struggle to install <kbd>pydot</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Within an IPython Notebook, perform several imports and type the following script:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>import numpy as np</strong><br/><strong>from sklearn import tree</strong><br/><strong>from sklearn.externals.six import StringIO</strong><br/><strong>import pydot</strong><br/><strong>from IPython.display import Image</strong><br/><br/><strong>dot_iris = StringIO() </strong><br/><strong>tree.export_graphviz(dtc, out_file = dot_iris, feature_names = iris.feature_names) </strong><br/><strong>graph = pydot.graph_from_dot_data(dot_iris.getvalue())</strong><br/><strong>Image(graph.create_png())</strong></pre>
<div class="CDPAlignCenter CDPAlign"><img src="assets/7a0cd685-1f72-4a14-a1d9-540000655e0e.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>This is the decision tree that was produced with the training; calling the <kbd>fit</kbd> method on <kbd>X_train</kbd> and <kbd>y_train</kbd>. Look at it closely, starting at the top of the tree. You have 105 samples in the training set. The training set is split into three sets of 35 each: <em>value = [35, 35, 35]</em>. Explicitly, these are 35 Setosa, 35 Versicolor, and 35 Virginica flowers:</p>
<div class="CDPAlignCenter CDPAlign"><img height="178" width="323" src="assets/7757355c-4e94-45fc-b93c-339e725fbeee.png"/></div>
<p>The first decision is whether the petal length of the flower is less than or equal to 2.45. If the answer is true, or yes, the flower is classified as being in the first category, <em>value = [35, 0, 0]</em>. The flower is classified as being a Setosa flower. In several examples of the iris dataset classification, this one was the easiest to classify.</p>
<p>Otherwise, if the petal length is greater than 2.45, the first decision leads to a smaller decision tree. The smaller decision tree only has flowers of the last two types, Versicolour and Virginica, and the <em>value = [0, 35, 35]</em>.</p>
<p>The algorithm proceeds to produce a complete tree of four levels, depth 4 (note that the top node is not included in counting the levels). With formal language, the three nodes characterizing a decision in the picture are called a <strong>split</strong>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>You might wonder what the gini reference is within the visualization of the decision tree. Gini refers to the gini function, which measures the quality of a split, with three nodes representing a decision. When the algorithm runs, a few splits <span>that optimize the gini function </span><span>are considered. The split that produces the best gini impurity measure is chosen.</span></p>
<p>Another option is to measure entropy to determine how to split the tree. You can try both options and determine which is best using cross-validation. Change the criterion in the decision tree as follows:</p>
<pre><strong>from sklearn.tree import DecisionTreeClassifier</strong><br/><br/><strong>dtc = DecisionTreeClassifier(criterion='entropy')</strong><br/><strong>dtc.fit(X_train, y_train)</strong></pre>
<p>This leads to the following diagram of the tree:</p>
<div class="CDPAlignCenter CDPAlign"><img height="324" width="314" src="assets/e4ace225-9883-4ac8-8f24-e5ebc5898b95.png"/></div>
<p>You can examine how this criterion performs under cross-validation using <kbd>GridSearchCV</kbd> and vary the criterion parameter in the parameter grid. We will do this in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Tuning a decision tree</h1>
                </header>
            
            <article>
                
<p>We will continue to explore the iris dataset further by focusing on the first two features (sepal length and sepal width), optimizing the decision tree, and creating some visualizations.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<ol>
<li>Load the iris dataset, focusing on the first two features. Additionally, split the data into training and testing sets:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.datasets import load_iris</strong><br/><br/><strong>iris = load_iris()</strong><br/><strong>X = iris.data[:,:2]</strong><br/><strong>y = iris.target</strong><br/><br/><strong>from sklearn.model_selection import train_test_split</strong><br/><br/><strong>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)</strong></pre>
<ol start="2">
<li>View the data with pandas:</li>
</ol>
<pre style="padding-left: 60px"><strong>import pandas as pd</strong><br/><strong>pd.DataFrame(X,columns=iris.feature_names[:2])</strong></pre>
<div class="CDPAlignCenter CDPAlign"><img height="252" width="268" src="assets/9ced7bac-4256-4fee-a792-e3b1bb470662.png"/></div>
<ol start="3">
<li>Before optimizing the decision tree, let's try a single decision tree with default parameters. Instantiate and train a decision tree:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.tree import DecisionTreeClassifier</strong><br/><br/><strong>dtc = DecisionTreeClassifier()     #Instantiate tree with default parameters</strong><br/><strong>dtc.fit(X_train, y_train)</strong></pre>
<ol start="4">
<li>Measure the accuracy score:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.metrics import accuracy_score</strong><br/><br/><strong>y_pred = dtc.predict(X_test)</strong><br/><strong>accuracy_score(y_test, y_pred)</strong><br/><br/><strong>0.66666666666666663</strong></pre>
<p>Visualizing the tree with <kbd>graphviz</kbd> reveals a very complex tree with many nodes and levels (the image is for representational purposes only: it is OK if you cannot read it! It is a very deep tree with lots of overfitting!):</p>
<div class="CDPAlignCenter CDPAlign"><img height="492" width="886" src="assets/0efa05a9-d506-4952-a84f-518c4df1f233.png"/></div>
<p>This is a case of overfitting. The decision tree is very elaborate. The whole iris dataset consists of 150 samples, and a very complex tree is undesirable. Recall that in previous chapters we have used linear SVMs, which split space in a simple way with a few straight lines.</p>
<p>Before continuing, visualize the training data points using matplotlib:</p>
<pre class="mce-root"><strong>import matplotlib.pyplot as plt</strong><br/><strong>%matplotlib inline</strong><br/><br/><strong>plt.figure(figsize=((12,6)))</strong><br/><strong>plt.xlabel(iris.feature_names[0])</strong><br/><strong>plt.ylabel(iris.feature_names[1])</strong><br/><br/><strong>plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train)</strong></pre>
<div class="mce-root CDPAlignCenter CDPAlign"><br/>
<img src="assets/4ad4b828-df97-4c91-a8d9-74837a60dacc.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>To optimize the decision tree's performance, use <kbd>GridSearchCV</kbd>. Start by instantiating a decision tree:</li>
</ol>
<pre style="padding-left: 60px"><strong>from sklearn.tree import DecisionTreeClassifier</strong><br/><strong>dtc = DecisionTreeClassifier()</strong></pre>
<ol start="2">
<li>Then, instantiate and train <kbd>GridSearchCV</kbd>:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.model_selection import GridSearchCV, cross_val_score</strong><br/><br/><strong>param_grid = {'criterion':['gini','entropy'], 'max_depth' : [3,5,7,20]}</strong><br/><br/><strong>gs_inst = GridSearchCV(dtc,param_grid=param_grid,cv=5)</strong><br/><strong>gs_inst.fit(X_train, y_train)</strong></pre>
<div class="packt_infobox">Note how in the parameter grid, <kbd>param_grid</kbd>, we vary the split scoring criterion between <kbd>gini</kbd> and <kbd>entropy</kbd> and vary the <kbd>max_depth</kbd> of a tree.</div>
<ol start="3">
<li>Now try to score the accuracy on the test set:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.metrics import accuracy_score</strong><br/><br/><strong>y_pred_gs = gs_inst.predict(X_test)</strong><br/><strong>accuracy_score(y_test, y_pred_gs)</strong><br/><br/><strong>0.68888888888888888</strong></pre>
<p style="padding-left: 60px">The accuracy improved slightly. Let's look at <kbd>GridSearchCV</kbd> more closely.</p>
<ol start="4">
<li>View the scores of all the decision trees tried in the grid search:</li>
</ol>
<pre style="padding-left: 60px"><strong>gs_inst.grid_scores_</strong><br/><br/><strong>[mean: 0.78095, std: 0.09331, params: {'criterion': 'gini', 'max_depth': 3},</strong><br/><strong> mean: 0.68571, std: 0.08832, params: {'criterion': 'gini', 'max_depth': 5},</strong><br/><strong> mean: 0.70476, std: 0.08193, params: {'criterion': 'gini', 'max_depth': 7},</strong><br/><strong> mean: 0.66667, std: 0.09035, params: {'criterion': 'gini', 'max_depth': 20},</strong><br/><strong> mean: 0.78095, std: 0.09331, params: {'criterion': 'entropy', 'max_depth': 3},</strong><br/><strong> mean: 0.69524, std: 0.11508, params: {'criterion': 'entropy', 'max_depth': 5},</strong><br/><strong> mean: 0.72381, std: 0.09712, params: {'criterion': 'entropy', 'max_depth': 7},</strong><br/><strong> mean: 0.67619, std: 0.09712, params: {'criterion': 'entropy', 'max_depth': 20}]</strong></pre>
<div class="packt_tip packt_infobox">Note that this method will be unavailable in future versions of scikit-learn. Feel free to use <kbd>zip(gs_inst.cv_results_['mean_test_score'],gs_inst.cv_results_['params'])</kbd> to produce similar results.</div>
<p style="padding-left: 60px">From this list of scores, you can see that deeper trees perform worse than shallow trees. In detail, the data in the training set is split into five parts. Training occurs in four parts while testing happens in one of the five parts. Very deep trees overfit: they perform well on the training sets, but on the five testing sets of the cross-validation, they perform badly.</p>
<ol start="5">
<li>Select the best performing tree with the <kbd>best_estimator_</kbd> attribute:</li>
</ol>
<pre style="padding-left: 60px"><strong>gs_inst.best_estimator_</strong><br/><br/><strong>DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,</strong><br/><strong> max_features=None, max_leaf_nodes=None,</strong><br/><strong> min_impurity_split=1e-07, min_samples_leaf=1,</strong><br/><strong> min_samples_split=2, min_weight_fraction_leaf=0.0,</strong><br/><strong> presort=False, random_state=None, splitter='best')</strong></pre>
<ol start="6">
<li>Visualize the tree with <kbd>graphviz</kbd>:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>import numpy as np</strong><br/><strong>from sklearn import tree</strong><br/><strong>from sklearn.externals.six import StringIO</strong><br/><br/><strong>import pydot</strong><br/><strong>from IPython.display import Image</strong><br/><br/><strong>dot_iris = StringIO()</strong><br/><strong>tree.export_graphviz(gs_inst.best_estimator_, out_file = dot_iris, feature_names = iris.feature_names[:2])</strong><br/><strong>graph = pydot.graph_from_dot_data(dot_iris.getvalue())</strong><br/><br/><strong>Image(graph.create_png())</strong></pre>
<div class="CDPAlignCenter CDPAlign"><img height="344" width="938" src="assets/159231ba-c3cb-4edc-9af6-7bf024922a4f.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<ol>
<li>For additional insight, we will create an additional visualization. Start by creating a NumPy mesh grid as follows:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>grid_interval = 0.02</strong><br/><br/><strong>x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5</strong><br/><strong>y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5</strong><br/><br/><strong>xmin, xmax = np.percentile(X[:, 0], [0, 100])</strong><br/><strong>ymin, ymax = np.percentile(X[:, 1], [0, 100])</strong><br/><br/><strong>xmin_plot, xmax_plot = xmin - .5, xmax + .5</strong><br/><strong>ymin_plot, ymax_plot = ymin - .5, ymax + .5</strong><br/><br/><strong>xx, yy = np.meshgrid(np.arange(xmin_plot, xmax_plot, grid_interval),</strong><br/><strong>np.arange(ymin_plot, ymax_plot, grid_interval))</strong></pre>
<ol start="2">
<li>Using the <kbd>best_estimator_</kbd> attribute in the grid search, predict the scenarios on the NumPy grid that was just created:</li>
</ol>
<pre style="padding-left: 60px"><strong>test_preds = gs_inst.best_estimator_.predict(np.array(zip(xx.ravel(), yy.ravel())))</strong></pre>
<ol start="3">
<li>Look at the visualization:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>import matplotlib.pyplot as plt</strong><br/><strong>%matplotlib inline</strong><br/><br/><strong>X_0 = X[y == 0]</strong><br/><strong>X_1 = X[y == 1]</strong><br/><strong>X_2 = X[y == 2]</strong><br/><br/><strong>plt.figure(figsize=(15,8)) #change figure-size for easier viewing</strong><br/><strong>plt.scatter(X_0[:,0],X_0[:,1], color = 'red')</strong><br/><strong>plt.scatter(X_1[:,0],X_1[:,1], color = 'blue')</strong><br/><strong>plt.scatter(X_2[:,0],X_2[:,1], color = 'green')</strong><br/><br/><strong>colors = np.array(['r', 'b','g'])</strong><br/><strong>plt.scatter(xx.ravel(), yy.ravel(), color=colors[test_preds], alpha=0.15)</strong><br/><strong>plt.scatter(X[:, 0], X[:, 1], color=colors[y])</strong><br/><strong>plt.title("Decision Tree Visualization")</strong><br/><strong>plt.xlabel(iris.feature_names[0])</strong><br/><strong>plt.ylabel(iris.feature_names[1])</strong></pre>
<div class="CDPAlignCenter CDPAlign"><img height="317" width="586" src="assets/f77dc2dd-a3ae-4675-96f4-90964fdb18b9.png"/></div>
<ol start="4">
<li>Using this type of visualization, you can see that decision trees try to construct rectangles to classify the type of iris flower. Every split creates a line perpendicular to one of the features. In the following graph there is a vertical line depicting the first decision, whether sepal length is greater (right of the line) or less than (left of the line) the number 5.45. Typing <kbd>plt.axvline(x = 5.45, color='black')</kbd> with the preceding code yields the following result:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img height="311" width="571" src="assets/9c2c6061-57fb-45ab-8eb1-af1d5a8e6848.png"/></div>
<ol start="5">
<li>Visualize the first three lines:</li>
</ol>
<pre style="padding-left: 60px"><strong>plt.axvline(x = 5.45, color='black')</strong><br/><strong>plt.axvline(x = 6.2, color='black')</strong><br/><strong>plt.plot((xmin_plot, 5.45), (2.8, 2.8), color='black')</strong></pre>
<div class="CDPAlignCenter CDPAlign"><img height="312" width="1011" src="assets/b9258f26-c92f-4f73-9efa-ae817d71e8f1.png"/></div>
<p style="padding-left: 60px">The horizontal line, <kbd>sepal_width = 2.8</kbd>, is shorter and ends at <kbd>x = 5.45</kbd> because it does not apply to the case of <em>sepal_length &gt;= 5.45</em>. In the end, several rectangular regions are created.</p>
<ol start="6">
<li>The following graph shows the same type of visualization applied to the very large decision tree that overfits. The decision tree classifier attempts to place a rectangle around many specific samples of the iris dataset, which shows how it generalizes poorly with new samples:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img height="318" width="600" src="assets/a71c1714-82ac-4921-aa81-2175af88ac99.png"/></div>
<ol start="7">
<li>Finally, you could also plot how max depth influences the cross-validation score. Script a grid search with a max depth range from 2 to 51:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.tree import DecisionTreeClassifier</strong><br/><strong>dtc = DecisionTreeClassifier()</strong><br/><br/><br/><strong>from sklearn.model_selection import GridSearchCV, cross_val_score</strong><br/><br/><strong>max_depths = range(2,51)</strong><br/><strong>param_grid = {'max_depth' : max_depths}</strong><br/><br/><strong>gs_inst = GridSearchCV(dtc, param_grid=param_grid,cv=5)</strong><br/><strong>gs_inst.fit(X_train, y_train)</strong><br/><br/><strong>plt.plot(max_depths,gs_inst.cv_results_['mean_test_score'])</strong><br/><strong>plt.xlabel('Max Depth')</strong><br/><strong>plt.ylabel("Cross-validation Score")</strong></pre>
<div class="CDPAlignCenter CDPAlign"><img height="270" width="405" src="assets/893f5599-9588-48ed-b239-2366de550aac.png"/></div>
<p>The plot shows, from a different perspective, that a higher max depth tends to decrease the cross-validation score.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using decision trees for regression</h1>
                </header>
            
            <article>
                
<p>Decision trees for regression are very similar to decision trees for classification. The procedure for developing a regression model consists of four parts:</p>
<ul>
<li>Load the dataset</li>
<li>Split the set into training/testing subsets</li>
<li>Instantiate a decision tree regressor and train it</li>
<li>Score the model on the test subset</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>For this example, load scikit-learn's diabetes dataset:</p>
<pre class="mce-root"><strong>#Use within an Jupyter notebook</strong><br/><strong>%matplotlib inline   </strong><br/><br/><strong>import numpy as np</strong><br/><strong>import pandas as pd</strong><br/><strong>import matplotlib.pyplot as plt</strong><br/><br/><strong>from sklearn.datasets import load_diabetes</strong><br/><br/><strong>diabetes = load_diabetes()</strong><br/><br/><strong>X = diabetes.data</strong><br/><strong>y = diabetes.target</strong><br/><br/><strong>X_feature_names = ['age', 'gender', 'body mass index', 'average blood pressure','bl_0','bl_1','bl_2','bl_3','bl_4','bl_5']</strong></pre>
<p>Now that we have loaded the dataset, we must split the data into training and testing subsets. Before doing that, however, visualize the target variable using pandas:</p>
<pre><strong>pd.Series(y).hist(bins=50)</strong></pre>
<div class="CDPAlignCenter CDPAlign"><img height="219" width="318" src="assets/3bc25907-7251-40db-9078-684918673037.png"/></div>
<p>This is a regression example, and we cannot use <kbd>stratify=y</kbd> when splitting the dataset. Instead, we will bin the target variable: we will keep track of whether the target variable is less than 50, or between 50 and 100, and so on.</p>
<p>Create bins of width 50:</p>
<pre><strong>bins = 50*np.arange(8)</strong><br/><strong>bins</strong><br/><br/><strong>array([ 0, 50, 100, 150, 200, 250, 300, 350])</strong></pre>
<p>Using <kbd>np.digitize</kbd>, bin the target variable:</p>
<pre><strong>binned_y = np.digitize(y, bins)</strong></pre>
<p>Visualize the <kbd>binned_y</kbd> variable with pandas:</p>
<pre><strong>pd.Series(binned_y).hist(bins=50)</strong></pre>
<div class="CDPAlignCenter CDPAlign"><img height="245" width="360" src="assets/bd0bf5d3-85e4-41ab-b633-2d7d0a022fcc.png"/></div>
<p>The NumPy array <kbd>binned_y</kbd> keeps track of which bin each element of <kbd>y</kbd> belongs to. Now, split the set into training and testing sets and stratify the <kbd>binned_y</kbd> array:</p>
<pre class="mce-root"><strong>from sklearn.model_selection import train_test_split</strong><br/><br/><strong>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=binned_y)</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>To create a decision tree regressor, instantiate the decision tree and train it:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.tree import DecisionTreeRegressor</strong><br/><br/><strong>dtr = DecisionTreeRegressor()</strong><br/><strong>dtr.fit(X_train, y_train)</strong></pre>
<ol start="2">
<li>To measure the model's accuracy, make predictions for the target variable using the test set:</li>
</ol>
<pre style="padding-left: 60px"><strong>y_pred = dtr.predict(X_test)</strong></pre>
<ol start="3">
<li>Use an error metric to compare <kbd>y_test</kbd> (ground truth) and <kbd>y_pred</kbd> (model predictions). Here, use the <kbd>mean_absolute_error</kbd>, which is the average of the absolute value of the differences between the elements of <kbd>y_test</kbd> and <kbd>y_pred</kbd>:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.metrics import mean_absolute_error</strong><br/><strong>mean_absolute_error(y_test, y_pred)</strong><br/><br/><strong>58.49438202247191</strong></pre>
<ol start="4">
<li>As an alternative, measure the mean absolute percentage error, which is the average of the absolute value of the differences divided by the size of elements of the ground truth. This measures the magnitude of the error relative to the size of the element of the ground truth:</li>
</ol>
<pre style="padding-left: 60px"><strong>(np.abs(y_test - y_pred)/(y_test)).mean()</strong><br/><br/><strong>0.4665997687095611</strong></pre>
<p>Thus, we have established a baseline of performance with regard to the diabetes dataset. Every change to the model will possibly affect the error measurements.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<ol>
<li>With pandas, you can quickly visualize the distribution of the errors. Turn the difference between the ground truth, <kbd>y_test</kbd>, and the predictions, <kbd>y_pred</kbd>, into a histogram:</li>
</ol>
<pre style="padding-left: 60px"><strong>pd.Series((y_test - y_pred)).hist(bins=50)</strong></pre>
<div class="CDPAlignCenter CDPAlign"><img height="250" width="355" src="assets/9e7ef642-acbc-4a03-823e-aad3a466bbc8.png"/></div>
<ol start="2">
<li>You can do the same for the percentage error:</li>
</ol>
<pre style="padding-left: 60px"><strong>pd.Series((y_test - y_pred)/(y_test)).hist(bins=50)</strong></pre>
<div class="CDPAlignCenter CDPAlign"><img height="240" width="356" src="assets/3ff52f44-dd66-481d-a32a-d5fcbfa8effa.png"/></div>
<ol start="3">
<li>Finally, using code from previous sections, look at the tree of decisions itself. Note that we did not optimize for max depth:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img height="138" width="953" src="assets/8050a13b-249b-4d5d-9498-f20fa1f80cdd.png"/></div>
<p>The tree is very elaborate and very likely to overfit.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Reducing overfitting with cross-validation</h1>
                </header>
            
            <article>
                
<p>Here, we will use cross-validation on the diabetes dataset from the previous recipe to improve performance. Start by loading the dataset, as in the previous recipe:</p>
<pre><strong>%matplotlib inline</strong><br/><strong>import numpy as np</strong><br/><strong>import pandas as pd</strong><br/><strong>import matplotlib.pyplot as plt</strong><br/><br/><strong>from sklearn.datasets import load_diabetes</strong><br/><br/><strong>diabetes = load_diabetes()</strong><br/><br/><strong>X = diabetes.data</strong><br/><strong>y = diabetes.target</strong><br/><br/><strong>X_feature_names = ['age', 'gender', 'body mass index', 'average blood pressure','bl_0','bl_1','bl_2','bl_3','bl_4','bl_5']</strong><br/><br/><strong>bins = 50*np.arange(8)</strong><br/><strong>binned_y = np.digitize(y, bins)</strong><br/><br/><strong>from sklearn.model_selection import train_test_split</strong><br/><strong>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=binned_y)</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Use grid search to reduce overfitting. Import a decision tree and instantiate it:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.tree import DecisionTreeRegressor</strong><br/><br/><strong>dtr = DecisionTreeRegressor()</strong></pre>
<ol start="2">
<li>Then, import <kbd>GridSearchCV</kbd> and instantiate this class:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.model_selection import GridSearchCV</strong><br/><br/><strong>gs_inst = GridSearchCV(dtr, param_grid = {'max_depth': [3,5,7,9,20]},cv=10)</strong><br/><strong>gs_inst.fit(X_train, y_train)</strong></pre>
<ol start="3">
<li>View the best estimator with the <kbd>best_estimator_</kbd> attribute:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>gs_inst.best_estimator_</strong><br/><br/><strong>DecisionTreeRegressor(criterion='mse', max_depth=3, max_features=None,</strong><br/><strong> max_leaf_nodes=None, min_impurity_split=1e-07,</strong><br/><strong> min_samples_leaf=1, min_samples_split=2,</strong><br/><strong> min_weight_fraction_leaf=0.0, presort=False, random_state=None,</strong><br/><strong> splitter='best')</strong></pre>
<ol start="4">
<li>The best estimator has <kbd>max_depth</kbd> of <kbd>3</kbd>. Now check the error metrics:</li>
</ol>
<pre style="padding-left: 60px"><strong>y_pred = gs_inst.predict(X_test)</strong><br/><br/><strong>from sklearn.metrics import mean_absolute_error</strong><br/><strong>mean_absolute_error(y_test, y_pred)</strong><br/><br/><strong>54.299263338774338</strong></pre>
<ol start="5">
<li>Check the mean percentage error:</li>
</ol>
<pre style="padding-left: 60px"><strong>(np.abs(y_test - y_pred)/(y_test)).mean()</strong><br/><br/><strong>0.4672742120960478</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>Finally, visualize the best regression tree with <kbd>graphviz</kbd>:</p>
<pre class="mce-root"><strong>import numpy as np</strong><br/><strong>from sklearn import tree</strong><br/><strong>from sklearn.externals.six import StringIO</strong><br/><br/><strong>import pydot</strong><br/><strong>from IPython.display import Image</strong><br/><br/><strong>dot_diabetes = StringIO()</strong><br/><strong>tree.export_graphviz(gs_inst.best_estimator_, out_file = dot_diabetes, feature_names = X_feature_names)</strong><br/><strong>graph = pydot.graph_from_dot_data(dot_diabetes.getvalue())</strong><br/><br/><strong>Image(graph.create_png())</strong></pre>
<div class="CDPAlignCenter CDPAlign"><img height="361" width="957" src="assets/fabe4e5a-52da-425e-93e4-d28b1f202181.png"/></div>
<p>The tree has a better accuracy metrics and has been cross-validated to minimize overfitting.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementing random forest regression</h1>
                </header>
            
            <article>
                
<p>Random forests is an ensemble algorithm. Ensemble algorithms use several algorithms together to improve predictions. Scikit-learn has several ensemble algorithms, most of which use trees to predict. Let's start by expanding on decision tree regression with several decision trees working together in a random forest.</p>
<p>A random forest is a mixture of several decision trees, where each tree provides a single vote toward the final prediction. The final random forest calculates a final output by averaging the results of all the trees it is composed of.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Load the diabetes regression dataset as we did with decision trees. Split all of the data into training and testing sets:</p>
<pre class="mce-root"><strong>%matplotlib inline</strong><br/><br/><strong>import numpy as np</strong><br/><strong>import pandas as pd</strong><br/><strong>import matplotlib.pyplot as plt</strong><br/><br/><strong>from sklearn.datasets import load_diabetes</strong><br/><br/><strong>diabetes = load_diabetes()</strong><br/><br/><strong>X = diabetes.data</strong><br/><strong>y = diabetes.target</strong><br/><br/><strong>X_feature_names = ['age', 'gender', 'body mass index', 'average blood pressure','bl_0','bl_1','bl_2','bl_3','bl_4','bl_5']</strong><br/><br/><strong>#bin target variable for better sampling</strong><br/><strong>bins = 50*np.arange(8)</strong><br/><strong>binned_y = np.digitize(y, bins)</strong><br/><br/><strong>from sklearn.model_selection import train_test_split</strong><br/><strong>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=binned_y)</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Let's dive in and import and instantiate a random forest. Train the random forest:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.ensemble import RandomForestRegressor</strong><br/><br/><strong>rft = RandomForestRegressor()</strong><br/><strong>rft.fit(X_train, y_train)</strong></pre>
<ol start="2">
<li>Measure prediction error. Try the random forest on the test set:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>y_pred = rft.predict(X_test)</strong><br/><br/><strong>from sklearn.metrics import mean_absolute_error</strong><br/><strong>mean_absolute_error(y_test, y_pred)</strong><br/><br/><strong>48.539325842696627</strong><br/><br/><strong>(np.abs(y_test - y_pred)/(y_test)).mean()</strong><br/><br/><strong>0.42821508503434541</strong></pre>
<p style="padding-left: 60px">The errors have gone down slightly compared to a single decision tree.</p>
<ol start="3">
<li>To access any of the trees that make up the random forest, use the <kbd>estimators_</kbd> attribute:</li>
</ol>
<pre style="padding-left: 60px"><strong>rft.estimators_</strong><br/><br/><strong>[DecisionTreeRegressor(criterion='mse', max_depth=None, max_features='auto',</strong><br/><strong> max_leaf_nodes=None, min_impurity_split=1e-07,</strong><br/><strong> min_samples_leaf=1, min_samples_split=2,</strong><br/><strong> min_weight_fraction_leaf=0.0, presort=False,</strong><br/><strong> random_state=492413116, splitter='best')</strong><br/><strong>...</strong></pre>
<ol start="4">
<li>To view the first tree on the list in <kbd>graphviz</kbd>, refer to the first element in the list, <kbd>rft.estimators_[0]</kbd>:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>import numpy as np</strong><br/><strong>from sklearn import tree</strong><br/><strong>from sklearn.externals.six import StringIO</strong><br/><br/><strong>import pydot</strong><br/><strong>from IPython.display import Image</strong><br/><br/><strong>dot_diabetes = StringIO()</strong><br/><strong>tree.export_graphviz(rft.estimators_[0], out_file = dot_diabetes, feature_names = X_feature_names)</strong><br/><strong>graph = pydot.graph_from_dot_data(dot_diabetes.getvalue())</strong><br/><br/><strong>Image(graph.create_png())<br/></strong></pre>
<div class="CDPAlignCenter CDPAlign"><img height="179" width="980" src="assets/78e9e1e5-64ef-446d-9643-e599d5302e4f.png"/></div>
<ol start="5">
<li>To view the second tree, use <kbd>best_rft.estimators_[1]</kbd>. To view the last tree, use <kbd>best_rft.estimators_[9]</kbd> because there are, by default, 10 trees, indexed 0 to 9, that make up the random forest.</li>
<li>An additional feature of the random forest is determining feature importance through the <kbd>feature_importances_</kbd> attribute:</li>
</ol>
<pre style="padding-left: 60px"><strong>rft.feature_importances_</strong><br/><br/><strong>array([ 0.06103037, 0.00969354, 0.34865274, 0.09091215, 0.04331388,</strong><br/><br/><strong> 0.04376602, 0.04827391, 0.02430837, 0.23251334, 0.09753567])</strong></pre>
<ol start="7">
<li>You can visualize feature importance as well:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>fig, ax = plt.subplots(figsize=(10,5))</strong><br/><br/><strong>bar_rects = ax.bar(np.arange(10), rft.feature_importances_,color='r',align='center')</strong><br/><strong>ax.xaxis.set_ticks(np.arange(10))</strong><br/><strong>ax.set_xticklabels(X_feature_names, rotation='vertical')</strong></pre>
<div class="CDPAlignCenter CDPAlign"><img height="287" width="411" src="assets/8d795ad3-455b-4d75-9b22-dc44156e6c5d.png"/></div>
<p>The most influential features are <strong>body mass index</strong> (<strong>BMI</strong>), followed by <kbd>bl_4</kbd> (the fourth of six blood serum measurements), and then average blood pressure.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"> Bagging regression with nearest neighbors</h1>
                </header>
            
            <article>
                
<p>Bagging is an additional ensemble type that, interestingly, does not necessarily involve trees. It builds several instances of a base estimator acting on random subsets of the first training set. In this section, we try <strong>k-nearest neighbors</strong> (<strong>KNN</strong>) as the base estimator.</p>
<p>Pragmatically, bagging estimators are great for reducing the variance of a complex base estimator, for example, a decision tree with many levels. On the other hand, boosting reduces the bias of weak models, such as decision trees of very few levels, or linear models.</p>
<p>To try out bagging, we will find the best parameters, a hyperparameter search, using scikit-learn's random grid search. As we have done previously, we will go through the following process:</p>
<ol>
<li>Figure out which parameters to optimize in the algorithm (these are the parameters researchers view as the best to optimize in the literature).</li>
<li>Create a parameter distribution where the most important parameters are varied.</li>
<li>Perform a random grid search. If you're using an ensemble, keep the number of estimators low at first.</li>
<li>Use the best parameters from the previous step with many estimators.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Once more, load the diabetes dataset used in the last section:</p>
<pre><strong>import numpy as np</strong><br/><strong>import pandas as pd</strong><br/><br/><strong>from sklearn.datasets import load_diabetes</strong><br/><strong>diabetes = load_diabetes()</strong><br/><br/><strong>X = diabetes.data</strong><br/><strong>y = diabetes.target</strong><br/><br/><strong>X_feature_names = ['age', 'gender', 'body mass index', 'average blood pressure','bl_0','bl_1','bl_2','bl_3','bl_4','bl_5']</strong><br/><br/><strong>#bin target variable for better sampling</strong><br/><strong>bins = 50*np.arange(8)</strong><br/><strong>binned_y = np.digitize(y, bins)</strong><br/><br/><strong>from sklearn.model_selection import train_test_split</strong><br/><strong>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=binned_y)</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li class="mce-root">First, import <kbd>BaggingRegressor</kbd> and <kbd>KNeighborsRegressor</kbd>. Additionally, also import <kbd>RandomizedSearchCV</kbd>:</li>
</ol>
<pre style="padding-left: 60px"><strong>from sklearn.ensemble import BaggingRegressor</strong><br/><strong>from sklearn.neighbors import KNeighborsRegressor</strong><br/><strong>from sklearn.model_selection import RandomizedSearchCV</strong></pre>
<ol start="2">
<li>Then, set up a parameter distribution for the grid search. For a bagging meta-estimator, some parameters to vary include <kbd>max_samples</kbd>, <kbd>max_features</kbd>, <kbd>oob_score</kbd>, and the number of estimators, <kbd>n_estimators</kbd>. The number of estimators is set to a low number, 100, to optimize the other parameters before trying a large number of estimators.</li>
<li>Additionally, there is one list of parameters for the KNN algorithm. It is named <kbd>base_estimator__n_neighbors</kbd>, where <kbd>n_neighbors</kbd> is the internal name within the KNN class. The <kbd>base_estimator</kbd> name is the name of the base estimator within the <kbd>BaggingRegressor</kbd> class. The <kbd>base_estimator__n_neighbors</kbd> list has the numbers <kbd>3</kbd> and <kbd>5</kbd>, which refer to the number of neighbors in the nearest neighbors algorithm:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>param_dist = {</strong><br/><strong> 'max_samples': [0.5,1.0],</strong><br/><strong> 'max_features' : [0.5,1.0],</strong><br/><strong> 'oob_score' : [True, False],</strong><br/><strong> 'base_estimator__n_neighbors': [3,5],</strong><br/><strong> 'n_estimators': [100]</strong><br/><strong> }</strong></pre>
<ol start="4">
<li class="mce-root">Instantiate the <kbd>KNeighboursRegressor</kbd> class and pass it as the <kbd>base_estimator</kbd> within <kbd>BaggingRegressor</kbd>:</li>
</ol>
<pre style="padding-left: 60px"><strong>single_estimator = KNeighborsRegressor()</strong><br/><strong>ensemble_estimator = BaggingRegressor(base_estimator = single_estimator)</strong></pre>
<ol start="5">
<li>Finally, instantiate and run a randomized search. Do a few iterations, <kbd>n_iter = 5</kbd>, as this could be time consuming:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>pre_gs_inst_bag = RandomizedSearchCV(ensemble_estimator,</strong><br/><strong> param_distributions = param_dist,</strong><br/><strong> cv=3,</strong><br/><strong> n_iter = 5,</strong><br/><strong> n_jobs=-1)</strong><br/><br/><strong>pre_gs_inst_bag.fit(X_train, y_train)</strong></pre>
<ol start="6">
<li>Look at the best parameters in the random search run:</li>
</ol>
<pre style="padding-left: 60px"><strong>pre_gs_inst_bag.best_params_</strong><br/><br/><strong>{'base_estimator__n_neighbors': 5,
 'max_features': 1.0,
 'max_samples': 0.5,
 'n_estimators': 100,
 'oob_score': True}</strong></pre>
<ol start="7">
<li>Train a <kbd>BaggingRegressor</kbd> using the best parameters, except for <kbd>n_estimators</kbd>, which you can increase. We increase the number of estimators to 1,000 in this case:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>rs_bag = BaggingRegressor(**{'max_features': 1.0,</strong><br/><strong> 'max_samples': 0.5,</strong><br/><strong> 'n_estimators': 1000,</strong><br/><strong> 'oob_score': True,</strong><br/><strong> 'base_estimator': KNeighborsRegressor(n_neighbors=5)})</strong><br/><br/><strong>rs_bag.fit(X_train, y_train)</strong></pre>
<ol start="8">
<li>Finally, measure the performance on a test set. The algorithm does not perform as well as others, but we can possibly use it as part of a stacking aggregator later:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>y_pred = rs_bag.predict(X_test)</strong><br/><br/><strong>from sklearn.metrics import r2_score, mean_absolute_error</strong><br/><br/><strong>print "R-squared",r2_score(y_test, y_pred)</strong><br/><strong>print "MAE : ",mean_absolute_error(y_test, y_pred)</strong><br/><strong>print "MAPE : ",(np.abs(y_test - y_pred)/y_test).mean()</strong><br/><br/><strong>R-squared 0.498096653258
MAE :  44.3642741573
MAPE :  0.419361955306</strong></pre>
<p>If you look carefully, bagging regression performed slightly better than the random forest in the previous section as both mean absolute error and mean absolute percentage error are better. Always remember that you do not have to limit your ensemble learning to trees—here, you build an ensemble regressor with the KNN algorithm.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Tuning gradient boosting trees</h1>
                </header>
            
            <article>
                
<p>We will examine the California housing dataset with gradient boosting trees. Our overall approach will be the same as before:</p>
<ol>
<li>Focus on important parameters in the gradient boosting algorithm:
<ul>
<li><kbd>max_features</kbd></li>
<li><kbd>max_depth</kbd></li>
<li><kbd>min_samples_leaf</kbd></li>
<li><kbd>learning_rate</kbd></li>
<li><kbd>loss</kbd></li>
</ul>
</li>
<li>Create a parameter distribution where the most important parameters are varied.</li>
<li>Perform a random grid search. If using an ensemble, keep the number of estimators low at first.</li>
<li>Use the best parameters from the previous step with many estimators.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Load the California housing dataset and split the loaded dataset into training and testing sets:</p>
<pre class="mce-root"><strong>%matplotlib inline </strong><br/><br/><strong>from __future__ import division #Load within Python 2.7 for regular division</strong><br/><strong>import numpy as np</strong><br/><strong>import pandas as pd</strong><br/><strong>import matplotlib.pyplot as plt</strong><br/><br/><strong>from sklearn.datasets import fetch_california_housing</strong><br/><br/><strong>cali_housing = fetch_california_housing()</strong><br/><br/><strong>X = cali_housing.data</strong><br/><strong>y = cali_housing.target</strong><br/><br/><strong>#bin output variable to split training and testing sets into two similar sets</strong><br/><strong>bins = np.arange(6)</strong><br/><strong>binned_y = np.digitize(y, bins)</strong><br/><br/><strong>from sklearn.model_selection import train_test_split</strong><br/><strong>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=binned_y)</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Load the gradient boosting algorithm and random grid search:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.ensemble import GradientBoostingRegressor</strong><br/><strong>from sklearn.model_selection import RandomizedSearchCV</strong></pre>
<ol start="2">
<li>Create a parameter distribution for the gradient boosting trees:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>param_dist = {'max_features' : ['log2',1.0],</strong><br/><strong> 'max_depth' : [3, 5, 7, 10],</strong><br/><strong> 'min_samples_leaf' : [2, 3, 5, 10],</strong><br/><strong> 'n_estimators': [50, 100],</strong><br/><strong> 'learning_rate' : [0.0001,0.001,0.01,0.05,0.1,0.3],</strong><br/><strong> 'loss' : ['ls','huber']</strong><br/><strong> }</strong></pre>
<ol start="3">
<li class="mce-root">Run the grid search to find the best parameters. Perform a randomized search with 30 iterations:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>pre_gs_inst = RandomizedSearchCV(GradientBoostingRegressor(warm_start=True),</strong><br/><strong> param_distributions = param_dist,</strong><br/><strong> cv=3,</strong><br/><strong> n_iter = 30, n_jobs=-1)</strong><br/><strong>pre_gs_inst.fit(X_train, y_train)</strong></pre>
<ol start="4">
<li>Now look at the report in dataframe form. The functions to view the report have been wrapped so that they can be used more times:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>import numpy as np</strong><br/><strong>import pandas as pd</strong><br/><br/><strong>def get_grid_df(fitted_gs_estimator):</strong><br/><strong>    res_dict = fitted_gs_estimator.cv_results_</strong><br/> <br/><strong>    results_df = pd.DataFrame()</strong><br/><strong>    for key in res_dict.keys():</strong><br/><strong>         results_df[key] = res_dict[key]</strong><br/> <br/><strong>    return results_df</strong><br/><br/><strong>def group_report(results_df):</strong><br/><strong>      param_cols = [x for x in results_df.columns if 'param' in x and x is not 'params']</strong><br/><strong>      focus_cols = param_cols + ['mean_test_score']</strong><br/> <br/><strong>      print "Grid CV Report \n"</strong><br/> <br/><strong>      output_df = pd.DataFrame(columns = ['param_type','param_set',</strong><br/><strong> 'mean_score','mean_std'])</strong><br/><strong>      cc = 0</strong><br/><strong>      for param in param_cols:</strong><br/><strong>         for key,group in results_df.groupby(param):</strong><br/><strong>              output_df.loc[cc] = (param, key, group['mean_test_score'].mean(), group['mean_test_score'].std())</strong><br/><strong>              cc += 1</strong><br/><strong>      return output_df</strong></pre>
<ol start="5">
<li class="mce-root">View the dataframe that shows how gradient boosting trees performed with various parameter settings:</li>
</ol>
<pre style="padding-left: 60px"><strong>results_df = get_grid_df(pre_gs_inst)</strong><br/><strong>group_report(results_df)</strong></pre>
<div class="CDPAlignCenter CDPAlign"><img height="487" width="357" src="assets/9bef6af7-a648-455f-b522-bc4791f310b1.png"/></div>
<p style="padding-left: 60px">From this dataframe; <kbd>ls</kbd> outperforms <kbd>huber</kbd> significantly as a loss function, <kbd>3</kbd> is the best <kbd>min_samples_leaf</kbd> (but <kbd>4</kbd> could perform well), <kbd>3</kbd> is the best <kbd>max_depth</kbd> (although <kbd>1</kbd> or <kbd>2</kbd> could work as well), <kbd>0.3</kbd> works well as a learning rate (so could <kbd>0.2</kbd> or <kbd>0.4</kbd> though), and a <kbd>max_features</kbd> of <kbd>1.0</kbd> works well, but so could some other number (such as half of the features: <kbd>0.5</kbd>).</p>
<ol start="6">
<li>With this information, try another randomized search:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>param_dist = {'max_features' : ['sqrt',0.5,1.0],</strong><br/><strong> 'max_depth' : [2,3,4],</strong><br/><strong> 'min_samples_leaf' : [3, 4],</strong><br/><strong> 'n_estimators': [50, 100],</strong><br/><strong> 'learning_rate' : [0.2,0.25, 0.3, 0.4],</strong><br/><strong> 'loss' : ['ls','huber']</strong><br/><strong> }</strong><br/><strong> pre_gs_inst = RandomizedSearchCV(GradientBoostingRegressor(warm_start=True),</strong><br/><strong> param_distributions = param_dist,</strong><br/><strong> cv=3,</strong><br/><strong> n_iter = 30, n_jobs=-1)</strong><br/><strong> pre_gs_inst.fit(X_train, y_train)</strong></pre>
<ol start="7">
<li class="mce-root">View the new report that is generated:</li>
</ol>
<pre style="padding-left: 60px"><strong>results_df = get_grid_df(pre_gs_inst)</strong><br/><strong>group_report(results_df)</strong></pre>
<div class="mce-root CDPAlignCenter CDPAlign"><br/>
<img height="398" width="343" src="assets/5f3155e2-5fdb-4ac0-804d-311617170495.png"/></div>
<ol start="8">
<li>With this information, you can run one more randomized search with the following parameter distributions:</li>
</ol>
<pre style="padding-left: 60px"><strong>param_dist = {'max_features' : [0.4, 0.5, 0.6],</strong><br/><strong> 'max_depth' : [5,6],</strong><br/><strong> 'min_samples_leaf' : [4,5],</strong><br/><strong> 'n_estimators': [300],</strong><br/><strong> 'learning_rate' : [0.3],</strong><br/><strong> 'loss' : ['ls','huber']</strong><br/><strong> }</strong></pre>
<ol start="9">
<li>Storing the result under <kbd>rs_gbt</kbd>, perform training one last time with 4,000 estimators:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>rs_gbt = GradientBoostingRegressor(warm_start=True,</strong><br/><strong> max_features = 0.5,</strong><br/><strong> min_samples_leaf = 4,</strong><br/><strong> learning_rate=0.3,</strong><br/><strong> max_depth = 6,</strong><br/><strong> n_estimators = 4000,loss = 'huber')</strong><br/><br/><strong>rs_gbt.fit(X_train, y_train)</strong></pre>
<ol start="10">
<li>Use scikit-learn's <kbd>metrics</kbd> module to describe the errors on the test set:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>y_pred = rs_gbt.predict(X_test)</strong><br/><br/><strong>from sklearn.metrics import r2_score, mean_absolute_error</strong><br/><br/><strong>print "R-squared",r2_score(y_test, y_pred)</strong><br/><strong>print "MAE : ",mean_absolute_error(y_test, y_pred)</strong><br/><strong>print "MAPE : ",(np.abs(y_test - y_pred)/y_test).mean()</strong><br/><br/><strong>R-squared 0.84490423214</strong><br/><strong>MAE : 0.302125381378</strong><br/><strong>MAPE : 0.169831775387</strong></pre>
<p>If you recall, the R-squared for the random forest was slightly lower at 0.8252. This algorithm was slightly better. For both, we performed randomized searches. Note that if you perform hyperparameter optimization with trees frequently, you can automate the multiple randomized parameter searches.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>Now, we will optimize a gradient boosting classifier instead of a regressor. The procedure is very similar.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Finding the best parameters of a gradient boosting classifier</h1>
                </header>
            
            <article>
                
<p>Classifying using gradient boosting trees is very similar to the regression we have been doing. Again, we will do the following:</p>
<ol>
<li>Find the best parameters of the gradient boosting classifier. These are the same as the gradient boosting regressor, with the exception that the loss function options are different. The parameters have the same names and are as follows:
<ul>
<li><kbd>max_features</kbd></li>
<li><kbd>max_depth</kbd></li>
<li><kbd>min_samples_leaf</kbd></li>
<li><kbd>learning_rate</kbd></li>
<li><kbd>loss</kbd></li>
</ul>
</li>
<li>Run an estimator with the best parameter but more trees in the estimator. In the following code, note the change in the loss function called deviance. To do the classification, we will use a binary variable. Recall the visualization of the target set, <kbd>y</kbd><span>:</span></li>
</ol>
<pre style="padding-left: 60px"><strong>pd.Series(y).hist(bins=50)</strong></pre>
<div class="CDPAlignCenter CDPAlign"><img height="226" width="341" src="assets/3acb7f7a-af30-4270-b9cf-b08d20cf0f52.png"/></div>
<p style="padding-left: 60px">On the far right, there seems to be an anomaly: a lot of values in the distribution are equal to five. Perhaps we would like to separate that set and analyze it separately. As part of that process, we might want to be able to predetermine whether a point should belong to the anomaly set or not. We will build a classifier to separate points where <kbd>y</kbd> is equal to or greater than five:</p>
<ol start="3">
<li>First, split the set into training and testing. Stratify the binned variable, <kbd>binned_y</kbd>:</li>
</ol>
<pre style="padding-left: 60px"><strong>bins = np.arange(6)</strong><br/><strong>binned_y = np.digitize(y, bins)</strong><br/><br/><strong>from sklearn.model_selection import train_test_split</strong><br/><strong>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=binned_y)</strong></pre>
<ol start="4">
<li>Create a binary variable that has the value <kbd>1</kbd> if the target variable <kbd>y</kbd> is <kbd>5</kbd> or greater and <kbd>0</kbd> if it is less than <kbd>5</kbd>. Note that if the binary variable is <kbd>1</kbd>, it belongs to the anomalous set:</li>
</ol>
<pre style="padding-left: 60px"><strong>y_binary = np.where(y &gt;= 5, 1,0)</strong></pre>
<ol start="5">
<li>Now, use the shape of <kbd>X_train</kbd> to split a binary variable into <kbd>y_train_binned</kbd> and <kbd>y_test_binned</kbd>:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>train_shape = X_train.shape[0]</strong><br/> <br/><strong>y_train_binned = y_binary[:train_shape]</strong><br/><strong>y_test_binned = y_binary[train_shape:]</strong></pre>
<ol start="6">
<li>Perform a randomized grid search:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.ensemble import GradientBoostingClassifier</strong><br/><strong>from sklearn.model_selection import RandomizedSearchCV</strong><br/><strong>param_dist = {'max_features' : ['log2',0.5,1.0],</strong><br/><strong>              'max_depth' : [2,3,6],</strong><br/><strong>              'min_samples_leaf' : [1,2,3,10],</strong><br/><strong>              'n_estimators': [100],</strong><br/><strong>              'learning_rate' : [0.1,0.2,0.3,1],</strong><br/><strong>              'loss' : ['deviance']</strong><br/><strong>             }</strong><br/><strong>pre_gs_inst = RandomizedSearchCV(GradientBoostingClassifier(warm_start=True),</strong><br/><strong>                                 param_distributions = param_dist,</strong><br/><strong>                                 cv=3,</strong><br/><strong>                                 n_iter = 10, n_jobs=-1)</strong><br/><br/><strong>pre_gs_inst.fit(X_train, y_train_binned)</strong></pre>
<ol start="7">
<li>View the best parameters:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>pre_gs_inst.best_params_</strong><br/><br/><strong>{'learning_rate': 0.2,</strong><br/><strong> 'loss': 'deviance',</strong><br/><strong> 'max_depth': 2,</strong><br/><strong> 'max_features': 1.0,</strong><br/><strong> 'min_samples_leaf': 2,</strong><br/><strong> 'n_estimators': 50}</strong></pre>
<ol start="8">
<li class="mce-root">Increase the number of estimators and train the final estimator:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>gbc = GradientBoostingClassifier(**{'learning_rate': 0.2,</strong><br/><strong> 'loss': 'deviance',</strong><br/><strong> 'max_depth': 2,</strong><br/><strong> 'max_features': 1.0,</strong><br/><strong> 'min_samples_leaf': 2,</strong><br/><strong> 'n_estimators': 1000, 'warm_start':True}).fit(X_train, y_train_binned)</strong></pre>
<ol start="9">
<li>View the performance of the algorithm:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>y_pred = gbc.predict(X_test)</strong><br/><br/><strong>from sklearn.metrics import accuracy_score</strong><br/><strong>accuracy_score(y_test_binned, y_pred)</strong><br/><br/><strong>0.93580426356589153</strong></pre>
<p>The algorithm, a binary classifier, is about 94% accurate at determining whether the house belongs to the anomalous set. The hyperparameter optimization of the gradient boosting classifier was very similar, with the same important parameters as gradient boosting regression.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Tuning an AdaBoost regressor</h1>
                </header>
            
            <article>
                
<p class="mce-root">The important parameters to vary in an AdaBoost regressor are <kbd>learning_rate</kbd> and <kbd>loss</kbd>. As with the previous algorithms, we will perform a randomized parameter search to find the best scores that the algorithm can do.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Import the algorithm and randomized grid search. Try a randomized parameter distribution:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.ensemble import AdaBoostRegressor</strong><br/><strong>from sklearn.model_selection import RandomizedSearchCV</strong><br/><br/><strong>param_dist = {</strong><br/><strong> 'n_estimators': [50, 100],</strong><br/><strong> 'learning_rate' : [0.01,0.05,0.1,0.3,1],</strong><br/><strong> 'loss' : ['linear', 'square', 'exponential']</strong><br/><strong> }</strong><br/><br/><strong>pre_gs_inst = RandomizedSearchCV(AdaBoostRegressor(),</strong><br/><strong> param_distributions = param_dist,</strong><br/><strong> cv=3,</strong><br/><strong> n_iter = 10,</strong><br/><strong> n_jobs=-1)</strong><br/><br/><strong>pre_gs_inst.fit(X_train, y_train)</strong></pre>
<ol start="2">
<li>View the best parameters:</li>
</ol>
<pre style="padding-left: 60px"><strong>pre_gs_inst.best_params_</strong><br/><br/><strong>{'learning_rate': 0.05, 'loss': 'linear', 'n_estimators': 100}</strong></pre>
<ol start="3">
<li>These suggest another randomized search with parameter distribution:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>param_dist = {</strong><br/><strong> 'n_estimators': [100],</strong><br/><strong> 'learning_rate' : [0.04,0.045,0.05,0.055,0.06],</strong><br/><strong> 'loss' : ['linear']</strong><br/><strong> }</strong></pre>
<ol start="4">
<li>Copy the dictionary that holds the best parameters. Increase the number of estimators in the copy to 3,000:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>import copy</strong><br/><strong>ada_best = copy.deepcopy(pre_gs_inst.best_params_)</strong><br/><strong>ada_best['n_estimators'] = 3000</strong></pre>
<ol start="5">
<li>Train the final AdaBoost model:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>rs_ada = AdaBoostRegressor(**ada_best)</strong><br/><strong>rs_ada.fit(X_train, y_train)</strong></pre>
<ol start="6">
<li>Measure the model performance on the test set:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>y_pred = rs_ada.predict(X_test)</strong><br/><br/><strong>from sklearn.metrics import r2_score, mean_absolute_error</strong><br/><br/><strong>print "R-squared",r2_score(y_test, y_pred)</strong><br/><strong>print "MAE : ",mean_absolute_error(y_test, y_pred)</strong><br/><strong>print "MAPE : ",(np.abs(y_test - y_pred)/y_test).mean()</strong><br/><br/><strong>R-squared 0.485619387823</strong><br/><strong>MAE : 0.708716094846</strong><br/><strong>MAPE : 0.524923208329</strong></pre>
<p>Unfortunately, this model clearly underperforms relative to the other tree models. We will set it aside without optimizing it any further because it would take more training time and Python development time.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>We have found the best parameters for a few algorithms. Here is a table summarizing the parameters to optimize for each algorithm under cross-validation. It is suggested you start optimizing these parameters:</p>
<div class="CDPAlignCenter CDPAlign"><img height="203" width="343" src="assets/01baf86e-5bbd-4420-8088-94e40924376c.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Writing a stacking aggregator with scikit-learn</h1>
                </header>
            
            <article>
                
<p>In this section, we will write a stacking aggregator with scikit-learn. A stacking aggregator mixes models of potentially very different types. Many of the ensemble algorithms we have seen mix models of the same type, usually decision trees.</p>
<p>The fundamental process in the stacking aggregator is that we use the predictions of several machine learning algorithms as input for the training of another machine learning algorithm.</p>
<p>In more detail, we train two or more machine learning algorithms using a pair of <kbd>X</kbd> and <kbd>y</kbd> sets (<kbd>X_1</kbd>, <kbd>y_1</kbd>). Then we make predictions on a second <kbd>X</kbd> set (<kbd>X_stack</kbd>), <kbd>y_pred_1</kbd>, <kbd>y_pred_2</kbd>, and so on.</p>
<p>These predictions, <kbd>y_pred_1</kbd> and <kbd>y_pred_2</kbd>, become inputs to a machine learning algorithm with the training output <kbd>y_stack</kbd>. Finally, the error can be measured on a third input set, <kbd>X_3</kbd>, and a ground truth set, <kbd>y_3</kbd>.</p>
<p>It will be easier to see in an example.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Load the data from the California housing dataset once again. Observe how we create bins once more to stratify a continuous variable:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>%matplotlib inline</strong><br/><br/><strong>import numpy as np</strong><br/><strong>import pandas as pd</strong><br/><strong>import matplotlib.pyplot as plt</strong><br/><br/><strong>from sklearn.datasets import fetch_california_housing</strong><br/><br/><strong>cali_housing = fetch_california_housing()</strong><br/><br/><strong>X = cali_housing.data</strong><br/><strong>y = cali_housing.target</strong><br/><br/><strong>bins = np.arange(6)</strong><br/> <br/><strong>from __future__ import division</strong><br/><br/><strong>from sklearn.model_selection import train_test_split</strong><br/><br/><strong>binned_y = np.digitize(y, bins)</strong><br/><br/><strong>from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor, GradientBoostingRegressor</strong><br/> <br/><strong>from sklearn.model_selection import GridSearchCV</strong></pre>
<ol start="2">
<li>Now split the pair, <kbd>X</kbd> and <kbd>y</kbd>, into three <kbd>X</kbd> and <kbd>y</kbd> pairs, input and output, by using <kbd>train_test_split</kbd> twice. Note how we stratify the continuous variable at each stage:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>X_train_prin, X_test_prin, y_train_prin, y_test_prin = train_test_split(X, y,</strong><br/><strong> test_size=0.2,</strong><br/><strong> stratify=binned_y)</strong><br/><br/><strong>binned_y_train_prin = np.digitize(y_train_prin, bins)</strong><br/><br/><strong>X_1, X_stack, y_1, y_stack = train_test_split(X_train_prin, </strong><br/><strong> y_train_prin,</strong><br/><strong> test_size=0.33,</strong><br/><strong> stratify=binned_y_train_prin )</strong></pre>
<ol start="3">
<li>Using <kbd>RandomizedSearchCV</kbd>, find the best parameters for the first of the algorithms in the stacking aggregator, in this case a bagging algorithm of several nearest neighbor models:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.ensemble import BaggingRegressor</strong><br/><strong>from sklearn.neighbors import KNeighborsRegressor</strong><br/><br/><strong>from sklearn.model_selection import RandomizedSearchCV</strong><br/><br/><strong>param_dist = {</strong><br/><strong> 'max_samples': [0.5,1.0],</strong><br/><strong> 'max_features' : [0.5,1.0],</strong><br/><strong> 'oob_score' : [True, False],</strong><br/><strong> 'base_estimator__n_neighbors': [3,5],</strong><br/><strong> 'n_estimators': [100]</strong><br/><strong> }</strong><br/><br/><strong>single_estimator = KNeighborsRegressor()</strong><br/><strong>ensemble_estimator = BaggingRegressor(base_estimator = single_estimator)</strong><br/><br/><strong>pre_gs_inst_bag = RandomizedSearchCV(ensemble_estimator,</strong><br/><strong> param_distributions = param_dist,</strong><br/><strong> cv=3,</strong><br/><strong> n_iter = 5,</strong><br/><strong> n_jobs=-1)</strong><br/><br/><strong>pre_gs_inst_bag.fit(X_1, y_1)</strong></pre>
<ol start="4">
<li>Using the best parameters, train the bagging regressor using many estimators, in this case, 3,000:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>rs_bag = BaggingRegressor(**{'max_features': 0.5,</strong><br/><strong> 'max_samples': 0.5,</strong><br/><strong> 'n_estimators': 3000,</strong><br/><strong> 'oob_score': False, </strong><br/><strong> 'base_estimator': KNeighborsRegressor(n_neighbors=3)})</strong><br/><br/><strong>rs_bag.fit(X_1, y_1)</strong></pre>
<ol start="5">
<li>Do the same process for the gradient boost algorithm on the <kbd>X_1</kbd>, <kbd>y_1</kbd> pair of sets:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.ensemble import GradientBoostingRegressor</strong><br/><strong>from sklearn.model_selection import RandomizedSearchCV</strong><br/><br/><strong>param_dist = {'max_features' : ['log2',0.4,0.5,0.6,1.0],</strong><br/><strong> 'max_depth' : [2,3, 4, 5,6, 7, 10],</strong><br/><strong> 'min_samples_leaf' : [1,2, 3, 4, 5, 10],</strong><br/><strong> 'n_estimators': [50, 100],</strong><br/><strong> 'learning_rate' : [0.01,0.05,0.1,0.25,0.275,0.3,0.325],</strong><br/><strong> 'loss' : ['ls','huber']</strong><br/><strong> }</strong><br/><strong>pre_gs_inst = RandomizedSearchCV(GradientBoostingRegressor(warm_start=True),</strong><br/><strong>param_distributions = param_dist,</strong><br/><strong> cv=3,</strong><br/><strong> n_iter = 30, n_jobs=-1)</strong><br/><strong> pre_gs_inst.fit(X_1, y_1)</strong></pre>
<ol start="6">
<li>Train the best parameter set with more estimators:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>gbt_inst = GradientBoostingRegressor(**{'learning_rate': 0.05,</strong><br/><strong> 'loss': 'huber',</strong><br/><strong> 'max_depth': 10,</strong><br/><strong> 'max_features': 0.4,</strong><br/><strong> 'min_samples_leaf': 5,</strong><br/><strong> 'n_estimators': 3000,</strong><br/><strong> 'warm_start': True}).fit(X_1, y_1)</strong></pre>
<ol start="7">
<li>Predict the target using <kbd>X_stack</kbd> using both algorithms:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>y_pred_bag = rs_bag.predict(X_stack)</strong><br/><strong>y_pred_gbt = gbt_inst.predict(X_stack)</strong></pre>
<ol start="8">
<li>View the metrics (error rates) that each algorithm produces. View the metrics for the bagging regressor:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.metrics import r2_score, mean_absolute_error</strong><br/><br/><strong>print "R-squared",r2_score(y_stack, y_pred_bag)</strong><br/><strong>print "MAE : ",mean_absolute_error(y_stack, y_pred_bag)</strong><br/><strong>print "MAPE : ",(np.abs(y_stack- y_pred_bag)/y_stack).mean()</strong><br/><br/><strong>R-squared 0.527045729567</strong><br/><strong>MAE : 0.605868386902</strong><br/><strong>MAPE : 0.397345752723</strong></pre>
<ol start="9">
<li>View the metrics for gradient boost:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.metrics import r2_score, mean_absolute_error</strong><br/><br/><strong>print "R-squared",r2_score(y_stack, y_pred_gbt)</strong><br/><strong>print "MAE : ",mean_absolute_error(y_stack, y_pred_gbt)</strong><br/><strong>print "MAPE : ",(np.abs(y_stack - y_pred_gbt)/y_stack).mean()</strong><br/><br/><strong>R-squared 0.841011059404</strong><br/><strong>MAE : 0.297099247278</strong><br/><strong>MAPE : 0.163956322255</strong></pre>
<ol start="10">
<li>Create a dataframe of the predictions from both algorithms. Alternatively, you could also create a NumPy array of the data:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>y_pred_bag = rs_bag.predict(X_stack)</strong><br/><strong>y_pred_gbt = gbt_inst.predict(X_stack)</strong><br/><br/><strong>preds_df = pd.DataFrame(columns = ['bag', 'gbt'])</strong><br/><br/><strong>preds_df['bag'] = y_pred_bag</strong><br/><strong>preds_df['gbt'] = y_pred_gbt</strong></pre>
<ol start="11">
<li>View the new dataframe of predictions:</li>
</ol>
<pre style="padding-left: 60px"><strong>preds_df</strong></pre>
<div class="mce-root CDPAlignCenter CDPAlign">&gt;<img height="238" width="139" src="assets/e48f9f14-cee9-4ac8-8199-782a1444fc27.png"/></div>
<ol start="12">
<li>Look at the correlation between the prediction columns. The columns are correlated, but not perfectly. The ideal situation is that the algorithms are not perfectly correlated and both perform well. In this case, the bagging regressor does not perform nearly as well as gradient boost:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>preds_df.corr()</strong></pre>
<div class="CDPAlignCenter CDPAlign"><img height="80" width="144" src="assets/e1501268-e7c9-4955-a014-8489c424be18.png"/></div>
<ol start="13">
<li>Now do a randomized search with a third algorithm. This algorithm takes as input the predictions of the first two. We will use an extra trees regressor to make predictions on the predictions of the other two algorithms:</li>
</ol>
<pre style="padding-left: 60px"><strong>from sklearn.ensemble import ExtraTreesRegressor</strong><br/><strong>from sklearn.model_selection import RandomizedSearchCV</strong><br/><br/><strong>param_dist = {'max_features' : ['sqrt','log2',1.0],</strong><br/><strong> 'min_samples_leaf' : [1, 2, 3, 7, 11],</strong><br/><strong> 'n_estimators': [50, 100],</strong><br/><strong> 'oob_score': [True, False]}</strong><br/><br/><strong>pre_gs_inst = RandomizedSearchCV(ExtraTreesRegressor(warm_start=True,bootstrap=True),</strong><br/><strong> param_distributions = param_dist,</strong><br/><strong> cv=3,</strong><br/><strong> n_iter = 15)</strong><br/><br/><strong>pre_gs_inst.fit(preds_df.values, y_stack)</strong></pre>
<ol start="14">
<li>Copy the parameter dictionary and increase the number of estimators within that copied dictionary. View the final dictionary, if you want to:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>import copy</strong><br/> <br/><strong> param_dict = copy.deepcopy(pre_gs_inst.best_params_)</strong><br/> <br/><strong> param_dict['n_estimators'] = 2000</strong><br/><strong> param_dict['warm_start'] = True</strong><br/><strong> param_dict['bootstrap'] = True</strong><br/><strong> param_dict['n_jobs'] = -1</strong><br/> <br/><strong> param_dict</strong><br/><br/><strong>{'bootstrap': True,</strong><br/><strong> 'max_features': 1.0,</strong><br/><strong> 'min_samples_leaf': 11,</strong><br/><strong> 'n_estimators': 2000,</strong><br/><strong> 'n_jobs': -1,</strong><br/><strong> 'oob_score': False,</strong><br/><strong> 'warm_start': True}</strong></pre>
<ol start="15">
<li>Train the extra trees regressor on the predictions dataframe using <span><kbd>y_stack</kbd> </span><span>as a target:</span></li>
</ol>
<pre style="padding-left: 60px"><strong>final_etr = ExtraTreesRegressor(**param_dict)</strong><br/><strong>final_etr.fit(preds_df.values, y_stack)</strong></pre>
<ol start="16">
<li>To examine the overall performance of the stacking aggregator, you need a function that takes <span>an <kbd>X</kbd> set </span><span>as input, predicts creating a dataframe using the bagging regressor and gradient boost, and finally predicts on those predictions:</span></li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>def handle_X_set(X_train_set):</strong><br/><strong>     y_pred_bag = rs_bag.predict(X_train_set)</strong><br/><strong>     y_pred_gbt = gbt_inst.predict(X_train_set)</strong><br/><strong>     preds_df = pd.DataFrame(columns = ['bag', 'gbt'])</strong><br/><br/><strong>     preds_df['bag'] = y_pred_bag</strong><br/><strong>     preds_df['gbt'] = y_pred_gbt</strong><br/> <br/><strong>     return preds_df.values</strong><br/><br/><strong>def predict_from_X_set(X_train_set):</strong><br/><strong>    return final_etr.predict(handle_X_set(X_train_set))</strong> </pre>
<ol start="17">
<li>Predict using <kbd>X_test_prin</kbd>, the <span><kbd>X</kbd> set that was</span> <span>left out, using the useful <kbd>predict_from_X_set</kbd> </span><span>function</span><span> </span><span>we just created:</span></li>
</ol>
<pre style="padding-left: 60px"><strong>y_pred = predict_from_X_set(X_test_prin)</strong></pre>
<ol start="18">
<li class="mce-root">Measure the performance of the model:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>from sklearn.metrics import r2_score, mean_absolute_error</strong><br/><br/><strong>print "R-squared",r2_score(y_test_prin, y_pred)</strong><br/><strong>print "MAE : ",mean_absolute_error(y_test_prin, y_pred)</strong><br/><strong>print "MAPE : ",(np.abs(y_test_prin- y_pred)/y_test_prin).mean()</strong><br/><br/><strong>R-squared 0.844114615094</strong><br/><strong>MAE : 0.298422222752</strong><br/><strong>MAPE : 0.173901911714</strong></pre>
<p>What now? The R-squared metric improved slightly, and we worked very hard for that slight improvement. What we could do next is write more robust, production-like code for the stacker that makes it easy to place a lot of estimators that are not correlated within the stacker.</p>
<p>Additionally, we could do feature engineering—improving the columns of the data using math and/or domain knowledge of the California housing industry. You can also try different algorithms for different inputs. Two columns, latitude and longitude, are well suited for random forests and other inputs could be well-modeled with a linear algorithm.</p>
<p>Thirdly, we could explore different algorithms on the dataset. For this dataset we focused on complex, high-variance algorithms. We could try simpler high-bias algorithms. These alternative algorithms could help the stacking aggregator we used at the end.</p>
<p>Finally, in regards to the stacker, you could rotate the <kbd>X_stacker</kbd> set through cross-validation to make the most of the training set.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    </body></html>