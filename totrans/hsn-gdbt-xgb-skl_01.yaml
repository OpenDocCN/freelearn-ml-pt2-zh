- en: 'Section 1: Bagging and Boosting'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An XGBoost model using scikit-learn defaults opens the book after preprocessing
    data with pandas and building standard regression and classification models. The
    practical theory behind XGBoost is explored by advancing through decision trees
    (XGBoost base learners), random forests (bagging), and gradient boosting to compare
    scores and fine-tune ensemble and tree-based hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'This section comprises the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 1*](B15551_01_Final_NM_ePUB.xhtml#_idTextAnchor022)*, Machine Learning
    Landscape*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 2*](B15551_02_Final_NM_ePUB.xhtml#_idTextAnchor047)*, Decision Trees
    in Depth*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 3*](B15551_03_Final_NM_ePUB.xhtml#_idTextAnchor070)*, Bagging with
    Random Forests*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B15551_04_Final_NM_ePUB.xhtml#_idTextAnchor093)*, From Gradient
    Boosting to XGBoost*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
