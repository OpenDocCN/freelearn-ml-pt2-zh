["```py\n> sms_raw <- read.csv(\"sms_spam.csv\", stringsAsFactors = FALSE)\n\n```", "```py\n> str(sms_raw)\n'data.frame':   5559 obs. of  2 variables:\n $ type: chr  \"ham\" \"ham\" \"ham\" \"spam\" ...\n $ text: chr  \"Hope you are having a good week. Just checking in\" \"K..give back my thanks.\" \"Am also doing in cbe only. But have to pay.\" \"complimentary 4 STAR Ibiza Holiday or Â£10,000 cash needs your URGENT collection. 09066364349 NOW from Landline not to lose out\"| __truncated__ ...\n\n```", "```py\n> sms_raw$type <- factor(sms_raw$type)\n\n```", "```py\n> str(sms_raw$type)\n Factor w/ 2 levels \"ham\",\"spam\": 1 1 1 2 2 1 1 1 2 1 ...\n> table(sms_raw$type)\n ham spam\n4812  747\n\n```", "```py\n> sms_corpus <- VCorpus(VectorSource(sms_raw$text))\n\n```", "```py\n> print(sms_corpus)\n<<VCorpus>>\nMetadata:  corpus specific: 0, document level (indexed): 0\nContent:  documents: 5559\n\n```", "```py\n> inspect(sms_corpus[1:2])\n<<VCorpus>>\nMetadata:  corpus specific: 0, document level (indexed): 0\nContent:  documents: 2\n\n[[1]]\n<<PlainTextDocument>>\nMetadata:  7\nContent:  chars: 49\n\n[[2]]\n<<PlainTextDocument>>\nMetadata:  7\nContent:  chars: 23\n\n```", "```py\n> as.character(sms_corpus[[1]])\n[1] \"Hope you are having a good week. Just checking in\"\n\n```", "```py\n> lapply(sms_corpus[1:2], as.character)\n$`1`\n[1] \"Hope you are having a good week. Just checking in\"\n\n$`2`\n[1] \"K..give back my thanks.\"\n\n```", "```py\n> sms_corpus_clean <- tm_map(sms_corpus,\n content_transformer(tolower))\n\n```", "```py\n> as.character(sms_corpus[[1]])\n[1] \"Hope you are having a good week. Just checking in\"\n> as.character(sms_corpus_clean[[1]])\n[1] \"hope you are having a good week. just checking in\"\n\n```", "```py\n> sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers)\n\n```", "```py\n> sms_corpus_clean <- tm_map(sms_corpus_clean,\n removeWords, stopwords())\n\n```", "```py\n> sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation)\n\n```", "```py\n> removePunctuation(\"hello...world\")\n[1] \"helloworld\"\n\n```", "```py\n> replacePunctuation <- function(x) {\n gsub(\"[[:punct:]]+\", \" \", x)\n}\n\n```", "```py\n> library(SnowballC)\n> wordStem(c(\"learn\", \"learned\", \"learning\", \"learns\"))\n[1] \"learn\"   \"learn\"   \"learn\"   \"learn\"\n\n```", "```py\n> sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)\n\n```", "```py\n> sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace)\n\n```", "```py\n> as.character(sms_corpus[1:3])\n\n[[1]] Hope you are having a good week. Just checking in\n\n[[2]] K..give back my thanks.\n\n[[3]] Am also doing in cbe only. But have to pay.\n\n```", "```py\n> as.character(sms_corpus_clean[1:3])\n\n[[1]] hope good week just check\n\n[[2]] kgive back thank\n\n[[3]] also cbe pay\n\n```", "```py\n> sms_dtm <- DocumentTermMatrix(sms_corpus_clean)\n\n```", "```py\n> sms_dtm2 <- DocumentTermMatrix(sms_corpus, control = list(\n tolower = TRUE,\n removeNumbers = TRUE,\n stopwords = TRUE,\n removePunctuation = TRUE,\n stemming = TRUE\n ))\n\n```", "```py\n> sms_dtm\n<<DocumentTermMatrix (documents: 5559, terms: 6518)>>\nNon-/sparse entries: 42113/36191449\nSparsity           : 100%\nMaximal term length: 40\nWeighting          : term frequency (tf)\n\n> sms_dtm2\n<<DocumentTermMatrix (documents: 5559, terms: 6909)>>\nNon-/sparse entries: 43192/38363939\nSparsity           : 100%\nMaximal term length: 40\nWeighting          : term frequency (tf)\n\n```", "```py\nstopwords = function(x) { removeWords(x, stopwords()) }\n\n```", "```py\n> sms_dtm_train <- sms_dtm[1:4169, ]\n> sms_dtm_test  <- sms_dtm[4170:5559, ]\n\n```", "```py\n> sms_train_labels <- sms_raw[1:4169, ]$type\n> sms_test_labels  <- sms_raw[4170:5559, ]$type\n\n```", "```py\n> prop.table(table(sms_train_labels))\n ham      spam\n0.8647158 0.1352842\n> prop.table(table(sms_test_labels))\n ham      spam\n0.8683453 0.1316547\n\n```", "```py\n> wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE)\n\n```", "```py\n> spam <- subset(sms_raw, type == \"spam\")\n\n```", "```py\n> ham <- subset(sms_raw, type == \"ham\")\n\n```", "```py\n> wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))\n> wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))\n\n```", "```py\n> findFreqTerms(sms_dtm_train, 5)\n\n```", "```py\n> sms_freq_words <- findFreqTerms(sms_dtm_train, 5)\n\n```", "```py\n> str(sms_freq_words)\n chr [1:1136] \"abiola\" \"abl\" \"abt\" \"accept\" \"access\" \"account\" \"across\" \"act\" \"activ\" ...\n\n```", "```py\n> sms_dtm_freq_train<- sms_dtm_train[ , sms_freq_words]\n> sms_dtm_freq_test <- sms_dtm_test[ , sms_freq_words]\n\n```", "```py\n> convert_counts <- function(x) {\n x <- ifelse(x > 0, \"Yes\", \"No\")\n }\n\n```", "```py\n> sms_train <- apply(sms_dtm_freq_train, MARGIN = 2,\n convert_counts)\n> sms_test <- apply(sms_dtm_freq_test, MARGIN = 2,\n convert_counts)\n\n```", "```py\n> sms_classifier <- naiveBayes(sms_train, sms_train_labels)\n\n```", "```py\n> sms_test_pred <- predict(sms_classifier, sms_test)\n\n```", "```py\n> library(gmodels)\n> CrossTable(sms_test_pred, sms_test_labels,\n prop.chisq = FALSE, prop.t = FALSE,\n dnn = c('predicted', 'actual'))\n\n```", "```py\n> sms_classifier2 <- naiveBayes(sms_train, sms_train_labels,\n laplace = 1)\n\n```", "```py\n> sms_test_pred2 <- predict(sms_classifier2, sms_test)\n\n```", "```py\n> CrossTable(sms_test_pred2, sms_test_labels,\n prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,\n dnn = c('predicted', 'actual'))\n\n```"]