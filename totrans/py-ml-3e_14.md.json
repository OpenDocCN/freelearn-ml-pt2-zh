["```py\n## TF v1.x style\n>>> g = tf.Graph()\n>>> with g.as_default():\n...     a = tf.constant(1, name='a')\n...\t     b = tf.constant(2, name='b')\n...\t     c = tf.constant(3, name='c')\n...\t     z = 2*(a-b) + c \n```", "```py\nz, as follows:\n```", "```py\n## TF v1.x style\n>>> with tf.compat.v1.Session(graph=g) as sess:\n...     print(Result: z =', sess.run(z))\nResult: z = 1 \n```", "```py\n## TF v2 style\n>>> a = tf.constant(1, name='a')\n>>> b = tf.constant(2, name='b')\n>>> c = tf.constant(3, name='c')\n>>> z = 2*(a - b) + c\n>>> tf.print('Result: z= ', z)\nResult: z = 1 \n```", "```py\n## TF-v1.x style\n>>> g = tf.Graph()\n>>> with g.as_default():\n...     a = tf.compat.v1.placeholder(shape=None,\n...                                  dtype=tf.int32, name='tf_a')\n...     b = tf.compat.v1.placeholder(shape=None,\n...                                  dtype=tf.int32, name='tf_b')\n...     c = tf.compat.v1.placeholder(shape=None,\n...                                  dtype=tf.int32, name='tf_c')\n...     z = 2*(a-b) + c\n>>> with tf.compat.v1.Session(graph=g) as sess:\n...     feed_dict={a:1, b:2, c:3}\n...     print('Result: z =', sess.run(z, feed_dict=feed_dict))\nResult: z = 1 \n```", "```py\n## TF-v2 style\n>>> def compute_z(a, b, c):\n...     r1 = tf.subtract(a, b)\n...     r2 = tf.multiply(2, r1)\n...     z = tf.add(r2, c)\n...     return z \n```", "```py\n>>> tf.print('Scalar Inputs:', compute_z(1, 2, 3))\nScalar Inputs: 1\n>>> tf.print('Rank 1 Inputs:', compute_z([1], [2], [3]))\nRank 1 Inputs: [1]\n>>> tf.print('Rank 2 Inputs:', compute_z([[1]], [[2]], [[3]]))\nRank 2 Inputs: [[1]] \n```", "```py\n>>> @tf.function\n... def compute_z(a, b, c):\n...     r1 = tf.subtract(a, b)\n...     r2 = tf.multiply(2, r1)\n...     z = tf.add(r2, c)\n...     return z \n```", "```py\n>>> tf.print('Scalar Inputs:', compute_z(1, 2, 3))\n>>> tf.print('Rank 1 Inputs:', compute_z([1], [2], [3]))\n>>> tf.print('Rank 2 Inputs:', compute_z([[1]], [[2]], [[3]])) \n```", "```py\n>>> @tf.function(input_signature=(tf.TensorSpec(shape=[None],\n...                                             dtype=tf.int32),\n...                               tf.TensorSpec(shape=[None],\n...                                             dtype=tf.int32),\n...                               tf.TensorSpec(shape=[None],\n...                                             dtype=tf.int32),))\n... def compute_z(a, b, c):\n...     r1 = tf.subtract(a, b)\n...     r2 = tf.multiply(2, r1)\n...     z = tf.add(r2, c)\n...     return z \n```", "```py\n>>> tf.print('Rank 1 Inputs:', compute_z([1], [2], [3]))\n>>> tf.print('Rank 1 Inputs:', compute_z([1, 2], [2, 4], [3, 6])) \n```", "```py\n>>> tf.print('Rank 0 Inputs:', compute_z(1, 2, 3)\n### will result in error\n>>> tf.print('Rank 2 Inputs:', compute_z([[1], [2]],\n...                                      [[2], [4]],\n...                                      [[3], [6]]))\n### will result in error \n```", "```py\n>>> a = tf.Variable(initial_value=3.14, name='var_a')\n>>> print(a)\n<tf.Variable 'var_a:0' shape=() dtype=float32, numpy=3.14>\n>>> b = tf.Variable(initial_value=[1, 2, 3], name='var_b')\n>>> print(b)\n<tf.Variable 'var_b:0' shape=(3,) dtype=int32, numpy=array([1, 2, 3], dtype=int32)>\n>>> c = tf.Variable(initial_value=[True, False], dtype=tf.bool)\n>>> print(c)\n<tf.Variable 'Variable:0' shape=(2,) dtype=bool, numpy=array([ True, False])>\n>>> d = tf.Variable(initial_value=['abc'], dtype=tf.string)\n>>> print(d)\n<tf.Variable 'Variable:0' shape=(1,) dtype=string, numpy=array([b'abc'], dtype=object)> \n```", "```py\n>>> w = tf.Variable([1, 2, 3], trainable=False)\n>>> print(w.trainable)\nFalse \n```", "```py\n>>> print(w.assign([3, 1, 4], read_value=True))\n<tf.Variable 'UnreadVariable' shape=(3,) dtype=int32, numpy=array(\n[3, 1, 4], dtype=int32)>\n>>> w.assign_add([2, -1, 2], read_value=False)\n>>> print(w.value())\ntf.Tensor([5 0 6], shape=(3,), dtype=int32) \n```", "```py\n>>> tf.random.set_seed(1)\n>>> init = tf.keras.initializers.GlorotNormal()\n>>> tf.print(init(shape=(3,)))\n[-0.722795904 1.01456821 0.251808226] \n```", "```py\n>>> v = tf.Variable(init(shape=(2, 3)))\n>>> tf.print(v)\n[[0.28982234 -0.782292783 -0.0453658961]\n [0.960991383 -0.120003454 0.708528221]] \n```", "```py\n>>> class MyModule(tf.Module):\n...     def __init__(self):\n...         init = tf.keras.initializers.GlorotNormal()\n...         self.w1 = tf.Variable(init(shape=(2, 3)),\n...                               trainable=True)\n...         self.w2 = tf.Variable(init(shape=(1, 2)),\n...                               trainable=False)\n>>> m = MyModule()\n>>> print('All module variables:', [v.shape for v in m.variables])\nAll module variables: [TensorShape([2, 3]), TensorShape([1, 2])]\n>>> print('Trainable variable:', [v.shape for v in\n...                               m.trainable_variables])\nTrainable variable: [TensorShape([2, 3])] \n```", "```py\n>>> @tf.function\n... def f(x):\n...     w = tf.Variable([1, 2, 3])\n>>> f([1])\nValueError: tf.function-decorated function tried to create variables on non-first call. \n```", "```py\n>>> w = tf.Variable(tf.random.uniform((3, 3)))\n>>> @tf.function\n... def compute_z(x):\n...     return tf.matmul(w, x)\n>>> x = tf.constant([[1], [2], [3]], dtype=tf.float32)\n>>> tf.print(compute_z(x)) \n```", "```py\n>>> w = tf.Variable(1.0)\n>>> b = tf.Variable(0.5)\n>>> print(w.trainable, b.trainable)\nTrue True\n>>> x = tf.convert_to_tensor([1.4])\n>>> y = tf.convert_to_tensor([2.1])\n>>> with tf.GradientTape() as tape:\n...     z = tf.add(tf.multiply(w, x), b)\n...     loss = tf.reduce_sum(tf.square(y – z))\n>>> dloss_dw = tape.gradient(loss, w)\n>>> tf.print('dL/dw:', dloss_dw)\ndL/dw: -0.559999764 \n```", "```py\n# verifying the computed gradient\n>>> tf.print(2*x*(w*x+b-y))\n[-0.559999764] \n```", "```py\n>>> with tf.GradientTape() as tape:\n...     tape.watch(x)\n...     z = tf.add(tf.multiply(w, x), b)\n...     loss = tf.reduce_sum(tf.square(y - z))\n>>> dloss_dx = tape.gradient(loss, x)\n>>> tf.print('dL/dx:', dloss_dx)\ndL/dx: [-0.399999857] \n```", "```py\n>>> with tf.GradientTape(persistent=True) as tape:\n...     z = tf.add(tf.multiply(w, x), b)\n...     loss = tf.reduce_sum(tf.square(y – z))\n>>> dloss_dw = tape.gradient(loss, w)\n>>> tf.print('dL/dw:', dloss_dw)\ndL/dw: -0.559999764\n>>> dloss_db = tape.gradient(loss, b)\n>>> tf.print('dL/db:', dloss_db)\ndL/db: -0.399999857 \n```", "```py\n>>> optimizer = tf.keras.optimizers.SGD()\n>>> optimizer.apply_gradients(zip([dloss_dw, dloss_db], [w, b]))\n>>> tf.print('Updated w:', w)\nUpdated w: 1.0056\n>>> tf.print('Updated bias:', b)\nUpdated bias: 0.504 \n```", "```py\n>>> model = tf.keras.Sequential()\n>>> model.add(tf.keras.layers.Dense(units=16, activation='relu'))\n>>> model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n>>> ## late variable creation\n>>> model.build(input_shape=(None, 4))\n>>> model.summary()\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                multiple                  80        \n_________________________________________________________________\ndense_1 (Dense)              multiple                  544       \n=================================================================\nTotal params: 624\nTrainable params: 624\nNon-trainable params: 0\n_________________________________________________________________ \n```", "```py\n>>> ## printing variables of the model\n>>> for v in model.variables:\n...     print('{:20s}'.format(v.name), v.trainable, v.shape)\ndense/kernel:0       True (4, 16)\ndense/bias:0         True (16,)\ndense_1/kernel:0     True (16, 32)\ndense_1/bias:0       True (32,) \n```", "```py\n>>> model = tf.keras.Sequential()\n>>> model.add(\n...     tf.keras.layers.Dense(\n...         units=16,\n...         activation=tf.keras.activations.relu,\n...         kernel_initializer= \\\n...             tf.keras.initializers.glorot_uniform(),\n...         bias_initializer=tf.keras.initializers.Constant(2.0)\n...     ))\n>>> model.add(\n...     tf.keras.layers.Dense(\n...         units=32,\n...         activation=tf.keras.activations.sigmoid,\n...         kernel_regularizer=tf.keras.regularizers.l1\n...     )) \n```", "```py\n>>> model.compile(\n...     optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n...     loss=tf.keras.losses.BinaryCrossentropy(),\n...     metrics=[tf.keras.metrics.Accuracy(),\n...              tf.keras.metrics.Precision(),\n...              tf.keras.metrics.Recall(),]) \n```", "```py\n>>> import tensorflow as tf\n>>> import numpy as np\n>>> import matplotlib.pyplot as plt\n>>> tf.random.set_seed(1)\n>>> np.random.seed(1)\n>>> x = np.random.uniform(low=-1, high=1, size=(200, 2))\n>>> y = np.ones(len(x))\n>>> y[x[:, 0] * x[:, 1]<0] = 0\n>>> x_train = x[:100, :]\n>>> y_train = y[:100]\n>>> x_valid = x[100:, :]\n>>> y_valid = y[100:]\n>>> fig = plt.figure(figsize=(6, 6))\n>>> plt.plot(x[y==0, 0],\n...          x[y==0, 1], 'o', alpha=0.75, markersize=10)\n>>> plt.plot(x[y==1, 0],\n...          x[y==1, 1], '<', alpha=0.75, markersize=10)\n>>> plt.xlabel(r'$x_1$', size=15)\n>>> plt.ylabel(r'$x_2$', size=15)\n>>> plt.show() \n```", "```py\n>>> model = tf.keras.Sequential()\n>>> model.add(tf.keras.layers.Dense(units=1,\n...                                 input_shape=(2,),\n...                                 activation='sigmoid'))\n>>> model.summary()\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 1)                 3         \n=================================================================\nTotal params: 3\nTrainable params: 3\nNon-trainable params: 0\n_________________________________________________________________ \n```", "```py\n>>> model.compile(optimizer=tf.keras.optimizers.SGD(),\n...               loss=tf.keras.losses.BinaryCrossentropy(),\n...               metrics=[tf.keras.metrics.BinaryAccuracy()])\n>>> hist = model.fit(x_train, y_train,\n...                  validation_data=(x_valid, y_valid),\n...                  epochs=200, batch_size=2, verbose=0) \n```", "```py\nconda install mlxtend -c conda-forge\npip install mlxtend \n```", "```py\n>>> from mlxtend.plotting import plot_decision_regions\n>>> history = hist.history\n>>> fig = plt.figure(figsize=(16, 4))\n>>> ax = fig.add_subplot(1, 3, 1)\n>>> plt.plot(history['loss'], lw=4)\n>>> plt.plot(history['val_loss'], lw=4)\n>>> plt.legend(['Train loss', 'Validation loss'], fontsize=15)\n>>> ax.set_xlabel('Epochs', size=15)\n>>> ax = fig.add_subplot(1, 3, 2)\n>>> plt.plot(history['binary_accuracy'], lw=4)\n>>> plt.plot(history['val_binary_accuracy'], lw=4)\n>>> plt.legend(['Train Acc.', 'Validation Acc.'], fontsize=15)\n>>> ax.set_xlabel('Epochs', size=15)\n>>> ax = fig.add_subplot(1, 3, 3)\n>>> plot_decision_regions(X=x_valid, y=y_valid.astype(np.integer),\n...                       clf=model)\n>>> ax.set_xlabel(r'$x_1$', size=15)\n>>> ax.xaxis.set_label_coords(1, -0.025)\n>>> ax.set_ylabel(r'$x_2$', size=15)\n>>> ax.yaxis.set_label_coords(-0.025, 1)\n>>> plt.show() \n```", "```py\n>>> tf.random.set_seed(1)\n>>> model = tf.keras.Sequential()\n>>> model.add(tf.keras.layers.Dense(units=4, input_shape=(2,),\n...                                 activation='relu'))\n>>> model.add(tf.keras.layers.Dense(units=4, activation='relu'))\n>>> model.add(tf.keras.layers.Dense(units=4, activation='relu'))\n>>> model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n>>> model.summary()\nModel: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_11 (Dense)             (None, 4)                 12        \n_________________________________________________________________\ndense_12 (Dense)             (None, 4)                 20        \n_________________________________________________________________\ndense_13 (Dense)             (None, 4)                 20        \n_________________________________________________________________\ndense_14 (Dense)             (None, 1)                 5         \n=================================================================\nTotal params: 57\nTrainable params: 57\nNon-trainable params: 0\n_________________________________________________________________\n>>> ## compile:\n>>> model.compile(optimizer=tf.keras.optimizers.SGD(),\n...               loss=tf.keras.losses.BinaryCrossentropy(),\n...               metrics=[tf.keras.metrics.BinaryAccuracy()])\n>>> ## train:\n>>> hist = model.fit(x_train, y_train,\n...                  validation_data=(x_valid, y_valid),\n...                  epochs=200, batch_size=2, verbose=0) \n```", "```py\n>>> tf.random.set_seed(1)\n>>> ## input layer:\n>>> inputs = tf.keras.Input(shape=(2,))\n>>> ## hidden layers\n>>> h1 = tf.keras.layers.Dense(units=4, activation='relu')(inputs)\n>>> h2 = tf.keras.layers.Dense(units=4, activation='relu')(h1)\n>>> h3 = tf.keras.layers.Dense(units=4, activation='relu')(h2)\n>>> ## output:\n>>> outputs = tf.keras.layers.Dense(units=1, activation='sigmoid')(h3)\n>>> ## construct a model:\n>>> model = tf.keras.Model(inputs=inputs, outputs=outputs)\n>>> model.summary() \n```", "```py\n>>> ## compile:\n>>> model.compile(\n...     optimizer=tf.keras.optimizers.SGD(),\n...     loss=tf.keras.losses.BinaryCrossentropy(),\n...     metrics=[tf.keras.metrics.BinaryAccuracy()])\n>>> ## train:\n>>> hist = model.fit(\n...     x_train, y_train,\n...     validation_data=(x_valid, y_valid),\n...     epochs=200, batch_size=2, verbose=0) \n```", "```py\n>>> class MyModel(tf.keras.Model):\n...     def __init__(self):\n...         super(MyModel, self).__init__()\n...         self.hidden_1 = tf.keras.layers.Dense(\n...             units=4, activation='relu')\n...         self.hidden_2 = tf.keras.layers.Dense(\n...             units=4, activation='relu')\n...         self.hidden_3 = tf.keras.layers.Dense(\n...             units=4, activation='relu')\n...         self.output_layer = tf.keras.layers.Dense(\n...             units=1, activation='sigmoid')\n...         \n...     def call(self, inputs):\n...         h = self.hidden_1(inputs)\n...         h = self.hidden_2(h)\n...         h = self.hidden_3(h)\n...         return self.output_layer(h) \n```", "```py\n>>> tf.random.set_seed(1)\n>>> model = MyModel()\n>>> model.build(input_shape=(None, 2))\n>>> model.summary()\n>>> ## compile:\n>>> model.compile(optimizer=tf.keras.optimizers.SGD(),\n...               loss=tf.keras.losses.BinaryCrossentropy(),\n...               metrics=[tf.keras.metrics.BinaryAccuracy()])\n>>> ## train:\n>>> hist = model.fit(x_train, y_train,\n...                  validation_data=(x_valid, y_valid),\n...                  epochs=200, batch_size=2, verbose=0) \n```", "```py\n>>> class NoisyLinear(tf.keras.layers.Layer):\n...     def __init__(self, output_dim, noise_stddev=0.1, **kwargs):\n...         self.output_dim = output_dim\n...         self.noise_stddev = noise_stddev\n...         super(NoisyLinear, self).__init__(**kwargs)\n...\n...     def build(self, input_shape):\n...         self.w = self.add_weight(name='weights',\n...                                  shape=(input_shape[1],\n...                                         self.output_dim),\n...                                  initializer='random_normal',\n...                                  trainable=True)\n...         \n...         self.b = self.add_weight(shape=(self.output_dim,),\n...                                  initializer='zeros',\n...                                  trainable=True)\n...\n...     def call(self, inputs, training=False):\n...         if training:\n...             batch = tf.shape(inputs)[0]\n...             dim = tf.shape(inputs)[1]\n...             noise = tf.random.normal(shape=(batch, dim),\n...                                      mean=0.0,\n...                                      stddev=self.noise_stddev)\n...\n...             noisy_inputs = tf.add(inputs, noise)\n...         else:\n...             noisy_inputs = inputs\n...         z = tf.matmul(noisy_inputs, self.w) + self.b\n...         return tf.keras.activations.relu(z)\n...     \n...     def get_config(self):\n...         config = super(NoisyLinear, self).get_config()\n...         config.update({'output_dim': self.output_dim,\n...                        'noise_stddev': self.noise_stddev})\n...         return config \n, was to be generated and added to the input during training only and not used for inference or evaluation.\n```", "```py\n>>> tf.random.set_seed(1)\n>>> noisy_layer = NoisyLinear(4)\n>>> noisy_layer.build(input_shape=(None, 4))\n>>> x = tf.zeros(shape=(1, 4))\n>>> tf.print(noisy_layer(x, training=True))\n[[0 0.00821428 0 0]]\n>>> ## re-building from config:\n>>> config = noisy_layer.get_config()\n>>> new_layer = NoisyLinear.from_config(config)\n>>> tf.print(new_layer(x, training=True))\n[[0 0.0108502861 0 0]] \nNoisyLinear layer added random noise to the input tensor.\n```", "```py\n>>> tf.random.set_seed(1)\n>>> model = tf.keras.Sequential([\n...     NoisyLinear(4, noise_stddev=0.1),\n...     tf.keras.layers.Dense(units=4, activation='relu'),\n...     tf.keras.layers.Dense(units=4, activation='relu'),\n...     tf.keras.layers.Dense(units=1, activation='sigmoid')])\n>>> model.build(input_shape=(None, 2))\n>>> model.summary()\n>>> ## compile:\n>>> model.compile(optimizer=tf.keras.optimizers.SGD(),\n...               loss=tf.keras.losses.BinaryCrossentropy(),\n...               metrics=[tf.keras.metrics.BinaryAccuracy()])\n>>> ## train:\n>>> hist = model.fit(x_train, y_train,\n...                  validation_data=(x_valid, y_valid),\n...                  epochs=200, batch_size=2,\n...                  verbose=0)\n>>> ## Plotting\n>>> history = hist.history\n>>> fig = plt.figure(figsize=(16, 4))\n>>> ax = fig.add_subplot(1, 3, 1)\n>>> plt.plot(history['loss'], lw=4)\n>>> plt.plot(history['val_loss'], lw=4)\n>>> plt.legend(['Train loss', 'Validation loss'], fontsize=15)\n>>> ax.set_xlabel('Epochs', size=15)\n>>> ax = fig.add_subplot(1, 3, 2)\n>>> plt.plot(history['binary_accuracy'], lw=4)\n>>> plt.plot(history['val_binary_accuracy'], lw=4)\n>>> plt.legend(['Train Acc.', 'Validation Acc.'], fontsize=15)\n>>> ax.set_xlabel('Epochs', size=15)\n>>> ax = fig.add_subplot(1, 3, 3)\n>>> plot_decision_regions(X=x_valid, y=y_valid.astype(np.integer),\n...                       clf=model)\n>>> ax.set_xlabel(r'$x_1$', size=15)\n>>> ax.xaxis.set_label_coords(1, -0.025)\n>>> ax.set_ylabel(r'$x_2$', size=15)\n>>> ax.yaxis.set_label_coords(-0.025, 1)\n>>> plt.show() \n```", "```py\n>>> import pandas as pd\n>>> dataset_path = tf.keras.utils.get_file(\n...     \"auto-mpg.data\",\n...     (\"http://archive.ics.uci.edu/ml/machine-learning\"\n...      \"-databases/auto-mpg/auto-mpg.data\"))\n>>> column_names = [\n...     'MPG', 'Cylinders', 'Displacement',\n...     'Horsepower', 'Weight', 'Acceleration',\n...     'ModelYear', 'Origin']\n>>> df = pd.read_csv(dataset_path, names=column_names,\n...                  na_values = '?', comment='\\t',\n...                  sep=' ', skipinitialspace=True)\n>>> ## drop the NA rows\n>>> df = df.dropna()\n>>> df = df.reset_index(drop=True)\n>>> ## train/test splits:\n>>> import sklearn\n>>> import sklearn.model_selection\n>>> df_train, df_test = sklearn.model_selection.train_test_split(\n...    df, train_size=0.8)\n>>> train_stats = df_train.describe().transpose()\n>>> numeric_column_names = [\n...     'Cylinders', 'Displacement',\n...     'Horsepower', 'Weight',\n...     'Acceleration']\n>>> df_train_norm, df_test_norm = df_train.copy(), df_test.copy()\n>>> for col_name in numeric_column_names:\n...     mean = train_stats.loc[col_name, 'mean']\n...     std  = train_stats.loc[col_name, 'std']\n...     df_train_norm.loc[:, col_name] = (\n...         df_train_norm.loc[:, col_name] - mean)/std\n...     df_test_norm.loc[:, col_name] = (\n...         df_test_norm.loc[:, col_name] - mean)/std\n>>> df_train_norm.tail() \n```", "```py\nfloat. These columns will constitute the continuous features. In the following code, we will use TensorFlow's feature_column function to transform these continuous features into the feature column data structure that TensorFlow Estimators can work with:\n```", "```py\n>>> numeric_features = []\n>>> for col_name in numeric_column_names:\n...     numeric_features.append(\n...         tf.feature_column.numeric_column(key=col_name)) \n```", "```py\n>>> feature_year = tf.feature_column.numeric_column(key='ModelYear')\n>>> bucketized_features = []\n>>> bucketized_features.append(\n...     tf.feature_column.bucketized_column(\n...         source_column=feature_year,\n...         boundaries=[73, 76, 79])) \n```", "```py\n>>> feature_origin = tf.feature_column.categorical_column_with_vocabulary_list(\n...     key='Origin',\n...     vocabulary_list=[1, 2, 3]) \n```", "```py\n>>> categorical_indicator_features = []\n>>> categorical_indicator_features.append(\n...     tf.feature_column.indicator_column(feature_origin)) \n```", "```py\n>>> def train_input_fn(df_train, batch_size=8):\n...     df = df_train.copy()\n...     train_x, train_y = df, df.pop('MPG')\n...     dataset = tf.data.Dataset.from_tensor_slices(\n...         (dict(train_x), train_y))\n... \n...     # shuffle, repeat, and batch the examples.\n...     return dataset.shuffle(1000).repeat().batch(batch_size) \n```", "```py\n>>> ds = train_input_fn(df_train_norm)\n>>> batch = next(iter(ds))\n>>> print('Keys:', batch[0].keys())\nKeys: dict_keys(['Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'ModelYear', 'Origin'])\n>>> print('Batch Model Years:', batch[0]['ModelYear'])\nBatch Model Years: tf.Tensor([74 71 81 72 82 81 70 74], shape=(8,), dtype=int32) \n```", "```py\n>>> def eval_input_fn(df_test, batch_size=8):\n...     df = df_test.copy()\n...     test_x, test_y = df, df.pop('MPG')\n...     dataset = tf.data.Dataset.from_tensor_slices(\n...         (dict(test_x), test_y))\n...     return dataset.batch(batch_size) \n```", "```py\n>>> all_feature_columns = (\n...     numeric_features +\n...     bucketized_features +\n...     categorical_indicator_features) \n```", "```py\n>>> regressor = tf.estimator.DNNRegressor(\n...     feature_columns=all_feature_columns,\n...     hidden_units=[32, 10],\n...     model_dir='models/autompg-dnnregressor/') \n```", "```py\n>>> EPOCHS = 1000\n>>> BATCH_SIZE = 8\n>>> total_steps = EPOCHS * int(np.ceil(len(df_train) / BATCH_SIZE))\n>>> print('Training Steps:', total_steps)\nTraining Steps: 40000\n>>> regressor.train(\n...     input_fn=lambda:train_input_fn(\n...         df_train_norm, batch_size=BATCH_SIZE),\n...     steps=total_steps) \n```", "```py\n>>> reloaded_regressor = tf.estimator.DNNRegressor(\n...     feature_columns=all_feature_columns,\n...     hidden_units=[32, 10],\n...     warm_start_from='models/autompg-dnnregressor/',\n...     model_dir='models/autompg-dnnregressor/') \n```", "```py\n>>> eval_results = reloaded_regressor.evaluate(\n...     input_fn=lambda:eval_input_fn(df_test_norm, batch_size=8))\n>>> print('Average-Loss {:.4f}'.format(\n...       eval_results['average_loss']))\nAverage-Loss 15.1866 \n```", "```py\n>>> pred_res = regressor.predict(\n...     input_fn=lambda: eval_input_fn(\n...         df_test_norm, batch_size=8))\n>>> print(next(iter(pred_res)))\n{'predictions': array([23.747658], dtype=float32)} \n```", "```py\n>>> boosted_tree = tf.estimator.BoostedTreesRegressor(\n...     feature_columns=all_feature_columns,\n...     n_batches_per_layer=20,\n...     n_trees=200)\n>>> boosted_tree.train(\n...     input_fn=lambda:train_input_fn(\n...         df_train_norm, batch_size=BATCH_SIZE))\n>>> eval_results = boosted_tree.evaluate(\n...     input_fn=lambda:eval_input_fn(\n...         df_test_norm, batch_size=8))\n>>> print('Average-Loss {:.4f}'.format(\n...       eval_results['average_loss']))\nAverage-Loss 11.2609 \n```", "```py\n>>> import tensorflow_datasets as tfds\n>>> import tensorflow as tf\n>>> import numpy as np\n>>> BUFFER_SIZE = 10000\n>>> BATCH_SIZE = 64\n>>> NUM_EPOCHS = 20\n>>> steps_per_epoch = np.ceil(60000 / BATCH_SIZE) \n```", "```py\n>>> def preprocess(item):\n...     image = item['image']\n...     label = item['label']\n...     image = tf.image.convert_image_dtype(\n...         image, tf.float32)\n...     image = tf.reshape(image, (-1,))\n...\n...     return {'image-pixels':image}, label[..., tf.newaxis] \n```", "```py\n>>> ## Step 1: Define the input functions\n>>> def train_input_fn():\n...     datasets = tfds.load(name='mnist')\n...     mnist_train = datasets['train']\n...\n...     dataset = mnist_train.map(preprocess)\n...     dataset = dataset.shuffle(BUFFER_SIZE)\n...     dataset = dataset.batch(BATCH_SIZE)\n...     return dataset.repeat()\n>>> def eval_input_fn():\n...     datasets = tfds.load(name='mnist')\n...     mnist_test = datasets['test']\n...     dataset = mnist_test.map(preprocess).batch(BATCH_SIZE)\n...     return dataset \n```", "```py\n>>> ## Step 2: feature columns\n>>> image_feature_column = tf.feature_column.numeric_column(\n...     key='image-pixels', shape=(28*28)) \n```", "```py\n>>> ## Step 3: instantiate the estimator\n>>> dnn_classifier = tf.estimator.DNNClassifier(\n...     feature_columns=[image_feature_column],\n...     hidden_units=[32, 16],\n...     n_classes=10,\n...     model_dir='models/mnist-dnn/') \n```", "```py\n>>> ## Step 4: train and evaluate\n>>> dnn_classifier.train(\n...     input_fn=train_input_fn,\n...     steps=NUM_EPOCHS * steps_per_epoch)\n>>> eval_result = dnn_classifier.evaluate(\n...     input_fn=eval_input_fn)\n>>> print(eval_result)\n{'accuracy': 0.8957, 'average_loss': 0.3876346, 'loss': 0.38815108, 'global_step': 18760} \n```", "```py\n>>> tf.random.set_seed(1)\n>>> np.random.seed(1)\n>>> ## Create the data\n>>> x = np.random.uniform(low=-1, high=1, size=(200, 2))\n>>> y = np.ones(len(x))\n>>> y[x[:, 0] * x[:, 1]<0] = 0\n>>> x_train = x[:100, :]\n>>> y_train = y[:100]\n>>> x_valid = x[100:, :]\n>>> y_valid = y[100:] \n```", "```py\n>>> model = tf.keras.Sequential([\n...     tf.keras.layers.Input(shape=(2,), name='input-features'),\n...     tf.keras.layers.Dense(units=4, activation='relu'),\n...     tf.keras.layers.Dense(units=4, activation='relu'),\n...     tf.keras.layers.Dense(units=4, activation='relu'),\n...     tf.keras.layers.Dense(1, activation='sigmoid')\n... ]) \n```", "```py\n>>> ## Step 1: Define the input functions\n>>> def train_input_fn(x_train, y_train, batch_size=8):\n...     dataset = tf.data.Dataset.from_tensor_slices(\n...         ({'input-features':x_train}, y_train.reshape(-1, 1)))\n...\n...     # shuffle, repeat, and batch the examples.\n...     return dataset.shuffle(100).repeat().batch(batch_size)\n>>> def eval_input_fn(x_test, y_test=None, batch_size=8):\n...     if y_test is None:\n...         dataset = tf.data.Dataset.from_tensor_slices(\n...             {'input-features':x_test})\n...     else:\n...         dataset = tf.data.Dataset.from_tensor_slices(\n...             ({'input-features':x_test}, y_test.reshape(-1, 1)))\n...\n...\n...     # shuffle, repeat, and batch the examples.\n...     return dataset.batch(batch_size)\n>>> ## Step 2: Define the feature columns\n>>> features = [\n...     tf.feature_column.numeric_column(\n...         key='input-features:', shape=(2,))\n... ] \n```", "```py\n>>> model.compile(optimizer=tf.keras.optimizers.SGD(),\n...               loss=tf.keras.losses.BinaryCrossentropy(),\n...               metrics=[tf.keras.metrics.BinaryAccuracy()])\n>>> my_estimator = tf.keras.estimator.model_to_estimator(\n...     keras_model=model,\n...     model_dir='models/estimator-for-XOR/') \n```", "```py\n>>> ## Step 4: Use the estimator\n>>> num_epochs = 200\n>>> batch_size = 2\n>>> steps_per_epoch = np.ceil(len(x_train) / batch_size)\n>>> my_estimator.train(\n...     input_fn=lambda: train_input_fn(x_train, y_train, batch_size),\n...     steps=num_epochs * steps_per_epoch)\n>>> my_estimator.evaluate(\n...     input_fn=lambda: eval_input_fn(x_valid, y_valid, batch_size))\n{'binary_accuracy': 0.96, 'loss': 0.081909806, 'global_step': 10000} \n```"]